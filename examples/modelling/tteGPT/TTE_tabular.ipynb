{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Demo Notebook:\n",
    "## Time to Event Transformer For Causal Time Series Modelling \n",
    "\n",
    "Including time and tabular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "env: SQLITE_TMPDIR=/rds/projects/g/gokhalkm-optimal/DataforCharles\n",
      "env: TMPDIR=/rds/projects/g/gokhalkm-optimal/DataforCharles\n",
      "/rds/projects/g/gokhalkm-optimal/DataforCharles\n",
      "/rds/projects/g/gokhalkm-optimal/DataforCharles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "# Perform sqlite operations on disk\n",
    "%env SQLITE_TMPDIR=/rds/projects/g/gokhalkm-optimal/DataforCharles\n",
    "%env TMPDIR=/rds/projects/g/gokhalkm-optimal/DataforCharles\n",
    "!echo $SQLITE_TMPDIR\n",
    "!echo $TMPDIR\n",
    "!echo $USERPROFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/tteGPT\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.TTE.task_heads.causal_tabular import TTETransformerForCausalTimeSeriesModelling\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(device)\n",
    "\n",
    "!pwd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config to be equivalent architecture of kaparthy benchmark, however they are not comparable tasks.\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    block_size: int = 8        # what is the maximum context length for predictions?\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 6\n",
    "    n_embd: int = 384\n",
    "    bias: bool = True\n",
    "    attention_type: str = \"global\"    \n",
    "    dropout: float = 0.0\n",
    "    unk_freq_threshold: float = 0.0\n",
    "    TTELayer = \"Exponential\"                                  # \"Geometric\"\n",
    "    tokens_for_univariate_regression = None\n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "@dataclass\n",
    "class OptConfig:\n",
    "    batch_size: int = 256\n",
    "    eval_interval: int = 1\n",
    "    learning_rate: float = 3e-4\n",
    "    epochs: int = 50\n",
    "    \n",
    "opt = OptConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader on a reduced cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building Polars dataset and saving to /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/polars/\n",
      "INFO:root:Chunking by unique practice ID with no inclusion conditions\n",
      "INFO:root:Creating train/test/val splits using practice_ids\n",
      "INFO:root:Extracting practice_patient_ids for each practice\n",
      "                                             Train: 100%|██████████| 1341/1341 [00:24<00:00, 53.87it/s]\n",
      "                                              Test: 100%|██████████| 75/75 [00:01<00:00, 64.24it/s]\n",
      "                                        Validation: 100%|██████████| 75/75 [00:01<00:00, 52.72it/s]\n",
      "INFO:root:Collating train split into a DL friendly format. Generating over practices IDs\n",
      "  0%|          | 0/1341 [00:00<?, ?it/s]INFO:root:collect time 339.5734267234802\n",
      "INFO:root:collate time 0.001291513442993164\n",
      "INFO:root:save time 2.993227243423462\n",
      "  0%|          | 1/1341 [05:42<127:30:43, 342.57s/it]INFO:root:collect time 276.8205626010895\n",
      "INFO:root:collate time 0.004151582717895508\n",
      "INFO:root:save time 0.6974549293518066\n",
      "  0%|          | 2/1341 [10:20<113:11:08, 304.31s/it]INFO:root:collect time 257.0450646877289\n",
      "INFO:root:collate time 0.003061056137084961\n",
      "INFO:root:save time 0.5738003253936768\n",
      "  0%|          | 3/1341 [14:37<105:10:42, 282.99s/it]INFO:root:collect time 303.2129282951355\n",
      "INFO:root:collate time 0.0031447410583496094\n",
      "INFO:root:save time 1.4584205150604248\n",
      "  0%|          | 4/1341 [22:19<124:19:43, 334.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_3378317/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">301559601.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_3378317/301559601.py'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/homes/g/gaddcz/Projects/CPRD/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">foundational_loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 67 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 68 │   │   # Get the DL friendly representation, either by loading or building from scratch</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 │   │   </span>polars_dataset = PolarsDataset(path_to_db=path_to_db)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 70 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>meta_information = polars_dataset.fit(path=path_to_db + <span style=\"color: #808000; text-decoration-color: #808000\">\"polars/\"</span>, load=load, **   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 │   │   </span>logging.debug(meta_information)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 72 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 │   │   # Create tokenizer, and build based on vocabulary from training set. </span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataset_polars.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">63</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">FileNotFoundError</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 │   │   │   </span>logging.info(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Building Polars dataset and saving to {</span>path<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 63 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.meta_information = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._build_DL_representation(save_path=path, **kwar   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(path + <span style=\"color: #808000; text-decoration-color: #808000\">'meta_information.pickle'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'wb'</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> handle:                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 │   │   │   │   </span>pickle.dump(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.meta_information, handle, protocol=pickle.HIGHEST_PROTO   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 66 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataset_polars.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">176</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_build_DL_representation</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 │   │   │   </span>start = time.time()                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>176 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> chunk_name, lazy_table_frames_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> tqdm(generator, total=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(split_id   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 │   │   │   │   </span>logging.info(<span style=\"color: #808000; text-decoration-color: #808000\">f\"collect time {</span>time.time()-start<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 │   │   │   │   # Merge the lazy polars tables provided by the generator into one lazy p</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/bear-apps/2022a/EL8-ice/software/tqdm/4.64.0-GCCcore-11.3.0/lib/python3.10/site-packages/tq</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">dm/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">std.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1195</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span>time = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._time                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1194 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1195 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> obj <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> iterable:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> obj                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   │   │   # Update and possibly print the progressbar.</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1198 │   │   │   │   # Note: does not call self.update(1) for speed optimisation.</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">collector.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">209</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_lazy_generate_by_distinct</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">206 │   │   │   │   │   │   </span>query += <span style=\"color: #808000; text-decoration-color: #808000\">f\" {</span>conditions[idx_table]<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">207 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">208 │   │   │   │   </span>logging.debug(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Query: {</span>query[:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">120</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(query) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">100</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> query<span style=\"color: #808000; text-decoration-color: #808000\">}...\"</span>)   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>209 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>df = pl.read_database(query=query, connection_uri=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.connection_token)   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(df) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">211 │   │   │   │   │   </span>rows_by_table[<span style=\"color: #808000; text-decoration-color: #808000\">\"lazy_\"</span> + table] = df.lazy()                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/bear-apps/2022a/EL8-ice/software/polars/0.17.12-foss-2022a/lib/python3.10/site-packages/pol</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ars/io/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">database.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">95</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">read_database</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 92 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> engine == <span style=\"color: #808000; text-decoration-color: #808000\">\"connectorx\"</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 95 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _read_sql_connectorx(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 96 │   │   │   </span>query,                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 97 │   │   │   </span>connection_uri,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 │   │   │   </span>partition_on=partition_on,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/bear-apps/2022a/EL8-ice/software/polars/0.17.12-foss-2022a/lib/python3.10/site-packages/pol</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ars/io/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">database.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">222</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_read_sql_connectorx</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"connectorx is not installed. Please run `pip install connectorx&gt;=0.3.1`.\"</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 │   │   </span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">None</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>222 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>tbl = cx.read_sql(                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">223 │   │   </span>conn=connection_uri,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">224 │   │   </span>query=query,                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225 │   │   </span>return_type=<span style=\"color: #808000; text-decoration-color: #808000\">\"arrow2\"</span>,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/bear-apps/2022a/EL8-ice/software/polars/0.17.12-foss-2022a/lib/python3.10/site-packages/con</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">nectorx/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">257</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">read_sql</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">254 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ModuleNotFoundError</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">255 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"You need to install pyarrow first\"</span>)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">256 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>257 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>result = _read_sql(                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258 │   │   │   </span>conn,                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">259 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"arrow\"</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_type <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> {<span style=\"color: #808000; text-decoration-color: #808000\">\"arrow\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"polars\"</span>} <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"arrow2\"</span>,                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 │   │   │   </span>queries=queries,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_3378317/\u001b[0m\u001b[1;33m301559601.py\u001b[0m:\u001b[94m6\u001b[0m in \u001b[92m<module>\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_3378317/301559601.py'\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/rds/homes/g/gaddcz/Projects/CPRD/data/\u001b[0m\u001b[1;33mfoundational_loader.py\u001b[0m:\u001b[94m70\u001b[0m in \u001b[92m__init__\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 67 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 68 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Get the DL friendly representation, either by loading or building from scratch\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   \u001b[0mpolars_dataset = PolarsDataset(path_to_db=path_to_db)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 70 \u001b[2m│   │   \u001b[0mmeta_information = polars_dataset.fit(path=path_to_db + \u001b[33m\"\u001b[0m\u001b[33mpolars/\u001b[0m\u001b[33m\"\u001b[0m, load=load, **   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   │   \u001b[0mlogging.debug(meta_information)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 72 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Create tokenizer, and build based on vocabulary from training set. \u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/\u001b[0m\u001b[1;33mdataset_polars.py\u001b[0m:\u001b[94m63\u001b[0m in \u001b[92mfit\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mFileNotFoundError\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogging.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mBuilding Polars dataset and saving to \u001b[0m\u001b[33m{\u001b[0mpath\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 63 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.meta_information = \u001b[96mself\u001b[0m._build_DL_representation(save_path=path, **kwar   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mopen\u001b[0m(path + \u001b[33m'\u001b[0m\u001b[33mmeta_information.pickle\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33mwb\u001b[0m\u001b[33m'\u001b[0m) \u001b[94mas\u001b[0m handle:                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpickle.dump(\u001b[96mself\u001b[0m.meta_information, handle, protocol=pickle.HIGHEST_PROTO   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/\u001b[0m\u001b[1;33mdataset_polars.py\u001b[0m:\u001b[94m176\u001b[0m in \u001b[92m_build_DL_representation\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   │   \u001b[0mstart = time.time()                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m176 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m chunk_name, lazy_table_frames_dict \u001b[95min\u001b[0m tqdm(generator, total=\u001b[96mlen\u001b[0m(split_id   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlogging.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mcollect time \u001b[0m\u001b[33m{\u001b[0mtime.time()-start\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Merge the lazy polars tables provided by the generator into one lazy p\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/rds/bear-apps/2022a/EL8-ice/software/tqdm/4.64.0-GCCcore-11.3.0/lib/python3.10/site-packages/tq\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mdm/\u001b[0m\u001b[1;33mstd.py\u001b[0m:\u001b[94m1195\u001b[0m in \u001b[92m__iter__\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0mtime = \u001b[96mself\u001b[0m._time                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1194 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1195 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m obj \u001b[95min\u001b[0m iterable:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94myield\u001b[0m obj                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Update and possibly print the progressbar.\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1198 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Note: does not call self.update(1) for speed optimisation.\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/\u001b[0m\u001b[1;33mcollector.py\u001b[0m:\u001b[94m209\u001b[0m in \u001b[92m_lazy_generate_by_distinct\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m206 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mquery += \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m{\u001b[0mconditions[idx_table]\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m207 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m208 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlogging.debug(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mQuery: \u001b[0m\u001b[33m{\u001b[0mquery[:\u001b[94m120\u001b[0m] \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(query) > \u001b[94m100\u001b[0m \u001b[94melse\u001b[0m query\u001b[33m}\u001b[0m\u001b[33m...\u001b[0m\u001b[33m\"\u001b[0m)   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m209 \u001b[2m│   │   │   │   \u001b[0mdf = pl.read_database(query=query, connection_uri=\u001b[96mself\u001b[0m.connection_token)   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(df) > \u001b[94m0\u001b[0m:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m211 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mrows_by_table[\u001b[33m\"\u001b[0m\u001b[33mlazy_\u001b[0m\u001b[33m\"\u001b[0m + table] = df.lazy()                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m212 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/rds/bear-apps/2022a/EL8-ice/software/polars/0.17.12-foss-2022a/lib/python3.10/site-packages/pol\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mars/io/\u001b[0m\u001b[1;33mdatabase.py\u001b[0m:\u001b[94m95\u001b[0m in \u001b[92mread_database\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m engine == \u001b[33m\"\u001b[0m\u001b[33mconnectorx\u001b[0m\u001b[33m\"\u001b[0m:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 95 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _read_sql_connectorx(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   │   \u001b[0mquery,                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│   │   │   \u001b[0mconnection_uri,                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   │   \u001b[0mpartition_on=partition_on,                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/rds/bear-apps/2022a/EL8-ice/software/polars/0.17.12-foss-2022a/lib/python3.10/site-packages/pol\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mars/io/\u001b[0m\u001b[1;33mdatabase.py\u001b[0m:\u001b[94m222\u001b[0m in \u001b[92m_read_sql_connectorx\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mconnectorx is not installed. Please run `pip install connectorx>=0.3.1`.\u001b[0m\u001b[33m\"\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   │   \u001b[0m) \u001b[94mfrom\u001b[0m \u001b[96mNone\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m221 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m222 \u001b[2m│   \u001b[0mtbl = cx.read_sql(                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2m│   │   \u001b[0mconn=connection_uri,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m224 \u001b[0m\u001b[2m│   │   \u001b[0mquery=query,                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_type=\u001b[33m\"\u001b[0m\u001b[33marrow2\u001b[0m\u001b[33m\"\u001b[0m,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/rds/bear-apps/2022a/EL8-ice/software/polars/0.17.12-foss-2022a/lib/python3.10/site-packages/con\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mnectorx/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m257\u001b[0m in \u001b[92mread_sql\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m254 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mModuleNotFoundError\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m255 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mYou need to install pyarrow first\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m256 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m257 \u001b[2m│   │   \u001b[0mresult = _read_sql(                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m258 \u001b[0m\u001b[2m│   │   │   \u001b[0mconn,                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m259 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33marrow\u001b[0m\u001b[33m\"\u001b[0m \u001b[94mif\u001b[0m return_type \u001b[95min\u001b[0m {\u001b[33m\"\u001b[0m\u001b[33marrow\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mpolars\u001b[0m\u001b[33m\"\u001b[0m} \u001b[94melse\u001b[0m \u001b[33m\"\u001b[0m\u001b[33marrow2\u001b[0m\u001b[33m\"\u001b[0m,                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   │   \u001b[0mqueries=queries,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a list of patients which fit a reduced set of criterion\n",
    "# path_to_db = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/archive/Version2/\"\n",
    "path_to_db = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/\"\n",
    "\n",
    "# Build \n",
    "dm = FoundationalDataModule(path_to_db=path_to_db,\n",
    "                            load=False,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            batch_size=opt.batch_size,\n",
    "                            max_seq_length=config.block_size,\n",
    "                            unk_freq_threshold=config.unk_freq_threshold,\n",
    "                            min_workers=10\n",
    "                           )\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "\n",
    "print(f\"{len(dm.train_set)} training patients\")\n",
    "print(f\"{len(dm.val_set)} validation patients\")\n",
    "print(f\"{len(dm.test_set)} test patients\")\n",
    "print(f\"{vocab_size} vocab elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(dm.train_set.tokenizer._itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the frequency of tokens in the extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(vocab_size + 1)\n",
    "display(dm.tokenizer._event_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the measurements, using the fact that the diagnoses are all up upper case. This is needed for automatically setting the configuration below\n",
    "measurements_for_univariate_regression = [record for record in dm.tokenizer._event_counts[\"EVENT\"] if record.upper() != record]\n",
    "\n",
    "display(measurements_for_univariate_regression[:3])\n",
    "# display(dm.encode(measurements_for_univariate_regression))\n",
    "# print(dm.decode([7,4,3,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, m_names = [], []\n",
    "\n",
    "# My development model\n",
    "for tte_layer in [\"Exponential\"]: #, \"Geometric\"]:\n",
    "    \n",
    "    ## Create configuration\n",
    "    config = DemoConfig()\n",
    "    # Specify which TTE layer to use\n",
    "    config.TTELayer = tte_layer    \n",
    "    # list of univariate measurements to model with Normal distribution\n",
    "    config.tokens_for_univariate_regression = dm.encode(measurements_for_univariate_regression)\n",
    "    \n",
    "    models.append(TTETransformerForCausalTimeSeriesModelling(config, vocab_size).to(device))\n",
    "    m_names.append(f\"TTETransformerForCausalTimeSeriesModelling: {tte_layer} TTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curves_train = [[] for _ in models]\n",
    "loss_curves_train_clf = [[] for _ in models]\n",
    "loss_curves_train_tte = [[] for _ in models]\n",
    "loss_curves_train_values = [[] for _ in models]\n",
    "\n",
    "loss_curves_val = [[] for _ in models]\n",
    "loss_curves_val_clf = [[] for _ in models]\n",
    "loss_curves_val_tte = [[] for _ in models]\n",
    "loss_curves_val_values = [[] for _ in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861"
   },
   "outputs": [],
   "source": [
    "for m_idx, (model, m_name) in enumerate(zip(models, m_names)):\n",
    "    \n",
    "    print(f\"Training model `{m_name}`, with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "    best_val, epochs_since_best = np.inf, 0\n",
    "    for epoch in range(opt.epochs):\n",
    "        epoch_loss, epoch_clf_loss, epoch_tte_loss, epoch_values_loss = 0, 0, 0, 0\n",
    "        model.train()\n",
    "        for i, batch in tqdm(enumerate(dm.train_dataloader()), desc=f\"Training epoch {epoch}\", total=len(dm.train_dataloader())):\n",
    "            if i > 500:\n",
    "                break\n",
    "\n",
    "            # evaluate the loss\n",
    "            _, (loss_clf, loss_tte, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                               ages=batch['ages'].to(device), \n",
    "                                                               values=batch['values'].to(device),\n",
    "                                                               attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                               )\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # record\n",
    "            epoch_clf_loss += loss_clf.item()\n",
    "            epoch_tte_loss += loss_tte.item()\n",
    "            epoch_values_loss += loss_values.item()\n",
    "        epoch_loss /= i\n",
    "        epoch_clf_loss /= i\n",
    "        epoch_tte_loss /= i\n",
    "        epoch_values_loss /= i\n",
    "        loss_curves_train[m_idx].append(epoch_loss)\n",
    "        loss_curves_train_clf[m_idx].append(epoch_clf_loss)\n",
    "        loss_curves_train_tte[m_idx].append(epoch_tte_loss)\n",
    "        loss_curves_train_values[m_idx].append(epoch_values_loss)\n",
    "\n",
    "        # evaluate the loss on val set\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            if epoch % opt.eval_interval == 0 or epoch == opt.epochs - 1:\n",
    "                val_loss, val_clf_loss, val_tte_loss, val_values_loss = 0, 0, 0, 0\n",
    "                for j, batch in tqdm(enumerate(dm.val_dataloader()), desc=f\"Validation epoch {epoch}\", total=len(dm.val_dataloader())):\n",
    "                    if j > 50:\n",
    "                        break\n",
    "                    _, (loss_clf, loss_tte, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                                       ages=batch['ages'].to(device),\n",
    "                                                                       values=batch['values'].to(device),\n",
    "                                                                       attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                                       )\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    # record\n",
    "                    val_clf_loss += loss_clf.item()\n",
    "                    val_tte_loss += loss_tte.item()\n",
    "                    val_values_loss += loss_values.item()\n",
    "                val_loss /= j\n",
    "                val_clf_loss /= j\n",
    "                val_tte_loss /= j\n",
    "                val_values_loss /= j\n",
    "                loss_curves_val[m_idx].append(val_loss)\n",
    "                loss_curves_val_clf[m_idx].append(val_clf_loss)\n",
    "                loss_curves_val_tte[m_idx].append(val_tte_loss)\n",
    "                loss_curves_val_values[m_idx].append(val_values_loss)\n",
    "\n",
    "                print(f\"Epoch {epoch}:\\tTrain loss {epoch_loss:.2f}  ({epoch_clf_loss:.2f}, {epoch_tte_loss:.2f}, {epoch_values_loss:.2f}). Val loss {val_loss:.2f} ({val_clf_loss:.2f}, {val_tte_loss:.2f}, {val_values_loss:.2f})\")          \n",
    "                # TODO: Note not fully accurate as last batch is likely not the same size, will be fixed with lightning\n",
    "        \n",
    "            if val_loss >= best_val:\n",
    "                epochs_since_best += 1\n",
    "                if epochs_since_best >= 5:\n",
    "                    break\n",
    "            else:\n",
    "                best_val = val_loss\n",
    "                epochs_since_best = 0\n",
    "\n",
    "    # Test trained model with a prompt\n",
    "    # ----------------    \n",
    "    # set context: diagnosis of depression at 20 years old\n",
    "    tokens = torch.from_numpy(np.array(dm.encode([\"DEPRESSION\"])).reshape((1,-1))).to(device)\n",
    "    ages = torch.tensor([[20*365]], device=device)\n",
    "    values = torch.tensor([[torch.nan]], device=device)\n",
    "    \n",
    "    # generate: sample the next 10 tokens\n",
    "    new_tokens, new_ages, new_values = model.generate(tokens, ages, values, max_new_tokens=10)\n",
    "    generated = dm.decode(new_tokens[0].tolist())\n",
    "    # report:\n",
    "    for _cat, _age, _value in zip(generated.split(\" \"), new_ages[0, :], new_values[0, :]):\n",
    "        try:\n",
    "            _value = unstandardise(_cat, _value)\n",
    "        except:\n",
    "            pass\n",
    "        print(f\"\\t {_cat}:{_value:.02f}, at age {_age/365:.0f} ({_age:.1f} days)\")    # with value {_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['attention_mask'].shape\n",
    "print(batch[\"values\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing output to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    break\n",
    "conditions = batch[\"tokens\"].numpy().tolist()\n",
    "# delta_ages = batch[\"ages\"][:, 1:] - batch[\"ages\"][:, :-1]\n",
    "for idx, (token, _age, _value) in enumerate(zip(conditions[0], batch[\"ages\"][0,:],  batch[\"values\"][0,:])):\n",
    "    if token == 0 or idx >= 10:\n",
    "        break\n",
    "    _cat = dm.decode([token])\n",
    "    try:\n",
    "        _value = unstandardise(_cat, _value)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    print(f\"{_cat}:{_value:.02f}, at age {_age/365:.0f} ({_age:.1f} days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"k\", \"r\", \"b\", \"y\"]\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train[m_idx]), len(loss_curves_train[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val[m_idx]), len(loss_curves_val[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/TTE_tab/loss.png\")\n",
    "\n",
    "# Plot classifier loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_clf[m_idx]), len(loss_curves_train_clf[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_clf[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_clf[m_idx]), len(loss_curves_val_clf[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_clf[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/TTE_tab/loss_clf.png\")\n",
    "\n",
    "# Plot tte loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_tte[m_idx]), len(loss_curves_train_tte[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_tte[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_tte[m_idx]), len(loss_curves_val_tte[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_tte[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/TTE_tab/loss_tte.png\")\n",
    "\n",
    "# Plot values loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_values[m_idx]), len(loss_curves_train_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_values[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_values[m_idx]), len(loss_curves_val_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_values[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/TTE_tab/loss_val.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes: How related conditions are impacted by each other\n",
    "Probability of type II diabetes before and after a type I diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"TYPE1DM\"]\n",
    "t2_token = dm.tokenizer._stoi[\"TYPE2DIABETES\"]\n",
    "\n",
    "\n",
    "base_prompt = [\"DEPRESSION\"]\n",
    "ages_in_years = [20]\n",
    "base_values = [torch.tensor([torch.nan])]\n",
    "\n",
    "to_days = lambda a_list: torch.FloatTensor([365 * _a for _a in a_list]).reshape((1,-1)).to(device)\n",
    "\n",
    "# Create a set of prompts\n",
    "prompts, ages, values, desc = [], [], [], []\n",
    "# control prompt\n",
    "desc.append(\"Control\")\n",
    "prompts.append(base_prompt)\n",
    "ages.append(ages_in_years)\n",
    "values.append(base_values)\n",
    "# prompt with type 1 diabetes\n",
    "desc.append(\"Type 1\")\n",
    "prompts.append(base_prompt + [\"TYPE1DM\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "desc.append(\"Type 2\")\n",
    "prompts.append(base_prompt + [\"TYPE2DIABETES\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        for p_idx, (prompt, age, value) in enumerate(zip(prompts, ages, values)):\n",
    "            print(f\"\\n{desc[p_idx]}: \\t ({','.join(prompt)}): \")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                     values=torch.tensor(value).to(device),\n",
    "                                                     ages=to_days(age),\n",
    "                                                     is_generation=True)\n",
    "            probs = torch.nn.functional.softmax(lgts, dim=2)\n",
    "            print(f\"\\tprobability of type I diabetes: {100*float(probs[0, 0, t1_token].cpu().detach().numpy()):.4f}%\")\n",
    "            print(f\"\\tprobability of type II diabetes: {100*float(probs[0, 0, t2_token].cpu().detach().numpy()):.4f}%\")\n",
    "\n",
    "# Note: adding a diagnosis (even if potentially orthogonal) at the beginning of the prompt increases probability of either type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing BMI affects likelihood of diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"bmi\", \"diastolic_blood_pressure\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF\", \"ISCHAEMICSTROKE\"\n",
    "                     ]\n",
    "\n",
    "prompt = [\"bmi\"]\n",
    "values = [torch.tensor([standardise(_cat, v) for _cat in prompt], device=device) for v in [12.,15.,18.,21.,24.,30.,40.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    # for condition in target_conditions:\n",
    "    #     print(f\"Probability of {condition}\")\n",
    "    #     target_token = dm.tokenizer._stoi[condition]\n",
    "\n",
    "    for p_idx, value in enumerate(values):\n",
    "        print(f\"Value {value}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                  values=value,\n",
    "                                                 ages=to_days(age),\n",
    "                                                 is_generation=True)\n",
    "        probs = torch.nn.functional.softmax(lgts, dim=2) * 100\n",
    "        \n",
    "        topk_prob, topk_ind = torch.sort(probs[0,0,:], descending=True)\n",
    "        for i, j in zip(dm.decode(topk_ind.tolist()).split(\" \"), topk_prob):\n",
    "            if i in events_of_interest:\n",
    "                print(f\"\\t{i}: {j:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing diastolic_blood_pressure affects likelihood of diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"bmi\", \"diastolic_blood_pressure\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF\", \"ISCHAEMICSTROKE\"\n",
    "                     ]\n",
    "\n",
    "prompt = [\"diastolic_blood_pressure\"]\n",
    "values = [torch.tensor([standardise(_cat, _value) for _cat in prompt], device=device) for _value in [60.,70.,80.,90.,100.,120.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    # for condition in target_conditions:\n",
    "    #     print(f\"Probability of {condition}\")\n",
    "    #     target_token = dm.tokenizer._stoi[condition]\n",
    "\n",
    "    for p_idx, value in enumerate(values):\n",
    "        print(f\"Value {value}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                  values=value,\n",
    "                                                 ages=to_days(age),\n",
    "                                                 is_generation=True)\n",
    "        probs = torch.nn.functional.softmax(lgts, dim=2) * 100\n",
    "        \n",
    "        topk_prob, topk_ind = torch.sort(probs[0,0,:], descending=True)\n",
    "        for i, j in zip(dm.decode(topk_ind.tolist()).split(\" \"), topk_prob):\n",
    "            if i in events_of_interest:\n",
    "                print(f\"\\t{i}: {j:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How varying diagnosis affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"diastolic_blood_pressure\"]\n",
    "\n",
    "diagnoses = [[\"DEPRESSION\"],[\"TYPE2DIABETES\"], [\"HF\"], [\"HYPERTENSION\"]]\n",
    "values = torch.tensor([torch.nan], device=device)\n",
    "age = [39]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    # for condition in target_conditions:\n",
    "    #     print(f\"Probability of {condition}\")\n",
    "    #     target_token = dm.tokenizer._stoi[condition]\n",
    "\n",
    "    for p_idx, diagnosis in enumerate(diagnoses):\n",
    "        print(f\"\\nDiagnosis {diagnosis}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(diagnosis)).reshape((1,-1))).to(device)\n",
    "        (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                  values=values,\n",
    "                                                 ages=to_days(age),\n",
    "                                                 is_generation=True)\n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "        # print(f\"\\tprobability of type II diabetes: {100*float(probs[0, 0, t2_token].cpu().detach().numpy()):.4f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing bmi affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"diastolic_blood_pressure\"]\n",
    "\n",
    "prompt = [\"bmi\"]\n",
    "values = [torch.tensor([standardise(_cat, _value) for _cat in prompt], device=device) for _value in [12.,15.,18.,21.,24.,30.,40.,50.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    # for condition in target_conditions:\n",
    "    #     print(f\"Probability of {condition}\")\n",
    "    #     target_token = dm.tokenizer._stoi[condition]\n",
    "\n",
    "    for p_idx, value in enumerate(values):\n",
    "        print(f\"Values {value.tolist()}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                 values=value,\n",
    "                                                 ages=to_days(age),\n",
    "                                                 is_generation=True)\n",
    "        \n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "        # print(f\"\\tprobability of type II diabetes: {100*float(probs[0, 0, t2_token].cpu().detach().numpy()):.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n\" + \"=\"*len(m_names[model_idx]))\n",
    "    print(f\"\\n\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html --no-input TTE_tabular.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
