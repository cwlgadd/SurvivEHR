{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Demo Notebook:\n",
    "## Time to Event Transformer For Causal Time Series Modelling \n",
    "\n",
    "Including time and tabular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/tteGPT\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.TTE.task_heads.causal_tabular import TTETransformerForCausalTimeSeriesModelling\n",
    "\n",
    "# TODO:\n",
    "# replace experiment boilerplate with pytorch lightning\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config to be equivalent architecture of kaparthy benchmark, however they are not comparable tasks.\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    block_size: int = 128        # what is the maximum context length for predictions?\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 6\n",
    "    n_embd: int = 384\n",
    "    bias: bool = True\n",
    "    attention_type: str = \"global\"    \n",
    "    dropout: float = 0.0\n",
    "    unk_freq_threshold: float = 0.0\n",
    "    TTELayer = \"Exponential\"                                  # \"Geometric\"\n",
    "    tokens_for_univariate_regression = None\n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "@dataclass\n",
    "class OptConfig:\n",
    "    batch_size: int = 64\n",
    "    eval_interval: int = 1\n",
    "    learning_rate: float = 3e-4\n",
    "    epochs: int = 50\n",
    "    \n",
    "opt = OptConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader on a reduced cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building polars dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all available 129717 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using measurements\n",
      "INFO:root:Using test/measurement standardisation method: normalise\n",
      "INFO:root:Removing measurement and test outliers. Using three deviations from mean as cutoff\n",
      "INFO:root:Using diagnoses\n",
      "INFO:root:Dropping samples with no dynamic events\n",
      "INFO:root:Using tabular tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107683 training samples\n",
      "5983 validation samples\n",
      "5982 test samples\n",
      "90 vocab elements\n"
     ]
    }
   ],
   "source": [
    "from CPRD.data.database import queries\n",
    "\n",
    "# Get a list of patients which fit a reduced set of criterion\n",
    "PATH_TO_DB = \"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModel/preprocessing/processed/cprd.db\"\n",
    "conn = sqlite3.connect(PATH_TO_DB)\n",
    "cursor = conn.cursor()\n",
    "# identifiers1 = queries.query_measurement([\"bmi\", \"diastolic_blood_pressure\"], cursor)        \n",
    "identifiers2 = queries.query_diagnosis([\"DEPRESSION\", \"TYPE1DM\", \"TYPE2DIABETES\"], cursor)    #  \"DEPRESSION\"  ,  \"ANXIETY\"\n",
    "# all_identifiers = list(set(identifiers1).intersection(identifiers2))    # Turn smaller list into the set\n",
    "all_identifiers = identifiers2\n",
    "\n",
    "if False:\n",
    "    # Lets take only the first N for faster run-time\n",
    "    N = np.min((len(all_identifiers), 10000))\n",
    "    print(f\"Using N={N} random samples, from the available {len(all_identifiers)}\")\n",
    "    identifiers = random.choices(all_identifiers, k=N)\n",
    "else:\n",
    "    print(f\"Using all available {len(all_identifiers)} samples\")\n",
    "    identifiers = all_identifiers\n",
    "\n",
    "# Build \n",
    "dm = FoundationalDataModule(identifiers=identifiers,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            batch_size=opt.batch_size,\n",
    "                            max_seq_length=config.block_size,\n",
    "                            unk_freq_threshold=config.unk_freq_threshold,\n",
    "                            include_measurements=True,\n",
    "                            include_diagnoses=True,\n",
    "                            preprocess_measurements=True\n",
    "                           )\n",
    "\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "\n",
    "print(f\"{len(dm.train_set)} training samples\")\n",
    "print(f\"{len(dm.val_set)} validation samples\")\n",
    "print(f\"{len(dm.test_set)} test samples\")\n",
    "print(f\"{vocab_size} vocab elements\")\n",
    "# print(dm.train_set.tokenizer._itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation\n",
    "\n",
    "This was performed automatically across measurements and tests in the dataloader. The standardisation statistics (bias and scale respectively) are given in the dictionary object. \n",
    "\n",
    "We define two mappings to simplify notation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hydroxyvitamin2': (3.268025477707002, 2.8054309314024435),\n",
       " 'combined_total_vitamin_D2_and_D3_level': (56.94353322028673,\n",
       "  29.241759267841857),\n",
       " 'brain_natriuretic_peptide_level': (156.9857534246576, 291.8915253494199),\n",
       " 'calculated_LDL_cholesterol_level': (2.5891371173802233, 1.0358897687206567),\n",
       " 'blood_urea': (6.702299445123703, 4.281261339020057),\n",
       " 'serum_level': (27.19654609350041, 20.584990688686364),\n",
       " 'corrected_serum_calcium_level': (2.319034923472716, 0.12451622974555095),\n",
       " 'diastolic_blood_pressure': (78.86937661562213, 11.727257179342669),\n",
       " 'hydroxyvitamin3': (52.36982317356912, 30.382475290251843),\n",
       " 'aspartate_transam': (26.791031390134528, 18.877776290025214),\n",
       " 'blood_calcium': (2.334465408805031, 0.1487655865623607),\n",
       " 'bmi': (29.629965163503474, 7.013281083178253),\n",
       " 'eosinophil_count': (0.22162065765491276, 0.18957815785763468),\n",
       " 'calcium_adjusted_level': (2.315393830170679, 0.10855075164585075),\n",
       " 'basophil_count': (0.06984214216499786, 0.10630741873638763),\n",
       " 'creatinine_ratio': (4.435476477683948, 8.185329269651573)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052762014256647304\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "display(dm.standardisation_dict)\n",
    "\n",
    "standardise = lambda key, v: (v - dm.standardisation_dict[key][0]) / dm.standardisation_dict[key][1]\n",
    "unstandardise = lambda key, v: (v * dm.standardisation_dict[key][1]) + dm.standardisation_dict[key][0]\n",
    "\n",
    "print(standardise(\"bmi\", 30))\n",
    "print(unstandardise(\"bmi\", standardise(\"bmi\", 20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the frequency of tokens in the extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (89, 3)\n",
      "┌───────────────────────────────────┬─────────┬──────────┐\n",
      "│ EVENT                             ┆ counts  ┆ freq     │\n",
      "│ ---                               ┆ ---     ┆ ---      │\n",
      "│ str                               ┆ u32     ┆ f64      │\n",
      "╞═══════════════════════════════════╪═════════╪══════════╡\n",
      "│ UNK                               ┆ 0       ┆ 0.0      │\n",
      "│ diastolic_blood_pressure          ┆ 2224693 ┆ 0.422634 │\n",
      "│ bmi                               ┆ 865693  ┆ 0.164459 │\n",
      "│ eosinophil_count                  ┆ 810388  ┆ 0.153953 │\n",
      "│ basophil_count                    ┆ 531006  ┆ 0.100877 │\n",
      "│ corrected_serum_calcium_level     ┆ 149133  ┆ 0.028331 │\n",
      "│ DEPRESSION                        ┆ 86627   ┆ 0.016457 │\n",
      "│ serum_level                       ┆ 75356   ┆ 0.014316 │\n",
      "│ calculated_LDL_cholesterol_level  ┆ 69562   ┆ 0.013215 │\n",
      "│ ANXIETY                           ┆ 48199   ┆ 0.009157 │\n",
      "│ HYPERTENSION                      ┆ 32810   ┆ 0.006233 │\n",
      "│ TYPE2DIABETES                     ┆ 27210   ┆ 0.005169 │\n",
      "│ ASTHMA_PUSHASTHMA                 ┆ 25338   ┆ 0.004814 │\n",
      "│ OSTEOARTHRITIS                    ┆ 25317   ┆ 0.00481  │\n",
      "│ ATOPICECZEMA                      ┆ 23133   ┆ 0.004395 │\n",
      "│ ALLERGICRHINITISCONJ              ┆ 18509   ┆ 0.003516 │\n",
      "│ ANY_DEAFNESS_HEARING_LOSS         ┆ 17145   ┆ 0.003257 │\n",
      "│ aspartate_transam                 ┆ 17008   ┆ 0.003231 │\n",
      "│ PREVALENT_IBS                     ┆ 11720   ┆ 0.002226 │\n",
      "│ ALLCA_NOBCC_VFINAL                ┆ 11695   ┆ 0.002222 │\n",
      "│ IHD_NOMI                          ┆ 11280   ┆ 0.002143 │\n",
      "│ ALCOHOLMISUSE                     ┆ 11170   ┆ 0.002122 │\n",
      "│ CKDSTAGE3TO5                      ┆ 10456   ┆ 0.001986 │\n",
      "│ blood_urea                        ┆ 9696    ┆ 0.001842 │\n",
      "│ PERIPHERAL_NEUROPATHY             ┆ 8762    ┆ 0.001665 │\n",
      "│ calcium_adjusted_level            ┆ 8553    ┆ 0.001625 │\n",
      "│ HYPOTHYROIDISM_DRAFT_V1           ┆ 8007    ┆ 0.001521 │\n",
      "│ COPD                              ┆ 7673    ┆ 0.001458 │\n",
      "│ AF                                ┆ 6242    ┆ 0.001186 │\n",
      "│ combined_total_vitamin_D2_and_D3… ┆ 5878    ┆ 0.001117 │\n",
      "│ HF                                ┆ 5768    ┆ 0.001096 │\n",
      "│ OSTEOPOROSIS                      ┆ 5725    ┆ 0.001088 │\n",
      "│ PSORIASIS                         ┆ 5649    ┆ 0.001073 │\n",
      "│ SUBSTANCEMISUSE                   ┆ 5614    ┆ 0.001067 │\n",
      "│ GOUT                              ┆ 5354    ┆ 0.001017 │\n",
      "│ MINFARCTION                       ┆ 4937    ┆ 0.000938 │\n",
      "│ STROKEUNSPECIFIED                 ┆ 4506    ┆ 0.000856 │\n",
      "│ ALL_DEMENTIA                      ┆ 4428    ┆ 0.000841 │\n",
      "│ hydroxyvitamin3                   ┆ 3846    ┆ 0.000731 │\n",
      "│ hydroxyvitamin2                   ┆ 3507    ┆ 0.000666 │\n",
      "│ PAD_STRICT                        ┆ 3224    ┆ 0.000612 │\n",
      "│ VALVULARDISEASES                  ┆ 3213    ┆ 0.00061  │\n",
      "│ OTHER_CHRONIC_LIVER_DISEASE_OPTI… ┆ 2946    ┆ 0.00056  │\n",
      "│ TYPE1DM                           ┆ 2884    ┆ 0.000548 │\n",
      "│ EPILEPSY                          ┆ 2559    ┆ 0.000486 │\n",
      "│ OSA                               ┆ 2450    ┆ 0.000465 │\n",
      "│ FIBROMYALGIA                      ┆ 2390    ┆ 0.000454 │\n",
      "│ POLYCYSTIC_OVARIAN_SYNDROME_PCOS  ┆ 2233    ┆ 0.000424 │\n",
      "│ NAFLD                             ┆ 2133    ┆ 0.000405 │\n",
      "│ RHEUMATOIDARTHRITIS               ┆ 2050    ┆ 0.000389 │\n",
      "│ EATINGDISORDERS                   ┆ 1992    ┆ 0.000378 │\n",
      "│ HYPERTHYROIDISM                   ┆ 1937    ┆ 0.000368 │\n",
      "│ PMRANDGCA                         ┆ 1922    ┆ 0.000365 │\n",
      "│ ENDOMETRIOSIS_ADENOMYOSIS_V2      ┆ 1802    ┆ 0.000342 │\n",
      "│ PTSDDIAGNOSIS                     ┆ 1714    ┆ 0.000326 │\n",
      "│ ISCHAEMICSTROKE                   ┆ 1495    ┆ 0.000284 │\n",
      "│ creatinine_ratio                  ┆ 1468    ┆ 0.000279 │\n",
      "│ VISUAL_IMPAIRMENT                 ┆ 1414    ┆ 0.000269 │\n",
      "│ BIPOLAR                           ┆ 1395    ┆ 0.000265 │\n",
      "│ SCHIZOPHRENIAMM                   ┆ 1328    ┆ 0.000252 │\n",
      "│ BRONCHIECTASIS                    ┆ 1068    ┆ 0.000203 │\n",
      "│ CHRONIC_LIVER_DISEASE_ALCOHOL     ┆ 923     ┆ 0.000175 │\n",
      "│ AORTICANEURYSM                    ┆ 892     ┆ 0.000169 │\n",
      "│ CHRONICFATIGUESYNDROMEMM          ┆ 841     ┆ 0.00016  │\n",
      "│ ULCERATIVE_COLITIS                ┆ 836     ┆ 0.000159 │\n",
      "│ LEARNINGDISABILITY                ┆ 733     ┆ 0.000139 │\n",
      "│ PERNICIOUSANAEMIA                 ┆ 710     ┆ 0.000135 │\n",
      "│ PARKINSONS                        ┆ 703     ┆ 0.000134 │\n",
      "│ MENIERESDISEASE                   ┆ 700     ┆ 0.000133 │\n",
      "│ STROKE_HAEMRGIC                   ┆ 697     ┆ 0.000132 │\n",
      "│ brain_natriuretic_peptide_level   ┆ 613     ┆ 0.000116 │\n",
      "│ LYMPHOMA_PREVALENCE               ┆ 595     ┆ 0.000113 │\n",
      "│ ILD_SH                            ┆ 548     ┆ 0.000104 │\n",
      "│ CROHNS_DISEASE                    ┆ 536     ┆ 0.000102 │\n",
      "│ AUTISM                            ┆ 515     ┆ 0.000098 │\n",
      "│ PSORIATICARTHRITIS2021            ┆ 484     ┆ 0.000092 │\n",
      "│ LEUKAEMIA_PREVALENCE              ┆ 413     ┆ 0.000078 │\n",
      "│ MS                                ┆ 412     ┆ 0.000078 │\n",
      "│ HIVAIDS                           ┆ 290     ┆ 0.000055 │\n",
      "│ SJOGRENSSYNDROME                  ┆ 238     ┆ 0.000045 │\n",
      "│ SYSTEMIC_LUPUS_ERYTHEMATOSUS      ┆ 226     ┆ 0.000043 │\n",
      "│ HAEMOCHROMATOSIS                  ┆ 200     ┆ 0.000038 │\n",
      "│ blood_calcium                     ┆ 147     ┆ 0.000028 │\n",
      "│ PLASMACELL_NEOPLASM               ┆ 135     ┆ 0.000026 │\n",
      "│ ADDISON_DISEASE                   ┆ 104     ┆ 0.00002  │\n",
      "│ SYSTEMIC_SCLEROSIS                ┆ 71      ┆ 0.000013 │\n",
      "│ DOWNSSYNDROME                     ┆ 44      ┆ 0.000008 │\n",
      "│ CYSTICFIBROSIS                    ┆ 43      ┆ 0.000008 │\n",
      "│ SICKLE_CELL_DISEASE               ┆ 22      ┆ 0.000004 │\n",
      "└───────────────────────────────────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(vocab_size + 1)\n",
    "print(dm.tokenizer._event_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diastolic_blood_pressure', 'bmi', 'eosinophil_count', 'basophil_count', 'corrected_serum_calcium_level', 'serum_level', 'calculated_LDL_cholesterol_level', 'aspartate_transam', 'blood_urea', 'calcium_adjusted_level', 'combined_total_vitamin_D2_and_D3_level', 'hydroxyvitamin3', 'hydroxyvitamin2', 'creatinine_ratio', 'brain_natriuretic_peptide_level', 'blood_calcium']\n",
      "[2, 3, 4, 5, 6, 8, 9, 18, 24, 26, 30, 39, 40, 57, 71, 83]\n",
      "DEPRESSION eosinophil_count bmi diastolic_blood_pressure\n"
     ]
    }
   ],
   "source": [
    "# Extract the measurements, using the fact that the diagnoses are all up upper case. This is needed for automatically setting the configuration below\n",
    "measurements_for_univariate_regression = [record for record in dm.tokenizer._event_counts[\"EVENT\"] if record.upper() != record]\n",
    "\n",
    "print(measurements_for_univariate_regression)\n",
    "print(dm.encode(measurements_for_univariate_regression))\n",
    "print(dm.decode([7,4,3,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using ExponentialTTELayer. This module predicts the time until next event as an exponential distribution\n",
      "INFO:root:ModuleDict(\n",
      "  (Token 2): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 3): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 4): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 5): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 6): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 8): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 9): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 18): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 24): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 26): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 30): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 39): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 40): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 57): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 71): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 83): Linear(in_features=384, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models, m_names = [], []\n",
    "\n",
    "# My development model\n",
    "for tte_layer in [\"Exponential\"]: #, \"Geometric\"]:\n",
    "    \n",
    "    ## Create configuration\n",
    "    config = DemoConfig()\n",
    "    # Specify which TTE layer to use\n",
    "    config.TTELayer = tte_layer    \n",
    "    # list of univariate measurements to model with Normal distribution\n",
    "    config.tokens_for_univariate_regression = dm.encode(measurements_for_univariate_regression) \n",
    "    \n",
    "    models.append(TTETransformerForCausalTimeSeriesModelling(config, vocab_size).to(device))\n",
    "    m_names.append(f\"TTETransformerForCausalTimeSeriesModelling: {tte_layer} TTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curves_train = [[] for _ in models]\n",
    "loss_curves_train_clf = [[] for _ in models]\n",
    "loss_curves_train_tte = [[] for _ in models]\n",
    "loss_curves_train_values = [[] for _ in models]\n",
    "\n",
    "loss_curves_val = [[] for _ in models]\n",
    "loss_curves_val_clf = [[] for _ in models]\n",
    "loss_curves_val_tte = [[] for _ in models]\n",
    "loss_curves_val_values = [[] for _ in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model `TTETransformerForCausalTimeSeriesModelling: Exponential TTE`, with 10.757217 M parameters\n",
      "Epoch 0:\tTrain loss 0.34  (1.59, -0.85, 0.29). Val loss 0.30 (1.56, -0.94, 0.27)\n",
      "Epoch 1:\tTrain loss 0.28  (1.53, -0.95, 0.26). Val loss 0.28 (1.54, -0.99, 0.28)\n",
      "Epoch 2:\tTrain loss 0.26  (1.51, -0.98, 0.25). Val loss 0.26 (1.52, -1.01, 0.26)\n",
      "Epoch 3:\tTrain loss 0.25  (1.51, -1.00, 0.25). Val loss 0.27 (1.54, -1.00, 0.27)\n",
      "Epoch 4:\tTrain loss 0.25  (1.50, -1.01, 0.25). Val loss 0.25 (1.52, -1.02, 0.26)\n",
      "Epoch 5:\tTrain loss 0.24  (1.50, -1.02, 0.25). Val loss 0.25 (1.51, -1.02, 0.25)\n",
      "Epoch 6:\tTrain loss 0.24  (1.50, -1.02, 0.25). Val loss 0.26 (1.52, -1.03, 0.29)\n",
      "Epoch 7:\tTrain loss 0.24  (1.49, -1.03, 0.25). Val loss 0.25 (1.52, -1.03, 0.27)\n",
      "Epoch 8:\tTrain loss 0.23  (1.48, -1.04, 0.25). Val loss 0.23 (1.50, -1.06, 0.25)\n",
      "Epoch 9:\tTrain loss 0.23  (1.48, -1.04, 0.24). Val loss 0.24 (1.50, -1.05, 0.27)\n",
      "Epoch 10:\tTrain loss 0.23  (1.48, -1.05, 0.24). Val loss 0.23 (1.49, -1.05, 0.25)\n",
      "Epoch 11:\tTrain loss 0.22  (1.47, -1.05, 0.24). Val loss 0.23 (1.49, -1.06, 0.25)\n",
      "Epoch 12:\tTrain loss 0.22  (1.47, -1.05, 0.24). Val loss 0.25 (1.51, -1.04, 0.28)\n",
      "Epoch 13:\tTrain loss 0.22  (1.48, -1.05, 0.25). Val loss 0.23 (1.49, -1.06, 0.25)\n",
      "Epoch 14:\tTrain loss 0.22  (1.47, -1.05, 0.24). Val loss 0.23 (1.50, -1.06, 0.25)\n",
      "Epoch 15:\tTrain loss 0.22  (1.47, -1.06, 0.24). Val loss 0.23 (1.49, -1.07, 0.26)\n",
      "Epoch 16:\tTrain loss 0.24  (1.50, -1.03, 0.26). Val loss 0.24 (1.51, -1.05, 0.27)\n",
      "\t DEPRESSION:nan, at age 20 (7300.0 days)\n",
      "\t ANXIETY:nan, at age 21 (7524.2 days)\n",
      "\t bmi:32.13, at age 23 (8550.4 days)\n",
      "\t diastolic_blood_pressure:69.71, at age 24 (8634.0 days)\n",
      "\t bmi:29.04, at age 25 (8991.2 days)\n",
      "\t diastolic_blood_pressure:67.83, at age 25 (8994.2 days)\n",
      "\t basophil_count:0.15, at age 25 (9067.9 days)\n",
      "\t eosinophil_count:0.20, at age 25 (9080.2 days)\n",
      "\t bmi:29.41, at age 27 (9676.4 days)\n",
      "\t diastolic_blood_pressure:69.09, at age 27 (9874.1 days)\n",
      "\t eosinophil_count:0.20, at age 28 (10074.5 days)\n"
     ]
    }
   ],
   "source": [
    "for m_idx, (model, m_name) in enumerate(zip(models, m_names)):\n",
    "    \n",
    "    print(f\"Training model `{m_name}`, with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "    best_val, epochs_since_best = np.inf, 0\n",
    "    for epoch in range(opt.epochs):\n",
    "        epoch_loss, epoch_clf_loss, epoch_tte_loss, epoch_values_loss = 0, 0, 0, 0\n",
    "        model.train()\n",
    "        for i, batch in enumerate(dm.train_dataloader()):\n",
    "            # evaluate the loss\n",
    "            _, (loss_clf, loss_tte, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                               ages=batch['ages'].to(device), \n",
    "                                                               values=batch['values'].to(device),\n",
    "                                                               attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                               )\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # record\n",
    "            epoch_clf_loss += loss_clf.item()\n",
    "            epoch_tte_loss += loss_tte.item()\n",
    "            epoch_values_loss += loss_values.item()\n",
    "        epoch_loss /= i\n",
    "        epoch_clf_loss /= i\n",
    "        epoch_tte_loss /= i\n",
    "        epoch_values_loss /= i\n",
    "        loss_curves_train[m_idx].append(epoch_loss)\n",
    "        loss_curves_train_clf[m_idx].append(epoch_clf_loss)\n",
    "        loss_curves_train_tte[m_idx].append(epoch_tte_loss)\n",
    "        loss_curves_train_values[m_idx].append(epoch_values_loss)\n",
    "\n",
    "        # evaluate the loss on val set\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            if epoch % opt.eval_interval == 0 or epoch == opt.epochs - 1:\n",
    "                val_loss, val_clf_loss, val_tte_loss, val_values_loss = 0, 0, 0, 0\n",
    "                for j, batch in enumerate(dm.val_dataloader()):\n",
    "                    _, (loss_clf, loss_tte, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                                       ages=batch['ages'].to(device),\n",
    "                                                                       values=batch['values'].to(device),\n",
    "                                                                       attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                                       )\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    # record\n",
    "                    val_clf_loss += loss_clf.item()\n",
    "                    val_tte_loss += loss_tte.item()\n",
    "                    val_values_loss += loss_values.item()\n",
    "                val_loss /= j\n",
    "                val_clf_loss /= j\n",
    "                val_tte_loss /= j\n",
    "                val_values_loss /= j\n",
    "                loss_curves_val[m_idx].append(val_loss)\n",
    "                loss_curves_val_clf[m_idx].append(val_clf_loss)\n",
    "                loss_curves_val_tte[m_idx].append(val_tte_loss)\n",
    "                loss_curves_val_values[m_idx].append(val_values_loss)\n",
    "\n",
    "                print(f\"Epoch {epoch}:\\tTrain loss {epoch_loss:.2f}  ({epoch_clf_loss:.2f}, {epoch_tte_loss:.2f}, {epoch_values_loss:.2f}). Val loss {val_loss:.2f} ({val_clf_loss:.2f}, {val_tte_loss:.2f}, {val_values_loss:.2f})\")          \n",
    "                # TODO: Note not fully accurate as last batch is likely not the same size, will be fixed with lightning\n",
    "        \n",
    "            if val_loss >= best_val:\n",
    "                epochs_since_best += 1\n",
    "                if epochs_since_best >= 5:\n",
    "                    break\n",
    "            else:\n",
    "                best_val = val_loss\n",
    "                epochs_since_best = 0\n",
    "\n",
    "    # Test trained model with a prompt\n",
    "    # ----------------    \n",
    "    # set context: diagnosis of depression at 20 years old\n",
    "    tokens = torch.from_numpy(np.array(dm.encode([\"DEPRESSION\"])).reshape((1,-1))).to(device)\n",
    "    ages = torch.tensor([[20*365]], device=device)\n",
    "    values = torch.tensor([[torch.nan]], device=device)\n",
    "    \n",
    "    # generate: sample the next 10 tokens\n",
    "    new_tokens, new_ages, new_values = model.generate(tokens, ages, values, max_new_tokens=10)\n",
    "    generated = dm.decode(new_tokens[0].tolist())\n",
    "    # report:\n",
    "    for _cat, _age, _value in zip(generated.split(\" \"), new_ages[0, :], new_values[0, :]):\n",
    "        try:\n",
    "            _value = unstandardise(_cat, _value)\n",
    "        except:\n",
    "            pass\n",
    "        print(f\"\\t {_cat}:{_value:.02f}, at age {_age/365:.0f} ({_age:.1f} days)\")    # with value {_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing output to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERIPHERAL_NEUROPATHY:nan, at age 40 (14780.0 days)\n",
      "bmi:23.80, at age 51 (18528.0 days)\n",
      "diastolic_blood_pressure:82.00, at age 51 (18528.0 days)\n",
      "basophil_count:0.08, at age 52 (19110.0 days)\n",
      "eosinophil_count:0.31, at age 52 (19110.0 days)\n",
      "diastolic_blood_pressure:74.00, at age 52 (19117.0 days)\n",
      "bmi:22.60, at age 53 (19432.0 days)\n",
      "diastolic_blood_pressure:77.00, at age 54 (19829.0 days)\n",
      "bmi:22.20, at age 55 (20221.0 days)\n",
      "diastolic_blood_pressure:70.00, at age 55 (20221.0 days)\n"
     ]
    }
   ],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    break\n",
    "conditions = batch[\"tokens\"].numpy().tolist()\n",
    "# delta_ages = batch[\"ages\"][:, 1:] - batch[\"ages\"][:, :-1]\n",
    "for idx, (token, _age, _value) in enumerate(zip(conditions[0], batch[\"ages\"][0,:],  batch[\"values\"][0,:])):\n",
    "    if token == 0 or idx >= 10:\n",
    "        break\n",
    "    _cat = dm.decode([token])\n",
    "    try:\n",
    "        _value = unstandardise(_cat, _value)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    print(f\"{_cat}:{_value:.02f}, at age {_age/365:.0f} ({_age:.1f} days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"k\", \"r\", \"b\", \"y\"]\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train[m_idx]), len(loss_curves_train[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val[m_idx]), len(loss_curves_val[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/TTE_tab/loss.png\")\n",
    "\n",
    "# Plot classifier loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_clf[m_idx]), len(loss_curves_train_clf[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_clf[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_clf[m_idx]), len(loss_curves_val_clf[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_clf[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/TTE_tab/loss_clf.png\")\n",
    "\n",
    "# Plot tte loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_tte[m_idx]), len(loss_curves_train_tte[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_tte[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_tte[m_idx]), len(loss_curves_val_tte[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_tte[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/TTE_tab/loss_tte.png\")\n",
    "\n",
    "# Plot values loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_values[m_idx]), len(loss_curves_train_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_values[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_values[m_idx]), len(loss_curves_val_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_values[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/TTE_tab/loss_val.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes: How related conditions are impacted by each other\n",
    "Probability of type II diabetes before and after a type I diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TTETransformerForCausalTimeSeriesModelling: Exponential TTE\n",
      "--------------------------------------\n",
      "\n",
      "Control: \t (DEPRESSION): \n",
      "\tprobability of type I diabetes: 0.0332%\n",
      "\tprobability of type II diabetes: 0.0948%\n",
      "\n",
      "Type 1: \t (DEPRESSION,TYPE1DM): \n",
      "\tprobability of type I diabetes: 0.2016%\n",
      "\tprobability of type II diabetes: 0.5103%\n",
      "\n",
      "Type 2: \t (DEPRESSION,TYPE2DIABETES): \n",
      "\tprobability of type I diabetes: 0.3173%\n",
      "\tprobability of type II diabetes: 0.1403%\n"
     ]
    }
   ],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"TYPE1DM\"]\n",
    "t2_token = dm.tokenizer._stoi[\"TYPE2DIABETES\"]\n",
    "\n",
    "\n",
    "base_prompt = [\"DEPRESSION\"]\n",
    "ages_in_years = [20]\n",
    "base_values = [torch.tensor([torch.nan])]\n",
    "\n",
    "to_days = lambda a_list: torch.FloatTensor([365 * _a for _a in a_list]).reshape((1,-1)).to(device)\n",
    "\n",
    "# Create a set of prompts\n",
    "prompts, ages, values, desc = [], [], [], []\n",
    "# control prompt\n",
    "desc.append(\"Control\")\n",
    "prompts.append(base_prompt)\n",
    "ages.append(ages_in_years)\n",
    "values.append(base_values)\n",
    "# prompt with type 1 diabetes\n",
    "desc.append(\"Type 1\")\n",
    "prompts.append(base_prompt + [\"TYPE1DM\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "desc.append(\"Type 2\")\n",
    "prompts.append(base_prompt + [\"TYPE2DIABETES\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        for p_idx, (prompt, age, value) in enumerate(zip(prompts, ages, values)):\n",
    "            print(f\"\\n{desc[p_idx]}: \\t ({','.join(prompt)}): \")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                     values=torch.tensor(value).to(device),\n",
    "                                                     ages=to_days(age),\n",
    "                                                     is_generation=True)\n",
    "            probs = torch.nn.functional.softmax(lgts, dim=2)\n",
    "            print(f\"\\tprobability of type I diabetes: {100*float(probs[0, 0, t1_token].cpu().detach().numpy()):.4f}%\")\n",
    "            print(f\"\\tprobability of type II diabetes: {100*float(probs[0, 0, t2_token].cpu().detach().numpy()):.4f}%\")\n",
    "\n",
    "# Note: adding a diagnosis (even if potentially orthogonal) at the beginning of the prompt increases probability of either type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing BMI affects likelihood of diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TTETransformerForCausalTimeSeriesModelling: Exponential TTE\n",
      "--------------------------------------\n",
      "Value tensor([-2.5138], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 66.71%\n",
      "\tbmi: 11.66%\n",
      "\tOSTEOARTHRITIS: 0.31%\n",
      "\tHYPERTENSION: 0.22%\n",
      "\tTYPE2DIABETES: 0.14%\n",
      "\tTYPE1DM: 0.09%\n",
      "\tHF: 0.01%\n",
      "\tISCHAEMICSTROKE: 0.01%\n",
      "\tCKDSTAGE3TO5: 0.01%\n",
      "Value tensor([-2.0860], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 70.73%\n",
      "\tbmi: 10.11%\n",
      "\tOSTEOARTHRITIS: 0.29%\n",
      "\tHYPERTENSION: 0.23%\n",
      "\tTYPE2DIABETES: 0.15%\n",
      "\tTYPE1DM: 0.07%\n",
      "\tHF: 0.01%\n",
      "\tISCHAEMICSTROKE: 0.01%\n",
      "\tCKDSTAGE3TO5: 0.00%\n",
      "Value tensor([-1.6583], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 75.75%\n",
      "\tbmi: 8.38%\n",
      "\tOSTEOARTHRITIS: 0.26%\n",
      "\tHYPERTENSION: 0.24%\n",
      "\tTYPE2DIABETES: 0.16%\n",
      "\tTYPE1DM: 0.05%\n",
      "\tHF: 0.01%\n",
      "\tISCHAEMICSTROKE: 0.01%\n",
      "\tCKDSTAGE3TO5: 0.00%\n",
      "Value tensor([-1.2305], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 80.96%\n",
      "\tbmi: 6.81%\n",
      "\tHYPERTENSION: 0.24%\n",
      "\tOSTEOARTHRITIS: 0.22%\n",
      "\tTYPE2DIABETES: 0.15%\n",
      "\tTYPE1DM: 0.04%\n",
      "\tHF: 0.01%\n",
      "\tISCHAEMICSTROKE: 0.00%\n",
      "\tCKDSTAGE3TO5: 0.00%\n",
      "Value tensor([-0.8028], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 85.89%\n",
      "\tbmi: 5.41%\n",
      "\tHYPERTENSION: 0.27%\n",
      "\tOSTEOARTHRITIS: 0.18%\n",
      "\tTYPE2DIABETES: 0.15%\n",
      "\tTYPE1DM: 0.02%\n",
      "\tHF: 0.00%\n",
      "\tISCHAEMICSTROKE: 0.00%\n",
      "\tCKDSTAGE3TO5: 0.00%\n",
      "Value tensor([0.0528], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 90.77%\n",
      "\tbmi: 4.49%\n",
      "\tHYPERTENSION: 0.33%\n",
      "\tTYPE2DIABETES: 0.26%\n",
      "\tOSTEOARTHRITIS: 0.10%\n",
      "\tTYPE1DM: 0.01%\n",
      "\tHF: 0.00%\n",
      "\tISCHAEMICSTROKE: 0.00%\n",
      "\tCKDSTAGE3TO5: 0.00%\n",
      "Value tensor([1.4786], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 83.78%\n",
      "\tbmi: 9.15%\n",
      "\tTYPE2DIABETES: 0.74%\n",
      "\tHYPERTENSION: 0.42%\n",
      "\tOSTEOARTHRITIS: 0.08%\n",
      "\tTYPE1DM: 0.01%\n",
      "\tHF: 0.01%\n",
      "\tCKDSTAGE3TO5: 0.00%\n",
      "\tISCHAEMICSTROKE: 0.00%\n"
     ]
    }
   ],
   "source": [
    "events_of_interest = [\"bmi\", \"diastolic_blood_pressure\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF\", \"ISCHAEMICSTROKE\"\n",
    "                     ]\n",
    "\n",
    "prompt = [\"bmi\"]\n",
    "values = [torch.tensor([standardise(_cat, v) for _cat in prompt], device=device) for v in [12.,15.,18.,21.,24.,30.,40.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    # for condition in target_conditions:\n",
    "    #     print(f\"Probability of {condition}\")\n",
    "    #     target_token = dm.tokenizer._stoi[condition]\n",
    "\n",
    "    for p_idx, value in enumerate(values):\n",
    "        print(f\"Value {value}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                  values=value,\n",
    "                                                 ages=to_days(age),\n",
    "                                                 is_generation=True)\n",
    "        probs = torch.nn.functional.softmax(lgts, dim=2) * 100\n",
    "        \n",
    "        topk_prob, topk_ind = torch.sort(probs[0,0,:], descending=True)\n",
    "        for i, j in zip(dm.decode(topk_ind.tolist()).split(\" \"), topk_prob):\n",
    "            if i in events_of_interest:\n",
    "                print(f\"\\t{i}: {j:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing diastolic_blood_pressure affects likelihood of diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TTETransformerForCausalTimeSeriesModelling: Exponential TTE\n",
      "--------------------------------------\n",
      "Value tensor([-1.6090], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 51.87%\n",
      "\tbmi: 16.95%\n",
      "\tOSTEOARTHRITIS: 0.91%\n",
      "\tTYPE2DIABETES: 0.44%\n",
      "\tHYPERTENSION: 0.30%\n",
      "\tTYPE1DM: 0.11%\n",
      "\tHF: 0.03%\n",
      "\tCKDSTAGE3TO5: 0.02%\n",
      "\tISCHAEMICSTROKE: 0.01%\n",
      "Value tensor([-0.7563], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 49.22%\n",
      "\tbmi: 18.18%\n",
      "\tOSTEOARTHRITIS: 0.96%\n",
      "\tTYPE2DIABETES: 0.60%\n",
      "\tHYPERTENSION: 0.36%\n",
      "\tTYPE1DM: 0.11%\n",
      "\tHF: 0.02%\n",
      "\tCKDSTAGE3TO5: 0.01%\n",
      "\tISCHAEMICSTROKE: 0.01%\n",
      "Value tensor([0.0964], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 46.92%\n",
      "\tbmi: 19.22%\n",
      "\tOSTEOARTHRITIS: 1.17%\n",
      "\tTYPE2DIABETES: 0.99%\n",
      "\tHYPERTENSION: 0.65%\n",
      "\tTYPE1DM: 0.11%\n",
      "\tHF: 0.02%\n",
      "\tCKDSTAGE3TO5: 0.01%\n",
      "\tISCHAEMICSTROKE: 0.01%\n",
      "Value tensor([0.9491], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 57.61%\n",
      "\tbmi: 15.66%\n",
      "\tHYPERTENSION: 2.65%\n",
      "\tTYPE2DIABETES: 1.12%\n",
      "\tOSTEOARTHRITIS: 0.99%\n",
      "\tTYPE1DM: 0.08%\n",
      "\tHF: 0.03%\n",
      "\tISCHAEMICSTROKE: 0.02%\n",
      "\tCKDSTAGE3TO5: 0.02%\n",
      "Value tensor([1.8018], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 67.06%\n",
      "\tbmi: 11.01%\n",
      "\tHYPERTENSION: 7.11%\n",
      "\tTYPE2DIABETES: 0.77%\n",
      "\tOSTEOARTHRITIS: 0.56%\n",
      "\tTYPE1DM: 0.05%\n",
      "\tHF: 0.04%\n",
      "\tISCHAEMICSTROKE: 0.03%\n",
      "\tCKDSTAGE3TO5: 0.02%\n",
      "Value tensor([3.5073], device='cuda:0')\n",
      "======\n",
      "\tdiastolic_blood_pressure: 69.68%\n",
      "\tHYPERTENSION: 13.25%\n",
      "\tbmi: 7.17%\n",
      "\tTYPE2DIABETES: 0.53%\n",
      "\tOSTEOARTHRITIS: 0.31%\n",
      "\tHF: 0.06%\n",
      "\tISCHAEMICSTROKE: 0.04%\n",
      "\tTYPE1DM: 0.03%\n",
      "\tCKDSTAGE3TO5: 0.03%\n"
     ]
    }
   ],
   "source": [
    "events_of_interest = [\"bmi\", \"diastolic_blood_pressure\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF\", \"ISCHAEMICSTROKE\"\n",
    "                     ]\n",
    "\n",
    "prompt = [\"diastolic_blood_pressure\"]\n",
    "values = [torch.tensor([standardise(_cat, _value) for _cat in prompt], device=device) for _value in [60.,70.,80.,90.,100.,120.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    # for condition in target_conditions:\n",
    "    #     print(f\"Probability of {condition}\")\n",
    "    #     target_token = dm.tokenizer._stoi[condition]\n",
    "\n",
    "    for p_idx, value in enumerate(values):\n",
    "        print(f\"Value {value}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                  values=value,\n",
    "                                                 ages=to_days(age),\n",
    "                                                 is_generation=True)\n",
    "        probs = torch.nn.functional.softmax(lgts, dim=2) * 100\n",
    "        \n",
    "        topk_prob, topk_ind = torch.sort(probs[0,0,:], descending=True)\n",
    "        for i, j in zip(dm.decode(topk_ind.tolist()).split(\" \"), topk_prob):\n",
    "            if i in events_of_interest:\n",
    "                print(f\"\\t{i}: {j:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How varying diagnosis affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TTETransformerForCausalTimeSeriesModelling: Exponential TTE\n",
      "--------------------------------------\n",
      "\n",
      "Diagnosis ['DEPRESSION']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.0, 0.9)\n",
      "\n",
      "Diagnosis ['TYPE2DIABETES']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.1, 0.9)\n",
      "\n",
      "Diagnosis ['HF']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.2, 0.9)\n",
      "\n",
      "Diagnosis ['HYPERTENSION']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.3, 1.0)\n"
     ]
    }
   ],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"diastolic_blood_pressure\"]\n",
    "\n",
    "diagnoses = [[\"DEPRESSION\"],[\"TYPE2DIABETES\"], [\"HF\"], [\"HYPERTENSION\"]]\n",
    "values = torch.tensor([torch.nan], device=device)\n",
    "age = [39]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    # for condition in target_conditions:\n",
    "    #     print(f\"Probability of {condition}\")\n",
    "    #     target_token = dm.tokenizer._stoi[condition]\n",
    "\n",
    "    for p_idx, diagnosis in enumerate(diagnoses):\n",
    "        print(f\"\\nDiagnosis {diagnosis}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(diagnosis)).reshape((1,-1))).to(device)\n",
    "        (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                  values=values,\n",
    "                                                 ages=to_days(age),\n",
    "                                                 is_generation=True)\n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "        # print(f\"\\tprobability of type II diabetes: {100*float(probs[0, 0, t2_token].cpu().detach().numpy()):.4f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing bmi affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TTETransformerForCausalTimeSeriesModelling: Exponential TTE\n",
      "--------------------------------------\n",
      "Values [-2.5137970447540283]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.8, 0.8)\n",
      "Values [-2.0860371589660645]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.7, 0.8)\n",
      "Values [-1.6582773923873901]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.6, 0.8)\n",
      "Values [-1.2305175065994263]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.5, 0.8)\n",
      "Values [-0.8027576804161072]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.3, 0.8)\n",
      "Values [0.05276201292872429]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.0, 0.8)\n",
      "Values [1.478628158569336]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.1, 0.9)\n",
      "Values [2.904494285583496]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.1, 1.0)\n"
     ]
    }
   ],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"diastolic_blood_pressure\"]\n",
    "\n",
    "prompt = [\"bmi\"]\n",
    "values = [torch.tensor([standardise(_cat, _value) for _cat in prompt], device=device) for _value in [12.,15.,18.,21.,24.,30.,40.,50.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    # for condition in target_conditions:\n",
    "    #     print(f\"Probability of {condition}\")\n",
    "    #     target_token = dm.tokenizer._stoi[condition]\n",
    "\n",
    "    for p_idx, value in enumerate(values):\n",
    "        print(f\"Values {value.tolist()}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        (lgts, tte_dist, val_dist), _, _ = model(encoded_prompt,\n",
    "                                                 values=value,\n",
    "                                                 ages=to_days(age),\n",
    "                                                 is_generation=True)\n",
    "        \n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "        # print(f\"\\tprobability of type II diabetes: {100*float(probs[0, 0, t2_token].cpu().detach().numpy()):.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TTETransformerForCausalTimeSeriesModelling: Exponential TTE\n",
      "===========================================================\n",
      "\n",
      "\n",
      "TTETransformerForCausalTimeSeriesModelling(\n",
      "  (transformer): TTETransformer(\n",
      "    (wpe): TemporalPositionalEncoding()\n",
      "    (wte): DataEmbeddingLayer(\n",
      "      (token_embed_layer): Embedding(90, 384, padding_idx=0)\n",
      "      (value_embed_layer): EmbeddingBag(90, 384, mode=sum, padding_idx=0)\n",
      "    )\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=384, out_features=90, bias=False)\n",
      "  (tte_layer): ExponentialTTELayer(\n",
      "    (proj): Linear(in_features=384, out_features=1, bias=True)\n",
      "  )\n",
      "  (value_layer): GaussianRegressionLayer(\n",
      "    (regression_layers): ModuleDict(\n",
      "      (Token 2): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 3): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 4): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 5): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 6): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 8): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 9): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 18): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 24): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 26): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 30): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 39): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 40): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 57): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 71): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 83): Linear(in_features=384, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n\" + \"=\"*len(m_names[model_idx]))\n",
    "    print(f\"\\n\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook TTE_tabular.ipynb to html\n",
      "[NbConvertApp] Writing 596446 bytes to TTE_tabular.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html --no-input TTE_tabular.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
