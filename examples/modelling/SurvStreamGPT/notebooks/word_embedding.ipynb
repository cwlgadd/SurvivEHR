{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a001d9b-9dfd-4707-8f9d-685f53b3fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e7c681-8147-477c-afa2-56bb7aa6249c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n",
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from CPRD.examples.modelling.SurvStreamGPT.run_experiment import run\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "\n",
    "import time\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(10000)\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10000\n",
    "\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")\n",
    "\n",
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab84e49-6b2b-41ee-92bb-560aefde28fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/split=train/ dataset, with 572,096 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 64\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "experiment:\n",
      "  type: zeroshot\n",
      "  project_name: SurvEHR_${head.SurvLayer}\n",
      "  run_id: CR_11M_Natalia\n",
      "  fine_tune_id: CVD-0shot\n",
      "  train: false\n",
      "  test: false\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - IHDINCLUDINGMI_OPTIMALV2\n",
      "  - ISCHAEMICSTROKE_V2\n",
      "  - MINFARCTION\n",
      "  - STROKEUNSPECIFIED_V2\n",
      "  - STROKE_HAEMRGIC\n",
      "optim:\n",
      "  num_epochs: 5\n",
      "  learning_rate: 0.0003\n",
      "  scheduler_warmup: true\n",
      "  scheduler: CAWarmRestarts\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 1000\n",
      "  early_stop: true\n",
      "  early_stop_patience: 30\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.025\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 6\n",
      "  n_head: 6\n",
      "  n_embd: 384\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.5\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# # Zero-shot learning experiment\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Loading a pre-trained model with the checkpoint path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_Natalia.ckpt.\n",
      "INFO:root:Fine tune outcomes encode into tokens [95, 41, 67, 65, 28]\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 11.433294 M parameters\n"
     ]
    }
   ],
   "source": [
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../confs\", job_name=\"testing_notebook\"):\n",
    "    cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                  overrides=[# Experiment setup\n",
    "                             \"experiment.type='zeroshot'\",\n",
    "                             \"experiment.run_id='CR_11M_Natalia'\",\n",
    "                              \"experiment.fine_tune_id='CVD-0shot'\",\n",
    "                             \"experiment.train=False\",\n",
    "                             \"experiment.test=False\",\n",
    "                             'experiment.fine_tune_outcomes=[\"IHDINCLUDINGMI_OPTIMALV2\", \"ISCHAEMICSTROKE_V2\", \"MINFARCTION\", \"STROKEUNSPECIFIED_V2\", \"STROKE_HAEMRGIC\"]',\n",
    "                             # Dataloader\n",
    "                             \"data.path_to_ds=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\",\n",
    "                             \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                             \"data.min_workers=12\",\n",
    "                             # \"data.batch_size=512\",\n",
    "                             # Optimiser\n",
    "                             \"optim.limit_test_batches=null\",\n",
    "                             # Single-Risk specific\n",
    "                            ]\n",
    "                 )     \n",
    "\n",
    "cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\"\n",
    "\n",
    "\n",
    "# print(OmegaConf.to_yaml(cfg))\n",
    "experiment, dm = run(cfg)\n",
    "print(f\"Loaded model with {sum(p.numel() for p in experiment.model.parameters())/1e6} M parameters\")\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13189762-3b59-48dd-8779-f543f59e0b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'static_covariates': tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.5081]),\n",
       " 'tokens': tensor([247, 261, 219, 251, 262, 247, 219, 251, 251, 260, 261, 262, 189, 231,\n",
       "         235, 135, 244, 185, 238, 232, 240, 237, 239, 243, 243, 231, 235, 135,\n",
       "         244, 238, 232, 240, 237, 239, 243, 231, 247, 261, 235, 101, 135, 244,\n",
       "         238, 232, 240, 237, 239, 251, 243, 248, 245, 246, 227, 262, 127, 214,\n",
       "         248, 180, 245, 246, 227, 261, 262, 231, 235, 226, 244, 238, 220, 232,\n",
       "         240, 237, 239, 243, 236, 241, 261, 262, 231, 261, 235, 193, 226, 244,\n",
       "         238, 220, 232, 240, 237, 239, 243, 236, 214, 180, 262, 241, 198, 213,\n",
       "         260, 260, 255, 247, 251, 189,  97, 160, 254, 254, 126, 205, 160, 218,\n",
       "         255, 255, 255, 205, 260, 160, 218, 260, 255, 205, 160, 218, 260, 160,\n",
       "         255, 205, 260, 160, 218, 255, 205, 160, 218, 217, 260, 205, 160, 218,\n",
       "         261, 262, 160, 231, 235, 193, 226, 244, 238, 220, 232, 240, 237, 239,\n",
       "         243, 236, 214, 229, 225, 248, 180, 181, 245, 246, 212, 227, 241, 205,\n",
       "         160, 218, 160, 205, 189, 218, 189, 160, 100, 197]),\n",
       " 'ages': tensor([7.0499, 7.0499, 7.0499, 7.0499, 7.0499, 7.1879, 7.1879, 7.1879, 7.1956,\n",
       "         7.4932, 7.6575, 7.6575, 7.6575, 7.8148, 7.8148, 7.8148, 7.8148, 7.8148,\n",
       "         7.8148, 7.8148, 7.8148, 7.8148, 7.8148, 7.8148, 7.8148, 7.8718, 7.8718,\n",
       "         7.8718, 7.8718, 7.8718, 7.8718, 7.8718, 7.8718, 7.8718, 7.8718, 7.9490,\n",
       "         7.9490, 7.9490, 7.9490, 7.9490, 7.9490, 7.9490, 7.9490, 7.9490, 7.9490,\n",
       "         7.9490, 7.9490, 7.9490, 7.9490, 7.9490, 7.9490, 7.9490, 7.9490, 7.9490,\n",
       "         7.9490, 8.1436, 8.1436, 8.1436, 8.1436, 8.1436, 8.1436, 8.1584, 8.1584,\n",
       "         8.2855, 8.2855, 8.2855, 8.2855, 8.2855, 8.2855, 8.2855, 8.2855, 8.2855,\n",
       "         8.2855, 8.2855, 8.2855, 8.2855, 8.3310, 8.3310, 8.4279, 8.4279, 8.4279,\n",
       "         8.4279, 8.4279, 8.4279, 8.4279, 8.4279, 8.4279, 8.4279, 8.4279, 8.4279,\n",
       "         8.4279, 8.4279, 8.4279, 8.4279, 8.4279, 8.4279, 8.4499, 8.4499, 8.4499,\n",
       "         8.4504, 8.4707, 8.5090, 8.5090, 8.5090, 8.5227, 8.5584, 8.5584, 8.5584,\n",
       "         8.5584, 8.5748, 8.5748, 8.5748, 8.5748, 8.5770, 8.5852, 8.5929, 8.5929,\n",
       "         8.5929, 8.5929, 8.5978, 8.5978, 8.6082, 8.6082, 8.6082, 8.6192, 8.6192,\n",
       "         8.6192, 8.6318, 8.6318, 8.6318, 8.6318, 8.6318, 8.6477, 8.6477, 8.6477,\n",
       "         8.6504, 8.6504, 8.6685, 8.6685, 8.6685, 8.6767, 8.6767, 8.6767, 8.6773,\n",
       "         8.6773, 8.6773, 8.6773, 8.6773, 8.6773, 8.6773, 8.6773, 8.6773, 8.6773,\n",
       "         8.6773, 8.6773, 8.6773, 8.6773, 8.6773, 8.6773, 8.6773, 8.6773, 8.6773,\n",
       "         8.6773, 8.6773, 8.6773, 8.6773, 8.6773, 8.6893, 8.6893, 8.6893, 8.7047,\n",
       "         8.7123, 8.7123, 8.7123, 8.7222, 8.7222, 8.7222, 9.1178]),\n",
       " 'values': tensor([-0.3280, -0.3421,  0.1052, -0.3788, -0.2838, -0.3016,  0.1060, -0.3634,\n",
       "         -0.3642,     nan, -0.3053, -0.2081,     nan, -0.4867, -0.4710, -0.1244,\n",
       "         -0.4831, -0.4945, -0.4884, -0.2000, -0.1654, -0.4598, -0.3744, -0.5000,\n",
       "         -0.5000, -0.4828, -0.4730, -0.1133, -0.4814, -0.4859, -0.1949, -0.1629,\n",
       "         -0.4573, -0.3928, -0.5000, -0.4848, -0.2904, -0.3421, -0.4750, -0.4841,\n",
       "         -0.1056, -0.4814, -0.4875, -0.1980, -0.1617, -0.4758, -0.3954, -0.3573,\n",
       "         -0.5000, -0.4904, -0.0253, -0.0455, -0.1153, -0.2676, -0.4955, -0.4953,\n",
       "         -0.4889, -0.4984, -0.0556, -0.0364, -0.0660, -0.3684, -0.2676, -0.4848,\n",
       "         -0.4691, -0.0510, -0.4817, -0.4865, -0.4508, -0.1990, -0.1646, -0.4553,\n",
       "         -0.4010, -0.5000, -0.4901, -0.4983, -0.3526, -0.2027, -0.4828, -0.3211,\n",
       "         -0.4730, -0.3189, -0.0520, -0.4828, -0.4848, -0.4520, -0.1980, -0.1567,\n",
       "         -0.4538, -0.3940, -0.5000, -0.4903, -0.4954, -0.4984, -0.2730, -0.4981,\n",
       "             nan,     nan,     nan,     nan,     nan, -0.2720, -0.3465,     nan,\n",
       "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
       "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
       "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
       "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
       "             nan,     nan,     nan,     nan, -0.3684, -0.2838,     nan, -0.4848,\n",
       "         -0.4700, -0.1176, -0.0860, -0.4852, -0.4880, -0.4500, -0.2010, -0.1721,\n",
       "         -0.4713, -0.4258, -0.5000, -0.4907, -0.4953, -0.3258, -0.4964, -0.4917,\n",
       "         -0.4984,  0.1708, -0.0556, -0.0455, -0.4912, -0.3126, -0.4986,     nan,\n",
       "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
       "             nan,     nan])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.val_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69dc9901-3a78-43f0-8bd3-4b659ca17ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD',\n",
       " 'UNK',\n",
       " 'ADDISONS_DISEASE',\n",
       " 'CYSTICFIBROSIS',\n",
       " 'SYSTEMIC_SCLEROSIS',\n",
       " 'SICKLE_CELL_DISEASE_V2',\n",
       " 'ADDISON_DISEASE',\n",
       " 'DOWNSSYNDROME',\n",
       " 'HAEMOCHROMATOSIS_V2',\n",
       " 'PLASMACELL_NEOPLASM_V2']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  16,  18,  19,  20,  21,  22,  23,  26,  28,  29,  30,  31,  32,\n",
      "         33,  34,  35,  36,  37,  38,  39,  40,  41,  43,  44,  45,  46,  48,\n",
      "         49,  52,  56,  57,  58,  60,  62,  65,  67,  70,  74,  75,  78,  79,\n",
      "         81,  82,  83,  89,  91,  93,  94,  95,  97, 100, 104, 106, 114, 120,\n",
      "        123, 126, 129, 133, 134, 136], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "token_labels = []\n",
    "tokens = []\n",
    "\n",
    "for token, event in enumerate(list(dm.train_set.tokenizer._stoi.keys())):\n",
    "\n",
    "    # only look at diagnoses\n",
    "    if event.upper() == event:\n",
    "        tokens.append(token)\n",
    "        token_labels.append(event)\n",
    "        \n",
    "display(token_labels[:10])\n",
    "\n",
    "tokens = torch.tensor(tokens).to(device)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66856daf-1d8d-44aa-ab6d-96f71aadf510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = torch.arange(265).to(device)[:50]\n",
    "\n",
    "\n",
    "tkn_embedding = experiment.model.transformer.wte.dynamic_embedding_layer(tokens)\n",
    "scaled_tkn_embedding = StandardScaler().fit_transform(tkn_embedding.detach().cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abf2be26-ebad-4608-8ca3-452b3e823a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.close()\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "embedding = reducer.fit_transform(scaled_tkn_embedding)\n",
    "print(embedding.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(embedding[:,0], embedding[:, 1], label=token_labels)\n",
    "for i, txt in enumerate(token_labels):\n",
    "    plt.annotate(txt[:10].lower(), (embedding[i,0], embedding[i,1]))\n",
    "\n",
    "plt.savefig(\"token_embedding.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5ee52-98a7-4267-9b40-676cd8f86c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
