{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4921342e-8ff8-45d4-b1f6-9fe480c2ee1d",
   "metadata": {},
   "source": [
    "# Demo Notebook:\n",
    "## Zero-shot evaluation the Competing Risk Survival Transformer: SurvivEHR\n",
    "\n",
    "Evaluating the pre-trained model on a cohort study for predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a671c59b-4428-4e63-a138-7244418a87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d866c7f0-eaa8-4129-b3b1-d4d6b504d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n",
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from CPRD.examples.modelling.SurvStreamGPT.run_experiment import run\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule, convert_batch_to_none_causal\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "from CPRD.examples.modelling.SurvStreamGPT.setup_zeroshot_experiment import setup_zeroshot_experiment, ZeroShotExperiment\n",
    "\n",
    "import time\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(10000)\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10000\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")\n",
    "\n",
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316b39b-7bd9-43dd-84e5-561c70351a45",
   "metadata": {},
   "source": [
    "## Load configurations\n",
    "Modifying as necesssary for zero-shot application. \n",
    "\n",
    "Here we choose to load in the configuration for a small **pre-trained** 11M parameter model, named \"CR_11M\". We specfiy the zero-shot experiment type, which will lead to running the ```ZeroShotExperiment```. \n",
    "We tell this experiment that no further training is needed. Additionally, we do choose to perform testing. As this is a causal model, this would not test the ability to predict the outcomes of interest, but to perform the causal modelling task on the new dataset. This also allows us to implement outcome predictions as a callback hook at the end of testing.\n",
    "\n",
    "Instead, we want to test the pre-trained model's capacity to predict the relative risk of outcomes. Here, this is to test will check for the pre-trained model's capacity to predict ```COPD``` and ```SUBSTANCEMISUSE```. To do this we point the experiment to the ```FineTune_CVD``` dataset, and set the outcomes of interest. This is performed internally in ```setup_zeroshot_experiment``` through callbacks, in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e00688-1426-4046-910c-45bde94db899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_decoder: true\n",
      "data:\n",
      "  batch_size: 64\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "experiment:\n",
      "  type: zero-shot\n",
      "  project_name: SurvEHR_${head.SurvLayer}\n",
      "  run_id: CR_11M\n",
      "  train: false\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - IHDINCLUDINGMI_OPTIMALV2\n",
      "  - ISCHAEMICSTROKE_V2\n",
      "  - MINFARCTION\n",
      "  - STROKEUNSPECIFIED_V2\n",
      "  - STROKE_HAEMRGIC\n",
      "optim:\n",
      "  num_epochs: 1\n",
      "  learning_rate: 0.0003\n",
      "  scheduler: CAWarmRestarts\n",
      "  scheduler_periods: 5000\n",
      "  scheduler_warmup: true\n",
      "  lr_cosine_decay_period: 10000000.0\n",
      "  val_check_interval: 1000\n",
      "  early_stop: false\n",
      "  early_stop_patience: 5\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.05\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 128\n",
      "  n_layer: 6\n",
      "  n_head: 6\n",
      "  n_embd: 384\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression: None\n",
      "  value_weight: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../../confs\", job_name=\"testing_zeroshot_notebook\"):\n",
    "    cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                  overrides=[\"experiment.type='zero-shot'\",\n",
    "                             \"experiment.run_id='CR_11M'\",\n",
    "                             \"experiment.train=False\",\n",
    "                             \"experiment.test=True\",\n",
    "                             'experiment.fine_tune_outcomes=[\"IHDINCLUDINGMI_OPTIMALV2\", \"ISCHAEMICSTROKE_V2\", \"MINFARCTION\", \"STROKEUNSPECIFIED_V2\", \"STROKE_HAEMRGIC\"]',\n",
    "                             \"data.path_to_ds=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\",\n",
    "                             \"optim.limit_test_batches=null\"\n",
    "                            ]\n",
    "                 )     \n",
    "\n",
    "# cfg.data.batch_size = 1024\n",
    "cfg.data.min_workers = 12\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "save_path = f\"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/{cfg.experiment.run_id}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e0a69-cc78-43d6-8e6c-bac2194a3f1b",
   "metadata": {},
   "source": [
    "# Load Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b018c920-1f4d-40a5-b6a9-a6877430385d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=train/ dataset, with 572,096 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:\n",
      "Creating Zero-Shot experiment. This will evaluate the pre-trained Foundation Model on a clinical prediction model task.\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp2rxat1mx\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp2rxat1mx/_remote_module_non_scriptable.py\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:Internally scaling time in survival head by 1825 days\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1825.0] with 1826 time-points of delta=1.0\n",
      "INFO:root:Creating hidden state embedding callback\n",
      "INFO:root:Creating Clinical Prediction Model callbacks\n",
      "INFO:root:Using outcomes ['IHDINCLUDINGMI_OPTIMALV2', 'ISCHAEMICSTROKE_V2', 'MINFARCTION', 'STROKEUNSPECIFIED_V2', 'STROKE_HAEMRGIC']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:root:Testing model.\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcwlgadd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20240917_123044-5fkw5opo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvEHR_cr/runs/5fkw5opo\" target=\"_blank\">CR_11M</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvEHR_cr\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee65e115b1f4bb3afebe1872e2f4547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -18.695920944213867    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_loss_desurv      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.1813836097717285     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_loss_values      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -39.57323455810547     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -18.695920944213867   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_loss_desurv     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.1813836097717285    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_loss_values     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -39.57323455810547    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 11.433294 M parameters\n"
     ]
    }
   ],
   "source": [
    "model, dm = run(cfg)\n",
    "print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "\n",
    "\n",
    "# Without loading checkpoint (random weights as baseline)\n",
    "# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "# ┃             Test metric             ┃            DataLoader 0             ┃\n",
    "# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "# │  Test:OutcomePerformanceMetricsctd  │         0.5253739953041077          │\n",
    "# │  Test:OutcomePerformanceMetricsibs  │         0.03524600533492127         │\n",
    "# │ Test:OutcomePerformanceMetricsinbll │         0.1908345136916868          │\n",
    "# │              test_loss              │          17.0719051361084           │\n",
    "# │          test_loss_desurv           │          6.091111183166504          │\n",
    "# │          test_loss_values           │         28.052692413330078          │\n",
    "# └─────────────────────────────────────┴─────────────────────────────────────┘\n",
    "\n",
    "# With loading checkpoint\n",
    "# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "# ┃             Test metric             ┃            DataLoader 0             ┃\n",
    "# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "# │  Test:OutcomePerformanceMetricsctd  │         0.5724685192108154          │\n",
    "# │  Test:OutcomePerformanceMetricsibs  │         0.03562949925737146         │\n",
    "# │ Test:OutcomePerformanceMetricsinbll │         0.30187424727675705         │\n",
    "# │              test_loss              │         -18.697189331054688         │\n",
    "# │          test_loss_desurv           │         2.1788339614868164          │\n",
    "# │          test_loss_values           │         -39.57322311401367          │\n",
    "# └─────────────────────────────────────┴─────────────────────────────────────┘\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e2467-bfc5-47cf-8e26-7a38cc093965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078715e-c1dc-4726-bf06-0d6cba9261fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.encode(['Diastolic_blood_pressure_5.png'])\n",
    "display(dm.decode([95, 175, 263,249]).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0352a-f7cc-40ea-b456-97f1e59adcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.tokenizer._event_counts[\"EVENT\"][-5:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e044f-4d3a-4c03-a3aa-c460e1ffd662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d7a7c-242a-4ba1-ae98-2a5ac7ed8d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8bb11-e10a-4319-8050-2703af0e4d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644335f-9a9e-49be-963a-6ed1ca22adf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2db2b285-c23f-4fd2-8e66-e20159e8e271",
   "metadata": {},
   "source": [
    "# Load Pre-Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f37089-e294-46c0-bc4a-ce3ae00300b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ckpt_path = cfg.experiment.log_dir + f'checkpoints/{cfg.experiment.run_id}.ckpt'\n",
    "model = SurvivalExperiment.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae57fb-6ca7-4e7f-9b79-b99bb5a10b52",
   "metadata": {},
   "source": [
    "# Initialise fine-tuning data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e90c2f-04c5-4f31-86f0-4f3800fa9325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update dataset path to point to the new dataset \n",
    "cfg.data.path_to_ds = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "\n",
    "# Build \n",
    "dm = FoundationalDataModule(path_to_db=cfg.data.path_to_db,\n",
    "                            path_to_ds=cfg.data.path_to_ds,\n",
    "                            load=True,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            batch_size=cfg.data.batch_size,\n",
    "                            max_seq_length=cfg.transformer.block_size,\n",
    "                            freq_threshold=cfg.data.unk_freq_threshold,\n",
    "                            min_workers=cfg.data.min_workers,\n",
    "                            overwrite_meta_information=cfg.data.meta_information_path,\n",
    "                           )\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "print(f\"{vocab_size} vocab elements\")\n",
    "\n",
    "# list of univariate measurements to model with Normal distribution\n",
    "# Extract the measurements, using the fact that the diagnoses are all up upper case.\n",
    "measurements_for_univariate_regression = [record for record in dm.tokenizer._event_counts[\"EVENT\"] if record.upper() != record]\n",
    "cfg.head.tokens_for_univariate_regression = dm.encode(measurements_for_univariate_regression) \n",
    "# display(measurements_for_univariate_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7a64a-4a5b-4811-847a-5ad8abe04c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# import pathlib\n",
    "\n",
    "pkl_file_to_amend = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\"\n",
    "\n",
    "with open(pkl_file_to_amend, 'rb') as pickle_file:\n",
    "    content = pickle.load(pickle_file)\n",
    "display(content)\n",
    "\n",
    "# new_dictionary = {}\n",
    "# for key in content.keys():\n",
    "#     str_to_remove = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/\"\n",
    "#     new_key = str(key)[len(str_to_remove):]\n",
    "#     new_dictionary[new_key] = content[key]\n",
    "# display(new_dictionary)\n",
    "\n",
    "\n",
    "# with open(pkl_file_to_amend, 'wb') as handle:\n",
    "#     pickle.dump(new_dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3bd66-0f95-4d0f-9e85-b05bf609037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a45cf-dcbe-4d66-a8fa-34fcc1e4a4de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()   # starting time\n",
    "for batch in dm.train_dataloader():\n",
    "    break\n",
    "print(f\"batch loaded in {time.time()-start} seconds\")    \n",
    "    \n",
    "# for key in batch.keys():\n",
    "#     print(f\"{key}\".ljust(20) + f\"{batch[key].shape}\")\n",
    "\n",
    "# tokens = batch[\"tokens\"][0].tolist()    \n",
    "# sentence = dm.decode(tokens).split(\" \")\n",
    "# for token, value in zip(sentence, batch[\"values\"][0].tolist()):\n",
    "#     print(f\"{token}:\".ljust(40) + f\"{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4c5b5-2121-4d10-8f8e-11a88ed16cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(batch.keys())\n",
    "display(convert_batch_to_none_causal(batch).keys())\n",
    "\n",
    "print(batch[\"static_covariates\"].shape)\n",
    "\n",
    "print(dm.train_set.static_1hot)\n",
    "print(dm.train_set.static_1hot[\"SEX\"].categories_)\n",
    "print(dm.train_set.static_1hot[\"IMD\"].categories_)\n",
    "print(dm.train_set.static_1hot[\"ETHNICITY\"].categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3e15f-1b7c-466b-825e-a84100d224a0",
   "metadata": {},
   "source": [
    "## View an example sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa22fa-ef08-485f-a948-c4ff8b3aade5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm.test_set.view_sample(1354, max_dynamic_events=None, report_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1943eec-f491-4a94-92d9-65b9cedbd433",
   "metadata": {},
   "source": [
    "# Custom wrapper prediction last token\n",
    "\n",
    "To begin with, I will just loop over samples individually to test the zero-shot capacity of SurvivEHR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439343da-a813-4ffa-b0a6-26074e80d11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Verifying on datamodule \n",
    "for _idx, batch in enumerate(dm.test_dataloader()):\n",
    "    if _idx > 10:\n",
    "        break\n",
    "    print(_idx)\n",
    "    print(torch.stack([batch[\"tokens\"][10,:5], \n",
    "                       batch[\"values\"][10,:5],  \n",
    "                       batch[\"ages\"][10,:5],\n",
    "                       batch[\"attention_mask\"][10,:5]]))\n",
    "    batch = replace_last_non_pad_with_pad(batch)\n",
    "    print(torch.stack([batch[\"tokens\"][10,:5], \n",
    "                       batch[\"values\"][10,:5],  \n",
    "                       batch[\"ages\"][10,:5],\n",
    "                       batch[\"attention_mask\"][10,:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c069ad-f41d-420e-819e-cf2c5a390baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_of_interest = [\"COPD\", \"SUBSTANCEMISUSE\"]\n",
    "outcome_token = dm.encode(outcome_of_interest)[0]\n",
    "print(outcome_token)\n",
    "# print(model(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f35b1-02d3-4db9-b376-ca44d9c1f770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Hs, labels = [], []\n",
    "mins,maxes=[],[]\n",
    "for _idx, batch in enumerate(dm.test_dataloader()):\n",
    "\n",
    "    batch = replace_last_non_pad_with_pad(batch)\n",
    "    print(batch[\"tokens\".shape)\n",
    "    outputs, _, hidden_states = model(batch, is_generation=True)\n",
    "    print(outputs)\n",
    "    \n",
    "    hidden_states = hidden_states.cpu().detach().numpy()                           # (64, 128, 384) \n",
    "    Hs.append( hidden_states.reshape(hidden_states.shape[0], -1) )\n",
    "    labels.append((batch[\"target_token\"] == outcome_token).long().numpy())\n",
    "\n",
    "    if _idx == 9:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bf156-cc66-4276-8c8d-23caec948e2d",
   "metadata": {},
   "source": [
    "# Visualise hidden dimension labelled by target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d857d-dbb0-487b-8278-42c04bcbea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "H = np.concatenate(Hs, 0)\n",
    "lbl = np.concatenate(labels, 0)\n",
    "\n",
    "H = StandardScaler().fit_transform(H)\n",
    "reducer = umap.UMAP()\n",
    "H_proj = reducer.fit_transform(H)\n",
    "\n",
    "plt.close()\n",
    "plt.scatter(H_proj[:,0], H_proj[:,1], c=lbl)\n",
    "plt.savefig(save_path + f\"zero_shot/hidden_umap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e686a-ebe9-43d4-8a14-b88df279ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[\"surv\"][\"surv_CDF\"][outcome_token].shape)\n",
    "\n",
    "# The first two tokens in the vocab correspond to the PAD and UNK tokens. There is no CDF corresponding to the PAD token, so the indexing for surv_CDF begins as [\"UNK\", \"ADDISONS_DISEASE\", ...]\n",
    "# print(dm.decode([0,1,2]))\n",
    "\n",
    "outcomes = [\"COPD\", \"SUBSTANCEMISUSE\"]\n",
    "outcome_tokens = dm.encode(outcomes)\n",
    "\n",
    "# for outcome in outcomes:\n",
    "    # observed_outcome_token = dm.encode([outcome])[0]\n",
    "cdf = np.zeros_like(outputs[\"surv\"][\"surv_CDF\"][0])\n",
    "lbls = np.zeros_like(batch[\"target_token\"])\n",
    "\n",
    "for _outcome_token in outcome_tokens:\n",
    "    cdf += outputs[\"surv\"][\"surv_CDF\"][_outcome_token - 1] \n",
    "    lbls += (batch[\"target_token\"] == _outcome_token).long().numpy()\n",
    "\n",
    "plt.close()\n",
    "cdf_true = cdf[lbls==1,:]\n",
    "cdf_false = cdf[lbls==0,:]\n",
    "for i in range(cdf_true.shape[0]):\n",
    "    plt.plot(np.linspace(1,1826,1826), cdf_true[i,:], c=\"r\", label=\"outcome occurred next\" if i == 0 else None, alpha=1)\n",
    "for i in range(cdf_false.shape[0]):\n",
    "    plt.plot(np.linspace(1,1826,1826), cdf_false[i,:], c=\"k\", label=\"outcome did not occur next\" if i == 0 else None, alpha=0.3)\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"P(t>T) - outcomes={','.join(outcomes)}\")\n",
    "plt.savefig(save_path + f\"zero_shot/cdf_outcomes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c2049-56bc-47ff-bcea-ce2e529266e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[\"target_token\"].unique())\n",
    "print(len(outputs[\"surv\"][\"surv_CDF\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3417a-d3c7-42f9-b288-82ab49ddb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90115137-0805-4f93-877b-2d98e51439d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[\"surv\"][\"surv_CDF\"][observed_outcome_token - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacadcc-f857-45e2-94e8-0ca43ccbd196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
