{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Demo Notebook:\n",
    "## SurvivEHR: Competing Risk Survival Transformer For Causal Sequence Modelling \n",
    "\n",
    "In this notebook we demonstrate how a pre-trained model can be used for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvStreamGPT/notebooks/CompetingRisk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from pycox.evaluation import EvalSurv\n",
    "from tqdm import tqdm\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from CPRD.examples.modelling.SurvStreamGPT.run_experiment import run\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Version of SurvStreamGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_decoder: true\n",
      "data:\n",
      "  batch_size: 64\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 20\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "experiment:\n",
      "  type: pre-train\n",
      "  project_name: SurvStreamGPT_${head.SurvLayer}\n",
      "  run_id: CR_11M\n",
      "  train: false\n",
      "  test: false\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: false\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes: None\n",
      "optim:\n",
      "  num_epochs: 1\n",
      "  learning_rate: 0.0003\n",
      "  scheduler: CAWarmRestarts\n",
      "  scheduler_periods: 5000\n",
      "  scheduler_warmup: true\n",
      "  lr_cosine_decay_period: 10000000.0\n",
      "  val_check_interval: 1000\n",
      "  early_stop: false\n",
      "  early_stop_patience: 5\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.05\n",
      "  limit_test_batches: 0.05\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 128\n",
      "  n_layer: 6\n",
      "  n_head: 6\n",
      "  n_embd: 384\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression: None\n",
      "  value_weight: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../../confs\", job_name=\"testing_notebook\"):\n",
    "    cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                  # overrides=[\n",
    "                  #     ]\n",
    "                 )\n",
    "\n",
    "# Just load in pretrained model\n",
    "cfg.experiment.train = False\n",
    "cfg.experiment.test = False\n",
    "cfg.experiment.log = False\n",
    "cfg.experiment.run_id=\"CR_11M\"\n",
    "\n",
    "\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "save_path = f\"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/{cfg.experiment.run_id}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=train/ dataset, with 23,613,894 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=test/ dataset, with 1,508,320 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=val/ dataset, with 1,426,714 samples\n",
      "INFO:root:265 vocab elements\n",
      "INFO:root:Running Causal experiment. This will create a pre-trained Foundation Model\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmplig9v2a7\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmplig9v2a7/_remote_module_non_scriptable.py\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:Internally scaling time in survival head by 1825 days\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1825.0] with 1826 time-points of delta=1.0\n",
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch/2.0.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "INFO:root:Loading from cached checkpoint /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M.ckpt\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:Internally scaling time in survival head by 1825 days\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1825.0] with 1826 time-points of delta=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 11.433294 M parameters\n"
     ]
    }
   ],
   "source": [
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28      \n",
    "\n",
    "model, dm = run(cfg)     \n",
    "print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to retrieve sample index 10 was 0.2120823860168457 seconds\n",
      "\n",
      "SEX                 | F\n",
      "IMD                 | 1.0\n",
      "ETHNICITY           | WHITE\n",
      "birth_year          | 1998.0\n",
      "Sequence of 58 events\n",
      "\n",
      "Token                                                                      | Age               | Standardised value\n",
      "===================================================================================================================\n",
      "Systemic_oral_corticosteroids_optimal                                      | 82                | nan               \n",
      "ATOPICECZEMA                                                               | 601               | nan               \n",
      "First_gen_H1_antihistamines                                                | 5691              | nan               \n",
      "Current_smoker_83                                                          | 6035              | nan               \n",
      "Diastolic_blood_pressure_5                                                 | 6035              | -0.38             \n",
      "Systolic_blood_pressure_4                                                  | 6035              | -0.29             \n",
      "COCP_reg_contraception                                                     | 6035              | nan               \n",
      "all_contraceptive                                                          | 6035              | nan               \n",
      "Body_mass_index_3                                                          | 6138              | -0.37             \n",
      "Diastolic_blood_pressure_5                                                 | 6138              | -0.38             \n",
      "Ex_smoker_84                                                               | 6138              | nan               \n",
      "O_E___height_1                                                             | 6138              | 0.05              \n",
      "O_E___weight_2                                                             | 6138              | -0.42             \n",
      "Systolic_blood_pressure_4                                                  | 6138              | -0.28             \n",
      "COCP_reg_contraception                                                     | 6138              | nan               \n",
      "all_contraceptive                                                          | 6138              | nan               \n",
      "COCP_reg_contraception                                                     | 6217              | nan               \n",
      "all_contraceptive                                                          | 6217              | nan               \n",
      "COCP_reg_contraception                                                     | 6300              | nan               \n",
      "all_contraceptive                                                          | 6300              | nan               \n",
      "Body_mass_index_3                                                          | 6386              | -0.36             \n",
      "Diastolic_blood_pressure_5                                                 | 6386              | -0.35             \n",
      "O_E___height_1                                                             | 6386              | 0.05              \n",
      "O_E___weight_2                                                             | 6386              | -0.41             \n",
      "Systolic_blood_pressure_4                                                  | 6386              | -0.31             \n",
      "COCP_reg_contraception                                                     | 6386              | nan               \n",
      "all_contraceptive                                                          | 6386              | nan               \n",
      "Diastolic_blood_pressure_5                                                 | 6669              | -0.37             \n",
      "Systolic_blood_pressure_4                                                  | 6669              | -0.29             \n",
      "Body_mass_index_3                                                          | 7350              | -0.33             \n",
      "Diastolic_blood_pressure_5                                                 | 7350              | -0.36             \n",
      "O_E___weight_2                                                             | 7350              | -0.40             \n",
      "Systolic_blood_pressure_4                                                  | 7350              | -0.30             \n",
      "Basophil_count_22                                                          | 7351              | -0.49             \n",
      "Eosinophil_count_21                                                        | 7351              | -0.48             \n",
      "GFR_calculated_abbreviated_MDRD_34                                         | 7351              | -0.20             \n",
      "Haematocrit_15                                                             | 7351              | -0.07             \n",
      "Haemoglobin_estimation_9                                                   | 7351              | -0.03             \n",
      "Lymphocyte_count_20                                                        | 7351              | -0.49             \n",
      "Mean_corpusc_haemoglobin_MCH__13                                           | 7351              | -0.19             \n",
      "Mean_corpuscular_volume__MCV__11                                           | 7351              | -0.15             \n",
      "Monocyte_count_23                                                          | 7351              | -0.48             \n",
      "Neutrophil_count_19                                                        | 7351              | -0.46             \n",
      "Platelet_count_12                                                          | 7351              | -0.50             \n",
      "Red_blood_cell__RBC__count_10                                              | 7351              | -0.49             \n",
      "Serum_C_reactive_protein_level_59                                          | 7351              | 0.01              \n",
      "Serum_C_reactive_protein_level_59                                          | 7351              | nan               \n",
      "Serum_alanine_aminotransferase_level_45                                    | 7351              | -0.50             \n",
      "Serum_albumin_51                                                           | 7351              | -0.28             \n",
      "Serum_creatinine_31                                                        | 7351              | -0.49             \n",
      "Serum_ferritin_63                                                          | 7351              | -0.50             \n",
      "Serum_gamma_glutamyl_transferase_level_57                                  | 7351              | -0.18             \n",
      "Serum_potassium_26                                                         | 7351              | -0.06             \n",
      "Serum_sodium_24                                                            | 7351              | -0.03             \n",
      "Serum_total_bilirubin_level_56                                             | 7351              | -0.49             \n",
      "Serum_urea_level_29                                                        | 7351              | -0.05             \n",
      "Total_white_cell_count_18                                                  | 7351              | -0.50             \n",
      "all_contraceptive                                                          | 7744              | nan               \n"
     ]
    }
   ],
   "source": [
    "dm.train_set.view_sample(10, max_dynamic_events=None, report_time=True)\n",
    "\n",
    "# for batch in dm.train_dataloader():\n",
    "#     break\n",
    "# print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0675, -0.3773]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Default context start\n",
    "baseline_covariates = {\"sex\": \"F\", \"deprivation\": 1.0, \"ethnicity\": \"WHITE\", \"year_of_birth\": 1997-40}\n",
    "prompt = [\"O_E___height_1\", \"O_E___weight_2\"]\n",
    "values = [163, 80]\n",
    "ages_in_years = [18.2, 18.2]\n",
    "\n",
    "# define encoding functions (TODO: add this wrap to datamodule\n",
    "encode_prompt = lambda prompt_list: torch.from_numpy(np.array(dm.encode(prompt_list)).reshape((1,-1))).to(device)\n",
    "encode_value = lambda prompt_list, value_list: torch.tensor(np.array([dm.standardise(_cat, _val) for _cat, _val in zip(prompt_list, value_list) ]).reshape((1,-1)), dtype=torch.float32).to(device)\n",
    "encode_age = lambda age_list: torch.tensor([365 * _age for _age in age_list], dtype=torch.int64).reshape((1,-1)).to(device)\n",
    "\n",
    "# Convert for model\n",
    "covariates = dm.train_set._encode_covariates(**baseline_covariates).reshape(1,-1).to(device)\n",
    "tokens = encode_prompt(prompt)\n",
    "values_scaled = encode_value(prompt, values)\n",
    "ages_in_days = encode_age(ages_in_years)\n",
    "\n",
    "print(values_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline covariates: \n",
      "{'sex': 'F', 'deprivation': 1.0, 'ethnicity': 'WHITE', 'year_of_birth': 1957}\n",
      "==========================================================================================\n",
      "PROMPT:\n",
      "O_E___height_1                                    0.07           at age 18 (6643 days)\n",
      "O_E___weight_2                                    -0.38          at age 18 (6643 days)\n",
      "==========================================================================================\n",
      "GENERATION\n",
      "Serum_TSH_level_71                                -0.48          at age 18 (6643 days)\n",
      "Serum_free_T4_level_75                            -0.50          at age 18 (6649 days)\n",
      "Serum_total_cholesterol_level_98                  -0.44          at age 18 (6652 days)\n",
      "Serum_urea_level_29                               -0.11          at age 18 (6654 days)\n",
      "Total_white_cell_count_18                         -0.50          at age 18 (6655 days)\n",
      "Body_mass_index_3                                 -0.35          at age 20 (7441 days)\n",
      "Never_smoked_tobacco_85                           0.07           at age 20 (7441 days)\n",
      "O_E___weight_2                                    -0.40          at age 20 (7443 days)\n",
      "Haemoglobin_estimation_9                          -0.33          at age 20 (7446 days)\n",
      "Mean_corpusc_haemoglobin_MCH__13                  -0.21          at age 20 (7446 days)\n",
      "Mean_corpuscular_volume__MCV__11                  -0.16          at age 20 (7446 days)\n",
      "Free_T4_level_76                                  -0.47          at age 20 (7473 days)\n",
      "Total_white_cell_count_18                         -0.50          at age 20 (7473 days)\n",
      "PREVALENT_IBS_V2                                  nan            at age 21 (7549 days)\n",
      "Body_mass_index_3                                 -0.34          at age 21 (7775 days)\n",
      "Diastolic_blood_pressure_5                        -0.36          at age 21 (7797 days)\n",
      "Systolic_blood_pressure_4                         -0.21          at age 21 (7797 days)\n",
      "COCP_reg_contraception                            nan            at age 21 (7799 days)\n",
      "all_contraceptive                                 nan            at age 21 (7799 days)\n",
      "Body_mass_index_3                                 -0.35          at age 22 (7955 days)\n",
      "Diastolic_blood_pressure_5                        -0.35          at age 22 (7977 days)\n",
      "O_E___height_1                                    0.06           at age 22 (7977 days)\n",
      "O_E___weight_2                                    -0.40          at age 22 (7977 days)\n",
      "SSRIs_Optimal                                     nan            at age 22 (8035 days)\n",
      "SSRIs_Optimal                                     nan            at age 22 (8063 days)\n",
      "COCP_reg_contraception                            nan            at age 22 (8098 days)\n",
      "all_contraceptive                                 nan            at age 22 (8098 days)\n",
      "all_contraceptive                                 nan            at age 22 (8103 days)\n",
      "all_contraceptive                                 nan            at age 22 (8112 days)\n",
      "SSRIs_Optimal                                     nan            at age 22 (8159 days)\n",
      "First_gen_H1_antihistamines                       nan            at age 22 (8169 days)\n",
      "SSRIs_Optimal                                     nan            at age 23 (8260 days)\n",
      "SSRIs_Optimal                                     nan            at age 23 (8300 days)\n",
      "SSRIs_Optimal                                     nan            at age 23 (8404 days)\n",
      "Basophil_count_22                                 -0.49          at age 23 (8468 days)\n",
      "Corrected_serum_calcium_level_42                  -0.29          at age 23 (8471 days)\n",
      "Eosinophil_count_21                               -0.46          at age 23 (8471 days)\n",
      "Haematocrit_15                                    -0.09          at age 23 (8478 days)\n",
      "Haemoglobin_estimation_9                          -0.21          at age 23 (8487 days)\n",
      "Serum_HDL_cholesterol_level_100                   -0.18          at age 23 (8490 days)\n",
      "Serum_alanine_aminotransferase_level_45           -0.50          at age 23 (8492 days)\n",
      "Serum_albumin_51                                  -0.28          at age 23 (8493 days)\n",
      "Serum_alkaline_phosphatase_50                     -0.50          at age 23 (8494 days)\n",
      "Serum_creatinine_31                               -0.49          at age 23 (8494 days)\n",
      "Serum_potassium_26                                -0.10          at age 23 (8495 days)\n",
      "Serum_sodium_24                                   -0.05          at age 23 (8499 days)\n",
      "Serum_total_bilirubin_level_56                    -0.48          at age 23 (8501 days)\n",
      "Serum_urea_level_29                               -0.20          at age 23 (8501 days)\n",
      "Total_white_cell_count_18                         -0.50          at age 23 (8505 days)\n",
      "eGFR_using_creatinine_CKD_EPI_per_1_73_square_metres_33-0.30          at age 23 (8505 days)\n"
     ]
    }
   ],
   "source": [
    "# generate: sample the next 10 tokens\n",
    "new_tokens, new_ages, new_values = model.generate(tokens, ages_in_days, values_scaled, covariates, max_new_tokens=50)\n",
    "\n",
    "# report:\n",
    "print(f\"Baseline covariates: \\n{baseline_covariates}\\n\" + \"=\"*90)\n",
    "print(f\"PROMPT:\")\n",
    "for _idx, (_cat, _age, _value) in enumerate(zip(dm.decode(new_tokens[0].tolist()).split(\" \"), \n",
    "                                                new_ages[0, :], \n",
    "                                                new_values[0, :]\n",
    "                                               )\n",
    "                                           ):\n",
    "    # _value = dm.unstandardise(_cat, _value)\n",
    "    print(f\"{_cat}\".ljust(50) + f\"{_value:.02f}\".ljust(15) + f\"at age {_age/365:.0f} ({int(_age)} days)\")    # with value {_value}\n",
    "    if _idx == tokens.shape[-1] - 1:\n",
    "        print(\"=\"*90)\n",
    "        print(f\"GENERATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnoses: How related conditions are impacted by each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_prompts = [[\"DEPRESSION\"], [\"TYPE1DM\"], [\"TYPE2DIABETES\"], [\"Never_smoked_tobacco_85\"], [\"Ex_smoker_84\"]]\n",
    "exp_ages = [[20] for _ in range(len(exp_prompts))]\n",
    "exp_values = [[np.nan] for _ in range(len(exp_prompts))]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, (_exp_prompt, _exp_age, _exp_value) in enumerate(zip(exp_prompts, \n",
    "                                                                    exp_ages, \n",
    "                                                                    exp_values)):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "        \n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_causal=False,\n",
    "                              return_loss=False,\n",
    "                              return_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        for p_idx in range(len(exp_prompts)):\n",
    "            plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{'->'.join(exp_prompts[p_idx]).lower()}\")\n",
    "        plt.xlabel(\"Time (years)\")\n",
    "        plt.ylabel(f\"$P(T>t)$ ({event_name})\")\n",
    "        plt.legend()\n",
    "        plt.savefig(save_path + f\"diabetes/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing BMI affects diagnosis risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\",\n",
    "                      \"DEATH\"\n",
    "                     ]\n",
    "\n",
    "_exp_prompt = [\"Body_mass_index_3\"]\n",
    "_exp_age = [40]\n",
    "_exp_values = [[18.], [21.], [24.], [30.], [40.]]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, _exp_value in enumerate(_exp_values):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "\n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_causal=False,\n",
    "                              return_loss=False,\n",
    "                              return_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        if event_name in events_of_interest:\n",
    "            for p_idx in range(len(_exp_values)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{_exp_values[p_idx][0]:.2f}\")\n",
    "            plt.xlabel(\"t (years)\")\n",
    "            plt.ylabel(f\"$P(T>t)$ ({event_name})\")\n",
    "            plt.legend()\n",
    "            plt.savefig(save_path + f\"bmi/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing DBP affects diagnosis risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\",\n",
    "                      \"DEATH\"\n",
    "                     ]\n",
    "\n",
    "\n",
    "_exp_prompt = [\"Diastolic_blood_pressure_5\"]\n",
    "_exp_age = [40]\n",
    "_exp_values = [[60.], [70.], [80.], [90.], [100.], [110.]]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, _exp_value in enumerate(_exp_values):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "\n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_causal=False,\n",
    "                              return_loss=False,\n",
    "                              return_generation=True\n",
    "                             )\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        if event_name in events_of_interest:\n",
    "            for p_idx in range(len(_exp_values)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{_exp_values[p_idx][0]:.2f}\")\n",
    "            plt.xlabel(\"t (years)\")\n",
    "            plt.ylabel(\"P(T>t) ()\")\n",
    "            plt.legend()\n",
    "            plt.savefig(save_path + f\"diastolic_blood_pressure/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How varying diagnosis affects value of DBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRESSION                    leads to            standardised Diastolic_blood_pressure_5 ~ N(-0.4, 0.0)\n",
      "TYPE2DIABETES                 leads to            standardised Diastolic_blood_pressure_5 ~ N(-0.3, 0.0)\n",
      "HF_V3                         leads to            standardised Diastolic_blood_pressure_5 ~ N(-0.4, 0.0)\n",
      "HYPERTENSION                  leads to            standardised Diastolic_blood_pressure_5 ~ N(-0.4, 0.0)\n"
     ]
    }
   ],
   "source": [
    "measurements_of_interest = \"Diastolic_blood_pressure_5\"\n",
    "\n",
    "\n",
    "_exp_prompts = [[\"DEPRESSION\"], [\"TYPE2DIABETES\"], [\"HF_V3\"], [\"HYPERTENSION\"]]\n",
    "_exp_age = [20]\n",
    "_exp_value = [np.nan]\n",
    "\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    for p_idx, _exp_prompt in enumerate(_exp_prompts):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "        \n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_causal=False,\n",
    "                              return_loss=False,\n",
    "                              return_generation=True\n",
    "                             )\n",
    "        val_dist = outputs[\"values_dist\"]\n",
    "\n",
    "        dist = val_dist[model.value_layer.token_key(dm.tokenizer._stoi[measurements_of_interest])]\n",
    "        print(f\"{'->'.join(_exp_prompt)}\".ljust(30) + \"leads to\".ljust(20) + f\"standardised {measurements_of_interest} ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing bmi affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body_mass_index_3 of 18.0     leads to            standardised Diastolic_blood_pressure_5 ~ N(-0.4, 0.0)\n",
      "Body_mass_index_3 of 21.0     leads to            standardised Diastolic_blood_pressure_5 ~ N(-0.4, 0.0)\n",
      "Body_mass_index_3 of 24.0     leads to            standardised Diastolic_blood_pressure_5 ~ N(-0.4, 0.0)\n",
      "Body_mass_index_3 of 30.0     leads to            standardised Diastolic_blood_pressure_5 ~ N(-0.4, 0.0)\n",
      "Body_mass_index_3 of 40.0     leads to            standardised Diastolic_blood_pressure_5 ~ N(-0.4, 0.0)\n"
     ]
    }
   ],
   "source": [
    "measurements_of_interest = \"Diastolic_blood_pressure_5\"\n",
    "\n",
    "\n",
    "_exp_prompt = [\"Body_mass_index_3\"]\n",
    "_exp_values = [[18.], [21.], [24.], [30.], [40.]]\n",
    "_exp_value = [np.nan]\n",
    "\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    for p_idx, _exp_value in enumerate(_exp_values):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "        \n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_causal=False,\n",
    "                              return_loss=False,\n",
    "                              return_generation=True\n",
    "                             )\n",
    "        val_dist = outputs[\"values_dist\"]\n",
    "\n",
    "        dist = val_dist[model.value_layer.token_key(dm.tokenizer._stoi[measurements_of_interest])]\n",
    "        print(f\"{'->'.join(_exp_prompt)} of {_exp_value[0]}\".ljust(30) + \"leads to\".ljust(20) + f\"standardised {measurements_of_interest} ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, impact of gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\",\n",
    "                      \"POLYCYSTIC_OVARIAN_SYNDROME_PCOS_V2\",\n",
    "                      \"DEATH\",\n",
    "                      \"COCP_reg_contraception\",\n",
    "                      \"all_contraceptive\"\n",
    "                     ]\n",
    "\n",
    "_genders = [\"M\", \"F\", \"I\"]\n",
    "_exp_prompt = [\"Diastolic_blood_pressure_5\"]\n",
    "_exp_age = [20]\n",
    "_exp_value = [90.]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, _gender in enumerate(_genders):\n",
    "\n",
    "        _baseline_covariate = {\"sex\": _gender, \"deprivation\": 4.0, \"ethnicity\": \"WHITE\", \"year_of_birth\": 1997}\n",
    "        _covariates = dm.train_set._encode_covariates(**_baseline_covariate).reshape(1,-1).to(device)\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "\n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=_covariates,\n",
    "                              is_causal=False,\n",
    "                              return_loss=False,\n",
    "                              return_generation=True\n",
    "                             )        \n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        if event_name in events_of_interest:\n",
    "            for p_idx in range(len(_genders)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{_genders[p_idx]}\")\n",
    "            plt.xlabel(\"t (years)\")\n",
    "            plt.ylabel(\"P(T>t) ()\")\n",
    "            plt.legend()\n",
    "            plt.savefig(save_path + f\"gender/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurvStreamGPTForCausalModelling(\n",
       "  (transformer): TTETransformer(\n",
       "    (wpe): TemporalPositionalEncoding()\n",
       "    (wte): DataEmbeddingLayer(\n",
       "      (static_proj): Linear(in_features=16, out_features=384, bias=True)\n",
       "      (dynamic_embedding_layer): SplitDynamicEmbeddingLayer(\n",
       "        (cat_event_embed_layer): Embedding(265, 384, padding_idx=0)\n",
       "        (cat_event_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (num_value_embed_layer): EmbeddingBag(265, 384, mode='sum', padding_idx=0)\n",
       "        (num_value_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiHeadedSelfAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (acti): ReLU()\n",
       "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (surv_layer): ODESurvCompetingRiskLayer(\n",
       "    (sr_ode): ODESurvMultiple(\n",
       "      (pinet): FCNet(\n",
       "        (mapping): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=264, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "      )\n",
       "      (odenet): CondODENet(\n",
       "        (BaseNet): FCNet(\n",
       "          (mapping): Sequential(\n",
       "            (0): Linear(in_features=385, out_features=264, bias=True)\n",
       "            (1): Softplus(beta=1, threshold=20)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (value_layer): GaussianRegressionLayer(\n",
       "    (regression_layers): ModuleDict(\n",
       "      (Token 84): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 86): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 107): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 154): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 42): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 231): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 63): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 85): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 247): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 51): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 103): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 146): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 66): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 172): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 152): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 261): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 235): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 193): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 184): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 101): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 223): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 135): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 226): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 202): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 145): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 244): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 165): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 64): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 185): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 238): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 220): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 232): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 240): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 237): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 17): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 239): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 217): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 118): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 219): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 251): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 25): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 150): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 111): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 102): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 15): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 110): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 130): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 128): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 122): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 99): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 77): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 96): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 140): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 50): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 80): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 108): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 138): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 27): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 139): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 125): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 117): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 105): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 109): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 243): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 236): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 208): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 98): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 176): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 209): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 194): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 61): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 73): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 214): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 206): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 229): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 225): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 183): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 186): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 215): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 187): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 248): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 179): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 163): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 180): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 181): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 153): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 245): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 54): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 246): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 112): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 212): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 141): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 204): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 227): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 173): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 55): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 119): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 262): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 127): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 71): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 59): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 144): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 113): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 170): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 241): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 168): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 47): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (Token 159): Linear(in_features=384, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 2_generation.ipynb to html\n",
      "[NbConvertApp] Writing 601747 bytes to 2_generation.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html --no-input 2_generation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
