{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4921342e-8ff8-45d4-b1f6-9fe480c2ee1d",
   "metadata": {},
   "source": [
    "# CPRD Notebook:\n",
    "## Evaluation of fine-tuning the pre-trained SurvivEHR-CR model on a supervised cohort study.\n",
    "\n",
    "Cohort study: predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population.\n",
    "\n",
    "This notebook quantifies the performance obtained when fine-tuning the pre-trained model to a sub-population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a671c59b-4428-4e63-a138-7244418a87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvStreamGPT/notebooks/CompetingRisk/CVD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d866c7f0-eaa8-4129-b3b1-d4d6b504d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n",
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from CPRD.examples.modelling.SurvStreamGPT.run_experiment import run\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "\n",
    "import time\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(10000)\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10000\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")\n",
    "\n",
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c237f8-679a-4fe4-a570-2c8c7b61da9b",
   "metadata": {},
   "source": [
    "# Choosing configurations\n",
    "The default configuration is for pre-training. Here we modify as necesssary\n",
    "\n",
    "Here we choose to load in the configuration for a small **pre-trained** 11.4M parameter model, named \"CR_11M\". We specfiy the `fine-tune` experiment type, which will lead to running the ```SupervisedExperiment```. \n",
    "\n",
    "We tell this experiment that we want to perform training (true by default). Additionally, we do choose to perform testing (true by default). As this is a supervised model, this tests the ability to predict the outcomes of interest. In this notebook, this is chosen to be those of the cohort study for predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population, and we add the folder containing this dataset to the configuration. \n",
    "\n",
    "```Note: As this is a supervised dataset, we need to tell the DataModule that the last event observed is a target and must be stripped. This is done by passing a list of targets to the configuration, overriding the null default. This lets the DataModule know that it should process batches as supervised.```\n",
    "\n",
    "We set the number of workers to be appropriate for the number of CPUs available to reduce bottlenecking, and tell the experiment that we do not want to limit the number of testing batches. In addition, we specify where we want any checkpoints to be saved to avoid bloating the repository.\n",
    "\n",
    "We design a new optimisation strategy for fine-tuning. Pre-training was achieved with a warmup and cosine annealing, with rates which are no appropriate for much smaller dataset sizes seen in clinical prediction models (CPMs). We here choose a simpler strategy: of ReduceOnPlateau with no warmup, increasing the number of epochs (default is 1) and reduced validation intervals, and the addition of early stopping. Additionally, as this is not a causal model we can increase the batch size. Finally, as this CPM is not trying to predict the value of any outcomes, we set the value weight to zero allowing the model to focus entirely on optimising survival outcome prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612bb987-1923-4f44-bf3d-d74952b33380",
   "metadata": {},
   "source": [
    "# Small 11.4M parameter model\n",
    "\n",
    "```\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃             Test metric             ┃            DataLoader 0             ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│  Test:OutcomePerformanceMetricsctd  │         0.6582537293434143          │\n",
    "│  Test:OutcomePerformanceMetricsibs  │        0.033626483186099766         │\n",
    "│ Test:OutcomePerformanceMetricsinbll │         0.14357818411009718         │\n",
    "│              test_loss              │          9.273333549499512          │\n",
    "│          test_loss_desurv           │          9.273333549499512          │\n",
    "└─────────────────────────────────────┴─────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e00688-1426-4046-910c-45bde94db899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running sr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/split=train/ dataset, with 572,096 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 64\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "experiment:\n",
      "  type: few-shot\n",
      "  project_name: SurvivEHR\n",
      "  run_id: 'NULL'\n",
      "  fine_tune_id: hypertension-few-shot-sr\n",
      "  train: true\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - HYPERTENSION\n",
      "optim:\n",
      "  num_epochs: 100\n",
      "  learning_rate: 0.0003\n",
      "  scheduler_warmup: false\n",
      "  scheduler: ReduceOnPlateau\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 50\n",
      "  early_stop: true\n",
      "  early_stop_patience: 20\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.025\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 10\n",
      "  n_head: 8\n",
      "  n_embd: 1024\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "head:\n",
      "  SurvLayer: sr\n",
      "  surv_weight: 1\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Few-shot learning experiment.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating new few-shot model from scratch.\n",
      "INFO:root:Running few-shot experiment with outcomes {'HYPERTENSION': 129}\n",
      "INFO:root:Creating new experiment\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpkiv20ag4\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpkiv20ag4/_remote_module_non_scriptable.py\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Single-Risk DeSurvival head. This module predicts an independent survival curve for each possible future event.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:root:Training model.\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcwlgadd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241112_191714-2q54nlgb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/2q54nlgb\" target=\"_blank\">NULL_hypertension-few-shot-sr</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvivEHR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:Using ReduceLROnPlateau scheduler\n",
      "INFO:root:Not using warm-up in scheduler\n",
      "\n",
      "  | Name  | Type                            | Params\n",
      "----------------------------------------------------------\n",
      "0 | model | SurvStreamGPTForCausalModelling | 128 M \n",
      "----------------------------------------------------------\n",
      "128 M     Trainable params\n",
      "512       Non-trainable params\n",
      "128 M     Total params\n",
      "515.259   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b2e782b094483ab552eb31b7605ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0955273be04272a263d824702bf323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_trained_models = [\"NULL\"] # [\"SR_11M_24_11_01_big_posencscale_\", \"NULL\"]\n",
    "experiments = [\"hypertension\", \"cvd\"] \n",
    "\n",
    "for pre_trained_model in pre_trained_models:\n",
    "\n",
    "    for experiment in experiments:\n",
    "    \n",
    "        # load the configuration file, override any settings \n",
    "        with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "            cfg = compose(config_name=\"config_CompetingRisk37M\", \n",
    "                          overrides=[# Experiment setup\n",
    "                                     \"experiment.type='few-shot'\",\n",
    "                                     f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                                     f\"experiment.fine_tune_id='{experiment}-few-shot-sr'\",\n",
    "                                     \"experiment.train=True\",\n",
    "                                     \"experiment.test=True\",\n",
    "                                     # Dataloader\n",
    "                                     \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                                     \"data.min_workers=12\",\n",
    "                                     # Optimiser\n",
    "                                     \"optim.num_epochs=100\",\n",
    "                                     \"optim.limit_test_batches=null\",\n",
    "                                     \"optim.scheduler=ReduceOnPlateau\",\n",
    "                                     \"optim.scheduler_warmup=False\",\n",
    "                                     # \"optim.scheduler_periods=250\",\n",
    "                                     \"optim.learning_rate=3e-4\",\n",
    "                                     \"optim.val_check_interval=50\",\n",
    "                                     \"optim.early_stop=True\",\n",
    "                                     \"optim.early_stop_patience=20\",\n",
    "                                     # Head\n",
    "                                     \"head.surv_weight=1\",\n",
    "                                     \"head.value_weight=0\",\n",
    "                                     \"head.SurvLayer='sr'\"\n",
    "                                    ]\n",
    "                         )     \n",
    "    \n",
    "        \n",
    "        match experiment.lower():\n",
    "            case \"cvd\":\n",
    "                cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "                cfg.experiment.fine_tune_outcomes=[\"IHDINCLUDINGMI_OPTIMALV2\", \"ISCHAEMICSTROKE_V2\", \"MINFARCTION\", \"STROKEUNSPECIFIED_V2\", \"STROKE_HAEMRGIC\"]\n",
    "            case \"hypertension\":\n",
    "                cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\"\n",
    "                cfg.experiment.fine_tune_outcomes=[\"HYPERTENSION\"]\n",
    "                \n",
    "        wandb.finish()\n",
    "        experiment, dm = run(cfg)\n",
    "        print(f\"Loaded model with {sum(p.numel() for p in experiment.model.parameters())/1e6} M parameters\")\n",
    "        wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84b03c-0a55-4c28-8297-c9cd2abe9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for batch in dm.train_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667745b2-e16c-49c4-af81-8545d8eb33ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dm.train_set.view_sample(1, max_dynamic_events=4)\n",
    "\n",
    "display(batch[\"tokens\"][0, :])\n",
    "display(batch[\"target_token\"][0])\n",
    "\n",
    "experiment.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dc5dd-bfe4-4435-9683-250b6dda92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.encode(cfg.experiment.fine_tune_outcomes)\n",
    "display(dm.decode([0]))\n",
    "display(len(list(dm.train_set.tokenizer._event_counts[\"EVENT\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59b00d-f391-4500-9acd-1aa6593577e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e2467-bfc5-47cf-8e26-7a38cc093965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import wandb\n",
    "print(model)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078715e-c1dc-4726-bf06-0d6cba9261fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.encode(['IHDINCLUDINGMI_OPTIMALV2', 'ISCHAEMICSTROKE_V2', 'MINFARCTION', 'STROKEUNSPECIFIED_V2', 'STROKE_HAEMRGIC'])\n",
    "# display(dm.decode([95, 175, 263,249]).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0352a-f7cc-40ea-b456-97f1e59adcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.tokenizer._event_counts[\"EVENT\"][-5:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e044f-4d3a-4c03-a3aa-c460e1ffd662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d7a7c-242a-4ba1-ae98-2a5ac7ed8d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8bb11-e10a-4319-8050-2703af0e4d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644335f-9a9e-49be-963a-6ed1ca22adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/{cfg.experiment.run_id}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2b285-c23f-4fd2-8e66-e20159e8e271",
   "metadata": {},
   "source": [
    "# Load Pre-Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f37089-e294-46c0-bc4a-ce3ae00300b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ckpt_path = cfg.experiment.log_dir + f'checkpoints/{cfg.experiment.run_id}.ckpt'\n",
    "model = SurvivalExperiment.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae57fb-6ca7-4e7f-9b79-b99bb5a10b52",
   "metadata": {},
   "source": [
    "# Initialise fine-tuning data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e90c2f-04c5-4f31-86f0-4f3800fa9325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update dataset path to point to the new dataset \n",
    "cfg.data.path_to_ds = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "\n",
    "# Build \n",
    "dm = FoundationalDataModule(path_to_db=cfg.data.path_to_db,\n",
    "                            path_to_ds=cfg.data.path_to_ds,\n",
    "                            load=True,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            batch_size=cfg.data.batch_size,\n",
    "                            max_seq_length=cfg.transformer.block_size,\n",
    "                            freq_threshold=cfg.data.unk_freq_threshold,\n",
    "                            min_workers=cfg.data.min_workers,\n",
    "                            overwrite_meta_information=cfg.data.meta_information_path,\n",
    "                           )\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "print(f\"{vocab_size} vocab elements\")\n",
    "\n",
    "# list of univariate measurements to model with Normal distribution\n",
    "# Extract the measurements, using the fact that the diagnoses are all up upper case.\n",
    "measurements_for_univariate_regression = [record for record in dm.tokenizer._event_counts[\"EVENT\"] if record.upper() != record]\n",
    "cfg.head.tokens_for_univariate_regression = dm.encode(measurements_for_univariate_regression) \n",
    "# display(measurements_for_univariate_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7a64a-4a5b-4811-847a-5ad8abe04c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # import pickle as pkl\n",
    "# # import pathlib\n",
    "\n",
    "# pkl_file_to_amend = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\"\n",
    "\n",
    "# with open(pkl_file_to_amend, 'rb') as pickle_file:\n",
    "#     content = pickle.load(pickle_file)\n",
    "# display(content)\n",
    "\n",
    "# # new_dictionary = {}\n",
    "# # for key in content.keys():\n",
    "# #     str_to_remove = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/\"\n",
    "# #     new_key = str(key)[len(str_to_remove):]\n",
    "# #     new_dictionary[new_key] = content[key]\n",
    "# # display(new_dictionary)\n",
    "\n",
    "\n",
    "# # with open(pkl_file_to_amend, 'wb') as handle:\n",
    "# #     pickle.dump(new_dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3bd66-0f95-4d0f-9e85-b05bf609037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a45cf-dcbe-4d66-a8fa-34fcc1e4a4de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "start = time.time()   # starting time\n",
    "for batch in dm.train_dataloader():\n",
    "    # print(batch[\"tokens\"][1,:])\n",
    "    \n",
    "    c_batch = convert_batch_to_none_causal(batch)\n",
    "    # print(c_batch[\"tokens\"][1,:])\n",
    "    # print(c_batch[\"target_token\"][1])\n",
    "\n",
    "    # print(batch[\"tokens\"][1,:])\n",
    "    \n",
    "    break\n",
    "    \n",
    "print(f\"batch loaded in {time.time()-start} seconds\")    \n",
    "    \n",
    "# for key in batch.keys():\n",
    "#     print(f\"{key}\".ljust(20) + f\"{batch[key].shape}\")\n",
    "\n",
    "# tokens = batch[\"tokens\"][0].tolist()    \n",
    "# sentence = dm.decode(tokens).split(\" \")\n",
    "# for token, value in zip(sentence, batch[\"values\"][0].tolist()):\n",
    "#     print(f\"{token}:\".ljust(40) + f\"{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4c5b5-2121-4d10-8f8e-11a88ed16cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(batch.keys())\n",
    "display(c_batch.keys())\n",
    "\n",
    "print(batch[\"static_covariates\"].shape)\n",
    "\n",
    "# print(dm.train_set.static_1hot)\n",
    "# print(dm.train_set.static_1hot[\"SEX\"].categories_)\n",
    "# print(dm.train_set.static_1hot[\"IMD\"].categories_)\n",
    "# print(dm.train_set.static_1hot[\"ETHNICITY\"].categories_)\n",
    "\n",
    "print(batch[\"tokens\"][1,:])\n",
    "print(c_batch[\"tokens\"][1,:])\n",
    "print(c_batch[\"target_token\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3e15f-1b7c-466b-825e-a84100d224a0",
   "metadata": {},
   "source": [
    "## View an example sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa22fa-ef08-485f-a948-c4ff8b3aade5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm.test_set.view_sample(11003, max_dynamic_events=None, report_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1943eec-f491-4a94-92d9-65b9cedbd433",
   "metadata": {},
   "source": [
    "# Custom wrapper prediction last token\n",
    "\n",
    "To begin with, I will just loop over samples individually to test the zero-shot capacity of SurvivEHR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439343da-a813-4ffa-b0a6-26074e80d11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Verifying on datamodule \n",
    "for _idx, batch in enumerate(dm.test_dataloader()):\n",
    "    if _idx > 10:\n",
    "        break\n",
    "    print(_idx)\n",
    "    print(torch.stack([batch[\"tokens\"][10,:5], \n",
    "                       batch[\"values\"][10,:5],  \n",
    "                       batch[\"ages\"][10,:5],\n",
    "                       batch[\"attention_mask\"][10,:5]]))\n",
    "    batch = replace_last_non_pad_with_pad(batch)\n",
    "    print(torch.stack([batch[\"tokens\"][10,:5], \n",
    "                       batch[\"values\"][10,:5],  \n",
    "                       batch[\"ages\"][10,:5],\n",
    "                       batch[\"attention_mask\"][10,:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c069ad-f41d-420e-819e-cf2c5a390baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_of_interest = [\"COPD\", \"SUBSTANCEMISUSE\"]\n",
    "outcome_token = dm.encode(outcome_of_interest)[0]\n",
    "print(outcome_token)\n",
    "# print(model(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f35b1-02d3-4db9-b376-ca44d9c1f770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Hs, labels = [], []\n",
    "mins,maxes=[],[]\n",
    "for _idx, batch in enumerate(dm.test_dataloader()):\n",
    "\n",
    "    batch = replace_last_non_pad_with_pad(batch)\n",
    "    print(batch[\"tokens\".shape)\n",
    "    outputs, _, hidden_states = model(batch, is_generation=True)\n",
    "    print(outputs)\n",
    "    \n",
    "    hidden_states = hidden_states.cpu().detach().numpy()                           # (64, 128, 384) \n",
    "    Hs.append( hidden_states.reshape(hidden_states.shape[0], -1) )\n",
    "    labels.append((batch[\"target_token\"] == outcome_token).long().numpy())\n",
    "\n",
    "    if _idx == 9:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bf156-cc66-4276-8c8d-23caec948e2d",
   "metadata": {},
   "source": [
    "# Visualise hidden dimension labelled by target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d857d-dbb0-487b-8278-42c04bcbea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "H = np.concatenate(Hs, 0)\n",
    "lbl = np.concatenate(labels, 0)\n",
    "\n",
    "H = StandardScaler().fit_transform(H)\n",
    "reducer = umap.UMAP()\n",
    "H_proj = reducer.fit_transform(H)\n",
    "\n",
    "plt.close()\n",
    "plt.scatter(H_proj[:,0], H_proj[:,1], c=lbl)\n",
    "plt.savefig(save_path + f\"zero_shot/hidden_umap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e686a-ebe9-43d4-8a14-b88df279ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[\"surv\"][\"surv_CDF\"][outcome_token].shape)\n",
    "\n",
    "# The first two tokens in the vocab correspond to the PAD and UNK tokens. There is no CDF corresponding to the PAD token, so the indexing for surv_CDF begins as [\"UNK\", \"ADDISONS_DISEASE\", ...]\n",
    "# print(dm.decode([0,1,2]))\n",
    "\n",
    "outcomes = [\"COPD\", \"SUBSTANCEMISUSE\"]\n",
    "outcome_tokens = dm.encode(outcomes)\n",
    "\n",
    "# for outcome in outcomes:\n",
    "    # observed_outcome_token = dm.encode([outcome])[0]\n",
    "cdf = np.zeros_like(outputs[\"surv\"][\"surv_CDF\"][0])\n",
    "lbls = np.zeros_like(batch[\"target_token\"])\n",
    "\n",
    "for _outcome_token in outcome_tokens:\n",
    "    cdf += outputs[\"surv\"][\"surv_CDF\"][_outcome_token - 1] \n",
    "    lbls += (batch[\"target_token\"] == _outcome_token).long().numpy()\n",
    "\n",
    "plt.close()\n",
    "cdf_true = cdf[lbls==1,:]\n",
    "cdf_false = cdf[lbls==0,:]\n",
    "for i in range(cdf_true.shape[0]):\n",
    "    plt.plot(np.linspace(1,1826,1826), cdf_true[i,:], c=\"r\", label=\"outcome occurred next\" if i == 0 else None, alpha=1)\n",
    "for i in range(cdf_false.shape[0]):\n",
    "    plt.plot(np.linspace(1,1826,1826), cdf_false[i,:], c=\"k\", label=\"outcome did not occur next\" if i == 0 else None, alpha=0.3)\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"P(t>T) - outcomes={','.join(outcomes)}\")\n",
    "plt.savefig(save_path + f\"zero_shot/cdf_outcomes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c2049-56bc-47ff-bcea-ce2e529266e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[\"target_token\"].unique())\n",
    "print(len(outputs[\"surv\"][\"surv_CDF\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3417a-d3c7-42f9-b288-82ab49ddb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90115137-0805-4f93-877b-2d98e51439d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[\"surv\"][\"surv_CDF\"][observed_outcome_token - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacadcc-f857-45e2-94e8-0ca43ccbd196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
