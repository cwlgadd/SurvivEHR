{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Demo Notebook:\n",
    "## Survival Transformer For Causal Sequence Modelling \n",
    "\n",
    "Including time, and excluding tabular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvStreamGPT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "from pycox.evaluation import EvalSurv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TODO:\n",
    "# replace experiment boilerplate with pytorch lightning\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config to be equivalent architecture of kaparthy benchmark, however they are not comparable tasks.\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    block_size: int = 128        # what is the maximum context length for predictions?\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 6\n",
    "    n_embd: int = 384\n",
    "    bias: bool = True\n",
    "    attention_type: str = \"global\"    \n",
    "    dropout: float = 0.0\n",
    "    unk_freq_threshold: float = 0.0\n",
    "    SurvLayer = \"Competing-Risk\"                                  # \"Competing-Risk\"\n",
    "    tokens_for_univariate_regression = None\n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "@dataclass\n",
    "class OptConfig:\n",
    "    batch_size: int = 64\n",
    "    eval_interval: int = 1\n",
    "    learning_rate: float = 3e-4\n",
    "    epochs: int = 30\n",
    "    \n",
    "opt = OptConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader on a reduced cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading Polars dataset from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/polars/\n",
      "INFO:root:Using tokenizer tabular\n",
      "INFO:root:Tokenzier created based on 3584.43M tokens\n",
      "INFO:root:Creating split=train/ dataset\n",
      "INFO:root:\t Loading split=train/ hash map for parquet\n",
      "INFO:root:\t Hash map created for split=train/ with 22,842,428 samples\n",
      "INFO:root:Creating split=test/ dataset\n",
      "INFO:root:\t Loading split=test/ hash map for parquet\n",
      "INFO:root:\t Hash map created for split=test/ with 1,417,644 samples\n",
      "INFO:root:Creating split=val/ dataset\n",
      "INFO:root:\t Loading split=val/ hash map for parquet\n",
      "INFO:root:\t Hash map created for split=val/ with 1,169,583 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 vocab elements\n"
     ]
    }
   ],
   "source": [
    "# Get a list of patients which fit a reduced set of criterion\n",
    "# path_to_db = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/archive/Version2/\"\n",
    "path_to_db = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/\"\n",
    "\n",
    "# Build \n",
    "dm = FoundationalDataModule(path_to_db=path_to_db,\n",
    "                            load=True,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            batch_size=opt.batch_size,\n",
    "                            max_seq_length=config.block_size,\n",
    "                            unk_freq_threshold=config.unk_freq_threshold,\n",
    "                            min_workers=20,\n",
    "                           )\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "print(f\"{vocab_size} vocab elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>count</th>\n",
       "      <th>count_obs</th>\n",
       "      <th>digest</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>approx_lqr</th>\n",
       "      <th>approx_uqr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25_Hydroxyvitamin_D2_level_92</td>\n",
       "      <td>782791</td>\n",
       "      <td>693470</td>\n",
       "      <td>({'m': 0.0, 'c': 9.0}, {'m': 0.1, 'c': 112.0},...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.860000e+02</td>\n",
       "      <td>3.908721e+00</td>\n",
       "      <td>-4.699694</td>\n",
       "      <td>10.870832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25_Hydroxyvitamin_D3_level_90</td>\n",
       "      <td>809104</td>\n",
       "      <td>781118</td>\n",
       "      <td>({'m': 0.1, 'c': 3.0}, {'m': 1.0, 'c': 314.0},...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.518000e+02</td>\n",
       "      <td>4.714889e+01</td>\n",
       "      <td>-36.308194</td>\n",
       "      <td>121.286799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AST___aspartate_transam_SGOT__46</td>\n",
       "      <td>1738489</td>\n",
       "      <td>1680613</td>\n",
       "      <td>({'m': 0.0, 'c': 3901.0}, {'m': 0.770571428571...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.533000e+04</td>\n",
       "      <td>2.661963e+01</td>\n",
       "      <td>3.417134</td>\n",
       "      <td>41.771075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AST_serum_level_47</td>\n",
       "      <td>10837982</td>\n",
       "      <td>10485351</td>\n",
       "      <td>({'m': 0.0, 'c': 53.0}, {'m': 1.8, 'c': 1.0}, ...</td>\n",
       "      <td>-5.000000e+00</td>\n",
       "      <td>2.070000e+04</td>\n",
       "      <td>2.725168e+01</td>\n",
       "      <td>4.558863</td>\n",
       "      <td>41.966985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albumin___creatinine_ratio_37</td>\n",
       "      <td>180911</td>\n",
       "      <td>78420</td>\n",
       "      <td>({'m': -1.0, 'c': 1.0}, {'m': 0.0, 'c': 4213.0...</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.282100e+04</td>\n",
       "      <td>1.067255e+01</td>\n",
       "      <td>-4.329046</td>\n",
       "      <td>8.827713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Basophil_count_22</td>\n",
       "      <td>86869779</td>\n",
       "      <td>85642540</td>\n",
       "      <td>({'m': 0.0, 'c': 37098.0}, {'m': 0.01, 'c': 28...</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>1.111110e+05</td>\n",
       "      <td>5.008992e-02</td>\n",
       "      <td>-0.093801</td>\n",
       "      <td>0.160919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Blood_calcium_level_38</td>\n",
       "      <td>415717</td>\n",
       "      <td>385464</td>\n",
       "      <td>({'m': 0.0, 'c': 33.0}, {'m': 1.0, 'c': 1.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.400000e+02</td>\n",
       "      <td>2.352980e+00</td>\n",
       "      <td>2.025402</td>\n",
       "      <td>2.622520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blood_urea_28</td>\n",
       "      <td>785766</td>\n",
       "      <td>671861</td>\n",
       "      <td>({'m': 0.0, 'c': 2746.0}, {'m': 0.09, 'c': 1.0...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.265000e+03</td>\n",
       "      <td>6.513018e+00</td>\n",
       "      <td>0.270987</td>\n",
       "      <td>10.954279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Body_mass_index_3</td>\n",
       "      <td>99868822</td>\n",
       "      <td>97759312</td>\n",
       "      <td>({'m': 0.0, 'c': 14.0}, {'m': 0.05, 'c': 1.0},...</td>\n",
       "      <td>-3.268000e+04</td>\n",
       "      <td>2.100000e+09</td>\n",
       "      <td>2.933050e+02</td>\n",
       "      <td>10.476686</td>\n",
       "      <td>43.320395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brain_natriuretic_peptide_level_66</td>\n",
       "      <td>229202</td>\n",
       "      <td>159318</td>\n",
       "      <td>({'m': 0.0, 'c': 120.0}, {'m': 0.1, 'c': 1.0},...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.001420e+05</td>\n",
       "      <td>4.168786e+02</td>\n",
       "      <td>-245.175243</td>\n",
       "      <td>483.219601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Calcium_adjusted_level_41</td>\n",
       "      <td>1464226</td>\n",
       "      <td>1457911</td>\n",
       "      <td>({'m': 0.99, 'c': 1.0}, {'m': 1.04, 'c': 1.0},...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.790000e+02</td>\n",
       "      <td>2.365999e+00</td>\n",
       "      <td>2.085297</td>\n",
       "      <td>2.628290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Calculated_LDL_cholesterol_level_103</td>\n",
       "      <td>6967780</td>\n",
       "      <td>6719746</td>\n",
       "      <td>({'m': 0.0, 'c': 1.0}, {'m': 0.1, 'c': 15.0}, ...</td>\n",
       "      <td>-8.400000e+00</td>\n",
       "      <td>2.400000e+02</td>\n",
       "      <td>2.819830e+00</td>\n",
       "      <td>0.201590</td>\n",
       "      <td>5.480098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Combined_total_vitamin_D2_and_D3_level_93</td>\n",
       "      <td>452984</td>\n",
       "      <td>424568</td>\n",
       "      <td>({'m': 0.0, 'c': 9.0}, {'m': 2.2, 'c': 1.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.222000e+03</td>\n",
       "      <td>5.235274e+01</td>\n",
       "      <td>-33.936660</td>\n",
       "      <td>127.121701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Corrected_serum_calcium_level_42</td>\n",
       "      <td>16683796</td>\n",
       "      <td>16264645</td>\n",
       "      <td>({'m': 0.0, 'c': 4.0}, {'m': 0.16, 'c': 1.0}, ...</td>\n",
       "      <td>-2.580000e+00</td>\n",
       "      <td>1.205201e+07</td>\n",
       "      <td>3.892081e+00</td>\n",
       "      <td>2.049077</td>\n",
       "      <td>2.602211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Current_smoker_83</td>\n",
       "      <td>10592787</td>\n",
       "      <td>2509612</td>\n",
       "      <td>({'m': 0.0, 'c': 893.0}, {'m': 0.2, 'c': 2.0},...</td>\n",
       "      <td>-2.030000e+03</td>\n",
       "      <td>1.710202e+07</td>\n",
       "      <td>6.982623e+01</td>\n",
       "      <td>-10.923047</td>\n",
       "      <td>31.401104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Diastolic_blood_pressure_5</td>\n",
       "      <td>241026671</td>\n",
       "      <td>240724855</td>\n",
       "      <td>({'m': 0.0, 'c': 8.0}, {'m': 5.0, 'c': 1.0}, {...</td>\n",
       "      <td>-1.200000e+02</td>\n",
       "      <td>9.066667e+11</td>\n",
       "      <td>3.849124e+03</td>\n",
       "      <td>48.776736</td>\n",
       "      <td>106.184113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Eosinophil_count_21</td>\n",
       "      <td>92193433</td>\n",
       "      <td>91608967</td>\n",
       "      <td>({'m': 0.0, 'c': 3017.0}, {'m': 0.01, 'c': 255...</td>\n",
       "      <td>-6.000000e-01</td>\n",
       "      <td>4.444440e+05</td>\n",
       "      <td>2.339810e-01</td>\n",
       "      <td>-0.185129</td>\n",
       "      <td>0.578140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Erythrocyte_sedimentation_rate_61</td>\n",
       "      <td>29892785</td>\n",
       "      <td>24659777</td>\n",
       "      <td>({'m': -4.0, 'c': 2.0}, {'m': 0.0, 'c': 127.0}...</td>\n",
       "      <td>-2.000000e+01</td>\n",
       "      <td>1.315371e+07</td>\n",
       "      <td>1.843387e+01</td>\n",
       "      <td>-21.913521</td>\n",
       "      <td>50.017065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ex_smoker_84</td>\n",
       "      <td>24891632</td>\n",
       "      <td>1988555</td>\n",
       "      <td>({'m': -1.0, 'c': 1.0}, {'m': 0.0, 'c': 3006.0...</td>\n",
       "      <td>-2.030000e+03</td>\n",
       "      <td>2.000000e+08</td>\n",
       "      <td>4.101646e+02</td>\n",
       "      <td>-2955.789198</td>\n",
       "      <td>4927.181066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Free_T4_level_76</td>\n",
       "      <td>1405341</td>\n",
       "      <td>1254654</td>\n",
       "      <td>({'m': -9.1, 'c': 1.0}, {'m': -8.8, 'c': 1.0},...</td>\n",
       "      <td>-1.340000e+02</td>\n",
       "      <td>9.800000e+10</td>\n",
       "      <td>2.859576e+05</td>\n",
       "      <td>5.339090</td>\n",
       "      <td>24.967467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GFR_calculated_abbreviated_MDRD_34</td>\n",
       "      <td>73709249</td>\n",
       "      <td>65832806</td>\n",
       "      <td>({'m': 0.0, 'c': 17.0}, {'m': 1.73, 'c': 1.0},...</td>\n",
       "      <td>-9.000000e+01</td>\n",
       "      <td>1.816032e+07</td>\n",
       "      <td>7.195087e+01</td>\n",
       "      <td>25.405996</td>\n",
       "      <td>112.369378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Haematocrit___PCV_16</td>\n",
       "      <td>4346108</td>\n",
       "      <td>4313923</td>\n",
       "      <td>({'m': -0.29, 'c': 1.0}, {'m': -0.28, 'c': 5.0...</td>\n",
       "      <td>-4.650000e-01</td>\n",
       "      <td>9.385000e+03</td>\n",
       "      <td>5.573050e+00</td>\n",
       "      <td>0.275897</td>\n",
       "      <td>0.544607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Haematocrit_15</td>\n",
       "      <td>76582325</td>\n",
       "      <td>76295018</td>\n",
       "      <td>({'m': 0.003, 'c': 2.0}, {'m': 0.004, 'c': 1.0...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.090678e+05</td>\n",
       "      <td>3.781405e+00</td>\n",
       "      <td>0.291792</td>\n",
       "      <td>0.528275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Haemoglobin_A1c_level___IFCC_standardised_6</td>\n",
       "      <td>35091904</td>\n",
       "      <td>32542190</td>\n",
       "      <td>({'m': 0.0, 'c': 2.0}, {'m': 3.9, 'c': 1.0}, {...</td>\n",
       "      <td>-7.900000e+01</td>\n",
       "      <td>6.000952e+12</td>\n",
       "      <td>1.888003e+05</td>\n",
       "      <td>13.021696</td>\n",
       "      <td>74.393380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Haemoglobin_A1c_level_8</td>\n",
       "      <td>6516701</td>\n",
       "      <td>2279027</td>\n",
       "      <td>({'m': 0.0, 'c': 6.0}, {'m': 0.1, 'c': 1.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.999990e+05</td>\n",
       "      <td>1.350703e+01</td>\n",
       "      <td>2.967688</td>\n",
       "      <td>11.229089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Haemoglobin_estimation_9</td>\n",
       "      <td>97391693</td>\n",
       "      <td>96533626</td>\n",
       "      <td>({'m': 1.38, 'c': 1.0}, {'m': 6.9, 'c': 1.0}, ...</td>\n",
       "      <td>-1.120000e+02</td>\n",
       "      <td>1.411201e+07</td>\n",
       "      <td>7.961700e+01</td>\n",
       "      <td>96.395174</td>\n",
       "      <td>177.320646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HbA1c_level__DCCT_aligned__7</td>\n",
       "      <td>14948615</td>\n",
       "      <td>12120543</td>\n",
       "      <td>({'m': 0.0, 'c': 17.0}, {'m': 0.67, 'c': 1.0},...</td>\n",
       "      <td>-4.100000e+01</td>\n",
       "      <td>3.302112e+07</td>\n",
       "      <td>1.169712e+01</td>\n",
       "      <td>3.021371</td>\n",
       "      <td>11.061291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>INR___international_normalised_ratio_81</td>\n",
       "      <td>426165</td>\n",
       "      <td>409175</td>\n",
       "      <td>({'m': 0.0, 'c': 22.0}, {'m': 0.1, 'c': 3.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.112000e+04</td>\n",
       "      <td>2.775144e+00</td>\n",
       "      <td>0.652468</td>\n",
       "      <td>4.394059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>International_normalised_ratio_82</td>\n",
       "      <td>27966697</td>\n",
       "      <td>24573431</td>\n",
       "      <td>({'m': 0.0, 'c': 36.0}, {'m': 0.2, 'c': 2.0}, ...</td>\n",
       "      <td>-3.400000e+01</td>\n",
       "      <td>3.012201e+07</td>\n",
       "      <td>2.391763e+01</td>\n",
       "      <td>0.384342</td>\n",
       "      <td>4.322383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lymphocyte_count_20</td>\n",
       "      <td>92896401</td>\n",
       "      <td>92370088</td>\n",
       "      <td>({'m': 0.0, 'c': 3.0}, {'m': 0.03, 'c': 2.0}, ...</td>\n",
       "      <td>-3.500000e+01</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>3.650021e+02</td>\n",
       "      <td>0.106279</td>\n",
       "      <td>3.928994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mean_corpusc_Hb_conc__MCHC__14</td>\n",
       "      <td>70867102</td>\n",
       "      <td>70624255</td>\n",
       "      <td>({'m': 0.0, 'c': 1.0}, {'m': 0.36, 'c': 1.0}, ...</td>\n",
       "      <td>-2.950000e+02</td>\n",
       "      <td>3.512660e+05</td>\n",
       "      <td>1.861975e+02</td>\n",
       "      <td>266.494363</td>\n",
       "      <td>388.562816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mean_corpusc_haemoglobin_MCH__13</td>\n",
       "      <td>90498376</td>\n",
       "      <td>90220814</td>\n",
       "      <td>({'m': 10.8, 'c': 1.0}, {'m': 12.7, 'c': 2.0},...</td>\n",
       "      <td>-2.890000e+01</td>\n",
       "      <td>3.550000e+07</td>\n",
       "      <td>8.281642e+01</td>\n",
       "      <td>24.965489</td>\n",
       "      <td>35.383949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mean_corpuscular_volume__MCV__11</td>\n",
       "      <td>94723195</td>\n",
       "      <td>94409919</td>\n",
       "      <td>({'m': 0.3, 'c': 1.0}, {'m': 0.4, 'c': 1.0}, {...</td>\n",
       "      <td>-1.004000e+02</td>\n",
       "      <td>2.000000e+12</td>\n",
       "      <td>2.127458e+04</td>\n",
       "      <td>74.595518</td>\n",
       "      <td>105.847735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Monocyte_count_23</td>\n",
       "      <td>92489278</td>\n",
       "      <td>91979180</td>\n",
       "      <td>({'m': 0.0, 'c': 10.0}, {'m': 0.03, 'c': 2.0},...</td>\n",
       "      <td>-4.000000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>8.190597e+01</td>\n",
       "      <td>-0.015579</td>\n",
       "      <td>1.095040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>N_terminal_pro_brain_natriuretic_peptide_level_67</td>\n",
       "      <td>57470</td>\n",
       "      <td>53401</td>\n",
       "      <td>({'m': 0.0, 'c': 1.0}, {'m': 1.0, 'c': 8.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.501200e+04</td>\n",
       "      <td>7.599375e+02</td>\n",
       "      <td>-608.949932</td>\n",
       "      <td>1182.072727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Neutrophil_count_19</td>\n",
       "      <td>93489124</td>\n",
       "      <td>92851403</td>\n",
       "      <td>({'m': 0.0, 'c': 7.0}, {'m': 0.01, 'c': 1.0}, ...</td>\n",
       "      <td>-6.700000e+01</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>8.505009e+01</td>\n",
       "      <td>-0.079727</td>\n",
       "      <td>7.888474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Never_smoked_tobacco_85</td>\n",
       "      <td>60751822</td>\n",
       "      <td>1538646</td>\n",
       "      <td>({'m': -25.0, 'c': 3.0}, {'m': -1.0, 'c': 2.0}...</td>\n",
       "      <td>-2.500000e+01</td>\n",
       "      <td>2.004000e+03</td>\n",
       "      <td>5.093185e+00</td>\n",
       "      <td>-1101.151007</td>\n",
       "      <td>1833.906998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Non_HDL_cholesterol_level_108</td>\n",
       "      <td>2408310</td>\n",
       "      <td>2393900</td>\n",
       "      <td>({'m': -1.6, 'c': 1.0}, {'m': -1.2, 'c': 1.0},...</td>\n",
       "      <td>-1.600000e+00</td>\n",
       "      <td>3.407000e+03</td>\n",
       "      <td>3.447365e+00</td>\n",
       "      <td>0.459064</td>\n",
       "      <td>6.395493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>O_E___height_1</td>\n",
       "      <td>69089436</td>\n",
       "      <td>68753070</td>\n",
       "      <td>({'m': 0.0, 'c': 148.0}, {'m': 0.14, 'c': 1.0}...</td>\n",
       "      <td>-1.079000e+05</td>\n",
       "      <td>1.980230e+10</td>\n",
       "      <td>6.643426e+02</td>\n",
       "      <td>131.879673</td>\n",
       "      <td>200.250338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>O_E___weight_2</td>\n",
       "      <td>117401338</td>\n",
       "      <td>116811930</td>\n",
       "      <td>({'m': 0.0, 'c': 23.0}, {'m': 0.093, 'c': 1.0}...</td>\n",
       "      <td>-1.170000e+04</td>\n",
       "      <td>4.000000e+12</td>\n",
       "      <td>5.843027e+04</td>\n",
       "      <td>17.533517</td>\n",
       "      <td>128.074173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Plasma_B_natriuretic_peptide_level_69</td>\n",
       "      <td>82488</td>\n",
       "      <td>78777</td>\n",
       "      <td>({'m': 0.0, 'c': 51.0}, {'m': 0.58, 'c': 12.0}...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.711570e+05</td>\n",
       "      <td>2.149659e+02</td>\n",
       "      <td>-179.011254</td>\n",
       "      <td>367.711169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Plasma_C_reactive_protein_60</td>\n",
       "      <td>9155551</td>\n",
       "      <td>7401061</td>\n",
       "      <td>({'m': 0.0, 'c': 17.0}, {'m': 0.1, 'c': 821.0}...</td>\n",
       "      <td>-3.814000e+03</td>\n",
       "      <td>1.255000e+07</td>\n",
       "      <td>1.373701e+01</td>\n",
       "      <td>-11.271099</td>\n",
       "      <td>23.118017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Plasma_HDL_cholesterol_level_101</td>\n",
       "      <td>2173456</td>\n",
       "      <td>2111774</td>\n",
       "      <td>({'m': 0.0, 'c': 4.0}, {'m': 0.05, 'c': 1.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>1.763100e+03</td>\n",
       "      <td>0.344858</td>\n",
       "      <td>2.340803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Plasma_LDL_cholesterol_level_104</td>\n",
       "      <td>1434461</td>\n",
       "      <td>1249520</td>\n",
       "      <td>({'m': 0.0, 'c': 37.0}, {'m': 0.1, 'c': 3.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.020000e+02</td>\n",
       "      <td>2.839491e+00</td>\n",
       "      <td>-0.073895</td>\n",
       "      <td>5.738996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Plasma_N_terminal_pro_B_type_natriuretic_pepti...</td>\n",
       "      <td>53534</td>\n",
       "      <td>52305</td>\n",
       "      <td>({'m': 0.2, 'c': 1.0}, {'m': 1.0, 'c': 31.0}, ...</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>1.012460e+05</td>\n",
       "      <td>8.320501e+02</td>\n",
       "      <td>-634.165544</td>\n",
       "      <td>1243.421119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Plasma_TSH_level_73</td>\n",
       "      <td>2049380</td>\n",
       "      <td>2017201</td>\n",
       "      <td>({'m': 0.0, 'c': 74.0}, {'m': 0.001, 'c': 1.0}...</td>\n",
       "      <td>-7.800000e+00</td>\n",
       "      <td>2.470000e+04</td>\n",
       "      <td>2.591849e+00</td>\n",
       "      <td>-1.344051</td>\n",
       "      <td>4.967614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Plasma_alanine_aminotransferase_level_44</td>\n",
       "      <td>4012790</td>\n",
       "      <td>3989304</td>\n",
       "      <td>({'m': 0.0, 'c': 13.0}, {'m': 1.0, 'c': 4.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.096500e+04</td>\n",
       "      <td>2.680884e+01</td>\n",
       "      <td>-6.462309</td>\n",
       "      <td>51.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Plasma_albumin_level_52</td>\n",
       "      <td>3719377</td>\n",
       "      <td>3707409</td>\n",
       "      <td>({'m': 0.0, 'c': 3.0}, {'m': 10.0, 'c': 1.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.354350e+04</td>\n",
       "      <td>4.083299e+01</td>\n",
       "      <td>31.295509</td>\n",
       "      <td>50.399080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Plasma_alkaline_phosphatase_level_49</td>\n",
       "      <td>3290802</td>\n",
       "      <td>3281396</td>\n",
       "      <td>({'m': 0.0, 'c': 6.0}, {'m': 0.69, 'c': 1.0}, ...</td>\n",
       "      <td>-2.400000e+01</td>\n",
       "      <td>2.021600e+04</td>\n",
       "      <td>1.284950e+02</td>\n",
       "      <td>-59.841461</td>\n",
       "      <td>281.110518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Plasma_calcium_level_40</td>\n",
       "      <td>1294409</td>\n",
       "      <td>1286874</td>\n",
       "      <td>({'m': 0.0, 'c': 2.0}, {'m': 0.13, 'c': 2.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.780000e+02</td>\n",
       "      <td>2.376339e+00</td>\n",
       "      <td>2.066500</td>\n",
       "      <td>2.655478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Plasma_cholesterol_HDL_ratio_96</td>\n",
       "      <td>587483</td>\n",
       "      <td>575593</td>\n",
       "      <td>({'m': 0.0, 'c': 6.0}, {'m': 0.16, 'c': 1.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>3.794378e+00</td>\n",
       "      <td>0.609005</td>\n",
       "      <td>6.832556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Plasma_corrected_calcium_level_43</td>\n",
       "      <td>1168224</td>\n",
       "      <td>900092</td>\n",
       "      <td>({'m': 0.0, 'c': 13.0}, {'m': 0.12, 'c': 1.0},...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.480000e+02</td>\n",
       "      <td>2.347791e+00</td>\n",
       "      <td>2.070485</td>\n",
       "      <td>2.603971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Plasma_creatinine_level_32</td>\n",
       "      <td>4513054</td>\n",
       "      <td>4489265</td>\n",
       "      <td>({'m': 0.0, 'c': 7.0}, {'m': 2.42, 'c': 1.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>9.151366e+02</td>\n",
       "      <td>29.784070</td>\n",
       "      <td>139.676969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Plasma_ferritin_level_62</td>\n",
       "      <td>220380</td>\n",
       "      <td>167898</td>\n",
       "      <td>({'m': 0.0, 'c': 3655.0}, {'m': 0.1, 'c': 1.0}...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.478000e+04</td>\n",
       "      <td>8.423415e+01</td>\n",
       "      <td>-90.142195</td>\n",
       "      <td>192.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Plasma_free_T4_level_77</td>\n",
       "      <td>724108</td>\n",
       "      <td>681695</td>\n",
       "      <td>({'m': 0.0, 'c': 547.0}, {'m': 0.0199999999999...</td>\n",
       "      <td>-7.720000e+01</td>\n",
       "      <td>2.530000e+10</td>\n",
       "      <td>5.727122e+05</td>\n",
       "      <td>3.870309</td>\n",
       "      <td>21.266291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Plasma_gamma_glutamyl_transferase_level_58</td>\n",
       "      <td>1762750</td>\n",
       "      <td>1749440</td>\n",
       "      <td>({'m': 0.0, 'c': 6.0}, {'m': 3.0, 'c': 4.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.215100e+04</td>\n",
       "      <td>5.360479e+01</td>\n",
       "      <td>-26.335878</td>\n",
       "      <td>90.693909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Plasma_potassium_level_27</td>\n",
       "      <td>4445152</td>\n",
       "      <td>4402840</td>\n",
       "      <td>({'m': 0.0, 'c': 33.0}, {'m': 1.3, 'c': 1.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>8.491083e+02</td>\n",
       "      <td>2.898841</td>\n",
       "      <td>5.296195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Plasma_pro_brain_natriuretic_peptide_level_64</td>\n",
       "      <td>83343</td>\n",
       "      <td>70129</td>\n",
       "      <td>({'m': 0.0, 'c': 12.0}, {'m': 0.01, 'c': 1.0},...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.686000e+04</td>\n",
       "      <td>5.495602e+02</td>\n",
       "      <td>-347.003824</td>\n",
       "      <td>670.037525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Plasma_sodium_level_25</td>\n",
       "      <td>4458632</td>\n",
       "      <td>4425530</td>\n",
       "      <td>({'m': 0.0, 'c': 6.0}, {'m': 4.5, 'c': 1.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>9.799688e+02</td>\n",
       "      <td>132.452214</td>\n",
       "      <td>146.099184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Plasma_total_bilirubin_level_54</td>\n",
       "      <td>3443114</td>\n",
       "      <td>3429483</td>\n",
       "      <td>({'m': 0.0, 'c': 36.0}, {'m': 0.9, 'c': 1.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.100000e+04</td>\n",
       "      <td>1.104913e+01</td>\n",
       "      <td>-0.947903</td>\n",
       "      <td>19.890396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Plasma_total_cholesterol_level_99</td>\n",
       "      <td>2331589</td>\n",
       "      <td>2302691</td>\n",
       "      <td>({'m': 0.0, 'c': 2073.0}, {'m': 1.01, 'c': 3.0...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>1.620601e+03</td>\n",
       "      <td>1.650045</td>\n",
       "      <td>8.133845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Plasma_triglyceride_level_106</td>\n",
       "      <td>1573268</td>\n",
       "      <td>1548859</td>\n",
       "      <td>({'m': 0.0, 'c': 8.0}, {'m': 0.1, 'c': 2.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>2.403661e+03</td>\n",
       "      <td>-0.488936</td>\n",
       "      <td>3.444129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Plasma_urea_level_30</td>\n",
       "      <td>1991274</td>\n",
       "      <td>1968449</td>\n",
       "      <td>({'m': 0.0, 'c': 5.0}, {'m': 0.3, 'c': 3.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.080000e+02</td>\n",
       "      <td>5.956689e+00</td>\n",
       "      <td>0.423573</td>\n",
       "      <td>10.138546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Platelet_count_12</td>\n",
       "      <td>95904116</td>\n",
       "      <td>95382243</td>\n",
       "      <td>({'m': 0.0, 'c': 4.0}, {'m': 1.44, 'c': 1.0}, ...</td>\n",
       "      <td>-5.600000e+02</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>2.535123e+04</td>\n",
       "      <td>75.644611</td>\n",
       "      <td>439.071809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Red_blood_cell__RBC__count_10</td>\n",
       "      <td>92326200</td>\n",
       "      <td>91855577</td>\n",
       "      <td>({'m': 0.0, 'c': 3.0}, {'m': 0.81, 'c': 1.0}, ...</td>\n",
       "      <td>-4.460000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>6.149268e+04</td>\n",
       "      <td>3.277186</td>\n",
       "      <td>5.871597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Red_blood_cell_distribution_width_17</td>\n",
       "      <td>49751137</td>\n",
       "      <td>46387000</td>\n",
       "      <td>({'m': 0.0, 'c': 2.0}, {'m': 5.2, 'c': 1.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.603070e+05</td>\n",
       "      <td>1.398563e+01</td>\n",
       "      <td>10.411794</td>\n",
       "      <td>16.548972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Serum_25_Hydroxy_vitamin_D3_level_88</td>\n",
       "      <td>1211141</td>\n",
       "      <td>847628</td>\n",
       "      <td>({'m': 0.0, 'c': 18.0}, {'m': 0.5, 'c': 3.0}, ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>4.997980e+01</td>\n",
       "      <td>-34.722049</td>\n",
       "      <td>124.493562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Serum_C_reactive_protein_level_59</td>\n",
       "      <td>19234068</td>\n",
       "      <td>16340825</td>\n",
       "      <td>({'m': 0.0, 'c': 21.0}, {'m': 0.1, 'c': 219.0}...</td>\n",
       "      <td>-1.150000e+02</td>\n",
       "      <td>2.104936e+08</td>\n",
       "      <td>2.375269e+01</td>\n",
       "      <td>-8.016134</td>\n",
       "      <td>17.194342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Serum_HDL_cholesterol_level_100</td>\n",
       "      <td>50953183</td>\n",
       "      <td>50016821</td>\n",
       "      <td>({'m': 0.0, 'c': 9.0}, {'m': 0.06, 'c': 1.0}, ...</td>\n",
       "      <td>-3.900000e+01</td>\n",
       "      <td>1.762016e+06</td>\n",
       "      <td>1.506581e+00</td>\n",
       "      <td>0.332601</td>\n",
       "      <td>2.370315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Serum_LDL_cholesterol_level_102</td>\n",
       "      <td>30073152</td>\n",
       "      <td>29091476</td>\n",
       "      <td>({'m': -999994.31, 'c': 2.0}, {'m': -1.1, 'c':...</td>\n",
       "      <td>-9.999943e+05</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>3.871861e+02</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>5.857908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Serum_N_terminal_pro_B_type_natriuretic_peptid...</td>\n",
       "      <td>383790</td>\n",
       "      <td>335656</td>\n",
       "      <td>({'m': 1.0, 'c': 13.0}, {'m': 1.478, 'c': 1.0}...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.247610e+05</td>\n",
       "      <td>7.859756e+02</td>\n",
       "      <td>-616.038970</td>\n",
       "      <td>1198.120663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Serum_T4_level_78</td>\n",
       "      <td>524777</td>\n",
       "      <td>450988</td>\n",
       "      <td>({'m': -25.0, 'c': 7.0}, {'m': -20.0, 'c': 1.0...</td>\n",
       "      <td>-2.500000e+01</td>\n",
       "      <td>1.550000e+11</td>\n",
       "      <td>5.216837e+06</td>\n",
       "      <td>-117.532589</td>\n",
       "      <td>233.365080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Serum_TSH_level_71</td>\n",
       "      <td>55655662</td>\n",
       "      <td>52458151</td>\n",
       "      <td>({'m': 0.0, 'c': 5.0}, {'m': 0.008, 'c': 12.0}...</td>\n",
       "      <td>-2.143000e+01</td>\n",
       "      <td>1.990000e+07</td>\n",
       "      <td>1.537853e+01</td>\n",
       "      <td>-1.159464</td>\n",
       "      <td>4.927924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Serum_alanine_aminotransferase_level_45</td>\n",
       "      <td>46896239</td>\n",
       "      <td>46118828</td>\n",
       "      <td>({'m': 2.0, 'c': 2.0}, {'m': 3.0, 'c': 12.0}, ...</td>\n",
       "      <td>-4.300000e+01</td>\n",
       "      <td>2.060000e+05</td>\n",
       "      <td>2.705385e+01</td>\n",
       "      <td>-4.416892</td>\n",
       "      <td>48.131274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Serum_albumin_51</td>\n",
       "      <td>83105055</td>\n",
       "      <td>82755894</td>\n",
       "      <td>({'m': 2.14, 'c': 1.0}, {'m': 4.0, 'c': 1.0}, ...</td>\n",
       "      <td>-4.500000e+01</td>\n",
       "      <td>9.000000e+09</td>\n",
       "      <td>7.911712e+02</td>\n",
       "      <td>30.640767</td>\n",
       "      <td>50.902597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Serum_alkaline_phosphatase_50</td>\n",
       "      <td>76052242</td>\n",
       "      <td>75709587</td>\n",
       "      <td>({'m': 0.6, 'c': 1.0}, {'m': 0.77, 'c': 1.0}, ...</td>\n",
       "      <td>-1.650000e+02</td>\n",
       "      <td>1.523013e+07</td>\n",
       "      <td>8.934480e+01</td>\n",
       "      <td>13.084213</td>\n",
       "      <td>146.109293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Serum_bilirubin_level_53</td>\n",
       "      <td>24090337</td>\n",
       "      <td>23943058</td>\n",
       "      <td>({'m': 0.0, 'c': 17.0}, {'m': 0.66, 'c': 1.0},...</td>\n",
       "      <td>-1.912620e+05</td>\n",
       "      <td>1.232190e+08</td>\n",
       "      <td>1.615846e+01</td>\n",
       "      <td>-1.367697</td>\n",
       "      <td>20.822091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Serum_calcium_39</td>\n",
       "      <td>28049902</td>\n",
       "      <td>26929397</td>\n",
       "      <td>({'m': 0.0, 'c': 13.0}, {'m': 0.5, 'c': 1.0}, ...</td>\n",
       "      <td>-2.120000e+00</td>\n",
       "      <td>7.042004e+06</td>\n",
       "      <td>2.638354e+00</td>\n",
       "      <td>2.058337</td>\n",
       "      <td>2.626330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Serum_cholesterol_97</td>\n",
       "      <td>57393841</td>\n",
       "      <td>55137024</td>\n",
       "      <td>({'m': 0.0, 'c': 67.0}, {'m': 0.7, 'c': 1.0}, ...</td>\n",
       "      <td>-7.500000e+01</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>7.465021e+01</td>\n",
       "      <td>1.749397</td>\n",
       "      <td>8.245063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Serum_cholesterol_HDL_ratio_94</td>\n",
       "      <td>28586515</td>\n",
       "      <td>27949257</td>\n",
       "      <td>({'m': 0.0, 'c': 13.0}, {'m': 0.14, 'c': 1.0},...</td>\n",
       "      <td>-3.400000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>1.368317e+02</td>\n",
       "      <td>0.637095</td>\n",
       "      <td>6.842963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Serum_creatinine_31</td>\n",
       "      <td>102915170</td>\n",
       "      <td>101600210</td>\n",
       "      <td>({'m': 1.0, 'c': 1.0}, {'m': 1.09, 'c': 1.0}, ...</td>\n",
       "      <td>-4.212000e+04</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>5.354401e+02</td>\n",
       "      <td>23.438298</td>\n",
       "      <td>136.812468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Serum_ferritin_63</td>\n",
       "      <td>21412371</td>\n",
       "      <td>18831052</td>\n",
       "      <td>({'m': 0.0, 'c': 10.0}, {'m': 0.1, 'c': 1.0}, ...</td>\n",
       "      <td>-2.810200e+06</td>\n",
       "      <td>1.905228e+08</td>\n",
       "      <td>1.202831e+02</td>\n",
       "      <td>-112.749797</td>\n",
       "      <td>247.068260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Serum_folate_80</td>\n",
       "      <td>14643748</td>\n",
       "      <td>13245269</td>\n",
       "      <td>({'m': 0.0, 'c': 27.0}, {'m': 0.009, 'c': 1.0}...</td>\n",
       "      <td>-2.000000e+01</td>\n",
       "      <td>2.400000e+04</td>\n",
       "      <td>8.601245e+00</td>\n",
       "      <td>-4.583597</td>\n",
       "      <td>20.453698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Serum_free_T4_level_75</td>\n",
       "      <td>22579062</td>\n",
       "      <td>21978910</td>\n",
       "      <td>({'m': 0.0, 'c': 2.0}, {'m': 0.3, 'c': 4.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+11</td>\n",
       "      <td>5.508446e+05</td>\n",
       "      <td>4.277789</td>\n",
       "      <td>20.917526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Serum_gamma_glutamyl_transferase_level_57</td>\n",
       "      <td>22592131</td>\n",
       "      <td>21804090</td>\n",
       "      <td>({'m': 0.0, 'c': 4.0}, {'m': 1.0, 'c': 1.0}, {...</td>\n",
       "      <td>-4.620000e+02</td>\n",
       "      <td>7.022400e+04</td>\n",
       "      <td>5.737895e+01</td>\n",
       "      <td>-29.040429</td>\n",
       "      <td>94.768018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Serum_non_high_density_lipoprotein_cholesterol...</td>\n",
       "      <td>10648096</td>\n",
       "      <td>10620740</td>\n",
       "      <td>({'m': 0.17, 'c': 2.0}, {'m': 0.4, 'c': 2.0}, ...</td>\n",
       "      <td>-2.500000e+00</td>\n",
       "      <td>7.265600e+03</td>\n",
       "      <td>3.402179e+00</td>\n",
       "      <td>0.135161</td>\n",
       "      <td>6.497331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Serum_potassium_26</td>\n",
       "      <td>99036754</td>\n",
       "      <td>97495916</td>\n",
       "      <td>({'m': 1.8, 'c': 1.0}, {'m': 2.0, 'c': 1.0}, {...</td>\n",
       "      <td>-2.179000e+03</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>4.322233e+01</td>\n",
       "      <td>3.136406</td>\n",
       "      <td>5.469470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Serum_pro_brain_natriuretic_peptide_level_65</td>\n",
       "      <td>243565</td>\n",
       "      <td>196058</td>\n",
       "      <td>({'m': 0.0, 'c': 44.0}, {'m': 0.05, 'c': 2.0},...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.700000e+05</td>\n",
       "      <td>7.009120e+02</td>\n",
       "      <td>-500.317557</td>\n",
       "      <td>931.130828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Serum_sodium_24</td>\n",
       "      <td>99409745</td>\n",
       "      <td>98817250</td>\n",
       "      <td>({'m': 1.18, 'c': 1.0}, {'m': 1.32, 'c': 1.0},...</td>\n",
       "      <td>-1.400000e+02</td>\n",
       "      <td>6.910678e+07</td>\n",
       "      <td>1.413177e+02</td>\n",
       "      <td>132.031609</td>\n",
       "      <td>146.183544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Serum_total_25_hydroxy_vitamin_D_level_87</td>\n",
       "      <td>2178432</td>\n",
       "      <td>1882341</td>\n",
       "      <td>({'m': 2.0, 'c': 20.0}, {'m': 5.0, 'c': 15.0},...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.210000e+02</td>\n",
       "      <td>5.323836e+01</td>\n",
       "      <td>-19.741510</td>\n",
       "      <td>124.038967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Serum_total_bilirubin_level_56</td>\n",
       "      <td>54098383</td>\n",
       "      <td>53753453</td>\n",
       "      <td>({'m': 1.0, 'c': 15.0}, {'m': 2.0, 'c': 110.0}...</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>4.300000e+07</td>\n",
       "      <td>3.203331e+01</td>\n",
       "      <td>-0.908074</td>\n",
       "      <td>25.216474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Serum_total_cholesterol_level_98</td>\n",
       "      <td>5185017</td>\n",
       "      <td>5100659</td>\n",
       "      <td>({'m': 0.0, 'c': 4.0}, {'m': 0.6, 'c': 1.0}, {...</td>\n",
       "      <td>-7.600000e+00</td>\n",
       "      <td>1.010101e+06</td>\n",
       "      <td>5.174581e+00</td>\n",
       "      <td>1.559155</td>\n",
       "      <td>8.244092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Serum_triglycerides_105</td>\n",
       "      <td>42415036</td>\n",
       "      <td>41980818</td>\n",
       "      <td>({'m': 0.0, 'c': 18.0}, {'m': 0.08, 'c': 1.0},...</td>\n",
       "      <td>-3.762000e+02</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>4.449784e+02</td>\n",
       "      <td>-0.529052</td>\n",
       "      <td>3.286620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Serum_urea_level_29</td>\n",
       "      <td>78670253</td>\n",
       "      <td>78276364</td>\n",
       "      <td>({'m': 0.2, 'c': 1.0}, {'m': 0.4, 'c': 1.0}, {...</td>\n",
       "      <td>-2.410000e+01</td>\n",
       "      <td>2.400000e+10</td>\n",
       "      <td>5.770647e+03</td>\n",
       "      <td>0.411447</td>\n",
       "      <td>10.238402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Serum_vitamin_B12_79</td>\n",
       "      <td>16797696</td>\n",
       "      <td>15132281</td>\n",
       "      <td>({'m': 0.0, 'c': 8.0}, {'m': 1.57, 'c': 1.0}, ...</td>\n",
       "      <td>-5.781707e+08</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>7.152044e+02</td>\n",
       "      <td>-93.228843</td>\n",
       "      <td>819.177614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Serum_vitamin_D2_level_89</td>\n",
       "      <td>249092</td>\n",
       "      <td>204719</td>\n",
       "      <td>({'m': -5.0, 'c': 1.0}, {'m': 0.0, 'c': 1786.0...</td>\n",
       "      <td>-5.000000e+00</td>\n",
       "      <td>7.280000e+02</td>\n",
       "      <td>1.481123e+01</td>\n",
       "      <td>-7.806517</td>\n",
       "      <td>20.627066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Serum_vitamin_D_86</td>\n",
       "      <td>2478806</td>\n",
       "      <td>1741767</td>\n",
       "      <td>({'m': 0.0, 'c': 26.0}, {'m': 0.1, 'c': 2.0}, ...</td>\n",
       "      <td>-3.970000e+01</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>5.367082e+01</td>\n",
       "      <td>-30.340287</td>\n",
       "      <td>119.125827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Systolic_blood_pressure_4</td>\n",
       "      <td>241541988</td>\n",
       "      <td>241223179</td>\n",
       "      <td>({'m': 0.0, 'c': 8.0}, {'m': 50.0, 'c': 1.0}, ...</td>\n",
       "      <td>-2.000000e+02</td>\n",
       "      <td>1.111111e+11</td>\n",
       "      <td>6.007336e+02</td>\n",
       "      <td>82.366694</td>\n",
       "      <td>183.856668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TSH___thyroid_stim_hormone_72</td>\n",
       "      <td>3568579</td>\n",
       "      <td>3063531</td>\n",
       "      <td>({'m': -0.36, 'c': 1.0}, {'m': -0.1, 'c': 1.0}...</td>\n",
       "      <td>-5.000000e+01</td>\n",
       "      <td>8.100000e+06</td>\n",
       "      <td>2.560645e+01</td>\n",
       "      <td>-1.532900</td>\n",
       "      <td>5.129190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>TSH_level_74</td>\n",
       "      <td>507085</td>\n",
       "      <td>272902</td>\n",
       "      <td>({'m': 0.0, 'c': 2901.0}, {'m': 0.001, 'c': 1....</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>9.780000e+03</td>\n",
       "      <td>4.040092e+00</td>\n",
       "      <td>-1.962217</td>\n",
       "      <td>5.614838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Total_25_hydroxyvitamin_D_level_91</td>\n",
       "      <td>333324</td>\n",
       "      <td>283455</td>\n",
       "      <td>({'m': 0.0, 'c': 1.0}, {'m': 0.9, 'c': 1.0}, {...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.229000e+03</td>\n",
       "      <td>4.803738e+01</td>\n",
       "      <td>-27.636647</td>\n",
       "      <td>120.531403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Total_alkaline_phosphatase_48</td>\n",
       "      <td>6461505</td>\n",
       "      <td>6422922</td>\n",
       "      <td>({'m': 0.96, 'c': 1.0}, {'m': 1.09, 'c': 1.0},...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.014000e+03</td>\n",
       "      <td>8.453068e+01</td>\n",
       "      <td>13.392947</td>\n",
       "      <td>138.915685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Total_bilirubin_55</td>\n",
       "      <td>2193031</td>\n",
       "      <td>2141609</td>\n",
       "      <td>({'m': 0.0, 'c': 314.0}, {'m': 0.14, 'c': 1.0}...</td>\n",
       "      <td>-7.000000e+00</td>\n",
       "      <td>1.800000e+07</td>\n",
       "      <td>1.466419e+02</td>\n",
       "      <td>-1.845050</td>\n",
       "      <td>22.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Total_cholesterol_HDL_ratio_95</td>\n",
       "      <td>15760772</td>\n",
       "      <td>15489099</td>\n",
       "      <td>({'m': 0.0, 'c': 21.0}, {'m': 0.001, 'c': 2.0}...</td>\n",
       "      <td>-3.100000e+00</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>9.647043e+02</td>\n",
       "      <td>0.518454</td>\n",
       "      <td>6.820118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Total_white_cell_count_18</td>\n",
       "      <td>94827537</td>\n",
       "      <td>94179010</td>\n",
       "      <td>({'m': -0.3, 'c': 1.0}, {'m': 0.0, 'c': 3.0}, ...</td>\n",
       "      <td>-1.470000e+01</td>\n",
       "      <td>3.720369e+09</td>\n",
       "      <td>2.501895e+02</td>\n",
       "      <td>1.609138</td>\n",
       "      <td>12.061040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Urine_albumin_creatinine_ratio_35</td>\n",
       "      <td>15107807</td>\n",
       "      <td>10249206</td>\n",
       "      <td>({'m': 0.0, 'c': 213.0}, {'m': 0.01, 'c': 3.0}...</td>\n",
       "      <td>-1.400000e+01</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>9.960699e+02</td>\n",
       "      <td>-3.815196</td>\n",
       "      <td>7.955124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Urine_microalbumin_creatinine_ratio_36</td>\n",
       "      <td>201318</td>\n",
       "      <td>94009</td>\n",
       "      <td>({'m': 0.0, 'c': 5691.0}, {'m': 0.001, 'c': 53...</td>\n",
       "      <td>-5.803000e+00</td>\n",
       "      <td>3.176800e+04</td>\n",
       "      <td>1.077503e+01</td>\n",
       "      <td>-4.143185</td>\n",
       "      <td>8.261282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>eGFR_using_creatinine_CKD_EPI_per_1_73_square_...</td>\n",
       "      <td>12869245</td>\n",
       "      <td>11902149</td>\n",
       "      <td>({'m': 0.0, 'c': 1.0}, {'m': 4.0, 'c': 9.0}, {...</td>\n",
       "      <td>-9.000000e+01</td>\n",
       "      <td>8.713000e+04</td>\n",
       "      <td>7.427459e+01</td>\n",
       "      <td>22.686686</td>\n",
       "      <td>129.955590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 event      count  count_obs  \\\n",
       "0                        25_Hydroxyvitamin_D2_level_92     782791     693470   \n",
       "1                        25_Hydroxyvitamin_D3_level_90     809104     781118   \n",
       "2                     AST___aspartate_transam_SGOT__46    1738489    1680613   \n",
       "3                                   AST_serum_level_47   10837982   10485351   \n",
       "4                        Albumin___creatinine_ratio_37     180911      78420   \n",
       "5                                    Basophil_count_22   86869779   85642540   \n",
       "6                               Blood_calcium_level_38     415717     385464   \n",
       "7                                        Blood_urea_28     785766     671861   \n",
       "8                                    Body_mass_index_3   99868822   97759312   \n",
       "9                   Brain_natriuretic_peptide_level_66     229202     159318   \n",
       "10                           Calcium_adjusted_level_41    1464226    1457911   \n",
       "11                Calculated_LDL_cholesterol_level_103    6967780    6719746   \n",
       "12           Combined_total_vitamin_D2_and_D3_level_93     452984     424568   \n",
       "13                    Corrected_serum_calcium_level_42   16683796   16264645   \n",
       "14                                   Current_smoker_83   10592787    2509612   \n",
       "15                          Diastolic_blood_pressure_5  241026671  240724855   \n",
       "16                                 Eosinophil_count_21   92193433   91608967   \n",
       "17                   Erythrocyte_sedimentation_rate_61   29892785   24659777   \n",
       "18                                        Ex_smoker_84   24891632    1988555   \n",
       "19                                    Free_T4_level_76    1405341    1254654   \n",
       "20                  GFR_calculated_abbreviated_MDRD_34   73709249   65832806   \n",
       "21                                Haematocrit___PCV_16    4346108    4313923   \n",
       "22                                      Haematocrit_15   76582325   76295018   \n",
       "23         Haemoglobin_A1c_level___IFCC_standardised_6   35091904   32542190   \n",
       "24                             Haemoglobin_A1c_level_8    6516701    2279027   \n",
       "25                            Haemoglobin_estimation_9   97391693   96533626   \n",
       "26                        HbA1c_level__DCCT_aligned__7   14948615   12120543   \n",
       "27             INR___international_normalised_ratio_81     426165     409175   \n",
       "28                   International_normalised_ratio_82   27966697   24573431   \n",
       "29                                 Lymphocyte_count_20   92896401   92370088   \n",
       "30                      Mean_corpusc_Hb_conc__MCHC__14   70867102   70624255   \n",
       "31                    Mean_corpusc_haemoglobin_MCH__13   90498376   90220814   \n",
       "32                    Mean_corpuscular_volume__MCV__11   94723195   94409919   \n",
       "33                                   Monocyte_count_23   92489278   91979180   \n",
       "34   N_terminal_pro_brain_natriuretic_peptide_level_67      57470      53401   \n",
       "35                                 Neutrophil_count_19   93489124   92851403   \n",
       "36                             Never_smoked_tobacco_85   60751822    1538646   \n",
       "37                       Non_HDL_cholesterol_level_108    2408310    2393900   \n",
       "38                                      O_E___height_1   69089436   68753070   \n",
       "39                                      O_E___weight_2  117401338  116811930   \n",
       "40               Plasma_B_natriuretic_peptide_level_69      82488      78777   \n",
       "41                        Plasma_C_reactive_protein_60    9155551    7401061   \n",
       "42                    Plasma_HDL_cholesterol_level_101    2173456    2111774   \n",
       "43                    Plasma_LDL_cholesterol_level_104    1434461    1249520   \n",
       "44   Plasma_N_terminal_pro_B_type_natriuretic_pepti...      53534      52305   \n",
       "45                                 Plasma_TSH_level_73    2049380    2017201   \n",
       "46            Plasma_alanine_aminotransferase_level_44    4012790    3989304   \n",
       "47                             Plasma_albumin_level_52    3719377    3707409   \n",
       "48                Plasma_alkaline_phosphatase_level_49    3290802    3281396   \n",
       "49                             Plasma_calcium_level_40    1294409    1286874   \n",
       "50                     Plasma_cholesterol_HDL_ratio_96     587483     575593   \n",
       "51                   Plasma_corrected_calcium_level_43    1168224     900092   \n",
       "52                          Plasma_creatinine_level_32    4513054    4489265   \n",
       "53                            Plasma_ferritin_level_62     220380     167898   \n",
       "54                             Plasma_free_T4_level_77     724108     681695   \n",
       "55          Plasma_gamma_glutamyl_transferase_level_58    1762750    1749440   \n",
       "56                           Plasma_potassium_level_27    4445152    4402840   \n",
       "57       Plasma_pro_brain_natriuretic_peptide_level_64      83343      70129   \n",
       "58                              Plasma_sodium_level_25    4458632    4425530   \n",
       "59                     Plasma_total_bilirubin_level_54    3443114    3429483   \n",
       "60                   Plasma_total_cholesterol_level_99    2331589    2302691   \n",
       "61                       Plasma_triglyceride_level_106    1573268    1548859   \n",
       "62                                Plasma_urea_level_30    1991274    1968449   \n",
       "63                                   Platelet_count_12   95904116   95382243   \n",
       "64                       Red_blood_cell__RBC__count_10   92326200   91855577   \n",
       "65                Red_blood_cell_distribution_width_17   49751137   46387000   \n",
       "66                Serum_25_Hydroxy_vitamin_D3_level_88    1211141     847628   \n",
       "67                   Serum_C_reactive_protein_level_59   19234068   16340825   \n",
       "68                     Serum_HDL_cholesterol_level_100   50953183   50016821   \n",
       "69                     Serum_LDL_cholesterol_level_102   30073152   29091476   \n",
       "70   Serum_N_terminal_pro_B_type_natriuretic_peptid...     383790     335656   \n",
       "71                                   Serum_T4_level_78     524777     450988   \n",
       "72                                  Serum_TSH_level_71   55655662   52458151   \n",
       "73             Serum_alanine_aminotransferase_level_45   46896239   46118828   \n",
       "74                                    Serum_albumin_51   83105055   82755894   \n",
       "75                       Serum_alkaline_phosphatase_50   76052242   75709587   \n",
       "76                            Serum_bilirubin_level_53   24090337   23943058   \n",
       "77                                    Serum_calcium_39   28049902   26929397   \n",
       "78                                Serum_cholesterol_97   57393841   55137024   \n",
       "79                      Serum_cholesterol_HDL_ratio_94   28586515   27949257   \n",
       "80                                 Serum_creatinine_31  102915170  101600210   \n",
       "81                                   Serum_ferritin_63   21412371   18831052   \n",
       "82                                     Serum_folate_80   14643748   13245269   \n",
       "83                              Serum_free_T4_level_75   22579062   21978910   \n",
       "84           Serum_gamma_glutamyl_transferase_level_57   22592131   21804090   \n",
       "85   Serum_non_high_density_lipoprotein_cholesterol...   10648096   10620740   \n",
       "86                                  Serum_potassium_26   99036754   97495916   \n",
       "87        Serum_pro_brain_natriuretic_peptide_level_65     243565     196058   \n",
       "88                                     Serum_sodium_24   99409745   98817250   \n",
       "89           Serum_total_25_hydroxy_vitamin_D_level_87    2178432    1882341   \n",
       "90                      Serum_total_bilirubin_level_56   54098383   53753453   \n",
       "91                    Serum_total_cholesterol_level_98    5185017    5100659   \n",
       "92                             Serum_triglycerides_105   42415036   41980818   \n",
       "93                                 Serum_urea_level_29   78670253   78276364   \n",
       "94                                Serum_vitamin_B12_79   16797696   15132281   \n",
       "95                           Serum_vitamin_D2_level_89     249092     204719   \n",
       "96                                  Serum_vitamin_D_86    2478806    1741767   \n",
       "97                           Systolic_blood_pressure_4  241541988  241223179   \n",
       "98                       TSH___thyroid_stim_hormone_72    3568579    3063531   \n",
       "99                                        TSH_level_74     507085     272902   \n",
       "100                 Total_25_hydroxyvitamin_D_level_91     333324     283455   \n",
       "101                      Total_alkaline_phosphatase_48    6461505    6422922   \n",
       "102                                 Total_bilirubin_55    2193031    2141609   \n",
       "103                     Total_cholesterol_HDL_ratio_95   15760772   15489099   \n",
       "104                          Total_white_cell_count_18   94827537   94179010   \n",
       "105                  Urine_albumin_creatinine_ratio_35   15107807   10249206   \n",
       "106             Urine_microalbumin_creatinine_ratio_36     201318      94009   \n",
       "107  eGFR_using_creatinine_CKD_EPI_per_1_73_square_...   12869245   11902149   \n",
       "\n",
       "                                                digest           min  \\\n",
       "0    ({'m': 0.0, 'c': 9.0}, {'m': 0.1, 'c': 112.0},...  0.000000e+00   \n",
       "1    ({'m': 0.1, 'c': 3.0}, {'m': 1.0, 'c': 314.0},...  0.000000e+00   \n",
       "2    ({'m': 0.0, 'c': 3901.0}, {'m': 0.770571428571...  0.000000e+00   \n",
       "3    ({'m': 0.0, 'c': 53.0}, {'m': 1.8, 'c': 1.0}, ... -5.000000e+00   \n",
       "4    ({'m': -1.0, 'c': 1.0}, {'m': 0.0, 'c': 4213.0... -1.000000e+00   \n",
       "5    ({'m': 0.0, 'c': 37098.0}, {'m': 0.01, 'c': 28... -1.000000e-01   \n",
       "6    ({'m': 0.0, 'c': 33.0}, {'m': 1.0, 'c': 1.0}, ...  0.000000e+00   \n",
       "7    ({'m': 0.0, 'c': 2746.0}, {'m': 0.09, 'c': 1.0...  0.000000e+00   \n",
       "8    ({'m': 0.0, 'c': 14.0}, {'m': 0.05, 'c': 1.0},... -3.268000e+04   \n",
       "9    ({'m': 0.0, 'c': 120.0}, {'m': 0.1, 'c': 1.0},...  0.000000e+00   \n",
       "10   ({'m': 0.99, 'c': 1.0}, {'m': 1.04, 'c': 1.0},...  0.000000e+00   \n",
       "11   ({'m': 0.0, 'c': 1.0}, {'m': 0.1, 'c': 15.0}, ... -8.400000e+00   \n",
       "12   ({'m': 0.0, 'c': 9.0}, {'m': 2.2, 'c': 1.0}, {...  0.000000e+00   \n",
       "13   ({'m': 0.0, 'c': 4.0}, {'m': 0.16, 'c': 1.0}, ... -2.580000e+00   \n",
       "14   ({'m': 0.0, 'c': 893.0}, {'m': 0.2, 'c': 2.0},... -2.030000e+03   \n",
       "15   ({'m': 0.0, 'c': 8.0}, {'m': 5.0, 'c': 1.0}, {... -1.200000e+02   \n",
       "16   ({'m': 0.0, 'c': 3017.0}, {'m': 0.01, 'c': 255... -6.000000e-01   \n",
       "17   ({'m': -4.0, 'c': 2.0}, {'m': 0.0, 'c': 127.0}... -2.000000e+01   \n",
       "18   ({'m': -1.0, 'c': 1.0}, {'m': 0.0, 'c': 3006.0... -2.030000e+03   \n",
       "19   ({'m': -9.1, 'c': 1.0}, {'m': -8.8, 'c': 1.0},... -1.340000e+02   \n",
       "20   ({'m': 0.0, 'c': 17.0}, {'m': 1.73, 'c': 1.0},... -9.000000e+01   \n",
       "21   ({'m': -0.29, 'c': 1.0}, {'m': -0.28, 'c': 5.0... -4.650000e-01   \n",
       "22   ({'m': 0.003, 'c': 2.0}, {'m': 0.004, 'c': 1.0...  0.000000e+00   \n",
       "23   ({'m': 0.0, 'c': 2.0}, {'m': 3.9, 'c': 1.0}, {... -7.900000e+01   \n",
       "24   ({'m': 0.0, 'c': 6.0}, {'m': 0.1, 'c': 1.0}, {...  0.000000e+00   \n",
       "25   ({'m': 1.38, 'c': 1.0}, {'m': 6.9, 'c': 1.0}, ... -1.120000e+02   \n",
       "26   ({'m': 0.0, 'c': 17.0}, {'m': 0.67, 'c': 1.0},... -4.100000e+01   \n",
       "27   ({'m': 0.0, 'c': 22.0}, {'m': 0.1, 'c': 3.0}, ...  0.000000e+00   \n",
       "28   ({'m': 0.0, 'c': 36.0}, {'m': 0.2, 'c': 2.0}, ... -3.400000e+01   \n",
       "29   ({'m': 0.0, 'c': 3.0}, {'m': 0.03, 'c': 2.0}, ... -3.500000e+01   \n",
       "30   ({'m': 0.0, 'c': 1.0}, {'m': 0.36, 'c': 1.0}, ... -2.950000e+02   \n",
       "31   ({'m': 10.8, 'c': 1.0}, {'m': 12.7, 'c': 2.0},... -2.890000e+01   \n",
       "32   ({'m': 0.3, 'c': 1.0}, {'m': 0.4, 'c': 1.0}, {... -1.004000e+02   \n",
       "33   ({'m': 0.0, 'c': 10.0}, {'m': 0.03, 'c': 2.0},... -4.000000e+00   \n",
       "34   ({'m': 0.0, 'c': 1.0}, {'m': 1.0, 'c': 8.0}, {...  0.000000e+00   \n",
       "35   ({'m': 0.0, 'c': 7.0}, {'m': 0.01, 'c': 1.0}, ... -6.700000e+01   \n",
       "36   ({'m': -25.0, 'c': 3.0}, {'m': -1.0, 'c': 2.0}... -2.500000e+01   \n",
       "37   ({'m': -1.6, 'c': 1.0}, {'m': -1.2, 'c': 1.0},... -1.600000e+00   \n",
       "38   ({'m': 0.0, 'c': 148.0}, {'m': 0.14, 'c': 1.0}... -1.079000e+05   \n",
       "39   ({'m': 0.0, 'c': 23.0}, {'m': 0.093, 'c': 1.0}... -1.170000e+04   \n",
       "40   ({'m': 0.0, 'c': 51.0}, {'m': 0.58, 'c': 12.0}...  0.000000e+00   \n",
       "41   ({'m': 0.0, 'c': 17.0}, {'m': 0.1, 'c': 821.0}... -3.814000e+03   \n",
       "42   ({'m': 0.0, 'c': 4.0}, {'m': 0.05, 'c': 1.0}, ...  0.000000e+00   \n",
       "43   ({'m': 0.0, 'c': 37.0}, {'m': 0.1, 'c': 3.0}, ...  0.000000e+00   \n",
       "44   ({'m': 0.2, 'c': 1.0}, {'m': 1.0, 'c': 31.0}, ...  2.000000e-01   \n",
       "45   ({'m': 0.0, 'c': 74.0}, {'m': 0.001, 'c': 1.0}... -7.800000e+00   \n",
       "46   ({'m': 0.0, 'c': 13.0}, {'m': 1.0, 'c': 4.0}, ...  0.000000e+00   \n",
       "47   ({'m': 0.0, 'c': 3.0}, {'m': 10.0, 'c': 1.0}, ...  0.000000e+00   \n",
       "48   ({'m': 0.0, 'c': 6.0}, {'m': 0.69, 'c': 1.0}, ... -2.400000e+01   \n",
       "49   ({'m': 0.0, 'c': 2.0}, {'m': 0.13, 'c': 2.0}, ...  0.000000e+00   \n",
       "50   ({'m': 0.0, 'c': 6.0}, {'m': 0.16, 'c': 1.0}, ...  0.000000e+00   \n",
       "51   ({'m': 0.0, 'c': 13.0}, {'m': 0.12, 'c': 1.0},...  0.000000e+00   \n",
       "52   ({'m': 0.0, 'c': 7.0}, {'m': 2.42, 'c': 1.0}, ...  0.000000e+00   \n",
       "53   ({'m': 0.0, 'c': 3655.0}, {'m': 0.1, 'c': 1.0}...  0.000000e+00   \n",
       "54   ({'m': 0.0, 'c': 547.0}, {'m': 0.0199999999999... -7.720000e+01   \n",
       "55   ({'m': 0.0, 'c': 6.0}, {'m': 3.0, 'c': 4.0}, {...  0.000000e+00   \n",
       "56   ({'m': 0.0, 'c': 33.0}, {'m': 1.3, 'c': 1.0}, ...  0.000000e+00   \n",
       "57   ({'m': 0.0, 'c': 12.0}, {'m': 0.01, 'c': 1.0},...  0.000000e+00   \n",
       "58   ({'m': 0.0, 'c': 6.0}, {'m': 4.5, 'c': 1.0}, {...  0.000000e+00   \n",
       "59   ({'m': 0.0, 'c': 36.0}, {'m': 0.9, 'c': 1.0}, ...  0.000000e+00   \n",
       "60   ({'m': 0.0, 'c': 2073.0}, {'m': 1.01, 'c': 3.0...  0.000000e+00   \n",
       "61   ({'m': 0.0, 'c': 8.0}, {'m': 0.1, 'c': 2.0}, {...  0.000000e+00   \n",
       "62   ({'m': 0.0, 'c': 5.0}, {'m': 0.3, 'c': 3.0}, {...  0.000000e+00   \n",
       "63   ({'m': 0.0, 'c': 4.0}, {'m': 1.44, 'c': 1.0}, ... -5.600000e+02   \n",
       "64   ({'m': 0.0, 'c': 3.0}, {'m': 0.81, 'c': 1.0}, ... -4.460000e+00   \n",
       "65   ({'m': 0.0, 'c': 2.0}, {'m': 5.2, 'c': 1.0}, {...  0.000000e+00   \n",
       "66   ({'m': 0.0, 'c': 18.0}, {'m': 0.5, 'c': 3.0}, ...  0.000000e+00   \n",
       "67   ({'m': 0.0, 'c': 21.0}, {'m': 0.1, 'c': 219.0}... -1.150000e+02   \n",
       "68   ({'m': 0.0, 'c': 9.0}, {'m': 0.06, 'c': 1.0}, ... -3.900000e+01   \n",
       "69   ({'m': -999994.31, 'c': 2.0}, {'m': -1.1, 'c':... -9.999943e+05   \n",
       "70   ({'m': 1.0, 'c': 13.0}, {'m': 1.478, 'c': 1.0}...  0.000000e+00   \n",
       "71   ({'m': -25.0, 'c': 7.0}, {'m': -20.0, 'c': 1.0... -2.500000e+01   \n",
       "72   ({'m': 0.0, 'c': 5.0}, {'m': 0.008, 'c': 12.0}... -2.143000e+01   \n",
       "73   ({'m': 2.0, 'c': 2.0}, {'m': 3.0, 'c': 12.0}, ... -4.300000e+01   \n",
       "74   ({'m': 2.14, 'c': 1.0}, {'m': 4.0, 'c': 1.0}, ... -4.500000e+01   \n",
       "75   ({'m': 0.6, 'c': 1.0}, {'m': 0.77, 'c': 1.0}, ... -1.650000e+02   \n",
       "76   ({'m': 0.0, 'c': 17.0}, {'m': 0.66, 'c': 1.0},... -1.912620e+05   \n",
       "77   ({'m': 0.0, 'c': 13.0}, {'m': 0.5, 'c': 1.0}, ... -2.120000e+00   \n",
       "78   ({'m': 0.0, 'c': 67.0}, {'m': 0.7, 'c': 1.0}, ... -7.500000e+01   \n",
       "79   ({'m': 0.0, 'c': 13.0}, {'m': 0.14, 'c': 1.0},... -3.400000e+00   \n",
       "80   ({'m': 1.0, 'c': 1.0}, {'m': 1.09, 'c': 1.0}, ... -4.212000e+04   \n",
       "81   ({'m': 0.0, 'c': 10.0}, {'m': 0.1, 'c': 1.0}, ... -2.810200e+06   \n",
       "82   ({'m': 0.0, 'c': 27.0}, {'m': 0.009, 'c': 1.0}... -2.000000e+01   \n",
       "83   ({'m': 0.0, 'c': 2.0}, {'m': 0.3, 'c': 4.0}, {...  0.000000e+00   \n",
       "84   ({'m': 0.0, 'c': 4.0}, {'m': 1.0, 'c': 1.0}, {... -4.620000e+02   \n",
       "85   ({'m': 0.17, 'c': 2.0}, {'m': 0.4, 'c': 2.0}, ... -2.500000e+00   \n",
       "86   ({'m': 1.8, 'c': 1.0}, {'m': 2.0, 'c': 1.0}, {... -2.179000e+03   \n",
       "87   ({'m': 0.0, 'c': 44.0}, {'m': 0.05, 'c': 2.0},...  0.000000e+00   \n",
       "88   ({'m': 1.18, 'c': 1.0}, {'m': 1.32, 'c': 1.0},... -1.400000e+02   \n",
       "89   ({'m': 2.0, 'c': 20.0}, {'m': 5.0, 'c': 15.0},...  0.000000e+00   \n",
       "90   ({'m': 1.0, 'c': 15.0}, {'m': 2.0, 'c': 110.0}... -2.000000e+00   \n",
       "91   ({'m': 0.0, 'c': 4.0}, {'m': 0.6, 'c': 1.0}, {... -7.600000e+00   \n",
       "92   ({'m': 0.0, 'c': 18.0}, {'m': 0.08, 'c': 1.0},... -3.762000e+02   \n",
       "93   ({'m': 0.2, 'c': 1.0}, {'m': 0.4, 'c': 1.0}, {... -2.410000e+01   \n",
       "94   ({'m': 0.0, 'c': 8.0}, {'m': 1.57, 'c': 1.0}, ... -5.781707e+08   \n",
       "95   ({'m': -5.0, 'c': 1.0}, {'m': 0.0, 'c': 1786.0... -5.000000e+00   \n",
       "96   ({'m': 0.0, 'c': 26.0}, {'m': 0.1, 'c': 2.0}, ... -3.970000e+01   \n",
       "97   ({'m': 0.0, 'c': 8.0}, {'m': 50.0, 'c': 1.0}, ... -2.000000e+02   \n",
       "98   ({'m': -0.36, 'c': 1.0}, {'m': -0.1, 'c': 1.0}... -5.000000e+01   \n",
       "99   ({'m': 0.0, 'c': 2901.0}, {'m': 0.001, 'c': 1.... -5.000000e-01   \n",
       "100  ({'m': 0.0, 'c': 1.0}, {'m': 0.9, 'c': 1.0}, {...  0.000000e+00   \n",
       "101  ({'m': 0.96, 'c': 1.0}, {'m': 1.09, 'c': 1.0},...  0.000000e+00   \n",
       "102  ({'m': 0.0, 'c': 314.0}, {'m': 0.14, 'c': 1.0}... -7.000000e+00   \n",
       "103  ({'m': 0.0, 'c': 21.0}, {'m': 0.001, 'c': 2.0}... -3.100000e+00   \n",
       "104  ({'m': -0.3, 'c': 1.0}, {'m': 0.0, 'c': 3.0}, ... -1.470000e+01   \n",
       "105  ({'m': 0.0, 'c': 213.0}, {'m': 0.01, 'c': 3.0}... -1.400000e+01   \n",
       "106  ({'m': 0.0, 'c': 5691.0}, {'m': 0.001, 'c': 53... -5.803000e+00   \n",
       "107  ({'m': 0.0, 'c': 1.0}, {'m': 4.0, 'c': 9.0}, {... -9.000000e+01   \n",
       "\n",
       "              max          mean   approx_lqr   approx_uqr  \n",
       "0    6.860000e+02  3.908721e+00    -4.699694    10.870832  \n",
       "1    9.518000e+02  4.714889e+01   -36.308194   121.286799  \n",
       "2    1.533000e+04  2.661963e+01     3.417134    41.771075  \n",
       "3    2.070000e+04  2.725168e+01     4.558863    41.966985  \n",
       "4    1.282100e+04  1.067255e+01    -4.329046     8.827713  \n",
       "5    1.111110e+05  5.008992e-02    -0.093801     0.160919  \n",
       "6    4.400000e+02  2.352980e+00     2.025402     2.622520  \n",
       "7    1.265000e+03  6.513018e+00     0.270987    10.954279  \n",
       "8    2.100000e+09  2.933050e+02    10.476686    43.320395  \n",
       "9    5.001420e+05  4.168786e+02  -245.175243   483.219601  \n",
       "10   2.790000e+02  2.365999e+00     2.085297     2.628290  \n",
       "11   2.400000e+02  2.819830e+00     0.201590     5.480098  \n",
       "12   1.222000e+03  5.235274e+01   -33.936660   127.121701  \n",
       "13   1.205201e+07  3.892081e+00     2.049077     2.602211  \n",
       "14   1.710202e+07  6.982623e+01   -10.923047    31.401104  \n",
       "15   9.066667e+11  3.849124e+03    48.776736   106.184113  \n",
       "16   4.444440e+05  2.339810e-01    -0.185129     0.578140  \n",
       "17   1.315371e+07  1.843387e+01   -21.913521    50.017065  \n",
       "18   2.000000e+08  4.101646e+02 -2955.789198  4927.181066  \n",
       "19   9.800000e+10  2.859576e+05     5.339090    24.967467  \n",
       "20   1.816032e+07  7.195087e+01    25.405996   112.369378  \n",
       "21   9.385000e+03  5.573050e+00     0.275897     0.544607  \n",
       "22   2.090678e+05  3.781405e+00     0.291792     0.528275  \n",
       "23   6.000952e+12  1.888003e+05    13.021696    74.393380  \n",
       "24   9.999990e+05  1.350703e+01     2.967688    11.229089  \n",
       "25   1.411201e+07  7.961700e+01    96.395174   177.320646  \n",
       "26   3.302112e+07  1.169712e+01     3.021371    11.061291  \n",
       "27   3.112000e+04  2.775144e+00     0.652468     4.394059  \n",
       "28   3.012201e+07  2.391763e+01     0.384342     4.322383  \n",
       "29   3.720369e+09  3.650021e+02     0.106279     3.928994  \n",
       "30   3.512660e+05  1.861975e+02   266.494363   388.562816  \n",
       "31   3.550000e+07  8.281642e+01    24.965489    35.383949  \n",
       "32   2.000000e+12  2.127458e+04    74.595518   105.847735  \n",
       "33   3.720369e+09  8.190597e+01    -0.015579     1.095040  \n",
       "34   7.501200e+04  7.599375e+02  -608.949932  1182.072727  \n",
       "35   3.720369e+09  8.505009e+01    -0.079727     7.888474  \n",
       "36   2.004000e+03  5.093185e+00 -1101.151007  1833.906998  \n",
       "37   3.407000e+03  3.447365e+00     0.459064     6.395493  \n",
       "38   1.980230e+10  6.643426e+02   131.879673   200.250338  \n",
       "39   4.000000e+12  5.843027e+04    17.533517   128.074173  \n",
       "40   5.711570e+05  2.149659e+02  -179.011254   367.711169  \n",
       "41   1.255000e+07  1.373701e+01   -11.271099    23.118017  \n",
       "42   3.720369e+09  1.763100e+03     0.344858     2.340803  \n",
       "43   5.020000e+02  2.839491e+00    -0.073895     5.738996  \n",
       "44   1.012460e+05  8.320501e+02  -634.165544  1243.421119  \n",
       "45   2.470000e+04  2.591849e+00    -1.344051     4.967614  \n",
       "46   1.096500e+04  2.680884e+01    -6.462309    51.710100  \n",
       "47   4.354350e+04  4.083299e+01    31.295509    50.399080  \n",
       "48   2.021600e+04  1.284950e+02   -59.841461   281.110518  \n",
       "49   3.780000e+02  2.376339e+00     2.066500     2.655478  \n",
       "50   9.990000e+02  3.794378e+00     0.609005     6.832556  \n",
       "51   2.480000e+02  2.347791e+00     2.070485     2.603971  \n",
       "52   3.720369e+09  9.151366e+02    29.784070   139.676969  \n",
       "53   2.478000e+04  8.423415e+01   -90.142195   192.510000  \n",
       "54   2.530000e+10  5.727122e+05     3.870309    21.266291  \n",
       "55   1.215100e+04  5.360479e+01   -26.335878    90.693909  \n",
       "56   3.720369e+09  8.491083e+02     2.898841     5.296195  \n",
       "57   6.686000e+04  5.495602e+02  -347.003824   670.037525  \n",
       "58   3.720369e+09  9.799688e+02   132.452214   146.099184  \n",
       "59   1.100000e+04  1.104913e+01    -0.947903    19.890396  \n",
       "60   3.720369e+09  1.620601e+03     1.650045     8.133845  \n",
       "61   3.720369e+09  2.403661e+03    -0.488936     3.444129  \n",
       "62   8.080000e+02  5.956689e+00     0.423573    10.138546  \n",
       "63   3.720369e+09  2.535123e+04    75.644611   439.071809  \n",
       "64   3.720369e+09  6.149268e+04     3.277186     5.871597  \n",
       "65   2.603070e+05  1.398563e+01    10.411794    16.548972  \n",
       "66   2.000000e+04  4.997980e+01   -34.722049   124.493562  \n",
       "67   2.104936e+08  2.375269e+01    -8.016134    17.194342  \n",
       "68   1.762016e+06  1.506581e+00     0.332601     2.370315  \n",
       "69   3.720369e+09  3.871861e+02     0.006261     5.857908  \n",
       "70   1.247610e+05  7.859756e+02  -616.038970  1198.120663  \n",
       "71   1.550000e+11  5.216837e+06  -117.532589   233.365080  \n",
       "72   1.990000e+07  1.537853e+01    -1.159464     4.927924  \n",
       "73   2.060000e+05  2.705385e+01    -4.416892    48.131274  \n",
       "74   9.000000e+09  7.911712e+02    30.640767    50.902597  \n",
       "75   1.523013e+07  8.934480e+01    13.084213   146.109293  \n",
       "76   1.232190e+08  1.615846e+01    -1.367697    20.822091  \n",
       "77   7.042004e+06  2.638354e+00     2.058337     2.626330  \n",
       "78   3.720369e+09  7.465021e+01     1.749397     8.245063  \n",
       "79   3.720369e+09  1.368317e+02     0.637095     6.842963  \n",
       "80   3.720369e+09  5.354401e+02    23.438298   136.812468  \n",
       "81   1.905228e+08  1.202831e+02  -112.749797   247.068260  \n",
       "82   2.400000e+04  8.601245e+00    -4.583597    20.453698  \n",
       "83   1.000000e+11  5.508446e+05     4.277789    20.917526  \n",
       "84   7.022400e+04  5.737895e+01   -29.040429    94.768018  \n",
       "85   7.265600e+03  3.402179e+00     0.135161     6.497331  \n",
       "86   3.720369e+09  4.322233e+01     3.136406     5.469470  \n",
       "87   7.700000e+05  7.009120e+02  -500.317557   931.130828  \n",
       "88   6.910678e+07  1.413177e+02   132.031609   146.183544  \n",
       "89   9.210000e+02  5.323836e+01   -19.741510   124.038967  \n",
       "90   4.300000e+07  3.203331e+01    -0.908074    25.216474  \n",
       "91   1.010101e+06  5.174581e+00     1.559155     8.244092  \n",
       "92   3.720369e+09  4.449784e+02    -0.529052     3.286620  \n",
       "93   2.400000e+10  5.770647e+03     0.411447    10.238402  \n",
       "94   3.720369e+09  7.152044e+02   -93.228843   819.177614  \n",
       "95   7.280000e+02  1.481123e+01    -7.806517    20.627066  \n",
       "96   3.000000e+06  5.367082e+01   -30.340287   119.125827  \n",
       "97   1.111111e+11  6.007336e+02    82.366694   183.856668  \n",
       "98   8.100000e+06  2.560645e+01    -1.532900     5.129190  \n",
       "99   9.780000e+03  4.040092e+00    -1.962217     5.614838  \n",
       "100  1.229000e+03  4.803738e+01   -27.636647   120.531403  \n",
       "101  9.014000e+03  8.453068e+01    13.392947   138.915685  \n",
       "102  1.800000e+07  1.466419e+02    -1.845050    22.003884  \n",
       "103  3.720369e+09  9.647043e+02     0.518454     6.820118  \n",
       "104  3.720369e+09  2.501895e+02     1.609138    12.061040  \n",
       "105  1.000000e+10  9.960699e+02    -3.815196     7.955124  \n",
       "106  3.176800e+04  1.077503e+01    -4.143185     8.261282  \n",
       "107  8.713000e+04  7.427459e+01    22.686686   129.955590  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADDISONS_DISEASE</td>\n",
       "      <td>6691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADDISON_DISEASE</td>\n",
       "      <td>11794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>731332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALCOHOLMISUSE_V2</td>\n",
       "      <td>1125212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALLCANCER_NOHAEM_NOBCC</td>\n",
       "      <td>1496973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALLERGICRHINITISCONJ</td>\n",
       "      <td>3291165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALL_DEMENTIA</td>\n",
       "      <td>528602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANXIETY</td>\n",
       "      <td>3560978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ANY_DEAFNESS_HEARING_LOSS_V2</td>\n",
       "      <td>2282766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AORTICANEURYSM_V2</td>\n",
       "      <td>101134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ASTHMA_PUSHASTHMA</td>\n",
       "      <td>4175115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATOPICECZEMA</td>\n",
       "      <td>4369082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AUTISM</td>\n",
       "      <td>156860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BIPOLAR</td>\n",
       "      <td>108852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BRONCHIECTASIS</td>\n",
       "      <td>112618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHRONICFATIGUESYNDROMEMM_V2</td>\n",
       "      <td>82799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CHRONIC_LIVER_DISEASE_ALCOHOL</td>\n",
       "      <td>63405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CKDSTAGE3TO5</td>\n",
       "      <td>1088754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>COPD</td>\n",
       "      <td>751320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CROHNS_DISEASE</td>\n",
       "      <td>81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CYSTICFIBROSIS</td>\n",
       "      <td>7053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DEATH</td>\n",
       "      <td>1629100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DEPRESSION</td>\n",
       "      <td>4109336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DOWNSSYNDROME</td>\n",
       "      <td>17006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EATINGDISORDERS</td>\n",
       "      <td>191873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ENDOMETRIOSIS_ADENOMYOSIS_V2</td>\n",
       "      <td>209157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EPILEPSY</td>\n",
       "      <td>377341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FIBROMYALGIA</td>\n",
       "      <td>153213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GOUT</td>\n",
       "      <td>632089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HAEMOCHROMATOSIS_V2</td>\n",
       "      <td>18631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HF_V3</td>\n",
       "      <td>524982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HIVAIDS</td>\n",
       "      <td>41951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HYPERTENSION</td>\n",
       "      <td>3934473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HYPERTHYROIDISM_V2</td>\n",
       "      <td>217964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HYPOTHYROIDISM_DRAFT_V1</td>\n",
       "      <td>932079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>IHDINCLUDINGMI_OPTIMALV2</td>\n",
       "      <td>1162843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ILD_SH</td>\n",
       "      <td>58104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ISCHAEMICSTROKE_V2</td>\n",
       "      <td>178437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LEUKAEMIA_PREVALENCEV2</td>\n",
       "      <td>54438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LYMPHOMA_PREVALENCE_V2</td>\n",
       "      <td>80511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MENIERESDISEASE</td>\n",
       "      <td>73688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MINFARCTION</td>\n",
       "      <td>477556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>MS</td>\n",
       "      <td>53204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NAFLD_V2</td>\n",
       "      <td>158688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>OSA</td>\n",
       "      <td>234938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>OSTEOARTHRITIS</td>\n",
       "      <td>2653242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>OSTEOPOROSIS</td>\n",
       "      <td>628118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>OTHER_CHRONIC_LIVER_DISEASE_OPTIMAL</td>\n",
       "      <td>289252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PAD_STRICT</td>\n",
       "      <td>254632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PARKINSONS</td>\n",
       "      <td>91718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PERIPHERAL_NEUROPATHY</td>\n",
       "      <td>840638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>PERNICIOUSANAEMIA</td>\n",
       "      <td>73331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>PLASMACELL_NEOPLASM_V2</td>\n",
       "      <td>20301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PMRANDGCA</td>\n",
       "      <td>195907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>POLYCYSTIC_OVARIAN_SYNDROME_PCOS_V2</td>\n",
       "      <td>332297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>PREVALENT_IBS_V2</td>\n",
       "      <td>1210229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PSORIASIS</td>\n",
       "      <td>743897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>PSORIATICARTHRITIS2021</td>\n",
       "      <td>51273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>PTSDDIAGNOSIS</td>\n",
       "      <td>126269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PVD_V3</td>\n",
       "      <td>185904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>RHEUMATOIDARTHRITIS</td>\n",
       "      <td>197253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SCHIZOPHRENIAMM_V2</td>\n",
       "      <td>125141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SICKLE_CELL_DISEASE_V2</td>\n",
       "      <td>11159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SJOGRENSSYNDROME</td>\n",
       "      <td>23326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>STROKEUNSPECIFIED_V2</td>\n",
       "      <td>446046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>STROKE_HAEMRGIC</td>\n",
       "      <td>83609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>SUBSTANCEMISUSE</td>\n",
       "      <td>502552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SYSTEMIC_LUPUS_ERYTHEMATOSUS</td>\n",
       "      <td>26820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SYSTEMIC_SCLEROSIS</td>\n",
       "      <td>8772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>TYPE1DM</td>\n",
       "      <td>145143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>TYPE2DIABETES</td>\n",
       "      <td>1404325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ULCERATIVE_COLITIS</td>\n",
       "      <td>120361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>VALVULARDISEASES_V2</td>\n",
       "      <td>401061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>VISUAL_IMPAIRMENT</td>\n",
       "      <td>155707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  event    count\n",
       "0                      ADDISONS_DISEASE     6691\n",
       "1                       ADDISON_DISEASE    11794\n",
       "2                                    AF   731332\n",
       "3                      ALCOHOLMISUSE_V2  1125212\n",
       "4                ALLCANCER_NOHAEM_NOBCC  1496973\n",
       "5                  ALLERGICRHINITISCONJ  3291165\n",
       "6                          ALL_DEMENTIA   528602\n",
       "7                               ANXIETY  3560978\n",
       "8          ANY_DEAFNESS_HEARING_LOSS_V2  2282766\n",
       "9                     AORTICANEURYSM_V2   101134\n",
       "10                    ASTHMA_PUSHASTHMA  4175115\n",
       "11                         ATOPICECZEMA  4369082\n",
       "12                               AUTISM   156860\n",
       "13                              BIPOLAR   108852\n",
       "14                       BRONCHIECTASIS   112618\n",
       "15          CHRONICFATIGUESYNDROMEMM_V2    82799\n",
       "16        CHRONIC_LIVER_DISEASE_ALCOHOL    63405\n",
       "17                         CKDSTAGE3TO5  1088754\n",
       "18                                 COPD   751320\n",
       "19                       CROHNS_DISEASE    81250\n",
       "20                       CYSTICFIBROSIS     7053\n",
       "21                                DEATH  1629100\n",
       "22                           DEPRESSION  4109336\n",
       "23                        DOWNSSYNDROME    17006\n",
       "24                      EATINGDISORDERS   191873\n",
       "25         ENDOMETRIOSIS_ADENOMYOSIS_V2   209157\n",
       "26                             EPILEPSY   377341\n",
       "27                         FIBROMYALGIA   153213\n",
       "28                                 GOUT   632089\n",
       "29                  HAEMOCHROMATOSIS_V2    18631\n",
       "30                                HF_V3   524982\n",
       "31                              HIVAIDS    41951\n",
       "32                         HYPERTENSION  3934473\n",
       "33                   HYPERTHYROIDISM_V2   217964\n",
       "34              HYPOTHYROIDISM_DRAFT_V1   932079\n",
       "35             IHDINCLUDINGMI_OPTIMALV2  1162843\n",
       "36                               ILD_SH    58104\n",
       "37                   ISCHAEMICSTROKE_V2   178437\n",
       "38               LEUKAEMIA_PREVALENCEV2    54438\n",
       "39               LYMPHOMA_PREVALENCE_V2    80511\n",
       "40                      MENIERESDISEASE    73688\n",
       "41                          MINFARCTION   477556\n",
       "42                                   MS    53204\n",
       "43                             NAFLD_V2   158688\n",
       "44                                  OSA   234938\n",
       "45                       OSTEOARTHRITIS  2653242\n",
       "46                         OSTEOPOROSIS   628118\n",
       "47  OTHER_CHRONIC_LIVER_DISEASE_OPTIMAL   289252\n",
       "48                           PAD_STRICT   254632\n",
       "49                           PARKINSONS    91718\n",
       "50                PERIPHERAL_NEUROPATHY   840638\n",
       "51                    PERNICIOUSANAEMIA    73331\n",
       "52               PLASMACELL_NEOPLASM_V2    20301\n",
       "53                            PMRANDGCA   195907\n",
       "54  POLYCYSTIC_OVARIAN_SYNDROME_PCOS_V2   332297\n",
       "55                     PREVALENT_IBS_V2  1210229\n",
       "56                            PSORIASIS   743897\n",
       "57               PSORIATICARTHRITIS2021    51273\n",
       "58                        PTSDDIAGNOSIS   126269\n",
       "59                               PVD_V3   185904\n",
       "60                  RHEUMATOIDARTHRITIS   197253\n",
       "61                   SCHIZOPHRENIAMM_V2   125141\n",
       "62               SICKLE_CELL_DISEASE_V2    11159\n",
       "63                     SJOGRENSSYNDROME    23326\n",
       "64                 STROKEUNSPECIFIED_V2   446046\n",
       "65                      STROKE_HAEMRGIC    83609\n",
       "66                      SUBSTANCEMISUSE   502552\n",
       "67         SYSTEMIC_LUPUS_ERYTHEMATOSUS    26820\n",
       "68                   SYSTEMIC_SCLEROSIS     8772\n",
       "69                              TYPE1DM   145143\n",
       "70                        TYPE2DIABETES  1404325\n",
       "71                   ULCERATIVE_COLITIS   120361\n",
       "72                  VALVULARDISEASES_V2   401061\n",
       "73                    VISUAL_IMPAIRMENT   155707"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3508530089269363\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000) #replace n with the number of columns you want to see completely\n",
    "display(dm.train_set.meta_measurement)\n",
    "display(dm.train_set.meta_information[\"diagnosis_table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Plasma_N_terminal_pro_B_type_natriuretic_peptide_conc_70',\n",
       " 'N_terminal_pro_brain_natriuretic_peptide_level_67',\n",
       " 'Plasma_B_natriuretic_peptide_level_69',\n",
       " 'Plasma_pro_brain_natriuretic_peptide_level_64',\n",
       " 'Albumin___creatinine_ratio_37',\n",
       " 'Urine_microalbumin_creatinine_ratio_36',\n",
       " 'Plasma_ferritin_level_62',\n",
       " 'Brain_natriuretic_peptide_level_66',\n",
       " 'Serum_pro_brain_natriuretic_peptide_level_65',\n",
       " 'Serum_vitamin_D2_level_89',\n",
       " 'Total_25_hydroxyvitamin_D_level_91',\n",
       " 'Serum_N_terminal_pro_B_type_natriuretic_peptide_conc_68',\n",
       " 'Blood_calcium_level_38',\n",
       " 'INR___international_normalised_ratio_81',\n",
       " 'Combined_total_vitamin_D2_and_D3_level_93',\n",
       " 'TSH_level_74',\n",
       " 'Serum_T4_level_78',\n",
       " 'Plasma_cholesterol_HDL_ratio_96',\n",
       " 'Plasma_free_T4_level_77',\n",
       " '25_Hydroxyvitamin_D2_level_92',\n",
       " 'Blood_urea_28',\n",
       " '25_Hydroxyvitamin_D3_level_90',\n",
       " 'Plasma_corrected_calcium_level_43',\n",
       " 'Serum_25_Hydroxy_vitamin_D3_level_88',\n",
       " 'Plasma_calcium_level_40',\n",
       " 'Free_T4_level_76',\n",
       " 'Plasma_LDL_cholesterol_level_104',\n",
       " 'Calcium_adjusted_level_41',\n",
       " 'Plasma_triglyceride_level_106',\n",
       " 'AST___aspartate_transam_SGOT__46',\n",
       " 'Plasma_gamma_glutamyl_transferase_level_58',\n",
       " 'Plasma_urea_level_30',\n",
       " 'Plasma_TSH_level_73',\n",
       " 'Plasma_HDL_cholesterol_level_101',\n",
       " 'Serum_total_25_hydroxy_vitamin_D_level_87',\n",
       " 'Total_bilirubin_55',\n",
       " 'Plasma_total_cholesterol_level_99',\n",
       " 'Non_HDL_cholesterol_level_108',\n",
       " 'Serum_vitamin_D_86',\n",
       " 'Plasma_alkaline_phosphatase_level_49',\n",
       " 'Plasma_total_bilirubin_level_54',\n",
       " 'TSH___thyroid_stim_hormone_72',\n",
       " 'Plasma_albumin_level_52',\n",
       " 'Plasma_alanine_aminotransferase_level_44',\n",
       " 'Haematocrit___PCV_16',\n",
       " 'Plasma_potassium_level_27',\n",
       " 'Plasma_sodium_level_25',\n",
       " 'Plasma_creatinine_level_32',\n",
       " 'Serum_total_cholesterol_level_98',\n",
       " 'Total_alkaline_phosphatase_48',\n",
       " 'Haemoglobin_A1c_level_8',\n",
       " 'Calculated_LDL_cholesterol_level_103',\n",
       " 'Plasma_C_reactive_protein_60',\n",
       " 'Current_smoker_83',\n",
       " 'Serum_non_high_density_lipoprotein_cholesterol_level_107',\n",
       " 'AST_serum_level_47',\n",
       " 'eGFR_using_creatinine_CKD_EPI_per_1_73_square_metres_33',\n",
       " 'Serum_folate_80',\n",
       " 'HbA1c_level__DCCT_aligned__7',\n",
       " 'Urine_albumin_creatinine_ratio_35',\n",
       " 'Total_cholesterol_HDL_ratio_95',\n",
       " 'Corrected_serum_calcium_level_42',\n",
       " 'Serum_vitamin_B12_79',\n",
       " 'Serum_C_reactive_protein_level_59',\n",
       " 'Serum_ferritin_63',\n",
       " 'Serum_free_T4_level_75',\n",
       " 'Serum_gamma_glutamyl_transferase_level_57',\n",
       " 'Serum_bilirubin_level_53',\n",
       " 'Ex_smoker_84',\n",
       " 'International_normalised_ratio_82',\n",
       " 'Serum_calcium_39',\n",
       " 'Serum_cholesterol_HDL_ratio_94',\n",
       " 'Erythrocyte_sedimentation_rate_61',\n",
       " 'Serum_LDL_cholesterol_level_102',\n",
       " 'Haemoglobin_A1c_level___IFCC_standardised_6',\n",
       " 'Serum_triglycerides_105',\n",
       " 'Serum_alanine_aminotransferase_level_45',\n",
       " 'Red_blood_cell_distribution_width_17',\n",
       " 'Serum_HDL_cholesterol_level_100',\n",
       " 'Serum_total_bilirubin_level_56',\n",
       " 'Serum_TSH_level_71',\n",
       " 'Serum_cholesterol_97',\n",
       " 'Never_smoked_tobacco_85',\n",
       " 'O_E___height_1',\n",
       " 'Mean_corpusc_Hb_conc__MCHC__14',\n",
       " 'GFR_calculated_abbreviated_MDRD_34',\n",
       " 'Serum_alkaline_phosphatase_50',\n",
       " 'Haematocrit_15',\n",
       " 'Serum_urea_level_29',\n",
       " 'Serum_albumin_51',\n",
       " 'Basophil_count_22',\n",
       " 'Mean_corpusc_haemoglobin_MCH__13',\n",
       " 'Eosinophil_count_21',\n",
       " 'Red_blood_cell__RBC__count_10',\n",
       " 'Monocyte_count_23',\n",
       " 'Lymphocyte_count_20',\n",
       " 'Neutrophil_count_19',\n",
       " 'Mean_corpuscular_volume__MCV__11',\n",
       " 'Total_white_cell_count_18',\n",
       " 'Platelet_count_12',\n",
       " 'Haemoglobin_estimation_9',\n",
       " 'Serum_potassium_26',\n",
       " 'Serum_sodium_24',\n",
       " 'Body_mass_index_3',\n",
       " 'Serum_creatinine_31',\n",
       " 'O_E___weight_2',\n",
       " 'Diastolic_blood_pressure_5',\n",
       " 'Systolic_blood_pressure_4']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the measurements, using the fact that the diagnoses are all up upper case. This is needed for automatically setting the configuration below\n",
    "measurements_for_univariate_regression = [record for record in dm.tokenizer._event_counts[\"EVENT\"] if record.upper() != record]\n",
    "\n",
    "display(measurements_for_univariate_regression)\n",
    "# print(dm.encode(measurements_for_univariate_regression))\n",
    "# print(dm.decode([7,4,3,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Single-Risk DeSurvival head. This module predicts a separate survival curve for each possible future event\n",
      "INFO:root:Internally scaling time in survival head by 1825 days\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1825.0], with delta=1/300\n",
      "INFO:root:ModuleDict(\n",
      "  (Token 15): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 17): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 24): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 26): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 41): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 46): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 49): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 50): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 52): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 53): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 57): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 59): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 61): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 62): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 64): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 67): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 68): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 71): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 74): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 78): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 79): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 80): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 86): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 88): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 89): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 91): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 92): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 93): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 95): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 97): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 98): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 99): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 100): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 101): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 102): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 103): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 105): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 106): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 107): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 109): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 111): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 113): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 114): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 116): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 119): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 121): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 122): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 123): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 124): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 125): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 126): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 127): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 128): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 129): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 130): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 131): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 132): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 133): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 134): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 135): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 136): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 137): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 138): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 139): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 140): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 141): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 142): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 143): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 144): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 145): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 146): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 147): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 148): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 149): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 150): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 151): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 152): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 153): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 154): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 155): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 156): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 157): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 158): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 159): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 160): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 161): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 162): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 163): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 164): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 165): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 166): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 167): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 168): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 169): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 170): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 171): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 172): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 173): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 174): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 175): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 176): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 177): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 178): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 179): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 180): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 181): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 182): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 183): Linear(in_features=384, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models, m_names = [], []\n",
    "\n",
    "# My development model\n",
    "for surv_layer in [\"Competing-Risk\"]: #, \"Single-Risk\"]:\n",
    "    \n",
    "    ## Create configuration\n",
    "    config = DemoConfig()\n",
    "    # Specify which survival head layer to use\n",
    "    config.SurvLayer = surv_layer   \n",
    "    # list of univariate measurements to model with Normal distribution\n",
    "    config.tokens_for_univariate_regression = dm.encode(measurements_for_univariate_regression) \n",
    "    \n",
    "    models.append(SurvStreamGPTForCausalModelling(config, vocab_size).to(device))\n",
    "    m_names.append(f\"SurvStreamGPTForCausalModelling: {surv_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curves_train = [[] for _ in models]\n",
    "loss_curves_train_clf = [[] for _ in models]\n",
    "loss_curves_train_surv = [[] for _ in models]\n",
    "loss_curves_train_values = [[] for _ in models]\n",
    "\n",
    "loss_curves_val = [[] for _ in models]\n",
    "loss_curves_val_clf = [[] for _ in models]\n",
    "loss_curves_val_surv = [[] for _ in models]\n",
    "loss_curves_val_values = [[] for _ in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model `SurvStreamGPTForCausalModelling: Competing-Risk`, with 11.006427 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:   0%|          | 1001/356913 [06:00<35:37:56,  2.77it/s]\n",
      "Validation epoch 0:   1%|          | 101/18275 [00:26<1:18:56,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\tTrain loss -3.65: (0.15, -7.45). Val loss -6.51: (-1.29, -11.72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   0%|          | 1001/356913 [05:53<34:52:26,  2.83it/s]\n",
      "Validation epoch 1:   1%|          | 101/18275 [00:26<1:18:41,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\tTrain loss -6.64: (-1.79, -11.48). Val loss -8.20: (-1.96, -14.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2:   0%|          | 1001/356913 [05:54<34:58:56,  2.83it/s]\n",
      "Validation epoch 2:   1%|          | 101/18275 [00:26<1:18:48,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\tTrain loss -7.53: (-2.25, -12.82). Val loss -8.85: (-2.30, -15.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 3:   0%|          | 1001/356913 [05:51<34:43:41,  2.85it/s]\n",
      "Validation epoch 3:   1%|          | 101/18275 [00:26<1:18:34,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\tTrain loss -8.20: (-2.55, -13.84). Val loss -9.07: (-2.55, -15.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 4:   0%|          | 1001/356913 [05:51<34:43:58,  2.85it/s]\n",
      "Validation epoch 4:   1%|          | 101/18275 [00:26<1:18:40,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\tTrain loss -8.37: (-2.77, -13.98). Val loss -9.75: (-2.77, -16.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 5:   0%|          | 1001/356913 [05:55<35:06:11,  2.82it/s]\n",
      "Validation epoch 5:   1%|          | 101/18275 [00:26<1:18:45,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\tTrain loss -8.76: (-2.96, -14.57). Val loss -8.90: (-2.90, -14.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 6:   0%|          | 1001/356913 [05:52<34:51:41,  2.84it/s]\n",
      "Validation epoch 6:   1%|          | 101/18275 [00:26<1:18:56,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\tTrain loss -9.06: (-3.13, -14.99). Val loss -10.03: (-3.10, -16.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 7:   0%|          | 1001/356913 [05:55<35:05:24,  2.82it/s]\n",
      "Validation epoch 7:   1%|          | 101/18275 [00:26<1:18:56,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\tTrain loss -9.40: (-3.29, -15.51). Val loss -8.93: (-3.24, -14.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 8:   0%|          | 1001/356913 [05:52<34:47:46,  2.84it/s]\n",
      "Validation epoch 8:   1%|          | 101/18275 [00:26<1:18:38,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\tTrain loss -9.74: (-3.42, -16.07). Val loss -10.61: (-3.36, -17.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 9:   0%|          | 1001/356913 [05:54<35:02:38,  2.82it/s]\n",
      "Validation epoch 9:   1%|          | 101/18275 [00:26<1:18:44,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\tTrain loss -9.88: (-3.54, -16.21). Val loss -10.84: (-3.46, -18.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 10:   0%|          | 1001/356913 [05:53<34:56:47,  2.83it/s]\n",
      "Validation epoch 10:   1%|          | 101/18275 [00:26<1:18:37,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\tTrain loss -9.90: (-3.63, -16.17). Val loss -10.56: (-3.53, -17.58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 11:   0%|          | 42/356913 [00:17<42:06:52,  2.35it/s]\n",
      "Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f8471982e60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/weakref.py\", line 106, in remove\n",
      "    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_820579/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3972667617.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_820579/3972667617.py'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/bear-apps/2022a/EL8-ice/software/PyTorch/1.12.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127       # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131       # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132       </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/homes/g/gaddcz/Projects/CPRD/src/models/survival/task_heads/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">causal.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">92</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 89                                </span>attention_mask=attention_mask)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># shape: (bsz, </span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 90       </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 91       # survival time to event head (survival curve until next token)</span>                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 92 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>surv, losses_desurv = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.surv_layer.predict(hidden_states,                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93                                          </span>target_tokens=tokens,                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94                                          </span>target_ages=ages,                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95                                          </span>attention_mask=attention_mask,       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/homes/g/gaddcz/Projects/CPRD/src/modules/head_layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">surv_layers.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">241</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict</span>          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238          # Calculate losses, excluding masked values. Each sr_ode returns the sum ove</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239          #    to be consistent with other heads, we scale by number of observed value</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240          #    and we sum across the mixture of survival ODEs</span>                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>241 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>surv_loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sr_ode.loss(in_hidden_state, tte_deltas, k) / k.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">242          </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">243          # In generation mode we will return a cumulative density curve which can be </span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">244          </span>surv_CDF = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/homes/g/gaddcz/Projects/CPRD/src/modules/head_layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">desurv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">159</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">loss</span>                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.K):                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157          </span>uncens_ids = torch.where(k == i + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch.numel(uncens_ids) != <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>159 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>cdf_uncens = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.odenet.forward(x[uncens_ids, :], t[uncens_ids, :])[:,    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160             </span>dudt_uncens = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.odenet.ode_mapping(x[uncens_ids, :], t[uncens_ids, :]   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161             </span>pi = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_pi(x[uncens_ids, :])[:, i]                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/rds/homes/g/gaddcz/Projects/CPRD/src/modules/head_layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">desurv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">59</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 56    </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 57    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x, t, derivative=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 58       </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 59 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>tau = torch.matmul(t / <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.u)                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60       </span>tau_ = torch.flatten(tau).unsqueeze(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61       </span>reppedx = x.repeat_interleave(torch.tensor([<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.n] * t.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], dtype=torch.lo   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/tmp/ipykernel_820579/\u001b[0m\u001b[1;33m3972667617.py\u001b[0m:\u001b[94m19\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_820579/3972667617.py'\u001b[0m                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/rds/bear-apps/2022a/EL8-ice/software/PyTorch/1.12.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33mpackages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1130 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/rds/homes/g/gaddcz/Projects/CPRD/src/models/survival/task_heads/\u001b[0m\u001b[1;33mcausal.py\u001b[0m:\u001b[94m92\u001b[0m in \u001b[92mforward\u001b[0m         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 89 \u001b[0m\u001b[2m                               \u001b[0mattention_mask=attention_mask)  \u001b[2m# shape: (bsz, \u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 90 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 91 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# survival time to event head (survival curve until next token)\u001b[0m                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 92 \u001b[2m      \u001b[0msurv, losses_desurv = \u001b[96mself\u001b[0m.surv_layer.predict(hidden_states,                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m                                         \u001b[0mtarget_tokens=tokens,                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m                                         \u001b[0mtarget_ages=ages,                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m                                         \u001b[0mattention_mask=attention_mask,       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/rds/homes/g/gaddcz/Projects/CPRD/src/modules/head_layers/\u001b[0m\u001b[1;33msurv_layers.py\u001b[0m:\u001b[94m241\u001b[0m in \u001b[92mpredict\u001b[0m          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m# Calculate losses, excluding masked values. Each sr_ode returns the sum ove\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m239 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m#    to be consistent with other heads, we scale by number of observed value\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m240 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m#    and we sum across the mixture of survival ODEs\u001b[0m                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m241 \u001b[2m         \u001b[0msurv_loss = \u001b[96mself\u001b[0m.sr_ode.loss(in_hidden_state, tte_deltas, k) / k.shape[\u001b[94m0\u001b[0m]      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m242 \u001b[0m\u001b[2m         \u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m243 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m# In generation mode we will return a cumulative density curve which can be \u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m244 \u001b[0m\u001b[2m         \u001b[0msurv_CDF = \u001b[94mNone\u001b[0m                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/rds/homes/g/gaddcz/Projects/CPRD/src/modules/head_layers/\u001b[0m\u001b[1;33mdesurv.py\u001b[0m:\u001b[94m159\u001b[0m in \u001b[92mloss\u001b[0m                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[96mself\u001b[0m.K):                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m         \u001b[0muncens_ids = torch.where(k == i + \u001b[94m1\u001b[0m)[\u001b[94m0\u001b[0m]                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m torch.numel(uncens_ids) != \u001b[94m0\u001b[0m:                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m159 \u001b[2m            \u001b[0mcdf_uncens = \u001b[96mself\u001b[0m.odenet.forward(x[uncens_ids, :], t[uncens_ids, :])[:,    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m            \u001b[0mdudt_uncens = \u001b[96mself\u001b[0m.odenet.ode_mapping(x[uncens_ids, :], t[uncens_ids, :]   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m            \u001b[0mpi = \u001b[96mself\u001b[0m.get_pi(x[uncens_ids, :])[:, i]                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m162 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/rds/homes/g/gaddcz/Projects/CPRD/src/modules/head_layers/\u001b[0m\u001b[1;33mdesurv.py\u001b[0m:\u001b[94m59\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 57 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, x, t, derivative=\u001b[94mFalse\u001b[0m):                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 58 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 59 \u001b[2m      \u001b[0mtau = torch.matmul(t / \u001b[94m2\u001b[0m, \u001b[94m1\u001b[0m + \u001b[96mself\u001b[0m.u)                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m      \u001b[0mtau_ = torch.flatten(tau).unsqueeze(\u001b[94m1\u001b[0m)                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m      \u001b[0mreppedx = x.repeat_interleave(torch.tensor([\u001b[96mself\u001b[0m.n] * t.shape[\u001b[94m0\u001b[0m], dtype=torch.lo   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 62 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m_idx, (model, m_name) in enumerate(zip(models, m_names)):\n",
    "    \n",
    "    print(f\"Training model `{m_name}`, with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "    best_val, epochs_since_best = np.inf, 0\n",
    "    for epoch in range(opt.epochs):\n",
    "        \n",
    "        epoch_loss, epoch_surv_loss, epoch_values_loss = 0, 0, 0\n",
    "        model.train()\n",
    "        for i, batch in tqdm(enumerate(dm.train_dataloader()), desc=f\"Training epoch {epoch}\", total=len(dm.train_dataloader())):\n",
    "            if i > 1000:\n",
    "                break\n",
    "                \n",
    "            # evaluate the loss\n",
    "            _, (losses_desurv, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                          ages=batch['ages'].to(device), \n",
    "                                                          values=batch['values'].to(device),\n",
    "                                                          attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                          )\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # record\n",
    "            epoch_loss += loss.item()            \n",
    "            epoch_surv_loss += torch.sum(losses_desurv).item()\n",
    "            epoch_values_loss += loss_values.item()\n",
    "        \n",
    "        epoch_loss /= i\n",
    "        epoch_surv_loss /= i\n",
    "        epoch_values_loss /= i\n",
    "        loss_curves_train[m_idx].append(epoch_loss)\n",
    "        loss_curves_train_surv[m_idx].append(epoch_surv_loss)\n",
    "        loss_curves_train_values[m_idx].append(epoch_values_loss)\n",
    "\n",
    "        # evaluate the loss on val set\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            if epoch % opt.eval_interval == 0 or epoch == opt.epochs - 1:\n",
    "                val_loss, val_surv_loss, val_values_loss = 0, 0, 0\n",
    "                for j, batch in tqdm(enumerate(dm.val_dataloader()), desc=f\"Validation epoch {epoch}\", total=len(dm.val_dataloader())):\n",
    "                    if j > 100:\n",
    "                        break\n",
    "                    _, (losses_desurv, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                                  ages=batch['ages'].to(device),\n",
    "                                                                  values=batch['values'].to(device),\n",
    "                                                                  attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                                  )\n",
    "                    # record\n",
    "                    val_loss += loss.item()                    \n",
    "                    val_surv_loss += torch.sum(losses_desurv).item()\n",
    "                    val_values_loss += loss_values.item()\n",
    "                    \n",
    "                val_loss /= j\n",
    "                val_surv_loss /= j\n",
    "                val_values_loss /= j\n",
    "                loss_curves_val[m_idx].append(val_loss)\n",
    "                loss_curves_val_surv[m_idx].append(val_surv_loss)\n",
    "                loss_curves_val_values[m_idx].append(val_values_loss)\n",
    "\n",
    "                print(f\"Epoch {epoch}:\\tTrain loss {epoch_loss:.2f}: ({epoch_surv_loss:.2f}, {epoch_values_loss:.2f}). Val loss {val_loss:.2f}: ({val_surv_loss:.2f}, {val_values_loss:.2f})\")          \n",
    "                # TODO: Note not fully accurate as last batch is likely not the same size, will be fixed with lightning\n",
    "\n",
    "            if val_loss >= best_val:\n",
    "                epochs_since_best += 1\n",
    "                if epochs_since_best >= 5:\n",
    "                    break\n",
    "            else:\n",
    "                best_val = val_loss\n",
    "                epochs_since_best = 0\n",
    "\n",
    "                # Save best seen model\n",
    "                torch.save(model.state_dict(), path_to_db + \"polars/CR.pt\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model `SurvStreamGPTForCausalModelling: Competing-Risk`, with 11.006427 M parameters\n",
      "DEPRESSION                                        nan            at age 20 (7300.0 days)\n",
      "ANXIETY                                           nan            at age 25 (9125.0 days)\n",
      "Basophil_count_22                                 0.02           at age 30 (10950.0 days)\n",
      "Eosinophil_count_21                               0.07           at age 35 (12775.0 days)\n",
      "Erythrocyte_sedimentation_rate_61                 4.09           at age 40 (14600.0 days)\n",
      "GFR_calculated_abbreviated_MDRD_34                92.08          at age 45 (16425.0 days)\n",
      "Haematocrit_15                                    0.46           at age 50 (18250.0 days)\n",
      "Haemoglobin_estimation_9                          154.31         at age 55 (20075.0 days)\n",
      "Lymphocyte_count_20                               1.71           at age 60 (21900.0 days)\n",
      "Mean_corpusc_haemoglobin_MCH__13                  29.97          at age 65 (23725.0 days)\n",
      "Mean_corpuscular_volume__MCV__11                  89.44          at age 70 (25550.0 days)\n"
     ]
    }
   ],
   "source": [
    "for m_idx, (model, m_name) in enumerate(zip(models, m_names)):\n",
    "    \n",
    "    print(f\"Training model `{m_name}`, with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Test trained model with a prompt\n",
    "    # ----------------    \n",
    "    # set context: diagnosis of depression at 20 years old\n",
    "    tokens = torch.from_numpy(np.array(dm.encode([\"DEPRESSION\"])).reshape((1,-1))).to(device)\n",
    "    ages = torch.tensor([[20*365]], device=device)\n",
    "    values = torch.tensor([[torch.nan]], device=device)\n",
    "    \n",
    "    # generate: sample the next 10 tokens\n",
    "    new_tokens, new_ages, new_values = model.generate(tokens, ages, values, max_new_tokens=10)\n",
    "    generated = dm.decode(new_tokens[0].tolist())\n",
    "    # report:\n",
    "    for _cat, _age, _value in zip(generated.split(\" \"), new_ages[0, :], new_values[0, :]):\n",
    "        try:\n",
    "            _value = unstandardise(_cat, _value)\n",
    "        except:\n",
    "            pass\n",
    "        print(f\"{_cat}\".ljust(50) + f\"{_value:.02f}\".ljust(15) + f\"at age {_age/365:.0f} ({_age:.1f} days)\")    # with value {_value}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing output to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red_blood_cell__RBC__count_10                     5.27000        at age 53 (19414.0 days)\n",
      "Red_blood_cell_distribution_width_17              13.20000       at age 53 (19414.0 days)\n",
      "Serum_HDL_cholesterol_level_100                   0.90000        at age 53 (19414.0 days)\n",
      "Serum_LDL_cholesterol_level_102                   2.20000        at age 53 (19414.0 days)\n",
      "Serum_TSH_level_71                                1.10000        at age 53 (19414.0 days)\n",
      "Serum_alanine_aminotransferase_level_45           22.00000       at age 53 (19414.0 days)\n",
      "Serum_albumin_51                                  39.00000       at age 53 (19414.0 days)\n",
      "Serum_alkaline_phosphatase_50                     116.00001      at age 53 (19414.0 days)\n",
      "Serum_cholesterol_HDL_ratio_94                    3.80000        at age 53 (19414.0 days)\n",
      "Serum_creatinine_31                               78.00000       at age 53 (19414.0 days)\n"
     ]
    }
   ],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    break\n",
    "    \n",
    "conditions = batch[\"tokens\"].numpy().tolist()\n",
    "# delta_ages = batch[\"ages\"][:, 1:] - batch[\"ages\"][:, :-1]\n",
    "for idx, (token, _age, _value) in enumerate(zip(conditions[0], batch[\"ages\"][0,:],  batch[\"values\"][0,:])):\n",
    "    if token == 0 or idx >= 10:\n",
    "        break\n",
    "    _cat = dm.decode([token])\n",
    "    try:\n",
    "        _value = dm.unstandardise(_cat, _value)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    print(f\"{_cat}\".ljust(50) + f\"{_value:.05f}\".ljust(15) + f\"at age {_age/365:.0f} ({_age:.1f} days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"k\", \"r\", \"b\", \"y\"]\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train[m_idx]), len(loss_curves_train[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val[m_idx]), len(loss_curves_val[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/competing_risk/loss.png\")\n",
    "\n",
    "# Plot DeSurv loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_surv[m_idx]), len(loss_curves_train_surv[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_surv[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_surv[m_idx]), len(loss_curves_val_surv[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_surv[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/competing_risk/loss_desurv.png\")\n",
    "\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_values[m_idx]), len(loss_curves_train_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_values[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_values[m_idx]), len(loss_curves_val_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_values[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/competing_risk/loss_val.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes: How related conditions are impacted by each other\n",
    "Probability of type II diabetes before and after a type I diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "\n",
      "Depression: \t (DEPRESSION): \n",
      "\n",
      "Depression -> Type 1: \t (DEPRESSION,TYPE1DM): \n",
      "\n",
      "Depression - > Type 2: \t (DEPRESSION,TYPE2DIABETES): \n"
     ]
    }
   ],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"TYPE1DM\"]\n",
    "t2_token = dm.tokenizer._stoi[\"TYPE2DIABETES\"]\n",
    "\n",
    "\n",
    "base_prompt = [\"DEPRESSION\"]\n",
    "ages_in_years = [20]\n",
    "base_values = [torch.tensor([torch.nan])]\n",
    "\n",
    "to_days = lambda a_list: torch.FloatTensor([365 * _a for _a in a_list]).reshape((1,-1)).to(device)\n",
    "\n",
    "# Create a set of prompts\n",
    "prompts, ages, values, desc = [], [], [], []\n",
    "# control prompt\n",
    "desc.append(\"Depression\")\n",
    "prompts.append(base_prompt)\n",
    "ages.append(ages_in_years)\n",
    "values.append(base_values)\n",
    "# prompt with type 1 diabetes\n",
    "desc.append(\"Depression -> Type 1\")\n",
    "prompts.append(base_prompt + [\"TYPE1DM\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "desc.append(\"Depression - > Type 2\")\n",
    "prompts.append(base_prompt + [\"TYPE2DIABETES\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        prompt_survs = []\n",
    "        for p_idx, (prompt, age, value) in enumerate(zip(prompts, ages, values)):\n",
    "            print(f\"\\n{desc[p_idx]}: \\t ({','.join(prompt)}): \")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                           values=torch.tensor(value).to(device),\n",
    "                                           ages=to_days(age),\n",
    "                                           is_generation=True)\n",
    "            prompt_survs.append(surv)\n",
    "\n",
    "        for si, _ in enumerate(surv):\n",
    "            plt.close()\n",
    "            event_name = dm.decode([si + 1])\n",
    "            for p_idx in range(len(prompts)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, prompt_survs[p_idx][si][0, :], label=f\"{desc[p_idx]}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"figs/competing_risk/diabetes/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing BMI affects diagnosis risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "Value tensor([0.0464], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.1377], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.2291], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.3204], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.4117], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.5944], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.8989], device='cuda:0')\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\"\n",
    "                     ]\n",
    "prompt = [\"Body_mass_index_3\"]\n",
    "values = [torch.tensor([dm.standardise(_cat, v) for _cat in prompt], device=device) for v in [12.,15.,18.,21.,24.,30.,40.]]\n",
    "# values = [torch.tensor([float(v) for _cat in prompt], device=device) for v in np.linspace(0,1,5)]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        prompt_survs = []\n",
    "        for p_idx, value in enumerate(values):\n",
    "            print(f\"Value {value}\\n======\")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                           values=value,\n",
    "                                           ages=to_days(age),\n",
    "                                           is_generation=True)\n",
    "            prompt_survs.append(surv)\n",
    "\n",
    "        for si, _ in enumerate(surv):\n",
    "            plt.close()\n",
    "            event_name = dm.decode([si + 1])\n",
    "            \n",
    "            if event_name in events_of_interest:\n",
    "                \n",
    "                for p_idx in range(len(prompt_survs)):\n",
    "                    bmi_value = dm.unstandardise(\"Body_mass_index_3\", values[p_idx])\n",
    "                    plt.plot(model.surv_layer.t_eval / 365, prompt_survs[p_idx][si][0, :], label=f\"BMI {bmi_value:.2f}\")\n",
    "                plt.xlabel(\"t (years)\")\n",
    "                plt.ylabel(\"P(T>t) ()\")\n",
    "                plt.legend()\n",
    "                plt.savefig(f\"figs/competing_risk/bmi/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing diastolic_blood_pressure affects likelihood of diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "Value tensor([0.1955], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.3697], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.5439], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.7181], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.8923], device='cuda:0')\n",
      "======\n",
      "Value tensor([1.2407], device='cuda:0')\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\"\n",
    "                     ]\n",
    "\n",
    "prompt = [\"Diastolic_blood_pressure_5\"]\n",
    "values = [torch.tensor([dm.standardise(_cat, _value) for _cat in prompt], device=device) for _value in [60.,70.,80.,90.,100.,120.]]\n",
    "# values = [torch.tensor([float(v) for _cat in prompt], device=device) for v in np.linspace(0,1,5)]\n",
    "age = [40]\n",
    "\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        prompt_survs = []\n",
    "        for p_idx, value in enumerate(values):\n",
    "            print(f\"Value {value}\\n======\")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                           values=value,\n",
    "                                           ages=to_days(age),\n",
    "                                           is_generation=True)\n",
    "            prompt_survs.append(surv)\n",
    "\n",
    "        for si, _ in enumerate(surv):\n",
    "            plt.close()\n",
    "            event_name = dm.decode([si + 1])\n",
    "            \n",
    "            if event_name in events_of_interest:\n",
    "                \n",
    "                for p_idx in range(len(prompt_survs)):\n",
    "                    dbp_value = unstandardise(\"Diastolic_blood_pressure_5\", values[p_idx])\n",
    "                    plt.plot(model.surv_layer.t_eval / 365, prompt_survs[p_idx][si][0, :], label=f\"DBP {dbp_value.item():.2f}\")\n",
    "                plt.xlabel(\"t (years)\")\n",
    "                plt.ylabel(\"P(T>t) ()\")\n",
    "                plt.legend()\n",
    "                plt.savefig(f\"figs/competing_risk/diastolic_blood_pressure/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How varying diagnosis affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "\n",
      "Diagnosis ['DEPRESSION']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.5, 0.2)\n",
      "\n",
      "Diagnosis ['TYPE2DIABETES']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.6, 0.2)\n",
      "\n",
      "Diagnosis ['HF_V3']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.5, 0.2)\n",
      "\n",
      "Diagnosis ['HYPERTENSION']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.6, 0.2)\n"
     ]
    }
   ],
   "source": [
    "measurements_of_interest = [\"Diastolic_blood_pressure_5\"]\n",
    "t1_token = dm.tokenizer._stoi[\"Diastolic_blood_pressure_5\"]\n",
    "\n",
    "diagnoses = [[\"DEPRESSION\"],[\"TYPE2DIABETES\"], [\"HF_V3\"], [\"HYPERTENSION\"]]\n",
    "values = torch.tensor([torch.nan], device=device)\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "    for p_idx, diagnosis in enumerate(diagnoses):\n",
    "        print(f\"\\nDiagnosis {diagnosis}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(diagnosis)).reshape((1,-1))).to(device)\n",
    "        (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                       values=values,\n",
    "                                       ages=to_days(age),\n",
    "                                       is_generation=True)\n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing bmi affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "\n",
      "Values [0.04638069495558739]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.5, 0.2)\n",
      "\n",
      "Values [0.13772238790988922]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.4, 0.2)\n",
      "\n",
      "Values [0.22906407713890076]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.4, 0.2)\n",
      "\n",
      "Values [0.3204057812690735]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.4, 0.2)\n",
      "\n",
      "Values [0.4117474853992462]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.4, 0.2)\n",
      "\n",
      "Values [0.5944308638572693]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.5, 0.2)\n",
      "\n",
      "Values [0.8989031910896301]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.6, 0.2)\n",
      "\n",
      "Values [1.2033754587173462]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.6, 0.2)\n"
     ]
    }
   ],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"Diastolic_blood_pressure_5\"]\n",
    "\n",
    "prompt = [\"Body_mass_index_3\"]\n",
    "values = [torch.tensor([dm.standardise(_cat, _value) for _cat in prompt], device=device) for _value in [12.,15.,18.,21.,24.,30.,40.,50.]]\n",
    "# values = [torch.tensor([float(v) for _cat in prompt], device=device) for v in np.linspace(-0.2,1.2,5)]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    for p_idx, value in enumerate(values):\n",
    "        print(f\"\\nValues {value.tolist()}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                       values=value,\n",
    "                                       ages=to_days(age),\n",
    "                                       is_generation=True)\n",
    "        \n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "        # print(f\"\\tprobability of type II diabetes: {100*float(probs[0, 0, t2_token].cpu().detach().numpy()):.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "===============================================\n",
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling(\n",
      "  (transformer): TTETransformer(\n",
      "    (wpe): TemporalPositionalEncoding()\n",
      "    (wte): DataEmbeddingLayer(\n",
      "      (token_embed_layer): Embedding(184, 384, padding_idx=0)\n",
      "      (value_embed_layer): EmbeddingBag(184, 384, mode=sum, padding_idx=0)\n",
      "    )\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (surv_layer): ODESurvCompetingRiskLayer(\n",
      "    (sr_ode): ODESurvMultiple(\n",
      "      (pinet): FCNet(\n",
      "        (mapping): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=183, bias=True)\n",
      "          (1): Softmax(dim=1)\n",
      "        )\n",
      "      )\n",
      "      (odenet): CondODENet(\n",
      "        (BaseNet): FCNet(\n",
      "          (mapping): Sequential(\n",
      "            (0): Linear(in_features=385, out_features=183, bias=True)\n",
      "            (1): Softplus(beta=1, threshold=20)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (value_layer): GaussianRegressionLayer(\n",
      "    (regression_layers): ModuleDict(\n",
      "      (Token 15): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 17): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 24): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 26): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 41): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 46): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 49): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 50): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 52): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 53): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 57): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 59): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 61): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 62): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 64): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 67): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 68): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 71): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 74): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 78): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 79): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 80): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 86): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 88): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 89): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 91): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 92): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 93): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 95): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 97): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 98): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 99): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 100): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 101): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 102): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 103): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 105): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 106): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 107): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 109): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 111): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 113): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 114): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 116): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 119): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 121): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 122): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 123): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 124): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 125): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 126): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 127): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 128): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 129): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 130): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 131): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 132): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 133): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 134): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 135): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 136): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 137): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 138): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 139): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 140): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 141): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 142): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 143): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 144): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 145): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 146): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 147): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 148): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 149): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 150): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 151): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 152): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 153): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 154): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 155): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 156): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 157): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 158): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 159): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 160): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 161): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 162): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 163): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 164): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 165): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 166): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 167): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 168): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 169): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 170): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 171): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 172): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 173): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 174): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 175): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 176): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 177): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 178): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 179): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 180): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 181): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 182): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 183): Linear(in_features=384, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n\" + \"=\"*len(m_names[model_idx]))\n",
    "    print(f\"\\n\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook competing_risk.ipynb to html\n",
      "[NbConvertApp] Writing 688398 bytes to competing_risk.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html --no-input competing_risk.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
