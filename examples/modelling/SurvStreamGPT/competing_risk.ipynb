{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Demo Notebook:\n",
    "## Survival Transformer For Causal Sequence Modelling \n",
    "\n",
    "Including time, and excluding tabular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvStreamGPT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "# TODO:\n",
    "# replace experiment boilerplate with pytorch lightning\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config to be equivalent architecture of kaparthy benchmark, however they are not comparable tasks.\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    block_size: int = 128        # what is the maximum context length for predictions?\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 6\n",
    "    n_embd: int = 384\n",
    "    bias: bool = True\n",
    "    attention_type: str = \"global\"    \n",
    "    dropout: float = 0.0\n",
    "    unk_freq_threshold: float = 0.0\n",
    "    SurvLayer = \"Competing-Risk\"                                  # \"Competing-Risk\"\n",
    "    tokens_for_univariate_regression = None\n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "@dataclass\n",
    "class OptConfig:\n",
    "    batch_size: int = 64\n",
    "    eval_interval: int = 1\n",
    "    learning_rate: float = 3e-4\n",
    "    epochs: int = 100\n",
    "    \n",
    "opt = OptConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader on a reduced cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building polars dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all available 129717 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using measurements\n",
      "INFO:root:Using test/measurement standardisation method: normalise\n",
      "INFO:root:Removing measurement and test outliers. Using three deviations from mean as cutoff\n",
      "INFO:root:Using diagnoses\n",
      "INFO:root:Dropping samples with no dynamic events\n",
      "INFO:root:Using tabular tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107683 training samples\n",
      "5983 validation samples\n",
      "5982 test samples\n",
      "90 vocab elements (including PAD and UNK tokens)\n",
      "{0: 'PAD', 1: 'UNK', 2: 'diastolic_blood_pressure', 3: 'bmi', 4: 'eosinophil_count', 5: 'basophil_count', 6: 'corrected_serum_calcium_level', 7: 'DEPRESSION', 8: 'serum_level', 9: 'calculated_LDL_cholesterol_level', 10: 'ANXIETY', 11: 'HYPERTENSION', 12: 'TYPE2DIABETES', 13: 'OSTEOARTHRITIS', 14: 'ASTHMA_PUSHASTHMA', 15: 'ATOPICECZEMA', 16: 'ALLERGICRHINITISCONJ', 17: 'ANY_DEAFNESS_HEARING_LOSS', 18: 'aspartate_transam', 19: 'PREVALENT_IBS', 20: 'ALLCA_NOBCC_VFINAL', 21: 'IHD_NOMI', 22: 'ALCOHOLMISUSE', 23: 'CKDSTAGE3TO5', 24: 'blood_urea', 25: 'PERIPHERAL_NEUROPATHY', 26: 'calcium_adjusted_level', 27: 'HYPOTHYROIDISM_DRAFT_V1', 28: 'COPD', 29: 'AF', 30: 'combined_total_vitamin_D2_and_D3_level', 31: 'HF', 32: 'OSTEOPOROSIS', 33: 'PSORIASIS', 34: 'SUBSTANCEMISUSE', 35: 'GOUT', 36: 'MINFARCTION', 37: 'STROKEUNSPECIFIED', 38: 'ALL_DEMENTIA', 39: 'hydroxyvitamin3', 40: 'hydroxyvitamin2', 41: 'VALVULARDISEASES', 42: 'PAD_STRICT', 43: 'OTHER_CHRONIC_LIVER_DISEASE_OPTIMAL', 44: 'TYPE1DM', 45: 'EPILEPSY', 46: 'OSA', 47: 'FIBROMYALGIA', 48: 'POLYCYSTIC_OVARIAN_SYNDROME_PCOS', 49: 'NAFLD', 50: 'RHEUMATOIDARTHRITIS', 51: 'EATINGDISORDERS', 52: 'HYPERTHYROIDISM', 53: 'PMRANDGCA', 54: 'ENDOMETRIOSIS_ADENOMYOSIS_V2', 55: 'PTSDDIAGNOSIS', 56: 'ISCHAEMICSTROKE', 57: 'creatinine_ratio', 58: 'BIPOLAR', 59: 'VISUAL_IMPAIRMENT', 60: 'SCHIZOPHRENIAMM', 61: 'BRONCHIECTASIS', 62: 'CHRONIC_LIVER_DISEASE_ALCOHOL', 63: 'AORTICANEURYSM', 64: 'CHRONICFATIGUESYNDROMEMM', 65: 'ULCERATIVE_COLITIS', 66: 'LEARNINGDISABILITY', 67: 'PERNICIOUSANAEMIA', 68: 'PARKINSONS', 69: 'STROKE_HAEMRGIC', 70: 'MENIERESDISEASE', 71: 'LYMPHOMA_PREVALENCE', 72: 'brain_natriuretic_peptide_level', 73: 'CROHNS_DISEASE', 74: 'ILD_SH', 75: 'AUTISM', 76: 'PSORIATICARTHRITIS2021', 77: 'MS', 78: 'LEUKAEMIA_PREVALENCE', 79: 'HIVAIDS', 80: 'SJOGRENSSYNDROME', 81: 'SYSTEMIC_LUPUS_ERYTHEMATOSUS', 82: 'HAEMOCHROMATOSIS', 83: 'blood_calcium', 84: 'PLASMACELL_NEOPLASM', 85: 'ADDISON_DISEASE', 86: 'SYSTEMIC_SCLEROSIS', 87: 'CYSTICFIBROSIS', 88: 'DOWNSSYNDROME', 89: 'SICKLE_CELL_DISEASE'}\n"
     ]
    }
   ],
   "source": [
    "from CPRD.data.database import queries\n",
    "\n",
    "# Get a list of patients which fit a reduced set of criterion\n",
    "PATH_TO_DB = \"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModel/preprocessing/processed/cprd.db\"\n",
    "conn = sqlite3.connect(PATH_TO_DB)\n",
    "cursor = conn.cursor()\n",
    "# identifiers1 = queries.query_measurement([\"bmi\", \"diastolic_blood_pressure\"], cursor)        \n",
    "identifiers2 = queries.query_diagnosis([\"DEPRESSION\", \"TYPE1DM\", \"TYPE2DIABETES\"], cursor)    #  \"DEPRESSION\"  ,  \"ANXIETY\"\n",
    "# all_identifiers = list(set(identifiers1).intersection(identifiers2))    # Turn smaller list into the set\n",
    "all_identifiers = identifiers2\n",
    "\n",
    "if False:\n",
    "    # Lets take only the first N for faster run-time\n",
    "    N = np.min((len(all_identifiers), 20000))\n",
    "    print(f\"Using N={N} random samples, from the available {len(all_identifiers)}\")\n",
    "    identifiers = random.choices(all_identifiers, k=N)\n",
    "else:\n",
    "    print(f\"Using all available {len(all_identifiers)} samples\")\n",
    "    identifiers = all_identifiers\n",
    "\n",
    "# Build \n",
    "dm = FoundationalDataModule(identifiers=identifiers,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            batch_size=opt.batch_size,\n",
    "                            max_seq_length=config.block_size,\n",
    "                            unk_freq_threshold=config.unk_freq_threshold,\n",
    "                            include_measurements=True,\n",
    "                            include_diagnoses=True,\n",
    "                            preprocess_measurements=True\n",
    "                           )\n",
    "\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "\n",
    "print(f\"{len(dm.train_set)} training samples\")\n",
    "print(f\"{len(dm.val_set)} validation samples\")\n",
    "print(f\"{len(dm.test_set)} test samples\")\n",
    "print(f\"{vocab_size} vocab elements (including PAD and UNK tokens)\")\n",
    "print(dm.train_set.tokenizer._itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation\n",
    "\n",
    "This was performed automatically across measurements and tests in the dataloader. The standardisation statistics (bias and scale respectively) are given in the dictionary object. \n",
    "\n",
    "We define two mappings to simplify notation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'combined_total_vitamin_D2_and_D3_level': (56.94353322028673,\n",
       "  29.241759267841857),\n",
       " 'bmi': (29.629965163503474, 7.013281083178253),\n",
       " 'hydroxyvitamin3': (52.36982317356912, 30.382475290251843),\n",
       " 'diastolic_blood_pressure': (78.86937661562213, 11.727257179342669),\n",
       " 'eosinophil_count': (0.22162065765491276, 0.18957815785763468),\n",
       " 'brain_natriuretic_peptide_level': (156.9857534246576, 291.8915253494199),\n",
       " 'creatinine_ratio': (4.435476477683948, 8.185329269651573),\n",
       " 'hydroxyvitamin2': (3.268025477707002, 2.8054309314024435),\n",
       " 'corrected_serum_calcium_level': (2.319034923472716, 0.12451622974555095),\n",
       " 'calculated_LDL_cholesterol_level': (2.5891371173802233, 1.0358897687206567),\n",
       " 'blood_urea': (6.702299445123703, 4.281261339020057),\n",
       " 'blood_calcium': (2.334465408805031, 0.1487655865623607),\n",
       " 'basophil_count': (0.06984214216499786, 0.10630741873638763),\n",
       " 'aspartate_transam': (26.791031390134528, 18.877776290025214),\n",
       " 'calcium_adjusted_level': (2.315393830170679, 0.10855075164585075),\n",
       " 'serum_level': (27.19654609350041, 20.584990688686364)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052762014256647304\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "display(dm.standardisation_dict)\n",
    "\n",
    "standardise = lambda key, v: (v - dm.standardisation_dict[key][0]) / dm.standardisation_dict[key][1]\n",
    "unstandardise = lambda key, v: (v * dm.standardisation_dict[key][1]) + dm.standardisation_dict[key][0]\n",
    "\n",
    "print(standardise(\"bmi\", 30))\n",
    "print(unstandardise(\"bmi\", standardise(\"bmi\", 20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the frequency of tokens in the extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (89, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>EVENT</th><th>counts</th><th>freq</th></tr><tr><td>str</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;UNK&quot;</td><td>0</td><td>0.0</td></tr><tr><td>&quot;diastolic_bloo…</td><td>2226462</td><td>0.422762</td></tr><tr><td>&quot;bmi&quot;</td><td>865608</td><td>0.164362</td></tr><tr><td>&quot;eosinophil_cou…</td><td>811240</td><td>0.154039</td></tr><tr><td>&quot;basophil_count…</td><td>531602</td><td>0.100941</td></tr><tr><td>&quot;corrected_seru…</td><td>148788</td><td>0.028252</td></tr><tr><td>&quot;DEPRESSION&quot;</td><td>86494</td><td>0.016424</td></tr><tr><td>&quot;serum_level&quot;</td><td>75845</td><td>0.014401</td></tr><tr><td>&quot;calculated_LDL…</td><td>69073</td><td>0.013116</td></tr><tr><td>&quot;ANXIETY&quot;</td><td>48181</td><td>0.009149</td></tr><tr><td>&quot;HYPERTENSION&quot;</td><td>32904</td><td>0.006248</td></tr><tr><td>&quot;TYPE2DIABETES&quot;</td><td>27354</td><td>0.005194</td></tr><tr><td>&quot;OSTEOARTHRITIS…</td><td>25398</td><td>0.004823</td></tr><tr><td>&quot;ASTHMA_PUSHAST…</td><td>25306</td><td>0.004805</td></tr><tr><td>&quot;ATOPICECZEMA&quot;</td><td>23091</td><td>0.004385</td></tr><tr><td>&quot;ALLERGICRHINIT…</td><td>18473</td><td>0.003508</td></tr><tr><td>&quot;ANY_DEAFNESS_H…</td><td>17177</td><td>0.003262</td></tr><tr><td>&quot;aspartate_tran…</td><td>16911</td><td>0.003211</td></tr><tr><td>&quot;PREVALENT_IBS&quot;</td><td>11727</td><td>0.002227</td></tr><tr><td>&quot;ALLCA_NOBCC_VF…</td><td>11671</td><td>0.002216</td></tr><tr><td>&quot;IHD_NOMI&quot;</td><td>11244</td><td>0.002135</td></tr><tr><td>&quot;ALCOHOLMISUSE&quot;</td><td>11203</td><td>0.002127</td></tr><tr><td>&quot;CKDSTAGE3TO5&quot;</td><td>10458</td><td>0.001986</td></tr><tr><td>&quot;blood_urea&quot;</td><td>9577</td><td>0.001818</td></tr><tr><td>&quot;PERIPHERAL_NEU…</td><td>8802</td><td>0.001671</td></tr><tr><td>&quot;calcium_adjust…</td><td>8513</td><td>0.001616</td></tr><tr><td>&quot;HYPOTHYROIDISM…</td><td>8036</td><td>0.001526</td></tr><tr><td>&quot;COPD&quot;</td><td>7731</td><td>0.001468</td></tr><tr><td>&quot;AF&quot;</td><td>6261</td><td>0.001189</td></tr><tr><td>&quot;combined_total…</td><td>5816</td><td>0.001104</td></tr><tr><td>&quot;HF&quot;</td><td>5749</td><td>0.001092</td></tr><tr><td>&quot;OSTEOPOROSIS&quot;</td><td>5709</td><td>0.001084</td></tr><tr><td>&quot;PSORIASIS&quot;</td><td>5643</td><td>0.001071</td></tr><tr><td>&quot;SUBSTANCEMISUS…</td><td>5594</td><td>0.001062</td></tr><tr><td>&quot;GOUT&quot;</td><td>5328</td><td>0.001012</td></tr><tr><td>&quot;MINFARCTION&quot;</td><td>4965</td><td>0.000943</td></tr><tr><td>&quot;STROKEUNSPECIF…</td><td>4509</td><td>0.000856</td></tr><tr><td>&quot;ALL_DEMENTIA&quot;</td><td>4419</td><td>0.000839</td></tr><tr><td>&quot;hydroxyvitamin…</td><td>3865</td><td>0.000734</td></tr><tr><td>&quot;hydroxyvitamin…</td><td>3515</td><td>0.000667</td></tr><tr><td>&quot;VALVULARDISEAS…</td><td>3219</td><td>0.000611</td></tr><tr><td>&quot;PAD_STRICT&quot;</td><td>3217</td><td>0.000611</td></tr><tr><td>&quot;OTHER_CHRONIC_…</td><td>2947</td><td>0.00056</td></tr><tr><td>&quot;TYPE1DM&quot;</td><td>2854</td><td>0.000542</td></tr><tr><td>&quot;EPILEPSY&quot;</td><td>2580</td><td>0.00049</td></tr><tr><td>&quot;OSA&quot;</td><td>2455</td><td>0.000466</td></tr><tr><td>&quot;FIBROMYALGIA&quot;</td><td>2409</td><td>0.000457</td></tr><tr><td>&quot;POLYCYSTIC_OVA…</td><td>2193</td><td>0.000416</td></tr><tr><td>&quot;NAFLD&quot;</td><td>2164</td><td>0.000411</td></tr><tr><td>&quot;RHEUMATOIDARTH…</td><td>2066</td><td>0.000392</td></tr><tr><td>&quot;EATINGDISORDER…</td><td>1972</td><td>0.000374</td></tr><tr><td>&quot;HYPERTHYROIDIS…</td><td>1907</td><td>0.000362</td></tr><tr><td>&quot;PMRANDGCA&quot;</td><td>1902</td><td>0.000361</td></tr><tr><td>&quot;ENDOMETRIOSIS_…</td><td>1833</td><td>0.000348</td></tr><tr><td>&quot;PTSDDIAGNOSIS&quot;</td><td>1695</td><td>0.000322</td></tr><tr><td>&quot;ISCHAEMICSTROK…</td><td>1541</td><td>0.000293</td></tr><tr><td>&quot;creatinine_rat…</td><td>1479</td><td>0.000281</td></tr><tr><td>&quot;BIPOLAR&quot;</td><td>1393</td><td>0.000265</td></tr><tr><td>&quot;VISUAL_IMPAIRM…</td><td>1374</td><td>0.000261</td></tr><tr><td>&quot;SCHIZOPHRENIAM…</td><td>1319</td><td>0.00025</td></tr><tr><td>&quot;BRONCHIECTASIS…</td><td>1068</td><td>0.000203</td></tr><tr><td>&quot;CHRONIC_LIVER_…</td><td>929</td><td>0.000176</td></tr><tr><td>&quot;AORTICANEURYSM…</td><td>906</td><td>0.000172</td></tr><tr><td>&quot;CHRONICFATIGUE…</td><td>840</td><td>0.000159</td></tr><tr><td>&quot;ULCERATIVE_COL…</td><td>840</td><td>0.000159</td></tr><tr><td>&quot;LEARNINGDISABI…</td><td>737</td><td>0.00014</td></tr><tr><td>&quot;PERNICIOUSANAE…</td><td>720</td><td>0.000137</td></tr><tr><td>&quot;PARKINSONS&quot;</td><td>709</td><td>0.000135</td></tr><tr><td>&quot;STROKE_HAEMRGI…</td><td>697</td><td>0.000132</td></tr><tr><td>&quot;MENIERESDISEAS…</td><td>693</td><td>0.000132</td></tr><tr><td>&quot;LYMPHOMA_PREVA…</td><td>589</td><td>0.000112</td></tr><tr><td>&quot;brain_natriure…</td><td>581</td><td>0.00011</td></tr><tr><td>&quot;CROHNS_DISEASE…</td><td>549</td><td>0.000104</td></tr><tr><td>&quot;ILD_SH&quot;</td><td>540</td><td>0.000103</td></tr><tr><td>&quot;AUTISM&quot;</td><td>505</td><td>0.000096</td></tr><tr><td>&quot;PSORIATICARTHR…</td><td>484</td><td>0.000092</td></tr><tr><td>&quot;MS&quot;</td><td>419</td><td>0.00008</td></tr><tr><td>&quot;LEUKAEMIA_PREV…</td><td>394</td><td>0.000075</td></tr><tr><td>&quot;HIVAIDS&quot;</td><td>288</td><td>0.000055</td></tr><tr><td>&quot;SJOGRENSSYNDRO…</td><td>238</td><td>0.000045</td></tr><tr><td>&quot;SYSTEMIC_LUPUS…</td><td>223</td><td>0.000042</td></tr><tr><td>&quot;HAEMOCHROMATOS…</td><td>197</td><td>0.000037</td></tr><tr><td>&quot;blood_calcium&quot;</td><td>146</td><td>0.000028</td></tr><tr><td>&quot;PLASMACELL_NEO…</td><td>130</td><td>0.000025</td></tr><tr><td>&quot;ADDISON_DISEAS…</td><td>105</td><td>0.00002</td></tr><tr><td>&quot;SYSTEMIC_SCLER…</td><td>73</td><td>0.000014</td></tr><tr><td>&quot;CYSTICFIBROSIS…</td><td>44</td><td>0.000008</td></tr><tr><td>&quot;DOWNSSYNDROME&quot;</td><td>39</td><td>0.000007</td></tr><tr><td>&quot;SICKLE_CELL_DI…</td><td>23</td><td>0.000004</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (89, 3)\n",
       "┌───────────────────────────────────┬─────────┬──────────┐\n",
       "│ EVENT                             ┆ counts  ┆ freq     │\n",
       "│ ---                               ┆ ---     ┆ ---      │\n",
       "│ str                               ┆ u32     ┆ f64      │\n",
       "╞═══════════════════════════════════╪═════════╪══════════╡\n",
       "│ UNK                               ┆ 0       ┆ 0.0      │\n",
       "│ diastolic_blood_pressure          ┆ 2226462 ┆ 0.422762 │\n",
       "│ bmi                               ┆ 865608  ┆ 0.164362 │\n",
       "│ eosinophil_count                  ┆ 811240  ┆ 0.154039 │\n",
       "│ basophil_count                    ┆ 531602  ┆ 0.100941 │\n",
       "│ corrected_serum_calcium_level     ┆ 148788  ┆ 0.028252 │\n",
       "│ DEPRESSION                        ┆ 86494   ┆ 0.016424 │\n",
       "│ serum_level                       ┆ 75845   ┆ 0.014401 │\n",
       "│ calculated_LDL_cholesterol_level  ┆ 69073   ┆ 0.013116 │\n",
       "│ ANXIETY                           ┆ 48181   ┆ 0.009149 │\n",
       "│ HYPERTENSION                      ┆ 32904   ┆ 0.006248 │\n",
       "│ TYPE2DIABETES                     ┆ 27354   ┆ 0.005194 │\n",
       "│ OSTEOARTHRITIS                    ┆ 25398   ┆ 0.004823 │\n",
       "│ ASTHMA_PUSHASTHMA                 ┆ 25306   ┆ 0.004805 │\n",
       "│ ATOPICECZEMA                      ┆ 23091   ┆ 0.004385 │\n",
       "│ ALLERGICRHINITISCONJ              ┆ 18473   ┆ 0.003508 │\n",
       "│ ANY_DEAFNESS_HEARING_LOSS         ┆ 17177   ┆ 0.003262 │\n",
       "│ aspartate_transam                 ┆ 16911   ┆ 0.003211 │\n",
       "│ PREVALENT_IBS                     ┆ 11727   ┆ 0.002227 │\n",
       "│ ALLCA_NOBCC_VFINAL                ┆ 11671   ┆ 0.002216 │\n",
       "│ IHD_NOMI                          ┆ 11244   ┆ 0.002135 │\n",
       "│ ALCOHOLMISUSE                     ┆ 11203   ┆ 0.002127 │\n",
       "│ CKDSTAGE3TO5                      ┆ 10458   ┆ 0.001986 │\n",
       "│ blood_urea                        ┆ 9577    ┆ 0.001818 │\n",
       "│ PERIPHERAL_NEUROPATHY             ┆ 8802    ┆ 0.001671 │\n",
       "│ calcium_adjusted_level            ┆ 8513    ┆ 0.001616 │\n",
       "│ HYPOTHYROIDISM_DRAFT_V1           ┆ 8036    ┆ 0.001526 │\n",
       "│ COPD                              ┆ 7731    ┆ 0.001468 │\n",
       "│ AF                                ┆ 6261    ┆ 0.001189 │\n",
       "│ combined_total_vitamin_D2_and_D3… ┆ 5816    ┆ 0.001104 │\n",
       "│ HF                                ┆ 5749    ┆ 0.001092 │\n",
       "│ OSTEOPOROSIS                      ┆ 5709    ┆ 0.001084 │\n",
       "│ PSORIASIS                         ┆ 5643    ┆ 0.001071 │\n",
       "│ SUBSTANCEMISUSE                   ┆ 5594    ┆ 0.001062 │\n",
       "│ GOUT                              ┆ 5328    ┆ 0.001012 │\n",
       "│ MINFARCTION                       ┆ 4965    ┆ 0.000943 │\n",
       "│ STROKEUNSPECIFIED                 ┆ 4509    ┆ 0.000856 │\n",
       "│ ALL_DEMENTIA                      ┆ 4419    ┆ 0.000839 │\n",
       "│ hydroxyvitamin3                   ┆ 3865    ┆ 0.000734 │\n",
       "│ hydroxyvitamin2                   ┆ 3515    ┆ 0.000667 │\n",
       "│ VALVULARDISEASES                  ┆ 3219    ┆ 0.000611 │\n",
       "│ PAD_STRICT                        ┆ 3217    ┆ 0.000611 │\n",
       "│ OTHER_CHRONIC_LIVER_DISEASE_OPTI… ┆ 2947    ┆ 0.00056  │\n",
       "│ TYPE1DM                           ┆ 2854    ┆ 0.000542 │\n",
       "│ EPILEPSY                          ┆ 2580    ┆ 0.00049  │\n",
       "│ OSA                               ┆ 2455    ┆ 0.000466 │\n",
       "│ FIBROMYALGIA                      ┆ 2409    ┆ 0.000457 │\n",
       "│ POLYCYSTIC_OVARIAN_SYNDROME_PCOS  ┆ 2193    ┆ 0.000416 │\n",
       "│ NAFLD                             ┆ 2164    ┆ 0.000411 │\n",
       "│ RHEUMATOIDARTHRITIS               ┆ 2066    ┆ 0.000392 │\n",
       "│ EATINGDISORDERS                   ┆ 1972    ┆ 0.000374 │\n",
       "│ HYPERTHYROIDISM                   ┆ 1907    ┆ 0.000362 │\n",
       "│ PMRANDGCA                         ┆ 1902    ┆ 0.000361 │\n",
       "│ ENDOMETRIOSIS_ADENOMYOSIS_V2      ┆ 1833    ┆ 0.000348 │\n",
       "│ PTSDDIAGNOSIS                     ┆ 1695    ┆ 0.000322 │\n",
       "│ ISCHAEMICSTROKE                   ┆ 1541    ┆ 0.000293 │\n",
       "│ creatinine_ratio                  ┆ 1479    ┆ 0.000281 │\n",
       "│ BIPOLAR                           ┆ 1393    ┆ 0.000265 │\n",
       "│ VISUAL_IMPAIRMENT                 ┆ 1374    ┆ 0.000261 │\n",
       "│ SCHIZOPHRENIAMM                   ┆ 1319    ┆ 0.00025  │\n",
       "│ BRONCHIECTASIS                    ┆ 1068    ┆ 0.000203 │\n",
       "│ CHRONIC_LIVER_DISEASE_ALCOHOL     ┆ 929     ┆ 0.000176 │\n",
       "│ AORTICANEURYSM                    ┆ 906     ┆ 0.000172 │\n",
       "│ CHRONICFATIGUESYNDROMEMM          ┆ 840     ┆ 0.000159 │\n",
       "│ ULCERATIVE_COLITIS                ┆ 840     ┆ 0.000159 │\n",
       "│ LEARNINGDISABILITY                ┆ 737     ┆ 0.00014  │\n",
       "│ PERNICIOUSANAEMIA                 ┆ 720     ┆ 0.000137 │\n",
       "│ PARKINSONS                        ┆ 709     ┆ 0.000135 │\n",
       "│ STROKE_HAEMRGIC                   ┆ 697     ┆ 0.000132 │\n",
       "│ MENIERESDISEASE                   ┆ 693     ┆ 0.000132 │\n",
       "│ LYMPHOMA_PREVALENCE               ┆ 589     ┆ 0.000112 │\n",
       "│ brain_natriuretic_peptide_level   ┆ 581     ┆ 0.00011  │\n",
       "│ CROHNS_DISEASE                    ┆ 549     ┆ 0.000104 │\n",
       "│ ILD_SH                            ┆ 540     ┆ 0.000103 │\n",
       "│ AUTISM                            ┆ 505     ┆ 0.000096 │\n",
       "│ PSORIATICARTHRITIS2021            ┆ 484     ┆ 0.000092 │\n",
       "│ MS                                ┆ 419     ┆ 0.00008  │\n",
       "│ LEUKAEMIA_PREVALENCE              ┆ 394     ┆ 0.000075 │\n",
       "│ HIVAIDS                           ┆ 288     ┆ 0.000055 │\n",
       "│ SJOGRENSSYNDROME                  ┆ 238     ┆ 0.000045 │\n",
       "│ SYSTEMIC_LUPUS_ERYTHEMATOSUS      ┆ 223     ┆ 0.000042 │\n",
       "│ HAEMOCHROMATOSIS                  ┆ 197     ┆ 0.000037 │\n",
       "│ blood_calcium                     ┆ 146     ┆ 0.000028 │\n",
       "│ PLASMACELL_NEOPLASM               ┆ 130     ┆ 0.000025 │\n",
       "│ ADDISON_DISEASE                   ┆ 105     ┆ 0.00002  │\n",
       "│ SYSTEMIC_SCLEROSIS                ┆ 73      ┆ 0.000014 │\n",
       "│ CYSTICFIBROSIS                    ┆ 44      ┆ 0.000008 │\n",
       "│ DOWNSSYNDROME                     ┆ 39      ┆ 0.000007 │\n",
       "│ SICKLE_CELL_DISEASE               ┆ 23      ┆ 0.000004 │\n",
       "└───────────────────────────────────┴─────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(vocab_size - 1)\n",
    "display(dm.tokenizer._event_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diastolic_blood_pressure', 'bmi', 'eosinophil_count', 'basophil_count', 'corrected_serum_calcium_level', 'serum_level', 'calculated_LDL_cholesterol_level', 'aspartate_transam', 'blood_urea', 'calcium_adjusted_level', 'combined_total_vitamin_D2_and_D3_level', 'hydroxyvitamin3', 'hydroxyvitamin2', 'creatinine_ratio', 'brain_natriuretic_peptide_level', 'blood_calcium']\n",
      "[2, 3, 4, 5, 6, 8, 9, 18, 24, 26, 30, 39, 40, 57, 72, 83]\n",
      "DEPRESSION eosinophil_count bmi diastolic_blood_pressure\n"
     ]
    }
   ],
   "source": [
    "# Extract the measurements, using the fact that the diagnoses are all up upper case. This is needed for automatically setting the configuration below\n",
    "measurements_for_univariate_regression = [record for record in dm.tokenizer._event_counts[\"EVENT\"] if record.upper() != record]\n",
    "\n",
    "print(measurements_for_univariate_regression)\n",
    "print(dm.encode(measurements_for_univariate_regression))\n",
    "print(dm.decode([7,4,3,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Single-Risk DeSurvival head. This module predicts a separate survival curve for each possible future event\n",
      "INFO:root:Internally scaling time in survival head by 1825 days\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1825.0], with delta=1/300\n",
      "INFO:root:ModuleDict(\n",
      "  (Token 2): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 3): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 4): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 5): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 6): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 8): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 9): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 18): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 24): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 26): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 30): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 39): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 40): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 57): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 72): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 83): Linear(in_features=384, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models, m_names = [], []\n",
    "\n",
    "# My development model\n",
    "for surv_layer in [\"Competing-Risk\"]: #, \"Single-Risk\"]:\n",
    "    \n",
    "    ## Create configuration\n",
    "    config = DemoConfig()\n",
    "    # Specify which survival head layer to use\n",
    "    config.SurvLayer = surv_layer   \n",
    "    # list of univariate measurements to model with Normal distribution\n",
    "    config.tokens_for_univariate_regression = dm.encode(measurements_for_univariate_regression) \n",
    "    \n",
    "    models.append(SurvStreamGPTForCausalModelling(config, vocab_size).to(device))\n",
    "    m_names.append(f\"SurvStreamGPTForCausalModelling: {surv_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curves_train = [[] for _ in models]\n",
    "loss_curves_train_clf = [[] for _ in models]\n",
    "loss_curves_train_surv = [[] for _ in models]\n",
    "loss_curves_train_values = [[] for _ in models]\n",
    "\n",
    "loss_curves_val = [[] for _ in models]\n",
    "loss_curves_val_clf = [[] for _ in models]\n",
    "loss_curves_val_surv = [[] for _ in models]\n",
    "loss_curves_val_values = [[] for _ in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model `SurvStreamGPTForCausalModelling: Competing-Risk`, with 10.790921 M parameters\n",
      "Epoch 0:\tTrain loss -0.08: (-0.45, 0.29). Val loss -0.19: (-0.66, 0.27)\n",
      "Epoch 1:\tTrain loss -0.25: (-0.76, 0.27). Val loss -0.26: (-0.80, 0.29)\n",
      "Epoch 2:\tTrain loss -0.31: (-0.88, 0.27). Val loss -0.32: (-0.91, 0.27)\n",
      "Epoch 3:\tTrain loss -0.36: (-0.97, 0.26). Val loss -0.31: (-0.90, 0.27)\n",
      "Epoch 4:\tTrain loss -0.38: (-1.03, 0.26). Val loss -0.36: (-1.01, 0.29)\n",
      "Epoch 5:\tTrain loss -0.38: (-1.04, 0.28). Val loss -0.39: (-1.05, 0.27)\n",
      "Epoch 6:\tTrain loss -0.41: (-1.09, 0.26). Val loss -0.41: (-1.08, 0.27)\n",
      "Epoch 7:\tTrain loss -0.41: (-1.10, 0.27). Val loss -0.41: (-1.09, 0.27)\n",
      "Epoch 8:\tTrain loss -0.44: (-1.15, 0.27). Val loss -0.42: (-1.13, 0.28)\n",
      "Epoch 9:\tTrain loss -0.45: (-1.18, 0.27). Val loss -0.46: (-1.18, 0.27)\n",
      "Epoch 10:\tTrain loss -0.48: (-1.21, 0.26). Val loss -0.47: (-1.21, 0.27)\n",
      "Epoch 11:\tTrain loss -0.47: (-1.22, 0.27). Val loss -0.46: (-1.21, 0.28)\n",
      "Epoch 12:\tTrain loss -0.49: (-1.25, 0.27). Val loss -0.46: (-1.21, 0.29)\n",
      "Epoch 13:\tTrain loss -0.50: (-1.27, 0.26). Val loss -0.51: (-1.28, 0.27)\n",
      "Epoch 14:\tTrain loss -0.52: (-1.30, 0.26). Val loss -0.47: (-1.22, 0.28)\n",
      "Epoch 15:\tTrain loss -0.50: (-1.28, 0.27). Val loss -0.39: (-1.11, 0.34)\n",
      "Epoch 16:\tTrain loss -0.51: (-1.29, 0.27). Val loss -0.49: (-1.28, 0.29)\n",
      "Epoch 17:\tTrain loss -0.53: (-1.33, 0.26). Val loss -0.49: (-1.26, 0.28)\n",
      "Epoch 18:\tTrain loss -0.56: (-1.37, 0.26). Val loss -0.48: (-1.26, 0.29)\n",
      "DEPRESSION                                        nan            at age 20 (7300.0 days)\n",
      "ANXIETY                                           nan            at age 25 (9125.0 days)\n",
      "bmi                                               24.35          at age 30 (10950.0 days)\n",
      "diastolic_blood_pressure                          71.61          at age 35 (12775.0 days)\n",
      "diastolic_blood_pressure                          76.75          at age 38 (13824.8 days)\n",
      "diastolic_blood_pressure                          85.14          at age 43 (15649.8 days)\n",
      "eosinophil_count                                  0.38           at age 43 (15698.7 days)\n",
      "eosinophil_count                                  0.09           at age 48 (17523.7 days)\n",
      "eosinophil_count                                  0.53           at age 53 (19348.7 days)\n",
      "diastolic_blood_pressure                          71.11          at age 54 (19574.5 days)\n",
      "diastolic_blood_pressure                          68.44          at age 59 (21399.5 days)\n"
     ]
    }
   ],
   "source": [
    "for m_idx, (model, m_name) in enumerate(zip(models, m_names)):\n",
    "    \n",
    "    print(f\"Training model `{m_name}`, with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "    best_val, epochs_since_best = np.inf, 0\n",
    "    for epoch in range(opt.epochs):\n",
    "        \n",
    "        epoch_loss, epoch_surv_loss, epoch_values_loss = 0, 0, 0\n",
    "        model.train()\n",
    "        for i, batch in enumerate(dm.train_dataloader()):\n",
    "            # print(i)\n",
    "            # evaluate the loss\n",
    "            _, (losses_desurv, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                          ages=batch['ages'].to(device), \n",
    "                                                          values=batch['values'].to(device),\n",
    "                                                          attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                          )\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # record\n",
    "            epoch_loss += loss.item()            \n",
    "            epoch_surv_loss += torch.sum(losses_desurv).item()\n",
    "            epoch_values_loss += loss_values.item()\n",
    "        \n",
    "        epoch_loss /= i\n",
    "        epoch_surv_loss /= i\n",
    "        epoch_values_loss /= i\n",
    "        loss_curves_train[m_idx].append(epoch_loss)\n",
    "        loss_curves_train_surv[m_idx].append(epoch_surv_loss)\n",
    "        loss_curves_train_values[m_idx].append(epoch_values_loss)\n",
    "\n",
    "        # evaluate the loss on val set\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            if epoch % opt.eval_interval == 0 or epoch == opt.epochs - 1:\n",
    "                val_loss, val_surv_loss, val_values_loss = 0, 0, 0\n",
    "                for j, batch in enumerate(dm.val_dataloader()):\n",
    "                    _, (losses_desurv, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                                  ages=batch['ages'].to(device),\n",
    "                                                                  values=batch['values'].to(device),\n",
    "                                                                  attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                                  )\n",
    "                    # record\n",
    "                    val_loss += loss.item()                    \n",
    "                    val_surv_loss += torch.sum(losses_desurv).item()\n",
    "                    val_values_loss += loss_values.item()\n",
    "                    \n",
    "                val_loss /= j\n",
    "                val_surv_loss /= j\n",
    "                val_values_loss /= j\n",
    "                loss_curves_val[m_idx].append(val_loss)\n",
    "                loss_curves_val_surv[m_idx].append(val_surv_loss)\n",
    "                loss_curves_val_values[m_idx].append(val_values_loss)\n",
    "\n",
    "                print(f\"Epoch {epoch}:\\tTrain loss {epoch_loss:.2f}: ({epoch_surv_loss:.2f}, {epoch_values_loss:.2f}). Val loss {val_loss:.2f}: ({val_surv_loss:.2f}, {val_values_loss:.2f})\")          \n",
    "                # TODO: Note not fully accurate as last batch is likely not the same size, will be fixed with lightning\n",
    "        \n",
    "            if val_loss >= best_val:\n",
    "                epochs_since_best += 1\n",
    "                if epochs_since_best >= 5:\n",
    "                    break\n",
    "            else:\n",
    "                best_val = val_loss\n",
    "                epochs_since_best = 0\n",
    "\n",
    "    # Test trained model with a prompt\n",
    "    # ----------------    \n",
    "    # set context: diagnosis of depression at 20 years old\n",
    "    tokens = torch.from_numpy(np.array(dm.encode([\"DEPRESSION\"])).reshape((1,-1))).to(device)\n",
    "    ages = torch.tensor([[20*365]], device=device)\n",
    "    values = torch.tensor([[torch.nan]], device=device)\n",
    "    \n",
    "    # generate: sample the next 10 tokens\n",
    "    new_tokens, new_ages, new_values = model.generate(tokens, ages, values, max_new_tokens=10)\n",
    "    generated = dm.decode(new_tokens[0].tolist())\n",
    "    # report:\n",
    "    for _cat, _age, _value in zip(generated.split(\" \"), new_ages[0, :], new_values[0, :]):\n",
    "        try:\n",
    "            _value = unstandardise(_cat, _value)\n",
    "        except:\n",
    "            pass\n",
    "        print(f\"{_cat}\".ljust(50) + f\"{_value:.02f}\".ljust(15) + f\"at age {_age/365:.0f} ({_age:.1f} days)\")    # with value {_value}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing output to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBSTANCEMISUSE                                   nan            at age 19 (7109.0 days)\n",
      "DEPRESSION                                        nan            at age 21 (7840.0 days)\n",
      "ANXIETY                                           nan            at age 21 (7840.0 days)\n",
      "bmi                                               29.50          at age 23 (8429.0 days)\n",
      "diastolic_blood_pressure                          70.00          at age 23 (8429.0 days)\n",
      "eosinophil_count                                  0.20           at age 23 (8429.0 days)\n",
      "diastolic_blood_pressure                          68.00          at age 23 (8450.0 days)\n",
      "diastolic_blood_pressure                          62.00          at age 23 (8471.0 days)\n",
      "diastolic_blood_pressure                          65.00          at age 23 (8479.0 days)\n",
      "diastolic_blood_pressure                          60.00          at age 23 (8485.0 days)\n"
     ]
    }
   ],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    break\n",
    "    \n",
    "conditions = batch[\"tokens\"].numpy().tolist()\n",
    "# delta_ages = batch[\"ages\"][:, 1:] - batch[\"ages\"][:, :-1]\n",
    "for idx, (token, _age, _value) in enumerate(zip(conditions[0], batch[\"ages\"][0,:],  batch[\"values\"][0,:])):\n",
    "    if token == 0 or idx >= 10:\n",
    "        break\n",
    "    _cat = dm.decode([token])\n",
    "    try:\n",
    "        _value = unstandardise(_cat, _value)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    print(f\"{_cat}\".ljust(50) + f\"{_value:.02f}\".ljust(15) + f\"at age {_age/365:.0f} ({_age:.1f} days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"k\", \"r\", \"b\", \"y\"]\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train[m_idx]), len(loss_curves_train[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val[m_idx]), len(loss_curves_val[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/competing_risk/loss.png\")\n",
    "\n",
    "# Plot DeSurv loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_surv[m_idx]), len(loss_curves_train_surv[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_surv[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_surv[m_idx]), len(loss_curves_val_surv[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_surv[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/competing_risk/loss_desurv.png\")\n",
    "\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_values[m_idx]), len(loss_curves_train_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_values[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_values[m_idx]), len(loss_curves_val_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_values[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/competing_risk/loss_val.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes: How related conditions are impacted by each other\n",
    "Probability of type II diabetes before and after a type I diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "\n",
      "Depression: \t (DEPRESSION): \n",
      "\n",
      "Depression -> Type 1: \t (DEPRESSION,TYPE1DM): \n",
      "\n",
      "Depression - > Type 2: \t (DEPRESSION,TYPE2DIABETES): \n"
     ]
    }
   ],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"TYPE1DM\"]\n",
    "t2_token = dm.tokenizer._stoi[\"TYPE2DIABETES\"]\n",
    "\n",
    "\n",
    "base_prompt = [\"DEPRESSION\"]\n",
    "ages_in_years = [20]\n",
    "base_values = [torch.tensor([torch.nan])]\n",
    "\n",
    "to_days = lambda a_list: torch.FloatTensor([365 * _a for _a in a_list]).reshape((1,-1)).to(device)\n",
    "\n",
    "# Create a set of prompts\n",
    "prompts, ages, values, desc = [], [], [], []\n",
    "# control prompt\n",
    "desc.append(\"Depression\")\n",
    "prompts.append(base_prompt)\n",
    "ages.append(ages_in_years)\n",
    "values.append(base_values)\n",
    "# prompt with type 1 diabetes\n",
    "desc.append(\"Depression -> Type 1\")\n",
    "prompts.append(base_prompt + [\"TYPE1DM\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "desc.append(\"Depression - > Type 2\")\n",
    "prompts.append(base_prompt + [\"TYPE2DIABETES\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        prompt_survs = []\n",
    "        for p_idx, (prompt, age, value) in enumerate(zip(prompts, ages, values)):\n",
    "            print(f\"\\n{desc[p_idx]}: \\t ({','.join(prompt)}): \")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                           values=torch.tensor(value).to(device),\n",
    "                                           ages=to_days(age),\n",
    "                                           is_generation=True)\n",
    "            prompt_survs.append(surv)\n",
    "\n",
    "        for si, _ in enumerate(surv):\n",
    "            plt.close()\n",
    "            event_name = dm.decode([si + 1])\n",
    "            for p_idx in range(len(prompts)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, prompt_survs[p_idx][si][0, :], label=f\"{desc[p_idx]}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"figs/competing_risk/diabetes/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing BMI affects diagnosis risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "Value tensor([-2.5138], device='cuda:0')\n",
      "======\n",
      "Value tensor([-2.0860], device='cuda:0')\n",
      "======\n",
      "Value tensor([-1.6583], device='cuda:0')\n",
      "======\n",
      "Value tensor([-1.2305], device='cuda:0')\n",
      "======\n",
      "Value tensor([-0.8028], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.0528], device='cuda:0')\n",
      "======\n",
      "Value tensor([1.4786], device='cuda:0')\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "events_of_interest = [\"bmi\", \"diastolic_blood_pressure\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF\", \"ISCHAEMICSTROKE\"\n",
    "                     ]\n",
    "prompt = [\"bmi\"]\n",
    "values = [torch.tensor([standardise(_cat, v) for _cat in prompt], device=device) for v in [12.,15.,18.,21.,24.,30.,40.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        prompt_survs = []\n",
    "        for p_idx, value in enumerate(values):\n",
    "            print(f\"Value {value}\\n======\")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                           values=value,\n",
    "                                           ages=to_days(age),\n",
    "                                           is_generation=True)\n",
    "            prompt_survs.append(surv)\n",
    "\n",
    "        for si, _ in enumerate(surv):\n",
    "            plt.close()\n",
    "            event_name = dm.decode([si + 1])\n",
    "            \n",
    "            if event_name in events_of_interest:\n",
    "                \n",
    "                for p_idx in range(len(prompt_survs)):\n",
    "                    bmi_value = unstandardise(\"bmi\", values[p_idx])\n",
    "                    plt.plot(model.surv_layer.t_eval / 365, prompt_survs[p_idx][si][0, :], label=f\"BMI {bmi_value.item():.2f}\")\n",
    "                plt.xlabel(\"t (years)\")\n",
    "                plt.ylabel(\"P(T>t) ()\")\n",
    "                plt.legend()\n",
    "                plt.savefig(f\"figs/competing_risk/bmi/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing diastolic_blood_pressure affects likelihood of diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "Value tensor([-1.6090], device='cuda:0')\n",
      "======\n",
      "Value tensor([-0.7563], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.0964], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.9491], device='cuda:0')\n",
      "======\n",
      "Value tensor([1.8018], device='cuda:0')\n",
      "======\n",
      "Value tensor([3.5073], device='cuda:0')\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "events_of_interest = [\"bmi\", \"diastolic_blood_pressure\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF\", \"ISCHAEMICSTROKE\"\n",
    "                     ]\n",
    "\n",
    "prompt = [\"diastolic_blood_pressure\"]\n",
    "values = [torch.tensor([standardise(_cat, _value) for _cat in prompt], device=device) for _value in [60.,70.,80.,90.,100.,120.]]\n",
    "age = [40]\n",
    "\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        prompt_survs = []\n",
    "        for p_idx, value in enumerate(values):\n",
    "            print(f\"Value {value}\\n======\")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                           values=value,\n",
    "                                           ages=to_days(age),\n",
    "                                           is_generation=True)\n",
    "            prompt_survs.append(surv)\n",
    "\n",
    "        for si, _ in enumerate(surv):\n",
    "            plt.close()\n",
    "            event_name = dm.decode([si + 1])\n",
    "            \n",
    "            if event_name in events_of_interest:\n",
    "                \n",
    "                for p_idx in range(len(prompt_survs)):\n",
    "                    dbp_value = unstandardise(\"diastolic_blood_pressure\", values[p_idx])\n",
    "                    plt.plot(model.surv_layer.t_eval / 365, prompt_survs[p_idx][si][0, :], label=f\"DBP {dbp_value.item():.2f}\")\n",
    "                plt.xlabel(\"t (years)\")\n",
    "                plt.ylabel(\"P(T>t) ()\")\n",
    "                plt.legend()\n",
    "                plt.savefig(f\"figs/competing_risk/diastolic_blood_pressure/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How varying diagnosis affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "\n",
      "Diagnosis ['DEPRESSION']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.1, 0.9)\n",
      "\n",
      "Diagnosis ['TYPE2DIABETES']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.0, 0.9)\n",
      "\n",
      "Diagnosis ['HF']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.0, 1.0)\n",
      "\n",
      "Diagnosis ['HYPERTENSION']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.4, 1.0)\n"
     ]
    }
   ],
   "source": [
    "measurements_of_interest = [\"diastolic_blood_pressure\"]\n",
    "t1_token = dm.tokenizer._stoi[\"diastolic_blood_pressure\"]\n",
    "\n",
    "diagnoses = [[\"DEPRESSION\"],[\"TYPE2DIABETES\"], [\"HF\"], [\"HYPERTENSION\"]]\n",
    "values = torch.tensor([torch.nan], device=device)\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "    for p_idx, diagnosis in enumerate(diagnoses):\n",
    "        print(f\"\\nDiagnosis {diagnosis}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(diagnosis)).reshape((1,-1))).to(device)\n",
    "        (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                       values=values,\n",
    "                                       ages=to_days(age),\n",
    "                                       is_generation=True)\n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing bmi affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "--------------------------------------\n",
      "\n",
      "Values [-2.5137970447540283]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.9, 0.9)\n",
      "\n",
      "Values [-2.0860371589660645]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.8, 0.8)\n",
      "\n",
      "Values [-1.6582773923873901]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.6, 0.8)\n",
      "\n",
      "Values [-1.2305175065994263]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.5, 0.8)\n",
      "\n",
      "Values [-0.8027576804161072]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.3, 0.8)\n",
      "\n",
      "Values [0.05276201292872429]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.1, 0.8)\n",
      "\n",
      "Values [1.478628158569336]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.6, 0.9)\n",
      "\n",
      "Values [2.904494285583496]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.5, 1.0)\n"
     ]
    }
   ],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"diastolic_blood_pressure\"]\n",
    "\n",
    "prompt = [\"bmi\"]\n",
    "values = [torch.tensor([standardise(_cat, _value) for _cat in prompt], device=device) for _value in [12.,15.,18.,21.,24.,30.,40.,50.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    for p_idx, value in enumerate(values):\n",
    "        print(f\"\\nValues {value.tolist()}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                       values=value,\n",
    "                                       ages=to_days(age),\n",
    "                                       is_generation=True)\n",
    "        \n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "        # print(f\"\\tprobability of type II diabetes: {100*float(probs[0, 0, t2_token].cpu().detach().numpy()):.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Competing-Risk\n",
      "===============================================\n",
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling(\n",
      "  (transformer): TTETransformer(\n",
      "    (wpe): TemporalPositionalEncoding()\n",
      "    (wte): DataEmbeddingLayer(\n",
      "      (token_embed_layer): Embedding(90, 384, padding_idx=0)\n",
      "      (value_embed_layer): EmbeddingBag(90, 384, mode=sum, padding_idx=0)\n",
      "    )\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (surv_layer): ODESurvCompetingRiskLayer(\n",
      "    (sr_ode): ODESurvMultiple(\n",
      "      (pinet): FCNet(\n",
      "        (mapping): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=89, bias=True)\n",
      "          (1): Softmax(dim=1)\n",
      "        )\n",
      "      )\n",
      "      (odenet): CondODENet(\n",
      "        (BaseNet): FCNet(\n",
      "          (mapping): Sequential(\n",
      "            (0): Linear(in_features=385, out_features=89, bias=True)\n",
      "            (1): Softplus(beta=1, threshold=20)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (value_layer): GaussianRegressionLayer(\n",
      "    (regression_layers): ModuleDict(\n",
      "      (Token 2): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 3): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 4): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 5): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 6): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 8): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 9): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 18): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 24): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 26): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 30): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 39): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 40): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 57): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 72): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 83): Linear(in_features=384, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n\" + \"=\"*len(m_names[model_idx]))\n",
    "    print(f\"\\n\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook competing_risk.ipynb to html\n",
      "[NbConvertApp] Writing 600727 bytes to competing_risk.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html --no-input competing_risk.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
