{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Demo Notebook:\n",
    "## Survival Transformer For Causal Sequence Modelling \n",
    "\n",
    "Including time, and excluding tabular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvStreamGPT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "# TODO:\n",
    "# replace experiment boilerplate with pytorch lightning\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config to be equivalent architecture of kaparthy benchmark, however they are not comparable tasks.\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    block_size: int = 128        # what is the maximum context length for predictions?\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 6\n",
    "    n_embd: int = 384\n",
    "    bias: bool = True\n",
    "    attention_type: str = \"global\"    \n",
    "    dropout: float = 0.0\n",
    "    unk_freq_threshold: float = 0.0\n",
    "    SurvLayer = \"Single-Risk\"                                  # \"Competing-Risk\"\n",
    "    tokens_for_univariate_regression = None\n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "@dataclass\n",
    "class OptConfig:\n",
    "    batch_size: int = 64\n",
    "    eval_interval: int = 1\n",
    "    learning_rate: float = 3e-4\n",
    "    epochs: int = 30\n",
    "    \n",
    "opt = OptConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader on a reduced cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building polars dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using N=20000 random samples, from the available 129717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using measurements\n",
      "INFO:root:Using test/measurement standardisation method: normalise\n",
      "INFO:root:Removing measurement and test outliers. Using three deviations from mean as cutoff\n",
      "INFO:root:Using diagnoses\n",
      "INFO:root:Dropping samples with no dynamic events\n",
      "INFO:root:Using tabular tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16440 training samples\n",
      "914 validation samples\n",
      "913 test samples\n",
      "90 vocab elements\n"
     ]
    }
   ],
   "source": [
    "from CPRD.data.database import queries\n",
    "\n",
    "# Get a list of patients which fit a reduced set of criterion\n",
    "PATH_TO_DB = \"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModel/preprocessing/processed/cprd.db\"\n",
    "conn = sqlite3.connect(PATH_TO_DB)\n",
    "cursor = conn.cursor()\n",
    "# identifiers1 = queries.query_measurement([\"bmi\", \"diastolic_blood_pressure\"], cursor)        \n",
    "identifiers2 = queries.query_diagnosis([\"DEPRESSION\", \"TYPE1DM\", \"TYPE2DIABETES\"], cursor)    #  \"DEPRESSION\"  ,  \"ANXIETY\"\n",
    "# all_identifiers = list(set(identifiers1).intersection(identifiers2))    # Turn smaller list into the set\n",
    "all_identifiers = identifiers2\n",
    "\n",
    "if True:\n",
    "    # Lets take only the first N for faster run-time\n",
    "    N = np.min((len(all_identifiers), 20000))\n",
    "    print(f\"Using N={N} random samples, from the available {len(all_identifiers)}\")\n",
    "    identifiers = random.choices(all_identifiers, k=N)\n",
    "else:\n",
    "    print(f\"Using all available {len(all_identifiers)} samples\")\n",
    "    identifiers = all_identifiers\n",
    "\n",
    "# Build \n",
    "dm = FoundationalDataModule(identifiers=identifiers,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            batch_size=opt.batch_size,\n",
    "                            max_seq_length=config.block_size,\n",
    "                            unk_freq_threshold=config.unk_freq_threshold,\n",
    "                            include_measurements=True,\n",
    "                            include_diagnoses=True,\n",
    "                            preprocess_measurements=True\n",
    "                           )\n",
    "\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "\n",
    "print(f\"{len(dm.train_set)} training samples\")\n",
    "print(f\"{len(dm.val_set)} validation samples\")\n",
    "print(f\"{len(dm.test_set)} test samples\")\n",
    "print(f\"{vocab_size} vocab elements\")\n",
    "# print(dm.train_set.tokenizer._itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation\n",
    "\n",
    "This was performed automatically across measurements and tests in the dataloader. The standardisation statistics (bias and scale respectively) are given in the dictionary object. \n",
    "\n",
    "We define two mappings to simplify notation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creatinine_ratio': (4.613647798742136, 8.013549757225261),\n",
       " 'blood_urea': (6.661150210084032, 3.5151115243185727),\n",
       " 'bmi': (29.96208708895408, 7.104642555249171),\n",
       " 'eosinophil_count': (0.22112432491405676, 0.18412155821672552),\n",
       " 'hydroxyvitamin2': (3.3176282051282047, 2.624011268273257),\n",
       " 'combined_total_vitamin_D2_and_D3_level': (54.18057692307692,\n",
       "  28.489483861873047),\n",
       " 'diastolic_blood_pressure': (78.89241975790014, 11.729769809594963),\n",
       " 'corrected_serum_calcium_level': (2.3180350373559864, 0.12127745858022278),\n",
       " 'calculated_LDL_cholesterol_level': (2.5496743006577454, 1.0433663664568302),\n",
       " 'basophil_count': (0.06863472505097562, 0.10071943861842063),\n",
       " 'blood_calcium': (2.3682051282051284, 0.20732471093066332),\n",
       " 'calcium_adjusted_level': (2.3160170045781627, 0.10605442751470515),\n",
       " 'aspartate_transam': (26.941471048513304, 19.44413875598056),\n",
       " 'brain_natriuretic_peptide_level': (173.09296875, 302.17777324463435),\n",
       " 'hydroxyvitamin3': (51.70338733431519, 29.183941674076287),\n",
       " 'serum_level': (26.455094021891664, 18.800583787545264)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0053363572834371955\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "display(dm.standardisation_dict)\n",
    "\n",
    "standardise = lambda key, v: (v - dm.standardisation_dict[key][0]) / dm.standardisation_dict[key][1]\n",
    "unstandardise = lambda key, v: (v * dm.standardisation_dict[key][1]) + dm.standardisation_dict[key][0]\n",
    "\n",
    "print(standardise(\"bmi\", 30))\n",
    "print(unstandardise(\"bmi\", standardise(\"bmi\", 20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the frequency of tokens in the extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (89, 3)\n",
      "┌───────────────────────────────────┬────────┬──────────┐\n",
      "│ EVENT                             ┆ counts ┆ freq     │\n",
      "│ ---                               ┆ ---    ┆ ---      │\n",
      "│ str                               ┆ u32    ┆ f64      │\n",
      "╞═══════════════════════════════════╪════════╪══════════╡\n",
      "│ UNK                               ┆ 0      ┆ 0.0      │\n",
      "│ diastolic_blood_pressure          ┆ 354853 ┆ 0.417141 │\n",
      "│ bmi                               ┆ 141779 ┆ 0.166666 │\n",
      "│ eosinophil_count                  ┆ 131696 ┆ 0.154813 │\n",
      "│ basophil_count                    ┆ 88056  ┆ 0.103513 │\n",
      "│ corrected_serum_calcium_level     ┆ 24429  ┆ 0.028717 │\n",
      "│ DEPRESSION                        ┆ 13328  ┆ 0.015668 │\n",
      "│ serum_level                       ┆ 12956  ┆ 0.01523  │\n",
      "│ calculated_LDL_cholesterol_level  ┆ 11295  ┆ 0.013278 │\n",
      "│ ANXIETY                           ┆ 7270   ┆ 0.008546 │\n",
      "│ HYPERTENSION                      ┆ 5272   ┆ 0.006197 │\n",
      "│ TYPE2DIABETES                     ┆ 4930   ┆ 0.005795 │\n",
      "│ OSTEOARTHRITIS                    ┆ 4072   ┆ 0.004787 │\n",
      "│ ASTHMA_PUSHASTHMA                 ┆ 3945   ┆ 0.004637 │\n",
      "│ ATOPICECZEMA                      ┆ 3545   ┆ 0.004167 │\n",
      "│ aspartate_transam                 ┆ 2875   ┆ 0.00338  │\n",
      "│ ALLERGICRHINITISCONJ              ┆ 2755   ┆ 0.003239 │\n",
      "│ ANY_DEAFNESS_HEARING_LOSS         ┆ 2729   ┆ 0.003208 │\n",
      "│ IHD_NOMI                          ┆ 1879   ┆ 0.002209 │\n",
      "│ ALLCA_NOBCC_VFINAL                ┆ 1814   ┆ 0.002132 │\n",
      "│ PREVALENT_IBS                     ┆ 1801   ┆ 0.002117 │\n",
      "│ CKDSTAGE3TO5                      ┆ 1736   ┆ 0.002041 │\n",
      "│ blood_urea                        ┆ 1722   ┆ 0.002024 │\n",
      "│ ALCOHOLMISUSE                     ┆ 1702   ┆ 0.002001 │\n",
      "│ PERIPHERAL_NEUROPATHY             ┆ 1492   ┆ 0.001754 │\n",
      "│ calcium_adjusted_level            ┆ 1353   ┆ 0.00159  │\n",
      "│ HYPOTHYROIDISM_DRAFT_V1           ┆ 1286   ┆ 0.001512 │\n",
      "│ COPD                              ┆ 1244   ┆ 0.001462 │\n",
      "│ AF                                ┆ 978    ┆ 0.00115  │\n",
      "│ combined_total_vitamin_D2_and_D3… ┆ 946    ┆ 0.001112 │\n",
      "│ HF                                ┆ 934    ┆ 0.001098 │\n",
      "│ OSTEOPOROSIS                      ┆ 899    ┆ 0.001057 │\n",
      "│ GOUT                              ┆ 870    ┆ 0.001023 │\n",
      "│ PSORIASIS                         ┆ 861    ┆ 0.001012 │\n",
      "│ SUBSTANCEMISUSE                   ┆ 857    ┆ 0.001007 │\n",
      "│ MINFARCTION                       ┆ 806    ┆ 0.000947 │\n",
      "│ STROKEUNSPECIFIED                 ┆ 740    ┆ 0.00087  │\n",
      "│ ALL_DEMENTIA                      ┆ 711    ┆ 0.000836 │\n",
      "│ TYPE1DM                           ┆ 635    ┆ 0.000746 │\n",
      "│ hydroxyvitamin3                   ┆ 596    ┆ 0.000701 │\n",
      "│ hydroxyvitamin2                   ┆ 547    ┆ 0.000643 │\n",
      "│ PAD_STRICT                        ┆ 531    ┆ 0.000624 │\n",
      "│ VALVULARDISEASES                  ┆ 517    ┆ 0.000608 │\n",
      "│ OTHER_CHRONIC_LIVER_DISEASE_OPTI… ┆ 496    ┆ 0.000583 │\n",
      "│ OSA                               ┆ 390    ┆ 0.000458 │\n",
      "│ EPILEPSY                          ┆ 385    ┆ 0.000453 │\n",
      "│ FIBROMYALGIA                      ┆ 363    ┆ 0.000427 │\n",
      "│ NAFLD                             ┆ 354    ┆ 0.000416 │\n",
      "│ POLYCYSTIC_OVARIAN_SYNDROME_PCOS  ┆ 338    ┆ 0.000397 │\n",
      "│ RHEUMATOIDARTHRITIS               ┆ 322    ┆ 0.000379 │\n",
      "│ PMRANDGCA                         ┆ 313    ┆ 0.000368 │\n",
      "│ ENDOMETRIOSIS_ADENOMYOSIS_V2      ┆ 300    ┆ 0.000353 │\n",
      "│ EATINGDISORDERS                   ┆ 292    ┆ 0.000343 │\n",
      "│ creatinine_ratio                  ┆ 289    ┆ 0.00034  │\n",
      "│ HYPERTHYROIDISM                   ┆ 289    ┆ 0.00034  │\n",
      "│ PTSDDIAGNOSIS                     ┆ 265    ┆ 0.000312 │\n",
      "│ ISCHAEMICSTROKE                   ┆ 238    ┆ 0.00028  │\n",
      "│ SCHIZOPHRENIAMM                   ┆ 230    ┆ 0.00027  │\n",
      "│ VISUAL_IMPAIRMENT                 ┆ 221    ┆ 0.00026  │\n",
      "│ BIPOLAR                           ┆ 212    ┆ 0.000249 │\n",
      "│ BRONCHIECTASIS                    ┆ 175    ┆ 0.000206 │\n",
      "│ AORTICANEURYSM                    ┆ 147    ┆ 0.000173 │\n",
      "│ ULCERATIVE_COLITIS                ┆ 136    ┆ 0.00016  │\n",
      "│ CHRONIC_LIVER_DISEASE_ALCOHOL     ┆ 128    ┆ 0.00015  │\n",
      "│ PARKINSONS                        ┆ 123    ┆ 0.000145 │\n",
      "│ CHRONICFATIGUESYNDROMEMM          ┆ 119    ┆ 0.00014  │\n",
      "│ brain_natriuretic_peptide_level   ┆ 119    ┆ 0.00014  │\n",
      "│ LEARNINGDISABILITY                ┆ 113    ┆ 0.000133 │\n",
      "│ PERNICIOUSANAEMIA                 ┆ 105    ┆ 0.000123 │\n",
      "│ MENIERESDISEASE                   ┆ 102    ┆ 0.00012  │\n",
      "│ STROKE_HAEMRGIC                   ┆ 94     ┆ 0.000111 │\n",
      "│ CROHNS_DISEASE                    ┆ 91     ┆ 0.000107 │\n",
      "│ PSORIATICARTHRITIS2021            ┆ 89     ┆ 0.000105 │\n",
      "│ ILD_SH                            ┆ 83     ┆ 0.000098 │\n",
      "│ LYMPHOMA_PREVALENCE               ┆ 82     ┆ 0.000096 │\n",
      "│ AUTISM                            ┆ 76     ┆ 0.000089 │\n",
      "│ MS                                ┆ 57     ┆ 0.000067 │\n",
      "│ LEUKAEMIA_PREVALENCE              ┆ 55     ┆ 0.000065 │\n",
      "│ SJOGRENSSYNDROME                  ┆ 41     ┆ 0.000048 │\n",
      "│ HIVAIDS                           ┆ 39     ┆ 0.000046 │\n",
      "│ blood_calcium                     ┆ 39     ┆ 0.000046 │\n",
      "│ HAEMOCHROMATOSIS                  ┆ 34     ┆ 0.00004  │\n",
      "│ SYSTEMIC_LUPUS_ERYTHEMATOSUS      ┆ 28     ┆ 0.000033 │\n",
      "│ PLASMACELL_NEOPLASM               ┆ 24     ┆ 0.000028 │\n",
      "│ ADDISON_DISEASE                   ┆ 18     ┆ 0.000021 │\n",
      "│ SYSTEMIC_SCLEROSIS                ┆ 8      ┆ 0.000009 │\n",
      "│ DOWNSSYNDROME                     ┆ 7      ┆ 0.000008 │\n",
      "│ SICKLE_CELL_DISEASE               ┆ 4      ┆ 0.000005 │\n",
      "│ CYSTICFIBROSIS                    ┆ 3      ┆ 0.000004 │\n",
      "└───────────────────────────────────┴────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(vocab_size + 1)\n",
    "print(dm.tokenizer._event_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diastolic_blood_pressure', 'bmi', 'eosinophil_count', 'basophil_count', 'corrected_serum_calcium_level', 'serum_level', 'calculated_LDL_cholesterol_level', 'aspartate_transam', 'blood_urea', 'calcium_adjusted_level', 'combined_total_vitamin_D2_and_D3_level', 'hydroxyvitamin3', 'hydroxyvitamin2', 'creatinine_ratio', 'brain_natriuretic_peptide_level', 'blood_calcium']\n",
      "[2, 3, 4, 5, 6, 8, 9, 16, 23, 26, 30, 40, 41, 54, 67, 81]\n",
      "DEPRESSION eosinophil_count bmi diastolic_blood_pressure\n"
     ]
    }
   ],
   "source": [
    "# Extract the measurements, using the fact that the diagnoses are all up upper case. This is needed for automatically setting the configuration below\n",
    "measurements_for_univariate_regression = [record for record in dm.tokenizer._event_counts[\"EVENT\"] if record.upper() != record]\n",
    "\n",
    "print(measurements_for_univariate_regression)\n",
    "print(dm.encode(measurements_for_univariate_regression))\n",
    "print(dm.decode([7,4,3,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Single-Risk DeSurvival head. This module predicts a separate survival curve for each possible future event\n",
      "INFO:root:Internally scaling time in survival head by 1825 days\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1825.0], with delta=1/300\n",
      "INFO:root:ModuleDict(\n",
      "  (Token 2): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 3): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 4): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 5): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 6): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 8): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 9): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 16): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 23): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 26): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 30): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 40): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 41): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 54): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 67): Linear(in_features=384, out_features=2, bias=True)\n",
      "  (Token 81): Linear(in_features=384, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models, m_names = [], []\n",
    "\n",
    "# My development model\n",
    "for surv_layer in [\"Single-Risk\"]: #, \"Competing-Risk\"]:\n",
    "    \n",
    "    ## Create configuration\n",
    "    config = DemoConfig()\n",
    "    # Specify which survival head layer to use\n",
    "    config.SurvLayer = surv_layer   \n",
    "    # list of univariate measurements to model with Normal distribution\n",
    "    config.tokens_for_univariate_regression = dm.encode(measurements_for_univariate_regression) \n",
    "    \n",
    "    models.append(SurvStreamGPTForCausalModelling(config, vocab_size).to(device))\n",
    "    m_names.append(f\"SurvStreamGPTForCausalModelling: {surv_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curves_train = [[] for _ in models]\n",
    "loss_curves_train_clf = [[] for _ in models]\n",
    "loss_curves_train_surv = [[] for _ in models]\n",
    "loss_curves_train_values = [[] for _ in models]\n",
    "\n",
    "loss_curves_val = [[] for _ in models]\n",
    "loss_curves_val_clf = [[] for _ in models]\n",
    "loss_curves_val_surv = [[] for _ in models]\n",
    "loss_curves_val_values = [[] for _ in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model `SurvStreamGPTForCausalModelling: Single-Risk`, with 10.722272 M parameters\n",
      "Epoch 0:\tTrain loss 1.02: (1.71, 0.34). Val loss 0.98: (1.65, 0.30)\n",
      "Epoch 1:\tTrain loss 0.81: (1.34, 0.28). Val loss 0.84: (1.39, 0.28)\n",
      "Epoch 2:\tTrain loss 0.69: (1.11, 0.27). Val loss 0.72: (1.16, 0.28)\n",
      "Epoch 3:\tTrain loss 0.59: (0.92, 0.26). Val loss 0.62: (0.97, 0.28)\n",
      "Epoch 4:\tTrain loss 0.51: (0.75, 0.26). Val loss 0.54: (0.80, 0.27)\n",
      "Epoch 5:\tTrain loss 0.43: (0.61, 0.25). Val loss 0.46: (0.65, 0.27)\n",
      "Epoch 6:\tTrain loss 0.37: (0.48, 0.25). Val loss 0.40: (0.53, 0.28)\n",
      "Epoch 7:\tTrain loss 0.31: (0.37, 0.24). Val loss 0.34: (0.41, 0.26)\n",
      "Epoch 8:\tTrain loss 0.26: (0.27, 0.24). Val loss 0.29: (0.32, 0.27)\n",
      "Epoch 9:\tTrain loss 0.21: (0.19, 0.24). Val loss 0.24: (0.23, 0.26)\n",
      "Epoch 10:\tTrain loss 0.18: (0.11, 0.24). Val loss 0.22: (0.16, 0.27)\n",
      "Epoch 11:\tTrain loss 0.15: (0.05, 0.24). Val loss 0.17: (0.09, 0.26)\n",
      "Epoch 12:\tTrain loss 0.11: (-0.02, 0.23). Val loss 0.15: (0.02, 0.28)\n",
      "Epoch 13:\tTrain loss 0.08: (-0.07, 0.24). Val loss 0.12: (-0.03, 0.26)\n",
      "Epoch 14:\tTrain loss 0.05: (-0.12, 0.23). Val loss 0.10: (-0.08, 0.28)\n",
      "Epoch 15:\tTrain loss 0.03: (-0.17, 0.23). Val loss 0.07: (-0.13, 0.27)\n",
      "Epoch 16:\tTrain loss 0.01: (-0.21, 0.23). Val loss 0.05: (-0.16, 0.27)\n",
      "Epoch 17:\tTrain loss -0.01: (-0.24, 0.23). Val loss 0.03: (-0.20, 0.26)\n",
      "Epoch 18:\tTrain loss -0.02: (-0.28, 0.23). Val loss 0.02: (-0.24, 0.28)\n",
      "Epoch 19:\tTrain loss -0.04: (-0.30, 0.23). Val loss 0.01: (-0.26, 0.29)\n",
      "Epoch 20:\tTrain loss -0.04: (-0.32, 0.24). Val loss -0.00: (-0.30, 0.29)\n",
      "Epoch 21:\tTrain loss -0.06: (-0.35, 0.23). Val loss -0.02: (-0.32, 0.27)\n",
      "Epoch 22:\tTrain loss -0.06: (-0.36, 0.24). Val loss -0.03: (-0.34, 0.29)\n",
      "Epoch 23:\tTrain loss -0.07: (-0.39, 0.24). Val loss -0.05: (-0.37, 0.27)\n",
      "Epoch 24:\tTrain loss -0.09: (-0.41, 0.24). Val loss -0.05: (-0.39, 0.29)\n",
      "Epoch 25:\tTrain loss -0.09: (-0.42, 0.25). Val loss -0.06: (-0.40, 0.27)\n",
      "Epoch 26:\tTrain loss -0.10: (-0.44, 0.24). Val loss -0.07: (-0.42, 0.28)\n",
      "Epoch 27:\tTrain loss -0.12: (-0.47, 0.23). Val loss -0.09: (-0.45, 0.28)\n",
      "Epoch 28:\tTrain loss -0.12: (-0.48, 0.23). Val loss -0.07: (-0.45, 0.31)\n",
      "Epoch 29:\tTrain loss -0.12: (-0.48, 0.24). Val loss -0.09: (-0.46, 0.28)\n",
      "rsample: 0.04120575559462154\n",
      "rsample: 0.17480038306570908\n",
      "rsample: 0.3025958646483645\n",
      "rsample: 0.911706348149658\n",
      "rsample: 0.6111269393827814\n",
      "rsample: 0.14285870617899396\n",
      "rsample: 0.7045634876266833\n",
      "rsample: 0.11863361836508668\n",
      "rsample: 0.23437977668540322\n",
      "rsample: 0.517930736099619\n",
      "DEPRESSION                                        nan            at age 20 (7300.0 days)\n",
      "ASTHMA_PUSHASTHMA                                 nan            at age 25 (9125.0 days)\n",
      "diastolic_blood_pressure                          72.33          at age 28 (10290.8 days)\n",
      "bmi                                               24.61          at age 33 (12115.8 days)\n",
      "diastolic_blood_pressure                          75.81          at age 38 (13940.8 days)\n",
      "diastolic_blood_pressure                          85.60          at age 43 (15765.8 days)\n",
      "basophil_count                                    0.20           at age 48 (17590.8 days)\n",
      "corrected_serum_calcium_level                     2.25           at age 53 (19415.8 days)\n",
      "PLASMACELL_NEOPLASM                               nan            at age 58 (21240.8 days)\n",
      "eosinophil_count                                  0.62           at age 60 (21900.0 days)\n",
      "basophil_count                                    0.08           at age 65 (23725.0 days)\n"
     ]
    }
   ],
   "source": [
    "for m_idx, (model, m_name) in enumerate(zip(models, m_names)):\n",
    "    \n",
    "    print(f\"Training model `{m_name}`, with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "    best_val, epochs_since_best = np.inf, 0\n",
    "    for epoch in range(opt.epochs):\n",
    "        \n",
    "        epoch_loss, epoch_surv_loss, epoch_values_loss = 0, 0, 0\n",
    "        model.train()\n",
    "        for i, batch in enumerate(dm.train_dataloader()):\n",
    "            # print(i)\n",
    "            # evaluate the loss\n",
    "            _, (losses_desurv, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                        ages=batch['ages'].to(device), \n",
    "                                                        values=batch['values'].to(device),\n",
    "                                                        attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                        )\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # record\n",
    "            epoch_loss += loss.item()            \n",
    "            epoch_surv_loss += torch.sum(losses_desurv).item()\n",
    "            epoch_values_loss += loss_values.item()\n",
    "        \n",
    "        epoch_loss /= i\n",
    "        epoch_surv_loss /= i\n",
    "        epoch_values_loss /= i\n",
    "        loss_curves_train[m_idx].append(epoch_loss)\n",
    "        loss_curves_train_surv[m_idx].append(epoch_surv_loss)\n",
    "        loss_curves_train_values[m_idx].append(epoch_values_loss)\n",
    "\n",
    "        # evaluate the loss on val set\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            if epoch % opt.eval_interval == 0 or epoch == opt.epochs - 1:\n",
    "                val_loss, val_surv_loss, val_values_loss = 0, 0, 0\n",
    "                for j, batch in enumerate(dm.val_dataloader()):\n",
    "                    _, (losses_desurv, loss_values), loss = model(batch['tokens'].to(device), \n",
    "                                                                  ages=batch['ages'].to(device),\n",
    "                                                                  values=batch['values'].to(device),\n",
    "                                                                  attention_mask=batch['attention_mask'].to(device)   \n",
    "                                                                  )\n",
    "                    # record\n",
    "                    val_loss += loss.item()                    \n",
    "                    val_surv_loss += torch.sum(losses_desurv).item()\n",
    "                    val_values_loss += loss_values.item()\n",
    "                    \n",
    "                val_loss /= j\n",
    "                val_surv_loss /= j\n",
    "                val_values_loss /= j\n",
    "                loss_curves_val[m_idx].append(val_loss)\n",
    "                loss_curves_val_surv[m_idx].append(val_surv_loss)\n",
    "                loss_curves_val_values[m_idx].append(val_values_loss)\n",
    "\n",
    "                print(f\"Epoch {epoch}:\\tTrain loss {epoch_loss:.2f}: ({epoch_surv_loss:.2f}, {epoch_values_loss:.2f}). Val loss {val_loss:.2f}: ({val_surv_loss:.2f}, {val_values_loss:.2f})\")          \n",
    "                # TODO: Note not fully accurate as last batch is likely not the same size, will be fixed with lightning\n",
    "        \n",
    "            if val_loss >= best_val:\n",
    "                epochs_since_best += 1\n",
    "                if epochs_since_best >= 5:\n",
    "                    break\n",
    "            else:\n",
    "                best_val = val_loss\n",
    "                epochs_since_best = 0\n",
    "\n",
    "    # Test trained model with a prompt\n",
    "    # ----------------    \n",
    "    # set context: diagnosis of depression at 20 years old\n",
    "    tokens = torch.from_numpy(np.array(dm.encode([\"DEPRESSION\"])).reshape((1,-1))).to(device)\n",
    "    ages = torch.tensor([[20*365]], device=device)\n",
    "    values = torch.tensor([[torch.nan]], device=device)\n",
    "    \n",
    "    # generate: sample the next 10 tokens\n",
    "    new_tokens, new_ages, new_values = model.generate(tokens, ages, values, max_new_tokens=10)\n",
    "    generated = dm.decode(new_tokens[0].tolist())\n",
    "    # report:\n",
    "    for _cat, _age, _value in zip(generated.split(\" \"), new_ages[0, :], new_values[0, :]):\n",
    "        try:\n",
    "            _value = unstandardise(_cat, _value)\n",
    "        except:\n",
    "            pass\n",
    "        print(f\"{_cat}\".ljust(50) + f\"{_value:.02f}\".ljust(15) + f\"at age {_age/365:.0f} ({_age:.1f} days)\")    # with value {_value}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing output to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi                                               37.70          at age 37 (13413.0 days)\n",
      "ASTHMA_PUSHASTHMA                                 nan            at age 37 (13684.0 days)\n",
      "diastolic_blood_pressure                          80.00          at age 40 (14480.0 days)\n",
      "bmi                                               38.30          at age 41 (14882.0 days)\n",
      "diastolic_blood_pressure                          70.00          at age 41 (14882.0 days)\n",
      "diastolic_blood_pressure                          88.00          at age 42 (15470.0 days)\n",
      "OSTEOARTHRITIS                                    nan            at age 44 (16024.0 days)\n",
      "aspartate_transam                                 18.00          at age 47 (17231.0 days)\n",
      "basophil_count                                    0.09           at age 47 (17231.0 days)\n",
      "eosinophil_count                                  0.53           at age 47 (17231.0 days)\n"
     ]
    }
   ],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    break\n",
    "    \n",
    "conditions = batch[\"tokens\"].numpy().tolist()\n",
    "# delta_ages = batch[\"ages\"][:, 1:] - batch[\"ages\"][:, :-1]\n",
    "for idx, (token, _age, _value) in enumerate(zip(conditions[0], batch[\"ages\"][0,:],  batch[\"values\"][0,:])):\n",
    "    if token == 0 or idx >= 10:\n",
    "        break\n",
    "    _cat = dm.decode([token])\n",
    "    try:\n",
    "        _value = unstandardise(_cat, _value)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    print(f\"{_cat}\".ljust(50) + f\"{_value:.02f}\".ljust(15) + f\"at age {_age/365:.0f} ({_age:.1f} days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"k\", \"r\", \"b\", \"y\"]\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train[m_idx]), len(loss_curves_train[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val[m_idx]), len(loss_curves_val[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/single_risk/loss.png\")\n",
    "\n",
    "# Plot DeSurv loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_surv[m_idx]), len(loss_curves_train_surv[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_surv[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_surv[m_idx]), len(loss_curves_val_surv[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_surv[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/single_risk/loss_desurv.png\")\n",
    "\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train_values[m_idx]), len(loss_curves_train_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train_values[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val_values[m_idx]), len(loss_curves_val_values[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val_values[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/single_risk/loss_val.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes: How related conditions are impacted by each other\n",
    "Probability of type II diabetes before and after a type I diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Single-Risk\n",
      "--------------------------------------\n",
      "\n",
      "Depression: \t (DEPRESSION): \n",
      "\n",
      "Depression -> Type 1: \t (DEPRESSION,TYPE1DM): \n",
      "\n",
      "Depression - > Type 2: \t (DEPRESSION,TYPE2DIABETES): \n"
     ]
    }
   ],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"TYPE1DM\"]\n",
    "t2_token = dm.tokenizer._stoi[\"TYPE2DIABETES\"]\n",
    "\n",
    "\n",
    "base_prompt = [\"DEPRESSION\"]\n",
    "ages_in_years = [20]\n",
    "base_values = [torch.tensor([torch.nan])]\n",
    "\n",
    "to_days = lambda a_list: torch.FloatTensor([365 * _a for _a in a_list]).reshape((1,-1)).to(device)\n",
    "\n",
    "# Create a set of prompts\n",
    "prompts, ages, values, desc = [], [], [], []\n",
    "# control prompt\n",
    "desc.append(\"Depression\")\n",
    "prompts.append(base_prompt)\n",
    "ages.append(ages_in_years)\n",
    "values.append(base_values)\n",
    "# prompt with type 1 diabetes\n",
    "desc.append(\"Depression -> Type 1\")\n",
    "prompts.append(base_prompt + [\"TYPE1DM\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "desc.append(\"Depression - > Type 2\")\n",
    "prompts.append(base_prompt + [\"TYPE2DIABETES\"])\n",
    "ages.append(ages_in_years + [21])\n",
    "values.append(base_values + [torch.tensor([torch.nan])])\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        prompt_survs = []\n",
    "        for p_idx, (prompt, age, value) in enumerate(zip(prompts, ages, values)):\n",
    "            print(f\"\\n{desc[p_idx]}: \\t ({','.join(prompt)}): \")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                           values=torch.tensor(value).to(device),\n",
    "                                           ages=to_days(age),\n",
    "                                           is_generation=True)\n",
    "            prompt_survs.append(surv)\n",
    "\n",
    "        for si, _ in enumerate(surv):\n",
    "            plt.close()\n",
    "            event_name = dm.decode([si + 1])\n",
    "            for p_idx in range(len(prompts)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, prompt_survs[p_idx][si][0, :], label=f\"{desc[p_idx]}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"figs/single_risk/diabetes/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing BMI affects diagnosis risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Single-Risk\n",
      "--------------------------------------\n",
      "Value tensor([-2.5282], device='cuda:0')\n",
      "======\n",
      "Value tensor([-2.1060], device='cuda:0')\n",
      "======\n",
      "Value tensor([-1.6837], device='cuda:0')\n",
      "======\n",
      "Value tensor([-1.2614], device='cuda:0')\n",
      "======\n",
      "Value tensor([-0.8392], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.0053], device='cuda:0')\n",
      "======\n",
      "Value tensor([1.4129], device='cuda:0')\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "events_of_interest = [\"bmi\", \"diastolic_blood_pressure\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF\", \"ISCHAEMICSTROKE\"\n",
    "                     ]\n",
    "prompt = [\"bmi\"]\n",
    "values = [torch.tensor([standardise(_cat, v) for _cat in prompt], device=device) for v in [12.,15.,18.,21.,24.,30.,40.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        prompt_survs = []\n",
    "        for p_idx, value in enumerate(values):\n",
    "            print(f\"Value {value}\\n======\")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                           values=value,\n",
    "                                           ages=to_days(age),\n",
    "                                           is_generation=True)\n",
    "            prompt_survs.append(surv)\n",
    "\n",
    "        for si, _ in enumerate(surv):\n",
    "            plt.close()\n",
    "            event_name = dm.decode([si + 1])\n",
    "            \n",
    "            if event_name in events_of_interest:\n",
    "                \n",
    "                for p_idx in range(len(prompt_survs)):\n",
    "                    bmi_value = unstandardise(\"bmi\", values[p_idx])\n",
    "                    plt.plot(model.surv_layer.t_eval / 365, prompt_survs[p_idx][si][0, :], label=f\"BMI {bmi_value.item():.2f}\")\n",
    "                plt.xlabel(\"t (years)\")\n",
    "                plt.ylabel(\"P(T>t) ()\")\n",
    "                plt.legend()\n",
    "                plt.savefig(f\"figs/single_risk/bmi/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing diastolic_blood_pressure affects likelihood of diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Single-Risk\n",
      "--------------------------------------\n",
      "Value tensor([-1.6106], device='cuda:0')\n",
      "======\n",
      "Value tensor([-0.7581], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.0944], device='cuda:0')\n",
      "======\n",
      "Value tensor([0.9470], device='cuda:0')\n",
      "======\n",
      "Value tensor([1.7995], device='cuda:0')\n",
      "======\n",
      "Value tensor([3.5046], device='cuda:0')\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "events_of_interest = [\"bmi\", \"diastolic_blood_pressure\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF\", \"ISCHAEMICSTROKE\"\n",
    "                     ]\n",
    "\n",
    "prompt = [\"diastolic_blood_pressure\"]\n",
    "values = [torch.tensor([standardise(_cat, _value) for _cat in prompt], device=device) for _value in [60.,70.,80.,90.,100.,120.]]\n",
    "age = [40]\n",
    "\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "        prompt_survs = []\n",
    "        for p_idx, value in enumerate(values):\n",
    "            print(f\"Value {value}\\n======\")\n",
    "            encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "            (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                           values=value,\n",
    "                                           ages=to_days(age),\n",
    "                                           is_generation=True)\n",
    "            prompt_survs.append(surv)\n",
    "\n",
    "        for si, _ in enumerate(surv):\n",
    "            plt.close()\n",
    "            event_name = dm.decode([si + 1])\n",
    "            \n",
    "            if event_name in events_of_interest:\n",
    "                \n",
    "                for p_idx in range(len(prompt_survs)):\n",
    "                    dbp_value = unstandardise(\"diastolic_blood_pressure\", values[p_idx])\n",
    "                    plt.plot(model.surv_layer.t_eval / 365, prompt_survs[p_idx][si][0, :], label=f\"DBP {dbp_value.item():.2f}\")\n",
    "                plt.xlabel(\"t (years)\")\n",
    "                plt.ylabel(\"P(T>t) ()\")\n",
    "                plt.legend()\n",
    "                plt.savefig(f\"figs/single_risk/diastolic_blood_pressure/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How varying diagnosis affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Single-Risk\n",
      "--------------------------------------\n",
      "\n",
      "Diagnosis ['DEPRESSION']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.1, 0.9)\n",
      "\n",
      "Diagnosis ['TYPE2DIABETES']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.2, 0.9)\n",
      "\n",
      "Diagnosis ['HF']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.2, 1.0)\n",
      "\n",
      "Diagnosis ['HYPERTENSION']\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.5, 1.1)\n"
     ]
    }
   ],
   "source": [
    "measurements_of_interest = [\"diastolic_blood_pressure\"]\n",
    "t1_token = dm.tokenizer._stoi[\"diastolic_blood_pressure\"]\n",
    "\n",
    "diagnoses = [[\"DEPRESSION\"],[\"TYPE2DIABETES\"], [\"HF\"], [\"HYPERTENSION\"]]\n",
    "values = torch.tensor([torch.nan], device=device)\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "\n",
    "    for p_idx, diagnosis in enumerate(diagnoses):\n",
    "        print(f\"\\nDiagnosis {diagnosis}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(diagnosis)).reshape((1,-1))).to(device)\n",
    "        (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                       values=values,\n",
    "                                       ages=to_days(age),\n",
    "                                       is_generation=True)\n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing bmi affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Single-Risk\n",
      "--------------------------------------\n",
      "\n",
      "Values [-2.5282182693481445]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.8, 0.9)\n",
      "\n",
      "Values [-2.105959177017212]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.7, 1.0)\n",
      "\n",
      "Values [-1.6837000846862793]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.6, 1.0)\n",
      "\n",
      "Values [-1.2614409923553467]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.4, 0.9)\n",
      "\n",
      "Values [-0.8391818404197693]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(-0.2, 0.9)\n",
      "\n",
      "Values [0.005336357280611992]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.1, 0.9)\n",
      "\n",
      "Values [1.4128667116165161]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.5, 1.1)\n",
      "\n",
      "Values [2.820397138595581]\n",
      "======\n",
      "standardised diastolic_blood_pressure ~ N(0.5, 1.2)\n"
     ]
    }
   ],
   "source": [
    "t1_token = dm.tokenizer._stoi[\"diastolic_blood_pressure\"]\n",
    "\n",
    "prompt = [\"bmi\"]\n",
    "values = [torch.tensor([standardise(_cat, _value) for _cat in prompt], device=device) for _value in [12.,15.,18.,21.,24.,30.,40.,50.]]\n",
    "age = [40]\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n--------------------------------------\")\n",
    "\n",
    "    for p_idx, value in enumerate(values):\n",
    "        print(f\"\\nValues {value.tolist()}\\n======\")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        (surv, val_dist), _, _ = model(encoded_prompt,\n",
    "                                       values=value,\n",
    "                                       ages=to_days(age),\n",
    "                                       is_generation=True)\n",
    "        \n",
    "        dist = val_dist[model.value_layer.token_key(t1_token)]\n",
    "        print(f\"standardised diastolic_blood_pressure ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n",
    "        # print(f\"\\tprobability of type II diabetes: {100*float(probs[0, 0, t2_token].cpu().detach().numpy()):.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling: Single-Risk\n",
      "============================================\n",
      "\n",
      "\n",
      "SurvStreamGPTForCausalModelling(\n",
      "  (transformer): TTETransformer(\n",
      "    (wpe): TemporalPositionalEncoding()\n",
      "    (wte): DataEmbeddingLayer(\n",
      "      (token_embed_layer): Embedding(90, 384, padding_idx=0)\n",
      "      (value_embed_layer): EmbeddingBag(90, 384, mode=sum, padding_idx=0)\n",
      "    )\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (surv_layer): ODESurvSingleLayer()\n",
      "  (value_layer): GaussianRegressionLayer(\n",
      "    (regression_layers): ModuleDict(\n",
      "      (Token 2): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 3): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 4): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 5): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 6): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 8): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 9): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 16): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 23): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 26): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 30): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 40): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 41): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 54): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 67): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 81): Linear(in_features=384, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for model_idx, model in enumerate(models):\n",
    "    print(f\"\\n\\n{m_names[model_idx]}\\n\" + \"=\"*len(m_names[model_idx]))\n",
    "    print(f\"\\n\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook single_risk.ipynb to html\n",
      "[NbConvertApp] Writing 597697 bytes to single_risk.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html --no-input single_risk.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
