{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4921342e-8ff8-45d4-b1f6-9fe480c2ee1d",
   "metadata": {},
   "source": [
    "# CPRD Notebook:\n",
    "## Evaluation of fine-tuning the pre-trained SurvivEHR-CR model on a supervised cohort study.\n",
    "\n",
    "Cohort study: predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population.\n",
    "\n",
    "This notebook quantifies the performance obtained when fine-tuning the pre-trained model to a sub-population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a671c59b-4428-4e63-a138-7244418a87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvStreamGPT/notebooks/CompetingRisk/CVD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d866c7f0-eaa8-4129-b3b1-d4d6b504d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n",
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from CPRD.examples.modelling.SurvStreamGPT.run_experiment import run\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "\n",
    "import time\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(10000)\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10000\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")\n",
    "\n",
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c237f8-679a-4fe4-a570-2c8c7b61da9b",
   "metadata": {},
   "source": [
    "# Choosing configurations\n",
    "The default configuration is for pre-training. Here we modify as necesssary\n",
    "\n",
    "Here we choose to load in the configuration for a small **pre-trained** 11.4M parameter model, named \"CR_11M\". We specfiy the `fine-tune` experiment type, which will lead to running the ```SupervisedExperiment```. \n",
    "\n",
    "We tell this experiment that we want to perform training (true by default). Additionally, we do choose to perform testing (true by default). As this is a supervised model, this tests the ability to predict the outcomes of interest. In this notebook, this is chosen to be those of the cohort study for predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population, and we add the folder containing this dataset to the configuration. \n",
    "\n",
    "```Note: As this is a supervised dataset, we need to tell the DataModule that the last event observed is a target and must be stripped. This is done by passing a list of targets to the configuration, overriding the null default. This lets the DataModule know that it should process batches as supervised.```\n",
    "\n",
    "We set the number of workers to be appropriate for the number of CPUs available to reduce bottlenecking, and tell the experiment that we do not want to limit the number of testing batches. In addition, we specify where we want any checkpoints to be saved to avoid bloating the repository.\n",
    "\n",
    "We design a new optimisation strategy for fine-tuning. Pre-training was achieved with a warmup and cosine annealing, with rates which are no appropriate for much smaller dataset sizes seen in clinical prediction models (CPMs). We here choose a simpler strategy: of ReduceOnPlateau with no warmup, increasing the number of epochs (default is 1) and reduced validation intervals, and the addition of early stopping. Additionally, as this is not a causal model we can increase the batch size. Finally, as this CPM is not trying to predict the value of any outcomes, we set the value weight to zero allowing the model to focus entirely on optimising survival outcome prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612bb987-1923-4f44-bf3d-d74952b33380",
   "metadata": {},
   "source": [
    "# Small 11.4M parameter model\n",
    "\n",
    "```\n",
    "Hypertension\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃             Test metric             ┃            DataLoader 0             ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│  Test:OutcomePerformanceMetricsctd  │         0.6980466246604919          │\n",
    "│  Test:OutcomePerformanceMetricsibs  │         0.09058867272886643         │\n",
    "│ Test:OutcomePerformanceMetricsinbll │         0.3116109046404026          │\n",
    "│              test_loss              │         1.3693411350250244          │\n",
    "└─────────────────────────────────────┴─────────────────────────────────────┘\n",
    "\n",
    "CVD (old)\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃             Test metric             ┃            DataLoader 0             ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│  Test:OutcomePerformanceMetricsctd  │         0.6582537293434143          │\n",
    "│  Test:OutcomePerformanceMetricsibs  │        0.033626483186099766         │\n",
    "│ Test:OutcomePerformanceMetricsinbll │         0.14357818411009718         │\n",
    "│              test_loss              │          9.273333549499512          │\n",
    "│          test_loss_desurv           │          9.273333549499512          │\n",
    "└─────────────────────────────────────┴─────────────────────────────────────┘\n",
    "\n",
    "SurvivEHR-cr-small-scratch\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃             Test metric             ┃            DataLoader 0             ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│  Test:OutcomePerformanceMetricsctd  │         0.5870776772499084          │\n",
    "│  Test:OutcomePerformanceMetricsibs  │         0.03397136150039864         │\n",
    "│ Test:OutcomePerformanceMetricsinbll │         0.1476862535572371          │\n",
    "│              test_loss              │          4.618246555328369          │\n",
    "└─────────────────────────────────────┴─────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6e33a0-0c57-4ba5-a4a7-4799ee6b1344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cvd on pre-trained model SurvivEHR-cr-small-v1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bfe15d1b5249c7b63476228a8fda9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.040 MB of 0.040 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▄▄▅▅▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>0.001</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>train_loss</td><td>-4.39977</td></tr><tr><td>trainer/global_step</td><td>119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SurvivEHR-cr-small-v1_cvd-few-shot</strong>: <a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/3iaqhjvu\" target=\"_blank\">https://wandb.ai/cwlgadd/SurvivEHR/runs/3iaqhjvu</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20250113_142337-3iaqhjvu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=train/ dataset, with 572,096 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 128\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 3\n",
      "  global_diagnoses: true\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: null\n",
      "experiment:\n",
      "  type: few-shot\n",
      "  project_name: SurvivEHR\n",
      "  run_id: SurvivEHR-cr-small-v1\n",
      "  fine_tune_id: cvd-few-shot\n",
      "  train: true\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - IHDINCLUDINGMI_OPTIMALV2\n",
      "  - ISCHAEMICSTROKE_V2\n",
      "  - MINFARCTION\n",
      "  - STROKEUNSPECIFIED_V2\n",
      "  - STROKE_HAEMRGIC\n",
      "  notes: null\n",
      "optim:\n",
      "  num_epochs: 10\n",
      "  learning_rate: 0.001\n",
      "  scheduler_warmup: false\n",
      "  scheduler: ReduceOnPlateau\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 0.1\n",
      "  early_stop: true\n",
      "  early_stop_patience: 4\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.25\n",
      "  limit_test_batches: null\n",
      "  accumulate_grad_batches: 1\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 512\n",
      "  n_layer: 6\n",
      "  n_head: 6\n",
      "  n_embd: 384\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "  use_fine_tune_adapter: true\n",
      "  adapter_dim: 8\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 1\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.1\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Few-shot learning experiment.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating new few-shot model at the path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SurvivEHR-cr-small-v1_cvd-few-shot.ckpt. This is initialised from a pre-trained causal model, which can be found at checkpoint /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SurvivEHR-cr-small-v1.ckpt.\n",
      "INFO:root:Running few-shot experiment with outcomes {'IHDINCLUDINGMI_OPTIMALV2': 95, 'ISCHAEMICSTROKE_V2': 41, 'MINFARCTION': 67, 'STROKEUNSPECIFIED_V2': 65, 'STROKE_HAEMRGIC': 28}\n",
      "INFO:root:Loading from checkpoint\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and fine-tuning using an Adapter mechanism.\n",
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:173: Found keys that are in the model state dict but not in the checkpoint: ['model.transformer.blocks.0.adapter_1.proj.0.weight', 'model.transformer.blocks.0.adapter_1.proj.0.bias', 'model.transformer.blocks.0.adapter_1.proj.2.weight', 'model.transformer.blocks.0.adapter_1.proj.2.bias', 'model.transformer.blocks.0.adapter_2.proj.0.weight', 'model.transformer.blocks.0.adapter_2.proj.0.bias', 'model.transformer.blocks.0.adapter_2.proj.2.weight', 'model.transformer.blocks.0.adapter_2.proj.2.bias', 'model.transformer.blocks.1.adapter_1.proj.0.weight', 'model.transformer.blocks.1.adapter_1.proj.0.bias', 'model.transformer.blocks.1.adapter_1.proj.2.weight', 'model.transformer.blocks.1.adapter_1.proj.2.bias', 'model.transformer.blocks.1.adapter_2.proj.0.weight', 'model.transformer.blocks.1.adapter_2.proj.0.bias', 'model.transformer.blocks.1.adapter_2.proj.2.weight', 'model.transformer.blocks.1.adapter_2.proj.2.bias', 'model.transformer.blocks.2.adapter_1.proj.0.weight', 'model.transformer.blocks.2.adapter_1.proj.0.bias', 'model.transformer.blocks.2.adapter_1.proj.2.weight', 'model.transformer.blocks.2.adapter_1.proj.2.bias', 'model.transformer.blocks.2.adapter_2.proj.0.weight', 'model.transformer.blocks.2.adapter_2.proj.0.bias', 'model.transformer.blocks.2.adapter_2.proj.2.weight', 'model.transformer.blocks.2.adapter_2.proj.2.bias', 'model.transformer.blocks.3.adapter_1.proj.0.weight', 'model.transformer.blocks.3.adapter_1.proj.0.bias', 'model.transformer.blocks.3.adapter_1.proj.2.weight', 'model.transformer.blocks.3.adapter_1.proj.2.bias', 'model.transformer.blocks.3.adapter_2.proj.0.weight', 'model.transformer.blocks.3.adapter_2.proj.0.bias', 'model.transformer.blocks.3.adapter_2.proj.2.weight', 'model.transformer.blocks.3.adapter_2.proj.2.bias', 'model.transformer.blocks.4.adapter_1.proj.0.weight', 'model.transformer.blocks.4.adapter_1.proj.0.bias', 'model.transformer.blocks.4.adapter_1.proj.2.weight', 'model.transformer.blocks.4.adapter_1.proj.2.bias', 'model.transformer.blocks.4.adapter_2.proj.0.weight', 'model.transformer.blocks.4.adapter_2.proj.0.bias', 'model.transformer.blocks.4.adapter_2.proj.2.weight', 'model.transformer.blocks.4.adapter_2.proj.2.bias', 'model.transformer.blocks.5.adapter_1.proj.0.weight', 'model.transformer.blocks.5.adapter_1.proj.0.bias', 'model.transformer.blocks.5.adapter_1.proj.2.weight', 'model.transformer.blocks.5.adapter_1.proj.2.bias', 'model.transformer.blocks.5.adapter_2.proj.0.weight', 'model.transformer.blocks.5.adapter_2.proj.0.bias', 'model.transformer.blocks.5.adapter_2.proj.2.weight', 'model.transformer.blocks.5.adapter_2.proj.2.bias']\n",
      "INFO:root:Re-initialising value/survival head parameters.\n",
      "INFO:root:Created Performance metric callback. Calculating metrics for dict_keys([95, 41, 67, 65, 28]) with map {95: 94, 41: 40, 67: 66, 65: 64, 28: 27}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:root:Training model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20250113_143442-1jbs96s8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/1jbs96s8\" target=\"_blank\">SurvivEHR-cr-small-v1_cvd-few-shot</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvivEHR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:Using ReduceLROnPlateau scheduler\n",
      "INFO:root:Not using warm-up in scheduler\n",
      "\n",
      "  | Name  | Type                            | Params\n",
      "----------------------------------------------------------\n",
      "0 | model | SurvStreamGPTForCausalModelling | 11.3 M\n",
      "----------------------------------------------------------\n",
      "153 K     Trainable params\n",
      "11.1 M    Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.159    Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451597756e3a43f3b948076c3dab5c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Invalid loss nan: with target tokens tensor([[200],\n",
      "        [167],\n",
      "        [200],\n",
      "        [241],\n",
      "        [143],\n",
      "        [263],\n",
      "        [204],\n",
      "        [202],\n",
      "        [255],\n",
      "        [263],\n",
      "        [106],\n",
      "        [106],\n",
      "        [259],\n",
      "        [200],\n",
      "        [200],\n",
      "        [249],\n",
      "        [175],\n",
      "        [255],\n",
      "        [263],\n",
      "        [255],\n",
      "        [260],\n",
      "        [262],\n",
      "        [224],\n",
      "        [162],\n",
      "        [ 41],\n",
      "        [259],\n",
      "        [159],\n",
      "        [147],\n",
      "        [249],\n",
      "        [221],\n",
      "        [168],\n",
      "        [106],\n",
      "        [143],\n",
      "        [177],\n",
      "        [ 65],\n",
      "        [224],\n",
      "        [210],\n",
      "        [190],\n",
      "        [106],\n",
      "        [218],\n",
      "        [200],\n",
      "        [ 95],\n",
      "        [222],\n",
      "        [263],\n",
      "        [218],\n",
      "        [190],\n",
      "        [200],\n",
      "        [ 95],\n",
      "        [249],\n",
      "        [263],\n",
      "        [ 95],\n",
      "        [263],\n",
      "        [263],\n",
      "        [255],\n",
      "        [263],\n",
      "        [106],\n",
      "        [199],\n",
      "        [263],\n",
      "        [190],\n",
      "        [218],\n",
      "        [224],\n",
      "        [120],\n",
      "        [200],\n",
      "        [249],\n",
      "        [259],\n",
      "        [258],\n",
      "        [199],\n",
      "        [143],\n",
      "        [222],\n",
      "        [161],\n",
      "        [106],\n",
      "        [ 95],\n",
      "        [ 95],\n",
      "        [241],\n",
      "        [224],\n",
      "        [197],\n",
      "        [200],\n",
      "        [200],\n",
      "        [254],\n",
      "        [254],\n",
      "        [263],\n",
      "        [224],\n",
      "        [ 67],\n",
      "        [263],\n",
      "        [168],\n",
      "        [200],\n",
      "        [224],\n",
      "        [262],\n",
      "        [262],\n",
      "        [224],\n",
      "        [241],\n",
      "        [168],\n",
      "        [185],\n",
      "        [262],\n",
      "        [263],\n",
      "        [263],\n",
      "        [224],\n",
      "        [190],\n",
      "        [204],\n",
      "        [200],\n",
      "        [167],\n",
      "        [159],\n",
      "        [202],\n",
      "        [255],\n",
      "        [224],\n",
      "        [252],\n",
      "        [262],\n",
      "        [222],\n",
      "        [ 75],\n",
      "        [251],\n",
      "        [252],\n",
      "        [ 67],\n",
      "        [255],\n",
      "        [106],\n",
      "        [212],\n",
      "        [230],\n",
      "        [ 95],\n",
      "        [106],\n",
      "        [241],\n",
      "        [143],\n",
      "        [106],\n",
      "        [ 95],\n",
      "        [106],\n",
      "        [ 95],\n",
      "        [106],\n",
      "        [255],\n",
      "        [200],\n",
      "        [263]], device='cuda:0'), target values tensor([[    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.4990],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.4790],\n",
      "        [-0.3000],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.2459],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.2573],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.4989],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.4853],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.1865],\n",
      "        [-0.2568],\n",
      "        [    nan],\n",
      "        [-0.4992],\n",
      "        [-0.4708],\n",
      "        [-0.4731],\n",
      "        [-0.2703],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.4816],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.3330],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.1757],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.3272],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.2148],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [-0.4981],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan],\n",
      "        [    nan]], device='cuda:0') and target ages tensor([[2.3090e+00],\n",
      "        [4.2038e+00],\n",
      "        [1.6466e+00],\n",
      "        [6.4932e-01],\n",
      "        [3.2690e+00],\n",
      "        [4.1096e-01],\n",
      "        [2.7332e+00],\n",
      "        [1.1397e+00],\n",
      "        [4.2893e+00],\n",
      "        [5.7315e-01],\n",
      "        [5.2548e-01],\n",
      "        [3.8323e+00],\n",
      "        [2.6301e+00],\n",
      "        [2.6301e+00],\n",
      "        [2.0915e+00],\n",
      "        [3.4899e+00],\n",
      "        [2.9184e+00],\n",
      "        [2.5364e+00],\n",
      "        [1.5940e+00],\n",
      "        [4.8055e-01],\n",
      "        [1.7923e+00],\n",
      "        [5.6603e-01],\n",
      "        [7.5617e-02],\n",
      "        [2.5732e+00],\n",
      "        [4.9863e-02],\n",
      "        [1.2307e+00],\n",
      "        [3.4329e+00],\n",
      "        [2.7792e+00],\n",
      "        [2.3222e+00],\n",
      "        [3.5841e+00],\n",
      "        [1.1704e+00],\n",
      "        [1.2115e+00],\n",
      "        [3.5282e+00],\n",
      "        [1.5019e+00],\n",
      "        [2.3671e-01],\n",
      "        [4.4055e-01],\n",
      "        [1.7447e+00],\n",
      "        [5.7863e-01],\n",
      "        [4.0219e-01],\n",
      "        [1.3764e+00],\n",
      "        [3.3129e+00],\n",
      "        [1.2981e+00],\n",
      "        [2.0849e+00],\n",
      "        [2.5627e+00],\n",
      "        [6.5808e-01],\n",
      "        [3.2767e-01],\n",
      "        [2.4400e+00],\n",
      "        [4.8548e-01],\n",
      "        [2.0701e+00],\n",
      "        [2.1145e+00],\n",
      "        [1.7342e+00],\n",
      "        [3.8016e+00],\n",
      "        [1.2647e+00],\n",
      "        [4.3890e-01],\n",
      "        [1.4422e+00],\n",
      "        [9.9945e-01],\n",
      "        [9.5233e-01],\n",
      "        [1.5266e+00],\n",
      "        [7.2767e-01],\n",
      "        [3.6110e-01],\n",
      "        [2.5206e-02],\n",
      "        [1.6290e+00],\n",
      "        [3.0071e+00],\n",
      "        [1.0263e+00],\n",
      "        [3.1282e+00],\n",
      "        [4.1595e+00],\n",
      "        [1.0318e+00],\n",
      "        [1.9556e+00],\n",
      "        [1.8586e+00],\n",
      "        [1.6723e+00],\n",
      "        [2.8055e-01],\n",
      "        [1.7315e-01],\n",
      "        [6.0055e-01],\n",
      "        [1.3315e+00],\n",
      "        [2.1315e-01],\n",
      "        [2.4460e+00],\n",
      "        [3.7841e+00],\n",
      "        [3.7206e-01],\n",
      "        [3.7118e+00],\n",
      "        [2.0159e+00],\n",
      "        [2.0899e+00],\n",
      "        [1.8307e+00],\n",
      "        [1.2668e+00],\n",
      "        [1.0910e+00],\n",
      "        [1.7425e-01],\n",
      "        [3.0521e-01],\n",
      "        [4.9918e-01],\n",
      "        [2.4115e+00],\n",
      "        [1.1342e+00],\n",
      "        [2.8504e+00],\n",
      "        [1.2603e-01],\n",
      "        [2.0866e+00],\n",
      "        [1.5797e+00],\n",
      "        [5.9452e-01],\n",
      "        [1.1814e+00],\n",
      "        [5.7589e-01],\n",
      "        [1.6438e-01],\n",
      "        [1.6822e-01],\n",
      "        [3.2208e+00],\n",
      "        [2.1920e-03],\n",
      "        [6.0110e-01],\n",
      "        [3.7348e+00],\n",
      "        [6.3836e-01],\n",
      "        [3.8088e+00],\n",
      "        [6.5315e-01],\n",
      "        [2.0110e-01],\n",
      "        [1.1167e+00],\n",
      "        [4.1868e+00],\n",
      "        [1.3381e+00],\n",
      "        [1.7052e+00],\n",
      "        [3.5452e-01],\n",
      "        [2.7644e+00],\n",
      "        [2.7288e-01],\n",
      "        [5.3698e-02],\n",
      "        [1.4997e+00],\n",
      "        [1.4959e+00],\n",
      "        [5.7479e-01],\n",
      "        [9.6712e-01],\n",
      "        [1.8373e+00],\n",
      "        [2.0148e+00],\n",
      "        [2.7918e+00],\n",
      "        [1.6055e+00],\n",
      "        [1.8603e+00],\n",
      "        [2.7786e+00],\n",
      "        [2.7540e+00],\n",
      "        [5.6164e-01],\n",
      "        [2.9825e+00],\n",
      "        [1.4690e+00]], device='cuda:0')\n",
      "WARNING:root:DeSurv losses [tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)]\n",
      "WARNING:root:from hidden state tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 56\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m experiment\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     49\u001b[0m         cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath_to_ds\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m         cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath_to_ds\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m         cfg\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mfine_tune_outcomes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHYPERTENSION\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     55\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m---> 56\u001b[0m experiment, dm \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m experiment\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e6\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m M parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/Hydra/1.3.2-GCCcore-11.3.0/lib/python3.10/site-packages/hydra/main.py:83\u001b[0m, in \u001b[0;36mmain.<locals>.main_decorator.<locals>.decorated_main\u001b[0;34m(cfg_passthrough)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(task_function)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorated_main\u001b[39m(cfg_passthrough: Optional[DictConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cfg_passthrough \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_passthrough\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m         args_parser \u001b[38;5;241m=\u001b[39m get_args_parser()\n",
      "File \u001b[0;32m~/Projects/CPRD/examples/modelling/SurvStreamGPT/run_experiment.py:234\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[1;32m    233\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 234\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Ensure we evaluate on the best/latest version of the model - particularly if we just trained then load the new best checkpoint\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-loading from best cached checkpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_checkpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    577\u001b[0m     ckpt_path,\n\u001b[1;32m    578\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    580\u001b[0m )\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 990\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    995\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1036\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1036\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:359\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:136\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:240\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:187\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         closure()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:265\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1282\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1245\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1249\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \n\u001b[1;32m   1281\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:151\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:230\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:117\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch/2.0.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch/2.0.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch/2.0.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/optim/adamw.py:148\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 148\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    151\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:104\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     93\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch/2.0.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:126\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 126\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:315\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_result_cls\u001b[38;5;241m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[38;5;241m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:382\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/CPRD/examples/modelling/SurvStreamGPT/setup_fewshot_experiment.py:125\u001b[0m, in \u001b[0;36mFewShotExperiment.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m--> 125\u001b[0m     _, loss_dict, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _key \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m _key, loss_dict[_key], prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sync_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/rds/bear-apps/2022a/EL8-ice/software/PyTorch/2.0.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/CPRD/examples/modelling/SurvStreamGPT/setup_fewshot_experiment.py:118\u001b[0m, in \u001b[0;36mFewShotExperiment.forward\u001b[0;34m(self, batch, return_loss, return_generation)\u001b[0m\n\u001b[1;32m    116\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeSurv losses \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses_desurv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom hidden state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39msum(in_hidden_state, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m128\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 118\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pre_trained_models = [\"SurvivEHR-cr-small-scratch\"] # [\"notebook-test3\", \"CR_11M_24_11_01_big_posencscale_\", \"NULL\"]\n",
    "pre_trained_model_ids = ['SurvivEHR-cr-small', 'SurvivEHR-cr-small-v1', 'SurvivEHR-cr', 'SurvivEHR-cr-v1', 'SurvivEHR-cr-v1-v1', 'SurvivEHR-cr-384', 'SurvivEHR-cr-384-v1',]\n",
    "experiments = [\"cvd\", \"hypertension\"] \n",
    "\n",
    "for pre_trained_model in pre_trained_model_ids[1:2]:\n",
    "\n",
    "    for experiment in experiments:\n",
    "                \n",
    "        print(f\"Running {experiment} on pre-trained model {pre_trained_model}\")\n",
    "    \n",
    "        # load the configuration file, override any settings \n",
    "        with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "            cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                          overrides=[# Experiment setup\n",
    "                                     \"experiment.type='few-shot'\",\n",
    "                                     f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                                     f\"experiment.fine_tune_id='{experiment}-few-shot'\",\n",
    "                                     \"experiment.train=True\",\n",
    "                                     \"experiment.test=True\",\n",
    "                                     # Dataloader\n",
    "                                     \"data.batch_size=128\",\n",
    "                                     \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                                     \"data.min_workers=3\",\n",
    "                                     \"data.global_diagnoses=True\",\n",
    "                                     # Optimiser\n",
    "                                     \"optim.num_epochs=10\",\n",
    "                                     \"optim.scheduler=ReduceOnPlateau\",\n",
    "                                     \"optim.scheduler_warmup=False\",\n",
    "                                     \"optim.learning_rate=1e-3\", #3e-4\",\n",
    "                                     \"optim.val_check_interval=0.1\",\n",
    "                                     \"optim.limit_val_batches=0.25\",\n",
    "                                     \"optim.limit_test_batches=null\",\n",
    "                                     \"optim.early_stop=True\",\n",
    "                                     \"optim.early_stop_patience=4\",\n",
    "                                     # Model\n",
    "                                     \"transformer.n_embd=384\", # 1024\n",
    "                                     \"transformer.use_fine_tune_adapter=True\",\n",
    "                                     \"transformer.adapter_dim=8\",\n",
    "                                     \"transformer.block_size=512\", \n",
    "                                     # Head\n",
    "                                     \"head.surv_weight=1\",\n",
    "                                     \"head.value_weight=0.1\",\n",
    "                                    ]\n",
    "                         )     \n",
    "    \n",
    "        \n",
    "        match experiment.lower():\n",
    "            case \"cvd\":\n",
    "                cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "                cfg.experiment.fine_tune_outcomes=[\"IHDINCLUDINGMI_OPTIMALV2\", \"ISCHAEMICSTROKE_V2\", \"MINFARCTION\", \"STROKEUNSPECIFIED_V2\", \"STROKE_HAEMRGIC\"]\n",
    "            case \"hypertension\":\n",
    "                cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\"\n",
    "                cfg.experiment.fine_tune_outcomes=[\"HYPERTENSION\"]\n",
    "                \n",
    "        wandb.finish()\n",
    "        experiment, dm = run(cfg)\n",
    "        print(f\"Loaded model with {sum(p.numel() for p in experiment.model.parameters())/1e6} M parameters\")\n",
    "        wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fb99aa-5e7a-4889-9feb-cc20b3c21acf",
   "metadata": {},
   "source": [
    "# Subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e00688-1426-4046-910c-45bde94db899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_trained_models = [\"CR_11M_24_11_01_big_posencscale_\", \"NULL\"]\n",
    "experiments = [\"hypertension\", \"cvd\"] \n",
    "\n",
    "for pre_trained_model in pre_trained_models:\n",
    "\n",
    "    for experiment in experiments:\n",
    "    \n",
    "        # load the configuration file, override any settings \n",
    "        with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "            cfg = compose(config_name=\"config_CompetingRisk37M\", \n",
    "                          overrides=[# Experiment setup\n",
    "                                     \"experiment.type='few-shot'\",\n",
    "                                     f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                                     f\"experiment.fine_tune_id='{experiment}-few-shot-cr3'\",\n",
    "                                     \"experiment.train=True\",\n",
    "                                     \"experiment.test=True\",\n",
    "                                     # Dataloader\n",
    "                                     \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                                     \"data.min_workers=12\",\n",
    "                                     \"data.subsample_training=600\",\n",
    "                                     # Optimiser\n",
    "                                     \"optim.num_epochs=50\",\n",
    "                                     \"optim.limit_test_batches=null\",\n",
    "                                     \"optim.scheduler=ReduceOnPlateau\",\n",
    "                                     \"optim.scheduler_warmup=True\",\n",
    "                                     \"optim.scheduler_periods=250\",\n",
    "                                     \"optim.learning_rate=1e-3\",\n",
    "                                     \"optim.val_check_interval=5\",\n",
    "                                     \"optim.early_stop=True\",\n",
    "                                     \"optim.early_stop_patience=20\",\n",
    "                                     # Head\n",
    "                                     \"head.surv_weight=1\",\n",
    "                                     \"head.value_weight=0\",\n",
    "                                    ]\n",
    "                         )     \n",
    "    \n",
    "        \n",
    "        match experiment.lower():\n",
    "            case \"cvd\":\n",
    "                cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "                cfg.experiment.fine_tune_outcomes=[\"IHDINCLUDINGMI_OPTIMALV2\", \"ISCHAEMICSTROKE_V2\", \"MINFARCTION\", \"STROKEUNSPECIFIED_V2\", \"STROKE_HAEMRGIC\"]\n",
    "            case \"hypertension\":\n",
    "                cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\"\n",
    "                cfg.experiment.fine_tune_outcomes=[\"HYPERTENSION\"]\n",
    "                \n",
    "        wandb.finish()\n",
    "        experiment, dm = run(cfg)\n",
    "        print(f\"Loaded model with {sum(p.numel() for p in experiment.model.parameters())/1e6} M parameters\")\n",
    "        wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84b03c-0a55-4c28-8297-c9cd2abe9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for batch in dm.train_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667745b2-e16c-49c4-af81-8545d8eb33ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dm.train_set.view_sample(1, max_dynamic_events=4)\n",
    "\n",
    "display(batch[\"tokens\"][0, :])\n",
    "display(batch[\"target_token\"][0])\n",
    "\n",
    "experiment.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dc5dd-bfe4-4435-9683-250b6dda92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.encode(cfg.experiment.fine_tune_outcomes)\n",
    "display(dm.decode([0]))\n",
    "display(len(list(dm.train_set.tokenizer._event_counts[\"EVENT\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59b00d-f391-4500-9acd-1aa6593577e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e2467-bfc5-47cf-8e26-7a38cc093965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import wandb\n",
    "print(model)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078715e-c1dc-4726-bf06-0d6cba9261fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.encode(['IHDINCLUDINGMI_OPTIMALV2', 'ISCHAEMICSTROKE_V2', 'MINFARCTION', 'STROKEUNSPECIFIED_V2', 'STROKE_HAEMRGIC'])\n",
    "# display(dm.decode([95, 175, 263,249]).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0352a-f7cc-40ea-b456-97f1e59adcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.tokenizer._event_counts[\"EVENT\"][-5:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e044f-4d3a-4c03-a3aa-c460e1ffd662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d7a7c-242a-4ba1-ae98-2a5ac7ed8d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8bb11-e10a-4319-8050-2703af0e4d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644335f-9a9e-49be-963a-6ed1ca22adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/{cfg.experiment.run_id}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2b285-c23f-4fd2-8e66-e20159e8e271",
   "metadata": {},
   "source": [
    "# Load Pre-Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f37089-e294-46c0-bc4a-ce3ae00300b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ckpt_path = cfg.experiment.log_dir + f'checkpoints/{cfg.experiment.run_id}.ckpt'\n",
    "model = SurvivalExperiment.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae57fb-6ca7-4e7f-9b79-b99bb5a10b52",
   "metadata": {},
   "source": [
    "# Initialise fine-tuning data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e90c2f-04c5-4f31-86f0-4f3800fa9325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update dataset path to point to the new dataset \n",
    "cfg.data.path_to_ds = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "\n",
    "# Build \n",
    "dm = FoundationalDataModule(path_to_db=cfg.data.path_to_db,\n",
    "                            path_to_ds=cfg.data.path_to_ds,\n",
    "                            load=True,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            batch_size=cfg.data.batch_size,\n",
    "                            max_seq_length=cfg.transformer.block_size,\n",
    "                            freq_threshold=cfg.data.unk_freq_threshold,\n",
    "                            min_workers=cfg.data.min_workers,\n",
    "                            overwrite_meta_information=cfg.data.meta_information_path,\n",
    "                           )\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "print(f\"{vocab_size} vocab elements\")\n",
    "\n",
    "# list of univariate measurements to model with Normal distribution\n",
    "# Extract the measurements, using the fact that the diagnoses are all up upper case.\n",
    "measurements_for_univariate_regression = [record for record in dm.tokenizer._event_counts[\"EVENT\"] if record.upper() != record]\n",
    "cfg.head.tokens_for_univariate_regression = dm.encode(measurements_for_univariate_regression) \n",
    "# display(measurements_for_univariate_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7a64a-4a5b-4811-847a-5ad8abe04c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # import pickle as pkl\n",
    "# # import pathlib\n",
    "\n",
    "# pkl_file_to_amend = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\"\n",
    "\n",
    "# with open(pkl_file_to_amend, 'rb') as pickle_file:\n",
    "#     content = pickle.load(pickle_file)\n",
    "# display(content)\n",
    "\n",
    "# # new_dictionary = {}\n",
    "# # for key in content.keys():\n",
    "# #     str_to_remove = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/\"\n",
    "# #     new_key = str(key)[len(str_to_remove):]\n",
    "# #     new_dictionary[new_key] = content[key]\n",
    "# # display(new_dictionary)\n",
    "\n",
    "\n",
    "# # with open(pkl_file_to_amend, 'wb') as handle:\n",
    "# #     pickle.dump(new_dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3bd66-0f95-4d0f-9e85-b05bf609037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a45cf-dcbe-4d66-a8fa-34fcc1e4a4de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "start = time.time()   # starting time\n",
    "for batch in dm.train_dataloader():\n",
    "    # print(batch[\"tokens\"][1,:])\n",
    "    \n",
    "    c_batch = convert_batch_to_none_causal(batch)\n",
    "    # print(c_batch[\"tokens\"][1,:])\n",
    "    # print(c_batch[\"target_token\"][1])\n",
    "\n",
    "    # print(batch[\"tokens\"][1,:])\n",
    "    \n",
    "    break\n",
    "    \n",
    "print(f\"batch loaded in {time.time()-start} seconds\")    \n",
    "    \n",
    "# for key in batch.keys():\n",
    "#     print(f\"{key}\".ljust(20) + f\"{batch[key].shape}\")\n",
    "\n",
    "# tokens = batch[\"tokens\"][0].tolist()    \n",
    "# sentence = dm.decode(tokens).split(\" \")\n",
    "# for token, value in zip(sentence, batch[\"values\"][0].tolist()):\n",
    "#     print(f\"{token}:\".ljust(40) + f\"{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4c5b5-2121-4d10-8f8e-11a88ed16cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(batch.keys())\n",
    "display(c_batch.keys())\n",
    "\n",
    "print(batch[\"static_covariates\"].shape)\n",
    "\n",
    "# print(dm.train_set.static_1hot)\n",
    "# print(dm.train_set.static_1hot[\"SEX\"].categories_)\n",
    "# print(dm.train_set.static_1hot[\"IMD\"].categories_)\n",
    "# print(dm.train_set.static_1hot[\"ETHNICITY\"].categories_)\n",
    "\n",
    "print(batch[\"tokens\"][1,:])\n",
    "print(c_batch[\"tokens\"][1,:])\n",
    "print(c_batch[\"target_token\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3e15f-1b7c-466b-825e-a84100d224a0",
   "metadata": {},
   "source": [
    "## View an example sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa22fa-ef08-485f-a948-c4ff8b3aade5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm.test_set.view_sample(11003, max_dynamic_events=None, report_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1943eec-f491-4a94-92d9-65b9cedbd433",
   "metadata": {},
   "source": [
    "# Custom wrapper prediction last token\n",
    "\n",
    "To begin with, I will just loop over samples individually to test the zero-shot capacity of SurvivEHR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439343da-a813-4ffa-b0a6-26074e80d11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Verifying on datamodule \n",
    "for _idx, batch in enumerate(dm.test_dataloader()):\n",
    "    if _idx > 10:\n",
    "        break\n",
    "    print(_idx)\n",
    "    print(torch.stack([batch[\"tokens\"][10,:5], \n",
    "                       batch[\"values\"][10,:5],  \n",
    "                       batch[\"ages\"][10,:5],\n",
    "                       batch[\"attention_mask\"][10,:5]]))\n",
    "    batch = replace_last_non_pad_with_pad(batch)\n",
    "    print(torch.stack([batch[\"tokens\"][10,:5], \n",
    "                       batch[\"values\"][10,:5],  \n",
    "                       batch[\"ages\"][10,:5],\n",
    "                       batch[\"attention_mask\"][10,:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c069ad-f41d-420e-819e-cf2c5a390baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_of_interest = [\"COPD\", \"SUBSTANCEMISUSE\"]\n",
    "outcome_token = dm.encode(outcome_of_interest)[0]\n",
    "print(outcome_token)\n",
    "# print(model(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f35b1-02d3-4db9-b376-ca44d9c1f770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Hs, labels = [], []\n",
    "mins,maxes=[],[]\n",
    "for _idx, batch in enumerate(dm.test_dataloader()):\n",
    "\n",
    "    batch = replace_last_non_pad_with_pad(batch)\n",
    "    print(batch[\"tokens\".shape)\n",
    "    outputs, _, hidden_states = model(batch, is_generation=True)\n",
    "    print(outputs)\n",
    "    \n",
    "    hidden_states = hidden_states.cpu().detach().numpy()                           # (64, 128, 384) \n",
    "    Hs.append( hidden_states.reshape(hidden_states.shape[0], -1) )\n",
    "    labels.append((batch[\"target_token\"] == outcome_token).long().numpy())\n",
    "\n",
    "    if _idx == 9:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bf156-cc66-4276-8c8d-23caec948e2d",
   "metadata": {},
   "source": [
    "# Visualise hidden dimension labelled by target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d857d-dbb0-487b-8278-42c04bcbea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "H = np.concatenate(Hs, 0)\n",
    "lbl = np.concatenate(labels, 0)\n",
    "\n",
    "H = StandardScaler().fit_transform(H)\n",
    "reducer = umap.UMAP()\n",
    "H_proj = reducer.fit_transform(H)\n",
    "\n",
    "plt.close()\n",
    "plt.scatter(H_proj[:,0], H_proj[:,1], c=lbl)\n",
    "plt.savefig(save_path + f\"zero_shot/hidden_umap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e686a-ebe9-43d4-8a14-b88df279ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[\"surv\"][\"surv_CDF\"][outcome_token].shape)\n",
    "\n",
    "# The first two tokens in the vocab correspond to the PAD and UNK tokens. There is no CDF corresponding to the PAD token, so the indexing for surv_CDF begins as [\"UNK\", \"ADDISONS_DISEASE\", ...]\n",
    "# print(dm.decode([0,1,2]))\n",
    "\n",
    "outcomes = [\"COPD\", \"SUBSTANCEMISUSE\"]\n",
    "outcome_tokens = dm.encode(outcomes)\n",
    "\n",
    "# for outcome in outcomes:\n",
    "    # observed_outcome_token = dm.encode([outcome])[0]\n",
    "cdf = np.zeros_like(outputs[\"surv\"][\"surv_CDF\"][0])\n",
    "lbls = np.zeros_like(batch[\"target_token\"])\n",
    "\n",
    "for _outcome_token in outcome_tokens:\n",
    "    cdf += outputs[\"surv\"][\"surv_CDF\"][_outcome_token - 1] \n",
    "    lbls += (batch[\"target_token\"] == _outcome_token).long().numpy()\n",
    "\n",
    "plt.close()\n",
    "cdf_true = cdf[lbls==1,:]\n",
    "cdf_false = cdf[lbls==0,:]\n",
    "for i in range(cdf_true.shape[0]):\n",
    "    plt.plot(np.linspace(1,1826,1826), cdf_true[i,:], c=\"r\", label=\"outcome occurred next\" if i == 0 else None, alpha=1)\n",
    "for i in range(cdf_false.shape[0]):\n",
    "    plt.plot(np.linspace(1,1826,1826), cdf_false[i,:], c=\"k\", label=\"outcome did not occur next\" if i == 0 else None, alpha=0.3)\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"P(t>T) - outcomes={','.join(outcomes)}\")\n",
    "plt.savefig(save_path + f\"zero_shot/cdf_outcomes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c2049-56bc-47ff-bcea-ce2e529266e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[\"target_token\"].unique())\n",
    "print(len(outputs[\"surv\"][\"surv_CDF\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3417a-d3c7-42f9-b288-82ab49ddb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90115137-0805-4f93-877b-2d98e51439d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[\"surv\"][\"surv_CDF\"][observed_outcome_token - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacadcc-f857-45e2-94e8-0ca43ccbd196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
