{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4921342e-8ff8-45d4-b1f6-9fe480c2ee1d",
   "metadata": {},
   "source": [
    "# CPRD Notebook:\n",
    "## Evaluation of fine-tuning the pre-trained SurvivEHR-CR model on a supervised cohort study.\n",
    "\n",
    "Cohort study: predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population.\n",
    "\n",
    "This notebook quantifies the performance obtained when fine-tuning the pre-trained model to a sub-population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a671c59b-4428-4e63-a138-7244418a87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvStreamGPT/notebooks/CompetingRisk/CVD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d866c7f0-eaa8-4129-b3b1-d4d6b504d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n",
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from CPRD.examples.modelling.SurvStreamGPT.run_experiment import run\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "\n",
    "import time\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(10000)\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10000\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")\n",
    "\n",
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c237f8-679a-4fe4-a570-2c8c7b61da9b",
   "metadata": {},
   "source": [
    "# Fine-tuning on full dataset\n",
    "The default configuration is for pre-training. Here we modify as necesssary\n",
    "\n",
    "Here we choose to load in the configuration for a small **pre-trained** 11.4M parameter model, named \"CR_11M\". We specfiy the `fine-tune` experiment type, which will lead to running the ```SupervisedExperiment```. \n",
    "\n",
    "We tell this experiment that we want to perform training (true by default). Additionally, we do choose to perform testing (true by default). As this is a supervised model, this tests the ability to predict the outcomes of interest. In this notebook, this is chosen to be those of the cohort study for predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population, and we add the folder containing this dataset to the configuration. \n",
    "\n",
    "```Note: As this is a supervised dataset, we need to tell the DataModule that the last event observed is a target and must be stripped. This is done by passing a list of targets to the configuration, overriding the null default. This lets the DataModule know that it should process batches as supervised.```\n",
    "\n",
    "We set the number of workers to be appropriate for the number of CPUs available to reduce bottlenecking, and tell the experiment that we do not want to limit the number of testing batches. In addition, we specify where we want any checkpoints to be saved to avoid bloating the repository.\n",
    "\n",
    "We design a new optimisation strategy for fine-tuning. Pre-training was achieved with a warmup and cosine annealing, with rates which are no appropriate for much smaller dataset sizes seen in clinical prediction models (CPMs). We here choose a simpler strategy: of ReduceOnPlateau with no warmup, increasing the number of epochs (default is 1) and reduced validation intervals, and the addition of early stopping. Additionally, as this is not a causal model we can increase the batch size. Finally, as this CPM is not trying to predict the value of any outcomes, we set the value weight to zero allowing the model to focus entirely on optimising survival outcome prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c662c49b-6a1d-4a35-82dc-f00c77d0cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=train/ dataset, with 572,096 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 256\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 3\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: null\n",
      "experiment:\n",
      "  type: fine-tune-cr\n",
      "  project_name: SurvivEHR\n",
      "  run_id: SCRATCH_SWEEP [2, 2, 256]\n",
      "  fine_tune_id: cvd-fine-tune-cr-notebook\n",
      "  train: true\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - IHDINCLUDINGMI_OPTIMALV2\n",
      "  - ISCHAEMICSTROKE_V2\n",
      "  - MINFARCTION\n",
      "  - STROKEUNSPECIFIED_V2\n",
      "  - STROKE_HAEMRGIC\n",
      "  notes: Testing run stopped early\n",
      "optim:\n",
      "  num_epochs: 20\n",
      "  learning_rate: 0.001\n",
      "  scheduler_warmup: false\n",
      "  scheduler: ReduceOnPlateau\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 50\n",
      "  early_stop: true\n",
      "  early_stop_patience: 4\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.035\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 512\n",
      "  n_layer: 2\n",
      "  n_head: 2\n",
      "  n_embd: 256\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 1\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.1\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Fine-tune learning experiment with a new competing-risk head\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating new fine-tuned model from scratch.\n",
      "INFO:root:Running competing-risk fine-tuning experiment with outcomes {'IHDINCLUDINGMI_OPTIMALV2': 95, 'ISCHAEMICSTROKE_V2': 41, 'MINFARCTION': 67, 'STROKEUNSPECIFIED_V2': 65, 'STROKE_HAEMRGIC': 28}\n",
      "INFO:root:Fine-tuning from scratch\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpgqd79t90\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpgqd79t90/_remote_module_non_scriptable.py\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Training all Transformer parameters\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Created Performance metric callback. Calculating metrics for dict_keys([95, 41, 67, 65, 28]) with map {95: 0, 41: 1, 67: 2, 65: 3, 28: 4}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:root:Training model.\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcwlgadd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20250106_222140-1moranhr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/1moranhr\" target=\"_blank\">SCRATCH_SWEEP [2, 2, 256]_cvd-fine-tune-cr-notebook</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvivEHR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:Using ReduceLROnPlateau scheduler\n",
      "INFO:root:Not using warm-up in scheduler\n",
      "\n",
      "  | Name       | Type                            | Params\n",
      "---------------------------------------------------------------\n",
      "0 | model      | SurvStreamGPTForCausalModelling | 1.9 M \n",
      "1 | surv_layer | ODESurvCompetingRiskLayer       | 19.0 K\n",
      "---------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "30        Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.687     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472e636aa258415c8bf9e092f68ce8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.576\n",
      "Epoch 0, global step 50: 'val_loss' reached 0.57608 (best 0.57608), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SCRATCH_SWEEP [2, 2, 256]_cvd-fine-tune-cr-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0. New best score: 0.573\n",
      "Epoch 0, global step 100: 'val_loss' reached 0.57281 (best 0.57281), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SCRATCH_SWEEP [2, 2, 256]_cvd-fine-tune-cr-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0. New best score: 0.564\n",
      "Epoch 0, global step 150: 'val_loss' reached 0.56444 (best 0.56444), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SCRATCH_SWEEP [2, 2, 256]_cvd-fine-tune-cr-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0. New best score: 0.563\n",
      "Epoch 0, global step 200: 'val_loss' reached 0.56272 (best 0.56272), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SCRATCH_SWEEP [2, 2, 256]_cvd-fine-tune-cr-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 250: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 300: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 350: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0. New best score: 0.561\n",
      "Epoch 0, global step 400: 'val_loss' reached 0.56093 (best 0.56093), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SCRATCH_SWEEP [2, 2, 256]_cvd-fine-tune-cr-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 450: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0. New best score: 0.557\n",
      "Epoch 0, global step 500: 'val_loss' reached 0.55715 (best 0.55715), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SCRATCH_SWEEP [2, 2, 256]_cvd-fine-tune-cr-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 550: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 600: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 650: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 4 records. Best score: 0.557. Signaling Trainer to stop.\n",
      "Epoch 0, global step 700: 'val_loss' was not in top 1\n",
      "INFO:root:Re-loading from best cached checkpoint /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SCRATCH_SWEEP [2, 2, 256]_cvd-fine-tune-cr-notebook.ckpt\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Training all Transformer parameters\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Testing model.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c1692cc4c84449b4c7a90ecb937b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">             Test metric             </span>┃<span style=\"font-weight: bold\">            DataLoader 0             </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  Test:OutcomePerformanceMetricsctd  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">         0.6408184766769409          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  Test:OutcomePerformanceMetricsibs  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">         0.03375233585389124         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetricsinbll </span>│<span style=\"color: #800080; text-decoration-color: #800080\">         0.14452052399369753         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">              test_loss              </span>│<span style=\"color: #800080; text-decoration-color: #800080\">         0.5720252394676208          </span>│\n",
       "└─────────────────────────────────────┴─────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m            Test metric            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m           DataLoader 0            \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m Test:OutcomePerformanceMetricsctd \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        0.6408184766769409         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m Test:OutcomePerformanceMetricsibs \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        0.03375233585389124        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetricsinbll\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        0.14452052399369753        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m             test_loss             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        0.5720252394676208         \u001b[0m\u001b[35m \u001b[0m│\n",
       "└─────────────────────────────────────┴─────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 1.921646 M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1a9bbbecd1497dba2095496e72a4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='19.185 MB of 19.220 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9981…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>▁</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>▁▂▄▇▆▃▅▆▇█▅▅▂▁</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>█▄▅▃▄▅▅▃▂▁▄▂▅▅</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>█▄▄▃▄▅▅▃▁▁▄▂▄▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>▆▅▃▆▅▆▅▁▂▄▅▃▅▄▄▄▁▄▃▄▅▄▄▆▃▄▂▄█▃▃▄▂▆▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▇▇█████████████████████████</td></tr><tr><td>val_loss</td><td>█▇▄▃▆▃▇▂▄▁▃▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>0.001</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>0.64082</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>0.03375</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>0.14452</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>0.62932</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>0.0364</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>0.15587</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>test_loss</td><td>0.57203</td></tr><tr><td>train_loss</td><td>0.52162</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_loss</td><td>0.56393</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SCRATCH_SWEEP [2, 2, 256]_cvd-fine-tune-cr-notebook</strong>: <a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/1moranhr\" target=\"_blank\">https://wandb.ai/cwlgadd/SurvivEHR/runs/1moranhr</a><br/>Synced 5 W&B file(s), 156 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20250106_222140-1moranhr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_trained_model_ids = ['SurvivEHR-cr-small', 'SurvivEHR-cr-small-v1', 'SurvivEHR-cr', 'SurvivEHR-cr-v1', 'SurvivEHR-cr-v1-v1', 'SurvivEHR-cr-384', 'SurvivEHR-cr-384-v1',]\n",
    "# pre_trained_models = ['SurvivEHR-cr-v1-v1', ] # SurvivEHR-cr-small  notebook-test3 [\"\"]   # , \"NULL-CR\" \"CR_11M_24_11_01_big_posencscale_\"\n",
    "experiments = [\"cvd\"] #, \"hypertension\"] \n",
    "experiment_types = [\"fine-tune-cr\"]#, \"fine-tune-sr\"]\n",
    "\n",
    "sweep = [#[1, 6, 126], \n",
    "         #[6, 1, 128], \n",
    "         #[1, 6, 384],\n",
    "         #[6, 1, 384],\n",
    "         [2, 2, 256]\n",
    "        ]\n",
    "names = ['SCRATCH_SWEEP ' + str(i) for i in sweep]\n",
    "\n",
    "# for pre_trained_model in pre_trained_model_ids[0:1]:\n",
    "for sweep_i in range(len(sweep)):\n",
    "    pre_trained_model = names[sweep_i]\n",
    "\n",
    "    for experiment in experiments:\n",
    "    \n",
    "        for experiment_type in experiment_types:\n",
    "\n",
    "            wandb.finish()\n",
    "            # load the configuration file, override any settings \n",
    "            with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "                cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                              overrides=[# Experiment setup\n",
    "                                         f\"experiment.type='{experiment_type}'\",\n",
    "                                         f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                                         f\"experiment.fine_tune_id='{experiment}-{experiment_type}-notebook'\",\n",
    "                                         \"experiment.train=True\",\n",
    "                                         \"experiment.test=True\",\n",
    "                                         \"experiment.notes=Testing run stopped early\",\n",
    "                                         # Dataloader\n",
    "                                         \"data.batch_size=256\",\n",
    "                                         \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                                         \"data.min_workers=3\",\n",
    "                                         # Optimiser\n",
    "                                         \"optim.num_epochs=20\",\n",
    "                                         \"optim.limit_test_batches=null\",\n",
    "                                         \"optim.scheduler=ReduceOnPlateau\",\n",
    "                                         \"optim.scheduler_warmup=False\",\n",
    "                                         \"optim.learning_rate=1e-3\",\n",
    "                                         \"optim.val_check_interval=50\",\n",
    "                                         \"optim.early_stop=True\",\n",
    "                                         \"optim.early_stop_patience=4\",\n",
    "                                         \"optim.limit_val_batches=0.035\",\n",
    "                                         # Model\n",
    "                                         f\"transformer.n_layer={sweep[sweep_i][0]}\",  # 2, 1, 1, 6,\n",
    "                                         f\"transformer.n_head={sweep[sweep_i][1]}\", # 2, 6, 6, 1,\n",
    "                                         f\"transformer.n_embd={sweep[sweep_i][2]}\", # 128, 384, 126. 128\n",
    "                                         \"transformer.block_size=512\", # 512, 512\n",
    "                                         # \"transformer.n_embd=1024\",\n",
    "                                        ]\n",
    "                             )\n",
    "            \n",
    "            \n",
    "            match experiment.lower():\n",
    "                case \"cvd\":\n",
    "                    cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "                    cfg.experiment.fine_tune_outcomes=[\"IHDINCLUDINGMI_OPTIMALV2\", \"ISCHAEMICSTROKE_V2\", \"MINFARCTION\", \"STROKEUNSPECIFIED_V2\", \"STROKE_HAEMRGIC\"]\n",
    "                case \"hypertension\":\n",
    "                    cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\"\n",
    "                    cfg.experiment.fine_tune_outcomes=[\"HYPERTENSION\"]\n",
    "            \n",
    "            \n",
    "            model, dm = run(cfg)\n",
    "            print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "            wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65799ee6-9462-42a0-a293-dd4cac545d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "# [_i if _i == _i.upper() else 0 for _i in dm.train_set.tokenizer._stoi.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62557fe3-6772-411b-b16a-14edc0d366de",
   "metadata": {},
   "source": [
    "# Fine-tuning on sub-set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4b72e2-a938-46b0-aea4-f56517283a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=train/ dataset, with 3,000 subsamples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 256\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: 3000\n",
      "experiment:\n",
      "  type: fine-tune-sr\n",
      "  project_name: SurvivEHR\n",
      "  run_id: CR_11M_24_11_01_big_posencscale_\n",
      "  fine_tune_id: cvd-fine-tune-sr-3000-notebook\n",
      "  train: true\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - IHDINCLUDINGMI_OPTIMALV2\n",
      "  - ISCHAEMICSTROKE_V2\n",
      "  - MINFARCTION\n",
      "  - STROKEUNSPECIFIED_V2\n",
      "  - STROKE_HAEMRGIC\n",
      "optim:\n",
      "  num_epochs: 500\n",
      "  learning_rate: 0.001\n",
      "  scheduler_warmup: false\n",
      "  scheduler: ReduceOnPlateau\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 1.0\n",
      "  early_stop: true\n",
      "  early_stop_patience: 1\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.25\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 10\n",
      "  n_head: 8\n",
      "  n_embd: 1024\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.5\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Fine-tune learning experiment with a new single-risk head\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating new fine-tuned model at the path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt.\n",
      "INFO:root:This is trained from a checkpointed pre-trained causal experiment, which can be found at /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:root:Running single-risk fine-tuning experiment with outcomes {'IHDINCLUDINGMI_OPTIMALV2': 95, 'ISCHAEMICSTROKE_V2': 41, 'MINFARCTION': 67, 'STROKEUNSPECIFIED_V2': 65, 'STROKE_HAEMRGIC': 28}\n",
      "INFO:root:Loading pre-trained model from checkpoint from /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp99wbqth0\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp99wbqth0/_remote_module_non_scriptable.py\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:173: Found keys that are in the model state dict but not in the checkpoint: ['surv_layer.sr_ode.net.u', 'surv_layer.sr_ode.net.w', 'surv_layer.sr_ode.net.BaseNet.mapping.0.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.0.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.2.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.2.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.4.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.4.bias']\n",
      "INFO:root:Created Performance metric callback. Calculating metrics for dict_keys([95, 41, 67, 65, 28]) with map {95: 0, 41: 0, 67: 0, 65: 0, 28: 0}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "INFO:root:Training model.\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcwlgadd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_114936-ojd6hrts</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/ojd6hrts\" target=\"_blank\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook_b</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvivEHR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:Using ReduceLROnPlateau scheduler\n",
      "INFO:root:Not using warm-up in scheduler\n",
      "\n",
      "  | Name       | Type                            | Params\n",
      "---------------------------------------------------------------\n",
      "0 | model      | SurvStreamGPTForCausalModelling | 129 M \n",
      "1 | surv_layer | ODESurvSingleRiskLayer          | 34.0 K\n",
      "2 | dropout    | Dropout                         | 0     \n",
      "---------------------------------------------------------------\n",
      "33.9 K    Trainable params\n",
      "129 M     Non-trainable params\n",
      "129 M     Total params\n",
      "517.561   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf381ef84964047b74237f8c21b3ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:377: ReduceLROnPlateau conditioned on metric val_loss which is not available but strict is set to `False`. Skipping learning rate update.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.806\n",
      "Epoch 0, global step 12: 'val_loss' reached 0.80616 (best 0.80616), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.297 >= min_delta = 0. New best score: 0.509\n",
      "Epoch 1, global step 24: 'val_loss' reached 0.50874 (best 0.50874), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.119 >= min_delta = 0. New best score: 0.389\n",
      "Epoch 2, global step 36: 'val_loss' reached 0.38925 (best 0.38925), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0. New best score: 0.387\n",
      "Epoch 3, global step 48: 'val_loss' reached 0.38666 (best 0.38666), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0. New best score: 0.377\n",
      "Epoch 4, global step 60: 'val_loss' reached 0.37741 (best 0.37741), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0. New best score: 0.375\n",
      "Epoch 5, global step 72: 'val_loss' reached 0.37466 (best 0.37466), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0. New best score: 0.372\n",
      "Epoch 6, global step 84: 'val_loss' reached 0.37205 (best 0.37205), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0. New best score: 0.370\n",
      "Epoch 7, global step 96: 'val_loss' reached 0.37037 (best 0.37037), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.369\n",
      "Epoch 8, global step 108: 'val_loss' reached 0.36922 (best 0.36922), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.368\n",
      "Epoch 9, global step 120: 'val_loss' reached 0.36843 (best 0.36843), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.368\n",
      "Epoch 10, global step 132: 'val_loss' reached 0.36785 (best 0.36785), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.367\n",
      "Epoch 11, global step 144: 'val_loss' reached 0.36694 (best 0.36694), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.366\n",
      "Epoch 12, global step 156: 'val_loss' reached 0.36631 (best 0.36631), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.366\n",
      "Epoch 13, global step 168: 'val_loss' reached 0.36570 (best 0.36570), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.365\n",
      "Epoch 14, global step 180: 'val_loss' reached 0.36515 (best 0.36515), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.365\n",
      "Epoch 15, global step 192: 'val_loss' reached 0.36482 (best 0.36482), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.365\n",
      "Epoch 16, global step 204: 'val_loss' reached 0.36458 (best 0.36458), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.364\n",
      "Epoch 17, global step 216: 'val_loss' reached 0.36408 (best 0.36408), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.364\n",
      "Epoch 18, global step 228: 'val_loss' reached 0.36366 (best 0.36366), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.363\n",
      "Epoch 19, global step 240: 'val_loss' reached 0.36349 (best 0.36349), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.363\n",
      "Epoch 20, global step 252: 'val_loss' reached 0.36334 (best 0.36334), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.363\n",
      "Epoch 21, global step 264: 'val_loss' reached 0.36324 (best 0.36324), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.363\n",
      "Epoch 22, global step 276: 'val_loss' reached 0.36300 (best 0.36300), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.363\n",
      "Epoch 23, global step 288: 'val_loss' reached 0.36297 (best 0.36297), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 0.363. Signaling Trainer to stop.\n",
      "Epoch 24, global step 300: 'val_loss' was not in top 1\n",
      "INFO:root:Re-loading from best cached checkpoint /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook.ckpt\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "INFO:root:Testing model.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb4468b4a94418682ce0aff1b22d692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                      Test metric                       </span>┃<span style=\"font-weight: bold\">                      DataLoader 0                      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6092104911804199                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.033816332642146466                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    Test:OutcomePerformanceMetrics_[95, 41, 67, 65,     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.14566626866403257                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                        28]inbll                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsctd            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6092104911804199                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsibs            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.033816332642146466                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          Test:OutcomePerformanceMetricsinbll           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.14566626866403257                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                       test_loss                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.42075619101524353                   </span>│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                     Test metric                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                     DataLoader 0                     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6092104911804199                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.033816332642146466                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   Test:OutcomePerformanceMetrics_[95, 41, 67, 65,    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.14566626866403257                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                       28]inbll                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m                                                        \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsctd           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6092104911804199                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsibs           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.033816332642146466                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         Test:OutcomePerformanceMetricsinbll          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.14566626866403257                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                      test_loss                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.42075619101524353                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 129.390253 M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>██████████████▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁▁▁▁▁▂▃▄▄▅▅▆▆▆▇▇▇▇▇██████</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>▁▁▁▁▁▂▃▄▄▅▅▆▆▆▇▇▇▇▇██████</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▂▄▃▅▄▃▁▃▃▃▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▂▃▄▅▆██████████████████████████████████</td></tr><tr><td>val_loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>0.0009</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.60921</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03382</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.14567</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>0.60921</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>0.03382</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>0.14567</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.60929</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03269</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.14184</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>0.60929</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>0.03269</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>0.14184</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>test_loss</td><td>0.42076</td></tr><tr><td>train_loss</td><td>0.34278</td></tr><tr><td>trainer/global_step</td><td>300</td></tr><tr><td>val_loss</td><td>0.36451</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-3000-notebook_b</strong>: <a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/ojd6hrts\" target=\"_blank\">https://wandb.ai/cwlgadd/SurvivEHR/runs/ojd6hrts</a><br/>Synced 5 W&B file(s), 280 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_114936-ojd6hrts/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=train/ dataset, with 12,500 subsamples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 256\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: 12500\n",
      "experiment:\n",
      "  type: fine-tune-sr\n",
      "  project_name: SurvivEHR\n",
      "  run_id: CR_11M_24_11_01_big_posencscale_\n",
      "  fine_tune_id: cvd-fine-tune-sr-12500-notebook\n",
      "  train: true\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - IHDINCLUDINGMI_OPTIMALV2\n",
      "  - ISCHAEMICSTROKE_V2\n",
      "  - MINFARCTION\n",
      "  - STROKEUNSPECIFIED_V2\n",
      "  - STROKE_HAEMRGIC\n",
      "optim:\n",
      "  num_epochs: 500\n",
      "  learning_rate: 0.001\n",
      "  scheduler_warmup: false\n",
      "  scheduler: ReduceOnPlateau\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 1.0\n",
      "  early_stop: true\n",
      "  early_stop_patience: 1\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.25\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 10\n",
      "  n_head: 8\n",
      "  n_embd: 1024\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.5\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Fine-tune learning experiment with a new single-risk head\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating new fine-tuned model at the path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook.ckpt.\n",
      "INFO:root:This is trained from a checkpointed pre-trained causal experiment, which can be found at /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:root:Running single-risk fine-tuning experiment with outcomes {'IHDINCLUDINGMI_OPTIMALV2': 95, 'ISCHAEMICSTROKE_V2': 41, 'MINFARCTION': 67, 'STROKEUNSPECIFIED_V2': 65, 'STROKE_HAEMRGIC': 28}\n",
      "INFO:root:Loading pre-trained model from checkpoint from /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:173: Found keys that are in the model state dict but not in the checkpoint: ['surv_layer.sr_ode.net.u', 'surv_layer.sr_ode.net.w', 'surv_layer.sr_ode.net.BaseNet.mapping.0.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.0.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.2.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.2.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.4.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.4.bias']\n",
      "INFO:root:Created Performance metric callback. Calculating metrics for dict_keys([95, 41, 67, 65, 28]) with map {95: 0, 41: 0, 67: 0, 65: 0, 28: 0}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "INFO:root:Training model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79ff61340364dde9b3520fd4265c8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016667957014093796, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_124614-39749qjo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/39749qjo\" target=\"_blank\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook_b</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvivEHR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:Using ReduceLROnPlateau scheduler\n",
      "INFO:root:Not using warm-up in scheduler\n",
      "\n",
      "  | Name       | Type                            | Params\n",
      "---------------------------------------------------------------\n",
      "0 | model      | SurvStreamGPTForCausalModelling | 129 M \n",
      "1 | surv_layer | ODESurvSingleRiskLayer          | 34.0 K\n",
      "2 | dropout    | Dropout                         | 0     \n",
      "---------------------------------------------------------------\n",
      "33.9 K    Trainable params\n",
      "129 M     Non-trainable params\n",
      "129 M     Total params\n",
      "517.561   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286e30a392354672aaaf9d1a50260efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:377: ReduceLROnPlateau conditioned on metric val_loss which is not available but strict is set to `False`. Skipping learning rate update.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.379\n",
      "Epoch 0, global step 49: 'val_loss' reached 0.37908 (best 0.37908), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0. New best score: 0.371\n",
      "Epoch 1, global step 98: 'val_loss' reached 0.37114 (best 0.37114), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.370\n",
      "Epoch 2, global step 147: 'val_loss' reached 0.36976 (best 0.36976), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0. New best score: 0.366\n",
      "Epoch 3, global step 196: 'val_loss' reached 0.36601 (best 0.36601), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.365\n",
      "Epoch 4, global step 245: 'val_loss' reached 0.36529 (best 0.36529), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.365\n",
      "Epoch 5, global step 294: 'val_loss' reached 0.36509 (best 0.36509), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.364\n",
      "Epoch 6, global step 343: 'val_loss' reached 0.36402 (best 0.36402), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 0.364. Signaling Trainer to stop.\n",
      "Epoch 7, global step 392: 'val_loss' was not in top 1\n",
      "INFO:root:Re-loading from best cached checkpoint /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook.ckpt\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "INFO:root:Testing model.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdc60cff3404c05bc6632bf02833c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                      Test metric                       </span>┃<span style=\"font-weight: bold\">                      DataLoader 0                      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6083229780197144                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.033932704061261414                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    Test:OutcomePerformanceMetrics_[95, 41, 67, 65,     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.1465910466560025                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                        28]inbll                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsctd            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6083229780197144                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsibs            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.033932704061261414                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          Test:OutcomePerformanceMetricsinbll           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.1465910466560025                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                       test_loss                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.42045852541923523                   </span>│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                     Test metric                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                     DataLoader 0                     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6083229780197144                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.033932704061261414                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   Test:OutcomePerformanceMetrics_[95, 41, 67, 65,    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.1465910466560025                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                       28]inbll                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m                                                        \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsctd           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6083229780197144                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsibs           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.033932704061261414                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         Test:OutcomePerformanceMetricsinbll          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.1465910466560025                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                      test_loss                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.42045852541923523                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 129.390253 M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>███▇▆▅▅▅▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁▅▇▇████</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>█▅▄▂▂▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>▁▅▇▇████</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>█▅▄▂▂▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▄▂▃▅▅▆▃█▄▄▆▁▂▂▃▅▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▄▅▆███████████████████████████████████</td></tr><tr><td>val_loss</td><td>█▄▄▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>0.00025</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.60832</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03393</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.14659</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>0.60832</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>0.03393</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>0.14659</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.61829</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03268</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.14189</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>0.61829</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>0.03268</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>0.14189</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>test_loss</td><td>0.42046</td></tr><tr><td>train_loss</td><td>0.45205</td></tr><tr><td>trainer/global_step</td><td>392</td></tr><tr><td>val_loss</td><td>0.36412</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-12500-notebook_b</strong>: <a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/39749qjo\" target=\"_blank\">https://wandb.ai/cwlgadd/SurvivEHR/runs/39749qjo</a><br/>Synced 5 W&B file(s), 280 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_124614-39749qjo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=train/ dataset, with 30,000 subsamples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 256\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: 30000\n",
      "experiment:\n",
      "  type: fine-tune-sr\n",
      "  project_name: SurvivEHR\n",
      "  run_id: CR_11M_24_11_01_big_posencscale_\n",
      "  fine_tune_id: cvd-fine-tune-sr-30000-notebook\n",
      "  train: true\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - IHDINCLUDINGMI_OPTIMALV2\n",
      "  - ISCHAEMICSTROKE_V2\n",
      "  - MINFARCTION\n",
      "  - STROKEUNSPECIFIED_V2\n",
      "  - STROKE_HAEMRGIC\n",
      "optim:\n",
      "  num_epochs: 500\n",
      "  learning_rate: 0.001\n",
      "  scheduler_warmup: false\n",
      "  scheduler: ReduceOnPlateau\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 1.0\n",
      "  early_stop: true\n",
      "  early_stop_patience: 1\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.25\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 10\n",
      "  n_head: 8\n",
      "  n_embd: 1024\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.5\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Fine-tune learning experiment with a new single-risk head\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating new fine-tuned model at the path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-30000-notebook.ckpt.\n",
      "INFO:root:This is trained from a checkpointed pre-trained causal experiment, which can be found at /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:root:Running single-risk fine-tuning experiment with outcomes {'IHDINCLUDINGMI_OPTIMALV2': 95, 'ISCHAEMICSTROKE_V2': 41, 'MINFARCTION': 67, 'STROKEUNSPECIFIED_V2': 65, 'STROKE_HAEMRGIC': 28}\n",
      "INFO:root:Loading pre-trained model from checkpoint from /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:173: Found keys that are in the model state dict but not in the checkpoint: ['surv_layer.sr_ode.net.u', 'surv_layer.sr_ode.net.w', 'surv_layer.sr_ode.net.BaseNet.mapping.0.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.0.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.2.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.2.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.4.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.4.bias']\n",
      "INFO:root:Created Performance metric callback. Calculating metrics for dict_keys([95, 41, 67, 65, 28]) with map {95: 0, 41: 0, 67: 0, 65: 0, 28: 0}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "INFO:root:Training model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_131523-1asrbh7y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/1asrbh7y\" target=\"_blank\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-30000-notebook_b</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvivEHR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:Using ReduceLROnPlateau scheduler\n",
      "INFO:root:Not using warm-up in scheduler\n",
      "\n",
      "  | Name       | Type                            | Params\n",
      "---------------------------------------------------------------\n",
      "0 | model      | SurvStreamGPTForCausalModelling | 129 M \n",
      "1 | surv_layer | ODESurvSingleRiskLayer          | 34.0 K\n",
      "2 | dropout    | Dropout                         | 0     \n",
      "---------------------------------------------------------------\n",
      "33.9 K    Trainable params\n",
      "129 M     Non-trainable params\n",
      "129 M     Total params\n",
      "517.561   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d5e4b12f9f46a9aafe03178f673182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:377: ReduceLROnPlateau conditioned on metric val_loss which is not available but strict is set to `False`. Skipping learning rate update.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.365\n",
      "Epoch 0, global step 118: 'val_loss' reached 0.36508 (best 0.36508), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-30000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0. New best score: 0.361\n",
      "Epoch 1, global step 236: 'val_loss' reached 0.36093 (best 0.36093), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-30000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 0.361. Signaling Trainer to stop.\n",
      "Epoch 2, global step 354: 'val_loss' was not in top 1\n",
      "INFO:root:Re-loading from best cached checkpoint /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-30000-notebook.ckpt\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "INFO:root:Testing model.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ed08fd556042038c50e99a826299ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                      Test metric                       </span>┃<span style=\"font-weight: bold\">                      DataLoader 0                      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6174553036689758                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.033808206963263115                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    Test:OutcomePerformanceMetrics_[95, 41, 67, 65,     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.14558040658406715                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                        28]inbll                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsctd            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6174553036689758                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsibs            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.033808206963263115                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          Test:OutcomePerformanceMetricsinbll           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.14558040658406715                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                       test_loss                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4184417426586151                   </span>│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                     Test metric                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                     DataLoader 0                     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6174553036689758                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.033808206963263115                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   Test:OutcomePerformanceMetrics_[95, 41, 67, 65,    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.14558040658406715                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                       28]inbll                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m                                                        \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsctd           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6174553036689758                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsibs           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.033808206963263115                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         Test:OutcomePerformanceMetricsinbll          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.14558040658406715                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                      test_loss                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4184417426586151                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 129.390253 M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>██████▇▇▆▅▄▃▃▂▁▁▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁▇█</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>█▁▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>█▂▁</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>▁▇█</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>█▁▁</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>█▂▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▃▃▃▃▃▃▃▆▆▆▆▆▆▆█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▂▄▄▂▄▂▂▃▁▂▂▁▃▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▃▅▆████████████████████████████████████</td></tr><tr><td>val_loss</td><td>█▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>0.00039</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.61746</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03381</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.14558</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>0.61746</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>0.03381</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>0.14558</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.63149</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03257</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.14069</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>0.63149</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>0.03257</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>0.14069</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>test_loss</td><td>0.41844</td></tr><tr><td>train_loss</td><td>0.42585</td></tr><tr><td>trainer/global_step</td><td>354</td></tr><tr><td>val_loss</td><td>0.36155</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-30000-notebook_b</strong>: <a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/1asrbh7y\" target=\"_blank\">https://wandb.ai/cwlgadd/SurvivEHR/runs/1asrbh7y</a><br/>Synced 5 W&B file(s), 280 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_131523-1asrbh7y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=train/ dataset, with 60,000 subsamples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 256\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: 60000\n",
      "experiment:\n",
      "  type: fine-tune-sr\n",
      "  project_name: SurvivEHR\n",
      "  run_id: CR_11M_24_11_01_big_posencscale_\n",
      "  fine_tune_id: cvd-fine-tune-sr-60000-notebook\n",
      "  train: true\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - IHDINCLUDINGMI_OPTIMALV2\n",
      "  - ISCHAEMICSTROKE_V2\n",
      "  - MINFARCTION\n",
      "  - STROKEUNSPECIFIED_V2\n",
      "  - STROKE_HAEMRGIC\n",
      "optim:\n",
      "  num_epochs: 500\n",
      "  learning_rate: 0.001\n",
      "  scheduler_warmup: false\n",
      "  scheduler: ReduceOnPlateau\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 1.0\n",
      "  early_stop: true\n",
      "  early_stop_patience: 1\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.25\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 10\n",
      "  n_head: 8\n",
      "  n_embd: 1024\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.5\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Fine-tune learning experiment with a new single-risk head\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating new fine-tuned model at the path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-60000-notebook.ckpt.\n",
      "INFO:root:This is trained from a checkpointed pre-trained causal experiment, which can be found at /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:root:Running single-risk fine-tuning experiment with outcomes {'IHDINCLUDINGMI_OPTIMALV2': 95, 'ISCHAEMICSTROKE_V2': 41, 'MINFARCTION': 67, 'STROKEUNSPECIFIED_V2': 65, 'STROKE_HAEMRGIC': 28}\n",
      "INFO:root:Loading pre-trained model from checkpoint from /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:173: Found keys that are in the model state dict but not in the checkpoint: ['surv_layer.sr_ode.net.u', 'surv_layer.sr_ode.net.w', 'surv_layer.sr_ode.net.BaseNet.mapping.0.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.0.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.2.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.2.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.4.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.4.bias']\n",
      "INFO:root:Created Performance metric callback. Calculating metrics for dict_keys([95, 41, 67, 65, 28]) with map {95: 0, 41: 0, 67: 0, 65: 0, 28: 0}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "INFO:root:Training model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_133520-rzq8jh14</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/rzq8jh14\" target=\"_blank\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-60000-notebook_b</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvivEHR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:Using ReduceLROnPlateau scheduler\n",
      "INFO:root:Not using warm-up in scheduler\n",
      "\n",
      "  | Name       | Type                            | Params\n",
      "---------------------------------------------------------------\n",
      "0 | model      | SurvStreamGPTForCausalModelling | 129 M \n",
      "1 | surv_layer | ODESurvSingleRiskLayer          | 34.0 K\n",
      "2 | dropout    | Dropout                         | 0     \n",
      "---------------------------------------------------------------\n",
      "33.9 K    Trainable params\n",
      "129 M     Non-trainable params\n",
      "129 M     Total params\n",
      "517.561   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9be4372ba8475b86c34012d2bb71bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:377: ReduceLROnPlateau conditioned on metric val_loss which is not available but strict is set to `False`. Skipping learning rate update.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.363\n",
      "Epoch 0, global step 235: 'val_loss' reached 0.36254 (best 0.36254), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-60000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0. New best score: 0.360\n",
      "Epoch 1, global step 470: 'val_loss' reached 0.36030 (best 0.36030), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-60000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.360\n",
      "Epoch 2, global step 705: 'val_loss' reached 0.36006 (best 0.36006), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-60000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.360\n",
      "Epoch 3, global step 940: 'val_loss' reached 0.35968 (best 0.35968), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-60000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.359\n",
      "Epoch 4, global step 1175: 'val_loss' reached 0.35910 (best 0.35910), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-60000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 0.359. Signaling Trainer to stop.\n",
      "Epoch 5, global step 1410: 'val_loss' was not in top 1\n",
      "INFO:root:Re-loading from best cached checkpoint /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-60000-notebook.ckpt\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "INFO:root:Testing model.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ea624485584f888035b7b03f296b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                      Test metric                       </span>┃<span style=\"font-weight: bold\">                      DataLoader 0                      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.631834864616394                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.03375763517456973                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    Test:OutcomePerformanceMetrics_[95, 41, 67, 65,     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.1448311489044284                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                        28]inbll                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsctd            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.631834864616394                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsibs            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.03375763517456973                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          Test:OutcomePerformanceMetricsinbll           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.1448311489044284                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                       test_loss                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4154930114746094                   </span>│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                     Test metric                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                     DataLoader 0                     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.631834864616394                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.03375763517456973                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   Test:OutcomePerformanceMetrics_[95, 41, 67, 65,    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.1448311489044284                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                       28]inbll                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m                                                        \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsctd           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.631834864616394                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsibs           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.03375763517456973                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         Test:OutcomePerformanceMetricsinbll          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.1448311489044284                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                      test_loss                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4154930114746094                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 129.390253 M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>███████▇▆▅▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁▆▇███</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>█▃▂▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>█▃▂▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>▁▆▇███</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>█▃▂▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>█▃▂▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▃▃▄▂▃▄▃▃▂▃▄▂▂▃▃▂▃▂▃▃▄▁▂▂▃▃▅▃▄▄▂▄▂▁▃▃▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▃▃▄▄▅▅▆▆▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>█▃▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>0.0001</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.63183</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03376</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.14483</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>0.63183</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>0.03376</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>0.14483</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.63925</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03252</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.14004</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>0.63925</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>0.03252</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>0.14004</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>test_loss</td><td>0.41549</td></tr><tr><td>train_loss</td><td>0.4547</td></tr><tr><td>trainer/global_step</td><td>1410</td></tr><tr><td>val_loss</td><td>0.35963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-60000-notebook_b</strong>: <a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/rzq8jh14\" target=\"_blank\">https://wandb.ai/cwlgadd/SurvivEHR/runs/rzq8jh14</a><br/>Synced 5 W&B file(s), 280 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_133520-rzq8jh14/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=train/ dataset, with 100,000 subsamples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=test/ dataset, with 35,758 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/ dataset, with 33,280 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 256\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: 100000\n",
      "experiment:\n",
      "  type: fine-tune-sr\n",
      "  project_name: SurvivEHR\n",
      "  run_id: CR_11M_24_11_01_big_posencscale_\n",
      "  fine_tune_id: cvd-fine-tune-sr-100000-notebook\n",
      "  train: true\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes:\n",
      "  - IHDINCLUDINGMI_OPTIMALV2\n",
      "  - ISCHAEMICSTROKE_V2\n",
      "  - MINFARCTION\n",
      "  - STROKEUNSPECIFIED_V2\n",
      "  - STROKE_HAEMRGIC\n",
      "optim:\n",
      "  num_epochs: 500\n",
      "  learning_rate: 0.001\n",
      "  scheduler_warmup: false\n",
      "  scheduler: ReduceOnPlateau\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 1.0\n",
      "  early_stop: true\n",
      "  early_stop_patience: 1\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.25\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 10\n",
      "  n_head: 8\n",
      "  n_embd: 1024\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.5\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Fine-tune learning experiment with a new single-risk head\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating new fine-tuned model at the path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-100000-notebook.ckpt.\n",
      "INFO:root:This is trained from a checkpointed pre-trained causal experiment, which can be found at /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:root:Running single-risk fine-tuning experiment with outcomes {'IHDINCLUDINGMI_OPTIMALV2': 95, 'ISCHAEMICSTROKE_V2': 41, 'MINFARCTION': 67, 'STROKEUNSPECIFIED_V2': 65, 'STROKE_HAEMRGIC': 28}\n",
      "INFO:root:Loading pre-trained model from checkpoint from /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale_.ckpt.\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:173: Found keys that are in the model state dict but not in the checkpoint: ['surv_layer.sr_ode.net.u', 'surv_layer.sr_ode.net.w', 'surv_layer.sr_ode.net.BaseNet.mapping.0.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.0.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.2.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.2.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.4.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.4.bias']\n",
      "INFO:root:Created Performance metric callback. Calculating metrics for dict_keys([95, 41, 67, 65, 28]) with map {95: 0, 41: 0, 67: 0, 65: 0, 28: 0}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "INFO:root:Training model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add7a99631744bf9b877ce3e3b0f8189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666790993573765, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_141944-1b2j0ios</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/1b2j0ios\" target=\"_blank\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-100000-notebook_b</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvivEHR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:Using ReduceLROnPlateau scheduler\n",
      "INFO:root:Not using warm-up in scheduler\n",
      "\n",
      "  | Name       | Type                            | Params\n",
      "---------------------------------------------------------------\n",
      "0 | model      | SurvStreamGPTForCausalModelling | 129 M \n",
      "1 | surv_layer | ODESurvSingleRiskLayer          | 34.0 K\n",
      "2 | dropout    | Dropout                         | 0     \n",
      "---------------------------------------------------------------\n",
      "33.9 K    Trainable params\n",
      "129 M     Non-trainable params\n",
      "129 M     Total params\n",
      "517.561   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa0f3ebdf53498e957cbd4f138fe380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:377: ReduceLROnPlateau conditioned on metric val_loss which is not available but strict is set to `False`. Skipping learning rate update.\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.359\n",
      "Epoch 0, global step 391: 'val_loss' reached 0.35935 (best 0.35935), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-100000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.359\n",
      "Epoch 1, global step 782: 'val_loss' reached 0.35934 (best 0.35934), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-100000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0. New best score: 0.359\n",
      "Epoch 2, global step 1173: 'val_loss' reached 0.35855 (best 0.35855), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-100000-notebook.ckpt' as top 1\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0. New best score: 0.358\n",
      "Epoch 3, global step 1564: 'val_loss' reached 0.35836 (best 0.35836), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-100000-notebook.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 0.358. Signaling Trainer to stop.\n",
      "Epoch 4, global step 1955: 'val_loss' was not in top 1\n",
      "INFO:root:Re-loading from best cached checkpoint /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-100000-notebook.ckpt\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Fixing Transformer parameters and training only new head.\n",
      "INFO:root:Testing model.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afd13ebda8b4400b4f105de543c3059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                      Test metric                       </span>┃<span style=\"font-weight: bold\">                      DataLoader 0                      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6391314268112183                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.033719895578714465                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    Test:OutcomePerformanceMetrics_[95, 41, 67, 65,     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.14433881325377276                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                        28]inbll                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsctd            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6391314268112183                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           Test:OutcomePerformanceMetricsibs            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.033719895578714465                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          Test:OutcomePerformanceMetricsinbll           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.14433881325377276                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                       test_loss                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4141594171524048                   </span>│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                     Test metric                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                     DataLoader 0                     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6391314268112183                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTest:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.033719895578714465                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   Test:OutcomePerformanceMetrics_[95, 41, 67, 65,    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.14433881325377276                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                       28]inbll                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m                                                        \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsctd           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6391314268112183                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          Test:OutcomePerformanceMetricsibs           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.033719895578714465                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         Test:OutcomePerformanceMetricsinbll          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.14433881325377276                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                      test_loss                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4141594171524048                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 129.390253 M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>█████████▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>▁</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>▁▆▇██</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>█▃▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>█▃▂▂▁</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>▁▆▇██</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>█▃▁▁▁</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>█▃▂▂▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▄▂▃▁▃▂▂▂▃▂▃▂▄▃▃▄▂▂▃▂▃▅▂▄▃▄▄▂▄▃▃▄▂▂▄▂▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▇▇▇████████████████████████</td></tr><tr><td>val_loss</td><td>██▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Scheduler</td><td>0.0001</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.63913</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03372</td></tr><tr><td>Test:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.14434</td></tr><tr><td>Test:OutcomePerformanceMetricsctd</td><td>0.63913</td></tr><tr><td>Test:OutcomePerformanceMetricsibs</td><td>0.03372</td></tr><tr><td>Test:OutcomePerformanceMetricsinbll</td><td>0.14434</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ctd</td><td>0.64504</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]ibs</td><td>0.03251</td></tr><tr><td>Val:OutcomePerformanceMetrics_[95, 41, 67, 65, 28]inbll</td><td>0.13974</td></tr><tr><td>Val:OutcomePerformanceMetricsctd</td><td>0.64504</td></tr><tr><td>Val:OutcomePerformanceMetricsibs</td><td>0.03251</td></tr><tr><td>Val:OutcomePerformanceMetricsinbll</td><td>0.13974</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>test_loss</td><td>0.41416</td></tr><tr><td>train_loss</td><td>0.39553</td></tr><tr><td>trainer/global_step</td><td>1955</td></tr><tr><td>val_loss</td><td>0.35855</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">CR_11M_24_11_01_big_posencscale__cvd-fine-tune-sr-100000-notebook_b</strong>: <a href=\"https://wandb.ai/cwlgadd/SurvivEHR/runs/1b2j0ios\" target=\"_blank\">https://wandb.ai/cwlgadd/SurvivEHR/runs/1b2j0ios</a><br/>Synced 5 W&B file(s), 280 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20241121_141944-1b2j0ios/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_trained_models = [\"CR_11M_24_11_01_big_posencscale_\"]   # , \"NULL-CR\"\n",
    "experiments = [\"cvd\"]  # \"hypertension\"\n",
    "experiment_types = [\"fine-tune-sr\"] #\"fine-tune-cr\", \n",
    "\n",
    "for pre_trained_model in pre_trained_models:\n",
    "\n",
    "    for experiment in experiments:\n",
    "    \n",
    "        for experiment_type in experiment_types:\n",
    "\n",
    "            for sample_size in [3000, 12500, 30000, 60000, 100000]: # 600, 1200, \n",
    "\n",
    "                wandb.finish()\n",
    "                # load the configuration file, override any settings \n",
    "                with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "                    cfg = compose(config_name=\"config_CompetingRisk37M\", \n",
    "                                  overrides=[# Experiment setup\n",
    "                                             f\"experiment.type='{experiment_type}'\",\n",
    "                                             f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                                             f\"experiment.fine_tune_id='{experiment}-{experiment_type}-{sample_size}-notebook'\",\n",
    "                                             \"experiment.train=True\",\n",
    "                                             \"experiment.test=True\",\n",
    "                                             # Dataloader\n",
    "                                             \"data.batch_size=256\",\n",
    "                                             \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                                             \"data.min_workers=12\",\n",
    "                                             f\"data.subsample_training={sample_size}\",\n",
    "                                             # Optimiser\n",
    "                                             \"optim.num_epochs=500\",\n",
    "                                             \"optim.scheduler=ReduceOnPlateau\",\n",
    "                                             \"optim.scheduler_warmup=False\",\n",
    "                                             \"optim.learning_rate=1e-3\",\n",
    "                                             \"optim.val_check_interval=1.0\",\n",
    "                                             \"optim.limit_val_batches=0.25\",\n",
    "                                             \"optim.limit_test_batches=null\",\n",
    "                                             \"optim.early_stop=True\",\n",
    "                                             \"optim.early_stop_patience=1\",\n",
    "                                            ]\n",
    "                                 )\n",
    "                \n",
    "                \n",
    "                match experiment.lower():\n",
    "                    case \"cvd\":\n",
    "                        cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "                        cfg.experiment.fine_tune_outcomes=[\"IHDINCLUDINGMI_OPTIMALV2\", \"ISCHAEMICSTROKE_V2\", \"MINFARCTION\", \"STROKEUNSPECIFIED_V2\", \"STROKE_HAEMRGIC\"]\n",
    "                    case \"hypertension\":\n",
    "                        cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\"\n",
    "                        cfg.experiment.fine_tune_outcomes=[\"HYPERTENSION\"]\n",
    "                \n",
    "                \n",
    "                model, dm = run(cfg)\n",
    "                print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "                wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b2aed-68b9-49b1-a804-2420199947a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4322e-5fa7-4079-8439-ca79cd6d1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.tokenizer._event_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184dc1d-6429-40cb-941a-5b21db8b8ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
