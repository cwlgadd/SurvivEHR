{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4921342e-8ff8-45d4-b1f6-9fe480c2ee1d",
   "metadata": {},
   "source": [
    "# Evaluation of a pre-trained SurvivEHR model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859d915-f1aa-4e57-a744-1fa9534583e8",
   "metadata": {},
   "source": [
    "Environment setup for BlueBear (Birmingham HPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e02b927b-cbbd-416a-87c5-b8e59681d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a671c59b-4428-4e63-a138-7244418a87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d866c7f0-eaa8-4129-b3b1-d4d6b504d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: detected 72 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "INFO:numexpr.utils:Note: NumExpr detected 72 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n",
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from hydra import compose, initialize\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(10000)\n",
    "# import pandas as pd\n",
    "# pd.options.display.max_rows = 10000\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from FastEHR.dataloader.foundational_loader import FoundationalDataModule\n",
    "from CPRD.examples.modelling.SurvivEHR.run_experiment import run\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}.\")\n",
    "\n",
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870f65b-d6e5-4716-a5f2-61a2131dad43",
   "metadata": {},
   "source": [
    "## Choosing configurations\n",
    "The default configuration is for pre-training. Here we modify as necesssary\n",
    "\n",
    "Here we choose to load in the configuration for a small **pre-trained** 11.4M parameter model, named \"CR_11M\". We specfiy the `zero-shot` experiment type, which will lead to running a ```CausalExperiment```. \n",
    "\n",
    "We tell this experiment that no further training is needed. Additionally, we do choose to perform testing (true by default). As this is a supervised model, this tests the ability to predict the outcomes of interest. In this notebook, this is chosen to be those of the cohort study for predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population, and we add the folder containing this dataset to the configuration. \n",
    "\n",
    "```Note: As this is a supervised dataset, we need to tell the DataModule that the last event observed is a target and must be stripped. This is done by passing a list of targets to the configuration, overriding the null default. This lets the DataModule know that it should process batches as supervised.```\n",
    "\n",
    "We set the number of workers to be appropriate for the number of CPUs available to reduce bottlenecking, and tell the experiment that we do not want to limit the number of testing batches. In addition, we specify where we want any checkpoints to be saved to avoid bloating the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00071773-72ba-418f-bfcf-b27eece1421f",
   "metadata": {},
   "source": [
    "# Run small (11M) Competing-Risk model experiment\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d912879-831d-422a-8684-81824695d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1\n"
     ]
    }
   ],
   "source": [
    "# pre_trained_model_ids = ['SurvivEHR-cr-small', 'SurvivEHR-cr-small-v1', 'SurvivEHR-cr', 'SurvivEHR-cr-v1', 'SurvivEHR-cr-v1-v1', 'SurvivEHR-cr-384', 'SurvivEHR-cr-384-v1', 'crPreTrain_small_1337',\n",
    "                        # 'SurvivEHR-cr-small-192', \"SurvivEHR-cr-small-192-v1\"]\n",
    "\n",
    "pre_trained_model, config_name = \"SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1\", \"config_CompetingRisk11M\"\n",
    "# pre_trained_model, config_name = \"SurvivEHR-cr-small-debug7_exp1000-v1-v4\", \"config_CompetingRisk11M\"\n",
    "# pre_trained_model, config_name = \"SurvivEHR-cr-small-debug7_exp1000\", \"config_CompetingRisk11M\"\n",
    "\n",
    "# pre_trained_model, config_name = \"SurvivEHR-cr-big-debug3_2_exp1000-v1\", \"config_CompetingRiskMOTOR\"\n",
    "\n",
    "print(pre_trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d834befc-fbf7-4b58-a532-0fd9519be631",
   "metadata": {},
   "source": [
    "# Embedding with different stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd8ff6d0-1ebe-4918-8890-45982d2f4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPRD.examples.modelling.SurvivEHR.callbacks.embedding_labels.log_token_count',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_labels.Token_count',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Number_of_preexisting_comorbidities',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Collection_history',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Type2_Diabetes_history',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.CVD_history',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Hypertension_history',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Gender',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.IMD',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Ethnicity',\n",
       " 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Birth_year']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root = \"CPRD.examples.modelling.SurvivEHR.callbacks.embedding_labels.\"\n",
    "core_stratification_methods = [root + _func for _func in [\"log_token_count\",\n",
    "                                                            \"Token_count\",]]\n",
    "\n",
    "root = \"CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.\"\n",
    "custom_stratification_methods = [root + _func for _func in [\"Number_of_preexisting_comorbidities\",\n",
    "                                                            \"Collection_history\",\n",
    "                                                            \"Type2_Diabetes_history\",\n",
    "                                                            \"CVD_history\",\n",
    "                                                            \"Hypertension_history\",\n",
    "                                                            \"Gender\",\n",
    "                                                            \"IMD\", \n",
    "                                                            \"Ethnicity\", \n",
    "                                                            \"Birth_year\"]]\n",
    "\n",
    "custom_stratification_methods = core_stratification_methods + custom_stratification_methods\n",
    "display(custom_stratification_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36929a02-db82-49dc-9526-a91978fac185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/. This will be loaded in supervised form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating supervised collator for DataModule\n",
      "INFO:root:Scaling supervised target ages by a factor of 1.0 times the context scale.\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Set seed to 1337\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/split=train/ dataset, with 1,650,998 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/split=test/ dataset, with 107,557 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/split=val/ dataset, with 91,487 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 128\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: true\n",
      "  repeating_events: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/cprd.db\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: null\n",
      "experiment:\n",
      "  type: fine-tune-sr\n",
      "  project_name: Evaluating fine-tuned models\n",
      "  run_id: SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1\n",
      "  fine_tune_id: MM_fine-tune-sr-Afalse8-Ns20000-s1\n",
      "  notes: null\n",
      "  tags: null\n",
      "  train: false\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "fine_tuning:\n",
      "  fine_tune_outcomes: null\n",
      "  custom_outcome_method:\n",
      "    _target_: CPRD.examples.modelling.SurvivEHR.helpers.custom_mm_outcomes\n",
      "  custom_stratification_method:\n",
      "    _target_:\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_labels.log_token_count\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_labels.Token_count\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Number_of_preexisting_comorbidities\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Collection_history\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Type2_Diabetes_history\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.CVD_history\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Hypertension_history\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Gender\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.IMD\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Ethnicity\n",
      "    - CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Birth_year\n",
      "  use_callbacks:\n",
      "    hidden_embedding: 100\n",
      "    performance_metrics: false\n",
      "    rmst: false\n",
      "  head:\n",
      "    surv_weight: 1\n",
      "    value_weight: 0\n",
      "optim:\n",
      "  num_epochs: 1\n",
      "  learning_rate: 0.0003\n",
      "  scheduler_warmup: true\n",
      "  scheduler: decaycawarmrestarts\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 2500\n",
      "  early_stop: true\n",
      "  early_stop_patience: 30\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.025\n",
      "  limit_test_batches: 1\n",
      "  accumulate_grad_batches: 1\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 6\n",
      "  n_head: 6\n",
      "  n_embd: 384\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "  use_fine_tune_adapter: false\n",
      "  adapter_dim: 8\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 1\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.1\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Fine-tune learning experiment with a new single-risk head\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Loading a fine-tuned model with the checkpoint path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1_MM_fine-tune-sr-Afalse8-Ns20000-s1.ckpt. Evaluating supervised performance\n",
      "INFO:root:Setting outcome list based on cfg.fine_tuning.custom_outcome_method._target_\n",
      "INFO:root:Running single-risk fine-tuning experiment with outcomes {'ADDISONS_DISEASE': 2, 'CYSTICFIBROSIS': 3, 'SYSTEMIC_SCLEROSIS': 4, 'SICKLE_CELL_DISEASE_V2': 5, 'ADDISON_DISEASE': 6, 'DOWNSSYNDROME': 7, 'HAEMOCHROMATOSIS_V2': 8, 'PLASMACELL_NEOPLASM_V2': 9, 'SJOGRENSSYNDROME': 10, 'SYSTEMIC_LUPUS_ERYTHEMATOSUS': 11, 'HIVAIDS': 12, 'PSORIATICARTHRITIS2021': 13, 'MS': 14, 'LEUKAEMIA_PREVALENCEV2': 16, 'ILD_SH': 18, 'CHRONIC_LIVER_DISEASE_ALCOHOL': 19, 'PERNICIOUSANAEMIA': 20, 'MENIERESDISEASE': 21, 'LYMPHOMA_PREVALENCE_V2': 22, 'CROHNS_DISEASE': 23, 'CHRONICFATIGUESYNDROMEMM_V2': 26, 'STROKE_HAEMRGIC': 28, 'PARKINSONS': 29, 'AORTICANEURYSM_V2': 30, 'BIPOLAR': 31, 'BRONCHIECTASIS': 32, 'ULCERATIVE_COLITIS': 33, 'SCHIZOPHRENIAMM_V2': 34, 'PTSDDIAGNOSIS': 35, 'TYPE1DM': 36, 'FIBROMYALGIA': 37, 'VISUAL_IMPAIRMENT': 38, 'AUTISM': 39, 'NAFLD_V2': 40, 'ISCHAEMICSTROKE_V2': 41, 'PVD_V3': 43, 'EATINGDISORDERS': 44, 'PMRANDGCA': 45, 'RHEUMATOIDARTHRITIS': 46, 'ENDOMETRIOSIS_ADENOMYOSIS_V2': 48, 'HYPERTHYROIDISM_V2': 49, 'OSA': 52, 'PAD_STRICT': 56, 'OTHER_CHRONIC_LIVER_DISEASE_OPTIMAL': 57, 'POLYCYSTIC_OVARIAN_SYNDROME_PCOS_V2': 58, 'EPILEPSY': 60, 'VALVULARDISEASES_V2': 62, 'STROKEUNSPECIFIED_V2': 65, 'MINFARCTION': 67, 'SUBSTANCEMISUSE': 70, 'HF_V3': 74, 'ALL_DEMENTIA': 75, 'OSTEOPOROSIS': 78, 'GOUT': 79, 'AF': 81, 'PSORIASIS': 82, 'COPD': 83, 'PERIPHERAL_NEUROPATHY': 89, 'HYPOTHYROIDISM_DRAFT_V1': 91, 'CKDSTAGE3TO5': 93, 'ALCOHOLMISUSE_V2': 94, 'IHDINCLUDINGMI_OPTIMALV2': 95, 'PREVALENT_IBS_V2': 97, 'TYPE2DIABETES': 100, 'ALLCANCER_NOHAEM_NOBCC': 104, 'DEATH': 106, 'ANY_DEAFNESS_HEARING_LOSS_V2': 114, 'OSTEOARTHRITIS': 120, 'ALLERGICRHINITISCONJ': 123, 'ANXIETY': 126, 'HYPERTENSION': 129, 'DEPRESSION': 133, 'ASTHMA_PUSHASTHMA': 134, 'ATOPICECZEMA': 136}\n",
      "INFO:root:Loading fine-tuned checkpoint from /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1_MM_fine-tune-sr-Afalse8-Ns20000-s1.ckpt\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpfg4fx4jr\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpfg4fx4jr/_remote_module_non_scriptable.py\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using a DeSurv Competing-Risk head.\n",
      "INFO:root:\tWith concurrent strategy=None for handling simultaneous events.\n",
      "INFO:root:\tEvaluating on a time grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Training all Transformer parameters\n",
      "INFO:root:custom_stratification_method._target_ ['CPRD.examples.modelling.SurvivEHR.callbacks.embedding_labels.log_token_count', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_labels.Token_count', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Number_of_preexisting_comorbidities', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Collection_history', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Type2_Diabetes_history', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.CVD_history', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Hypertension_history', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Gender', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.IMD', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Ethnicity', 'CPRD.examples.modelling.SurvivEHR.callbacks.embedding_wrappers.Birth_year']\n",
      "INFO:root:Created hidden state embedding callback log token count\n",
      "INFO:root:Created hidden state embedding callback Token count\n",
      "INFO:root:Created hidden state embedding callback Number of preexisting comorbidities\n",
      "INFO:root:Created hidden state embedding callback Collection history\n",
      "INFO:root:Created hidden state embedding callback Type2 Diabetes history\n",
      "INFO:root:Created hidden state embedding callback CVD history\n",
      "INFO:root:Created hidden state embedding callback Hypertension history\n",
      "INFO:root:Created hidden state embedding callback Gender\n",
      "INFO:root:Created hidden state embedding callback IMD\n",
      "INFO:root:Created hidden state embedding callback Ethnicity\n",
      "INFO:root:Created hidden state embedding callback Birth year\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "INFO:root:Testing model.\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcwlgadd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20250505_112715-3f057zlu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/Evaluating%20fine-tuned%20models/runs/3f057zlu\" target=\"_blank\">SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1_MM_fine-tune-sr-Afalse8-Ns20000-s1</a></strong> to <a href=\"https://wandb.ai/cwlgadd/Evaluating%20fine-tuned%20models\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.trainer.connectors.signal_connector:SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4f69d43f954f209185e1bcb979cebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvivEHR/callbacks/embedding_labels.py:35: RuntimeWarning: divide by zero encountered in log\n",
      "  log_labels = [np.log(_label) for _label in labels]\n",
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:211: You called `self.log('test_loss_values', ...)` in your `test_step` but the value needs to be floating point. Converting it to torch.float32.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6335986852645874     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_loss_desurv      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6335986852645874     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_loss_values      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6335986852645874    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_loss_desurv     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6335986852645874    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_loss_values     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 11.370501 M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_loss_desurv</td><td>▁</td></tr><tr><td>test_loss_values</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test_loss</td><td>0.6336</td></tr><tr><td>test_loss_desurv</td><td>0.6336</td></tr><tr><td>test_loss_values</td><td>0.0</td></tr><tr><td>trainer/global_step</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1_MM_fine-tune-sr-Afalse8-Ns20000-s1</strong>: <a href=\"https://wandb.ai/cwlgadd/Evaluating%20fine-tuned%20models/runs/3f057zlu\" target=\"_blank\">https://wandb.ai/cwlgadd/Evaluating%20fine-tuned%20models/runs/3f057zlu</a><br/>Synced 5 W&B file(s), 19 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20250505_112715-3f057zlu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "\n",
    "\n",
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"causal_metric_testing_notebook\"):\n",
    "    cfg = compose(config_name=config_name, \n",
    "                  overrides=[# Experiment setup\n",
    "                             \"experiment.project_name='Evaluating fine-tuned models'\",\n",
    "                             \"experiment.type=fine-tune-sr\",\n",
    "                             f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                             f\"experiment.fine_tune_id='MM_fine-tune-sr-Afalse8-Ns20000-s1'\",\n",
    "                             \"experiment.train=False\",\n",
    "                             \"experiment.test=True\",\n",
    "                             \"data.batch_size=128\",\n",
    "                             \"data.path_to_ds='/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/'\",\n",
    "                             \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                             \"data.min_workers=12\",\n",
    "                             \"data.global_diagnoses=True\",\n",
    "                             \"data.repeating_events=False\",\n",
    "                             \"optim.limit_test_batches=1\",\n",
    "                             \"fine_tuning.custom_outcome_method._target_='CPRD.examples.modelling.SurvivEHR.helpers.custom_mm_outcomes'\",\n",
    "                             f\"fine_tuning.custom_stratification_method._target_={custom_stratification_methods}\",\n",
    "                             \"fine_tuning.use_callbacks.performance_metrics=False\",\n",
    "                             \"fine_tuning.use_callbacks.hidden_embedding=100\",\n",
    "                             # \"transformer.block_size=1000\",\n",
    "                            ]\n",
    "                 )     \n",
    "\n",
    "model, dm = run(cfg)\n",
    "print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e00688-1426-4046-910c-45bde94db899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()\n",
    "\n",
    "\n",
    "# # load the configuration file, override any settings \n",
    "# with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"causal_metric_testing_notebook\"):\n",
    "#     cfg = compose(config_name=config_name, \n",
    "#                   overrides=[# Experiment setup\n",
    "#                              \"experiment.project_name='Evaluating pre-trained models'\",\n",
    "#                              f\"experiment.run_id='{pre_trained_model}'\",\n",
    "#                              \"experiment.train=False\",\n",
    "#                              \"experiment.test=True\",\n",
    "#                              \"data.batch_size=128\",\n",
    "#                              \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "#                              \"data.min_workers=12\",\n",
    "#                              \"optim.limit_test_batches=1\",\n",
    "#                              f\"fine_tuning.custom_stratification_method._target_={custom_stratification_methods}\",\n",
    "#                              \"fine_tuning.use_callbacks.performance_metrics=False\",\n",
    "#                              \"fine_tuning.use_callbacks.hidden_embedding=100\",\n",
    "#                              # \"transformer.block_size=2000\",\n",
    "#                             ]\n",
    "#                  )     \n",
    "\n",
    "# model, dm = run(cfg)\n",
    "# print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5a8c6-7533-4a9a-a6d8-4bb71b9545ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "print(pre_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c69bfcf-973c-4807-8538-dd6a9c0d1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in dm.test_dataloader():\n",
    "#     break\n",
    "for patient_tokens, patient_mask in zip(batch[\"tokens\"], batch[\"attention_mask\"]):\n",
    "    break\n",
    "print(patient_tokens)\n",
    "print(patient_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317dba27-765e-4263-8289-65e821929ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(dm.train_set._decode_covariates(batch[\"static_covariates\"]).keys())\n",
    "\n",
    "key = \"birth_year\"\n",
    "key_static_covariates = dm.train_set._decode_covariates(batch[\"static_covariates\"])[key]\n",
    "for patient_tokens in key_static_covariates:\n",
    "    print(patient_tokens.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078715e-c1dc-4726-bf06-0d6cba9261fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dm.encode(['IHDINCLUDINGMI_OPTIMALV2', 'ISCHAEMICSTROKE_V2', 'MINFARCTION', 'STROKEUNSPECIFIED_V2', 'STROKE_HAEMRGIC']))\n",
    "display(dm.encode(['HYPERTENSION']))\n",
    "# display(dm.decode([95, 175, 263,249]).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0352a-f7cc-40ea-b456-97f1e59adcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.tokenizer._event_counts[\"EVENT\"][-5:].to_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
