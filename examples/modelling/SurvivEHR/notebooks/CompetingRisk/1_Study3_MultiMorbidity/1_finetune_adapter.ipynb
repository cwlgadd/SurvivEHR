{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4921342e-8ff8-45d4-b1f6-9fe480c2ee1d",
   "metadata": {},
   "source": [
    "# CPRD Notebook:\n",
    "## Evaluation of fine-tuning the pre-trained SurvivEHR-CR model on a supervised cohort study.\n",
    "\n",
    "Cohort study:\n",
    "\n",
    "This notebook quantifies the performance obtained when fine-tuning the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a671c59b-4428-4e63-a138-7244418a87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvivEHR/notebooks/CompetingRisk/1_Study3_MultiMorbidity\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ce5a65-2a59-4fa7-98b3-ff2dd36018de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FastEHR\n",
    "from FastEHR.dataloader import FoundationalDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d866c7f0-eaa8-4129-b3b1-d4d6b504d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import wandb\n",
    "import pickle\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from FastEHR.dataloader import FoundationalDataModule\n",
    "\n",
    "from CPRD.examples.modelling.SurvivEHR.run_experiment import run\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "from CPRD.examples.modelling.SurvivEHR.helpers import count_prior_tokens\n",
    "\n",
    "import time\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(10000)\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10000\n",
    "\n",
    "\n",
    "# TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c237f8-679a-4fe4-a570-2c8c7b61da9b",
   "metadata": {},
   "source": [
    "# Fine-tuning on full dataset\n",
    "The default configuration is for pre-training. Here we modify as necesssary\n",
    "\n",
    "Here we choose to load in the configuration for a small **pre-trained** 11.4M parameter model, named \"CR_11M\". We specfiy the `fine-tune` experiment type, which will lead to running the ```SupervisedExperiment```. \n",
    "\n",
    "We tell this experiment that we want to perform training (true by default). Additionally, we do choose to perform testing (true by default). As this is a supervised model, this tests the ability to predict the outcomes of interest. In this notebook, this is chosen to be those of the cohort study for predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population, and we add the folder containing this dataset to the configuration. \n",
    "\n",
    "```Note: As this is a supervised dataset, we need to tell the DataModule that the last event observed is a target and must be stripped. This is done by passing a list of targets to the configuration, overriding the null default. This lets the DataModule know that it should process batches as supervised.```\n",
    "\n",
    "We set the number of workers to be appropriate for the number of CPUs available to reduce bottlenecking, and tell the experiment that we do not want to limit the number of testing batches. In addition, we specify where we want any checkpoints to be saved to avoid bloating the repository.\n",
    "\n",
    "We design a new optimisation strategy for fine-tuning. Pre-training was achieved with a warmup and cosine annealing, with rates which are no appropriate for much smaller dataset sizes seen in clinical prediction models (CPMs). We here choose a simpler strategy: of ReduceOnPlateau with no warmup, increasing the number of epochs (default is 1) and reduced validation intervals, and the addition of early stopping. Additionally, as this is not a causal model we can increase the batch size. Finally, as this CPM is not trying to predict the value of any outcomes, we set the value weight to zero allowing the model to focus entirely on optimising survival outcome prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e42878-b97d-4cba-a4c9-d35f745a1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_trained_model_ids = ['SurvivEHR-cr-small', 'SurvivEHR-cr-small-v1', 'SurvivEHR-cr-384', 'SurvivEHR-cr-384-v1', 'crPreTrain_small_1337']\n",
    "pre_trained_model_ids = [\"SurvivEHR-cr-small-debug7_exp1000-v1\"]\n",
    "experiments = [\"mm\"] \n",
    "experiment_types = [ \"fine-tune-sr\"] \n",
    "adapter = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63089870-fd77-4716-9dcb-cacbd4380ed0",
   "metadata": {},
   "source": [
    "## Extract MM information for experiment setup\n",
    "\n",
    "We want to stratify RMST by level of existing multi-morbidity, so we create a custom function to pass to the callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33c0bbe-d212-495c-b9b0-d75118853d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset in most minimal form (this isnt used for the experiment - only to extract the token names for the diagnoses)\n",
    "with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "    cfg = compose(config_name=\"config_CompetingRisk11M\")\n",
    "\n",
    "dm = FoundationalDataModule(path_to_db=cfg.data.path_to_db,\n",
    "                            path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/\",\n",
    "                            overwrite_meta_information=cfg.data.meta_information_path,\n",
    "                            load=True)\n",
    "\n",
    "conditions = (\n",
    "    dm.tokenizer._event_counts.filter((pl.col(\"COUNT\") > 0) &\n",
    "        (pl.col(\"EVENT\").str.contains(r'^[A-Z0-9_]+$')))\n",
    "      .select(\"EVENT\")\n",
    "      .to_series()\n",
    "      .to_list()\n",
    ")\n",
    "encoded_conditions = dm.tokenizer.encode(conditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08cbdb20-16cc-4892-a159-1f2ad60eeada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_decoder': True, 'data': {'batch_size': 64, 'unk_freq_threshold': 0.0, 'min_workers': 12, 'global_diagnoses': False, 'repeating_events': True, 'path_to_db': '/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/cprd.db', 'path_to_ds': '/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/', 'meta_information_path': '/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle', 'subsample_training': None}, 'experiment': {'type': 'pre-train', 'project_name': 'SurvivEHR', 'run_id': '${head.SurvLayer}PreTrain_small_${experiment.seed}', 'fine_tune_id': None, 'notes': None, 'tags': None, 'train': True, 'test': True, 'verbose': True, 'seed': 1337, 'log': True, 'log_dir': '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/', 'ckpt_dir': '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/', 'fine_tune_outcomes': None}, 'fine_tuning': {'custom_stratification_method': {'_target_': None, 'tokens': None}, 'head': {'surv_weight': 1, 'value_weight': 0}}, 'optim': {'num_epochs': 1, 'learning_rate': 0.0003, 'scheduler_warmup': True, 'scheduler': 'decaycawarmrestarts', 'scheduler_periods': 10000, 'learning_rate_decay': 0.8, 'val_check_interval': 2500, 'early_stop': True, 'early_stop_patience': 30, 'log_every_n_steps': 20, 'limit_val_batches': 0.025, 'limit_test_batches': None, 'accumulate_grad_batches': 1}, 'transformer': {'block_type': 'Neo', 'block_size': 256, 'n_layer': 6, 'n_head': 6, 'n_embd': 384, 'layer_norm_bias': False, 'attention_type': 'global', 'bias': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'resid_dropout': 0.0, 'private_heads': 0, 'use_fine_tune_adapter': False, 'adapter_dim': 8}, 'head': {'SurvLayer': 'cr', 'surv_weight': 1, 'tokens_for_univariate_regression': 'None', 'value_weight': 0.1}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4fdc572-8637-4e1f-83e1-e20cb5789ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Antipsychotics_OPTIMAL Anticonvulsants_OPTIMAL'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dm.tokenizer.decode([196,233]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182958f7-e801-4661-8f7d-23c20747f740",
   "metadata": {},
   "source": [
    "# Test utility function\n",
    "\n",
    "Utility function `count_prior_tokens()` is used to stratify samples basedon the number of times they experienced a set of events. In this case these are diagnoses events and our stratification is on the level of existing multi-morbidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b870141-e7e3-48a3-b7c2-cd245c91adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180b856e-a1c3-4ac1-85d4-2e609163128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3512\n",
      "tensor([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 254, 255, 255, 255, 255, 133, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 255,  70])\n",
      "5021\n",
      "tensor([198, 213, 218, 198, 213, 218, 198, 213, 213, 218, 198, 213, 218, 198,\n",
      "        213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218,\n",
      "        198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213,\n",
      "        218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198,\n",
      "        213, 198, 213, 218, 198, 213, 198, 213, 218, 198, 213, 218, 198, 213,\n",
      "        218, 198, 213, 218, 198, 213, 198, 213, 218, 198, 213, 218, 198, 213,\n",
      "        218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198,\n",
      "        213, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198,\n",
      "        213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218,\n",
      "        198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213,\n",
      "        218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198,\n",
      "        213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218,\n",
      "        198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213,\n",
      "        218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198,\n",
      "        213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218,\n",
      "        198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213,\n",
      "        218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198,\n",
      "        213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218, 198, 213, 218,\n",
      "        198, 213, 218, 114])\n",
      "5467\n",
      "tensor([196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196])\n",
      "11338\n",
      "tensor([191, 233, 191, 233, 191, 233, 191, 233, 191, 233, 191, 233, 191, 233,\n",
      "        191, 233, 191, 233, 233, 233, 233, 191, 233, 191, 233, 233, 233, 233,\n",
      "        191, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233,\n",
      "        191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233,\n",
      "        191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233,\n",
      "        233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233,\n",
      "        233, 233, 191, 233, 233, 233, 233, 233, 191, 233, 233, 233, 191, 233,\n",
      "        233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191,\n",
      "        233, 191, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 233,\n",
      "        233, 233, 191, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233,\n",
      "        233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233,\n",
      "        233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233,\n",
      "        233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191,\n",
      "        233, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233,\n",
      "        191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233,\n",
      "        233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 191, 233, 233, 233,\n",
      "        233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233, 233,\n",
      "        233, 233, 191, 233, 233, 233, 233, 191, 233, 233, 233, 233, 191, 233,\n",
      "        233, 233, 233,  60])\n",
      "15809\n",
      "tensor([198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213, 198, 213,\n",
      "        198, 213, 198, 213, 198, 213, 198, 213, 114])\n",
      "18698\n",
      "tensor([160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 261, 217, 262, 160,\n",
      "        160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160])\n",
      "22069\n",
      "tensor([ 34, 196, 196, 133, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 134])\n",
      "22478\n",
      "tensor([213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254,\n",
      "        254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198,\n",
      "        213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254,\n",
      "        254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198,\n",
      "        213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254,\n",
      "        254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198,\n",
      "        213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254,\n",
      "        254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 198, 213, 213, 254,\n",
      "        254, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254,\n",
      "        254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198,\n",
      "        213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254,\n",
      "        254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198,\n",
      "        213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254,\n",
      "        254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198,\n",
      "        213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254,\n",
      "        254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198,\n",
      "        213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254,\n",
      "        254, 198, 213, 254, 254, 198, 213, 254, 254, 198, 213, 254, 254, 198,\n",
      "        213, 254, 254, 254])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sample in enumerate(dm.train_set):\n",
    "    if torch.unique(sample[\"tokens\"]).shape[0] < 5:\n",
    "        print(idx)\n",
    "        print(sample[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e87722-915e-4d99-ae73-d8e446c2aebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 current diagnoses',\n",
       " '3 current diagnoses',\n",
       " '1 current diagnosis',\n",
       " '1 current diagnosis',\n",
       " '0 current diagnoses']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 52, 56, 57, 58, 60, 62, 65, 67, 70, 74, 75, 78, 79, 81, 82, 83, 89, 91, 93, 94, 95, 97, 100, 104, 106, 114, 120, 123, 126, 129, 133, 134, 136]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "display(count_prior_tokens(batch, encoded_conditions)[:5])\n",
    "\n",
    "print(encoded_conditions)\n",
    "print(sum([_i in encoded_conditions for _i in batch[\"tokens\"][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6b791-c60c-4989-896d-420e4ba6ab4e",
   "metadata": {},
   "source": [
    "## Get outcome list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662c49b-6a1d-4a35-82dc-f00c77d0cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurvivEHR-cr-small-debug7_exp1000-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:173: Found keys that are in the model state dict but not in the checkpoint: ['reduce_hidden.0.weight', 'reduce_hidden.0.bias', 'surv_layer.sr_ode.net.u', 'surv_layer.sr_ode.net.w', 'surv_layer.sr_ode.net.BaseNet.mapping.0.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.0.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.2.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.2.bias', 'surv_layer.sr_ode.net.BaseNet.mapping.4.weight', 'surv_layer.sr_ode.net.BaseNet.mapping.4.bias']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcwlgadd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20250328_151606-3mhmsnp6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvivEHR-Study3-MM/runs/3mhmsnp6\" target=\"_blank\">SurvivEHR-cr-small-debug7_exp1000-v1_mm-fine-tune-sr-AFalse-notebook-MM50+_3</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvivEHR-Study3-MM\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:630: Checkpoint directory /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                            | Params\n",
      "------------------------------------------------------------------\n",
      "0 | model         | SurvStreamGPTForCausalModelling | 11.2 M\n",
      "1 | reduce_hidden | Sequential                      | 147 K \n",
      "2 | surv_layer    | ODESurvSingleRiskLayer          | 13.5 K\n",
      "------------------------------------------------------------------\n",
      "11.4 M    Trainable params\n",
      "30        Non-trainable params\n",
      "11.4 M    Total params\n",
      "45.482    Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:211: You called `self.log('val_loss_values', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349b48ed237248c1b2315379ec5b05b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/bear-apps/2022a/EL8-ice/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:211: You called `self.log('train_loss_values', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "WARNING:root:Fine-tuning batch has 1 samples without at least two events.\n",
      "WARNING:root:\tContinuing by removing singular samples, but these should be removed from the dataset.\n",
      "                                    \t\t Bad sample tokens: tensor([[196,   0,   0,   0,   0]])\n",
      "                                    \t\t and corresponding ages tensor([[10.2296,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "WARNING:root:Fine-tuning batch has 1 samples without at least two events.\n",
      "WARNING:root:\tContinuing by removing singular samples, but these should be removed from the dataset.\n",
      "                                    \t\t Bad sample tokens: tensor([[160,   0,   0,   0,   0]])\n",
      "                                    \t\t and corresponding ages tensor([[11.5134,  0.0000,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Fine-tuning batch has 1 samples without at least two events.\n",
      "WARNING:root:\tContinuing by removing singular samples, but these should be removed from the dataset.\n",
      "                                    \t\t Bad sample tokens: tensor([[233,   0,   0,   0,   0]])\n",
      "                                    \t\t and corresponding ages tensor([[11.6395,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "Metric val_loss improved. New best score: 0.678\n",
      "Epoch 0, global step 644: 'val_loss' reached 0.67848 (best 0.67848), saving model to '/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SurvivEHR-cr-small-debug7_exp1000-v1_mm-fine-tune-sr-AFalse-notebook-MM50+_3.ckpt' as top 1\n"
     ]
    }
   ],
   "source": [
    "for pre_trained_model in pre_trained_model_ids:\n",
    "    print(pre_trained_model)\n",
    "\n",
    "    for experiment, experiment_type in zip(experiments, experiment_types):\n",
    "    \n",
    "        wandb.finish()\n",
    "        # load the configuration file, override any settings \n",
    "        with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "            cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                          overrides=[# Experiment setup\n",
    "                                     f\"experiment.project_name='SurvivEHR-Study3-MM'\",\n",
    "                                     f\"experiment.type='{experiment_type}'\",\n",
    "                                     f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                                     f\"experiment.fine_tune_id='{experiment}-{experiment_type}-A{adapter}-notebook-MM50+_3'\",\n",
    "                                     \"experiment.train=True\",\n",
    "                                     \"experiment.test=True\",\n",
    "                                     # Dataloader\n",
    "                                     \"data.batch_size=128\",\n",
    "                                     \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                                     \"data.min_workers=12\",\n",
    "                                     \"data.global_diagnoses=True\",\n",
    "                                     \"data.repeating_events=False\",\n",
    "                                     # f\"data.subsample_training={1000}\",\n",
    "                                     # Optimiser\n",
    "                                     \"optim.num_epochs=20\",\n",
    "                                     \"optim.limit_test_batches=null\",\n",
    "                                     \"optim.scheduler=ReduceOnPlateau\",\n",
    "                                     \"optim.scheduler_warmup=False\",\n",
    "                                     \"optim.learning_rate=1e-3\",\n",
    "                                     \"optim.val_check_interval=0.25\",\n",
    "                                     \"optim.early_stop=True\",\n",
    "                                     \"optim.early_stop_patience=10\",\n",
    "                                     \"optim.limit_val_batches=1.0\",\n",
    "                                     \"optim.limit_test_batches=1.0\",\n",
    "                                     \"optim.accumulate_grad_batches=5\",\n",
    "                                     # Model\n",
    "                                     # \"transformer.n_embd=384\",\n",
    "                                     f\"transformer.use_fine_tune_adapter={False if adapter is False else True}\",\n",
    "                                     f\"transformer.adapter_dim={8 if adapter is False else adapter}\",\n",
    "                                     \"transformer.block_size=500\", \n",
    "                                     \"head.value_weight=0\",\n",
    "                                    ]\n",
    "                         )\n",
    "        \n",
    "        match experiment.lower():\n",
    "            case \"mm\":\n",
    "                cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_MultiMorbidity50+/\"\n",
    "                cfg.experiment.fine_tune_outcomes=conditions\n",
    "                cfg.fine_tuning.custom_stratification_method._target_=\"CPRD.examples.modelling.SurvivEHR.helpers.count_prior_tokens\"\n",
    "                cfg.fine_tuning.custom_stratification_method.tokens=encoded_conditions\n",
    "        \n",
    "        model, dm = run(cfg)\n",
    "        print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "        wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e4721-b2ca-44c8-9760-55442aa8803f",
   "metadata": {},
   "source": [
    "```\n",
    "/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SurvivEHR-cr-small-v1.ckpt\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃             Test metric             ┃            DataLoader 0             ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "└─────────────────────────────────────┴─────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65799ee6-9462-42a0-a293-dd4cac545d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = encoded_conditions\n",
    "print(isinstance(tokens, list))\n",
    "print([isinstance(i, int) for i in tokens])\n",
    "# [_i if _i == _i.upper() else 0 for _i in dm.train_set.tokenizer._stoi.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62557fe3-6772-411b-b16a-14edc0d366de",
   "metadata": {},
   "source": [
    "# Fine-tuning on sub-set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bdffe-a788-4b32-8563-044daaf283b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [int(np.exp(_log_n)) for _log_n in np.linspace(np.log(3000), np.log(500000), 10)]\n",
    "print(sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4b72e2-a938-46b0-aea4-f56517283a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [int(np.exp(_log_n)) for _log_n in np.linspace(np.log(3000), np.log(500000), 10)]      # [3000, 12500, 30000, 60000, 100000]: # 600, 1200, \n",
    "sample_sizes = [None]\n",
    "\n",
    "accumulate_grad_batches = 5\n",
    "\n",
    "\n",
    "for pre_trained_model in pre_trained_model_ids[1:2]:\n",
    "    print(pre_trained_model)\n",
    "\n",
    "    for experiment, experiment_type in zip(experiments, experiment_types):\n",
    "\n",
    "        for sample_size in sample_sizes:\n",
    "\n",
    "            wandb.finish()\n",
    "            # load the configuration file, override any settings \n",
    "            with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "                cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                              overrides=[# Experiment setup\n",
    "                                         f\"experiment.project_name='SurvivEHR-Study1-CVD'\",\n",
    "                                         f\"experiment.type='{experiment_type}'\",\n",
    "                                         f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                                         f\"experiment.fine_tune_id='{experiment}-{experiment_type}-A{adapter}-Ns{sample_size}-500-notebook'\",\n",
    "                                         \"experiment.train=True\",\n",
    "                                         \"experiment.test=True\",\n",
    "                                         \"experiment.notes=Ablation on increasing cohort study size result\",\n",
    "                                         # Dataloader\n",
    "                                         \"data.batch_size=128\",\n",
    "                                         \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                                         \"data.min_workers=3\",\n",
    "                                         \"data.global_diagnoses=True\",\n",
    "                                         \"data.repeating_events=False\",\n",
    "                                         # f\"data.subsample_training={sample_size}\",\n",
    "                                         # Optimiser\n",
    "                                         \"optim.num_epochs=500\",\n",
    "                                         \"optim.limit_test_batches=null\",\n",
    "                                         \"optim.scheduler=ReduceOnPlateau\",\n",
    "                                         \"optim.scheduler_warmup=False\",\n",
    "                                         \"optim.learning_rate=1e-3\",\n",
    "                                         \"optim.val_check_interval=0.25\",\n",
    "                                         \"optim.early_stop=True\",\n",
    "                                         \"optim.early_stop_patience=4\",\n",
    "                                         \"optim.limit_val_batches=0.035\",\n",
    "                                         f\"optim.accumulate_grad_batches={accumulate_grad_batches}\",\n",
    "                                         # Model\n",
    "                                         # \"transformer.n_embd=384\",\n",
    "                                         f\"transformer.use_fine_tune_adapter={False if adapter is False else True}\",\n",
    "                                         f\"transformer.adapter_dim={8 if adapter is False else adapter}\",\n",
    "                                         \"transformer.block_size=500\", \n",
    "                                        ]\n",
    "                             )\n",
    "            \n",
    "            \n",
    "            match experiment.lower():\n",
    "                case \"cvd\":\n",
    "                    cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "                    cfg.experiment.fine_tune_outcomes=[\"IHDINCLUDINGMI_OPTIMALV2\", \"ISCHAEMICSTROKE_V2\", \"MINFARCTION\", \"STROKEUNSPECIFIED_V2\", \"STROKE_HAEMRGIC\"]\n",
    "                case \"hypertension\":\n",
    "                    cfg.data.path_to_ds=\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/\"\n",
    "                    cfg.experiment.fine_tune_outcomes=[\"HYPERTENSION\"]\n",
    "            \n",
    "            \n",
    "            model, dm = run(cfg)\n",
    "            print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "            wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b2aed-68b9-49b1-a804-2420199947a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4322e-5fa7-4079-8439-ca79cd6d1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.tokenizer._event_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184dc1d-6429-40cb-941a-5b21db8b8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_CVD = {\n",
    "    \"SurvivEHR-cr-small-v1\": (\n",
    "        \"SurvivEHR-CR\",\n",
    "        [2999, 5296, 9351, 16509, 29148, 51461, 90856, 160407, 283203, 500000]],\n",
    "        [0.6270919442176819],\n",
    "        [0.03389651543792928],\n",
    "        [0.14657540914939907]\n",
    "        ),\n",
    "    \n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
