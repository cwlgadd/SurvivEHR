{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4921342e-8ff8-45d4-b1f6-9fe480c2ee1d",
   "metadata": {},
   "source": [
    "# Evaluation of a pre-trained SurvivEHR model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a671c59b-4428-4e63-a138-7244418a87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d866c7f0-eaa8-4129-b3b1-d4d6b504d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: detected 72 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "INFO:numexpr.utils:Note: NumExpr detected 72 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n",
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from hydra import compose, initialize\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(10000)\n",
    "# import pandas as pd\n",
    "# pd.options.display.max_rows = 10000\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from FastEHR.dataloader.foundational_loader import FoundationalDataModule\n",
    "from CPRD.examples.modelling.SurvivEHR.run_experiment import run\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}.\")\n",
    "\n",
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870f65b-d6e5-4716-a5f2-61a2131dad43",
   "metadata": {},
   "source": [
    "## Choosing configurations\n",
    "The default configuration is for pre-training. Here we modify as necesssary\n",
    "\n",
    "Here we choose to load in the configuration for a small **pre-trained** 11.4M parameter model, named \"CR_11M\". We specfiy the `zero-shot` experiment type, which will lead to running a ```CausalExperiment```. \n",
    "\n",
    "We tell this experiment that no further training is needed. Additionally, we do choose to perform testing (true by default). As this is a supervised model, this tests the ability to predict the outcomes of interest. In this notebook, this is chosen to be those of the cohort study for predicting Cardiovascular Disease in a Type 2 Diabetes Mellitus population, and we add the folder containing this dataset to the configuration. \n",
    "\n",
    "```Note: As this is a supervised dataset, we need to tell the DataModule that the last event observed is a target and must be stripped. This is done by passing a list of targets to the configuration, overriding the null default. This lets the DataModule know that it should process batches as supervised.```\n",
    "\n",
    "We set the number of workers to be appropriate for the number of CPUs available to reduce bottlenecking, and tell the experiment that we do not want to limit the number of testing batches. In addition, we specify where we want any checkpoints to be saved to avoid bloating the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00071773-72ba-418f-bfcf-b27eece1421f",
   "metadata": {},
   "source": [
    "# Run small (11M) Competing-Risk model experiment\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d912879-831d-422a-8684-81824695d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurvivEHR-cr-small-v1\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model_ids = ['SurvivEHR-cr-small', 'SurvivEHR-cr-small-v1', 'SurvivEHR-cr', 'SurvivEHR-cr-v1', 'SurvivEHR-cr-v1-v1', 'SurvivEHR-cr-384', 'SurvivEHR-cr-384-v1', 'crPreTrain_small_1337',\n",
    "                        'SurvivEHR-cr-small-192', \"SurvivEHR-cr-small-192-v1\"]\n",
    "\n",
    "pre_trained_model = pre_trained_model_ids[1]\n",
    "print(pre_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e00688-1426-4046-910c-45bde94db899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/. This will be loaded in causal form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating unsupervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=train/ dataset, with 23,613,894 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=test/ dataset, with 1,508,320 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=val/ dataset, with 1,426,714 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 128\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 3\n",
      "  global_diagnoses: false\n",
      "  repeating_events: true\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/cprd.db\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: null\n",
      "experiment:\n",
      "  type: pre-train\n",
      "  project_name: Evaluating pre-trained models\n",
      "  run_id: SurvivEHR-cr-small-v1\n",
      "  fine_tune_id: null\n",
      "  notes: null\n",
      "  tags: null\n",
      "  train: false\n",
      "  test: false\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes: null\n",
      "optim:\n",
      "  num_epochs: 1\n",
      "  learning_rate: 0.0003\n",
      "  scheduler_warmup: true\n",
      "  scheduler: decaycawarmrestarts\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 2500\n",
      "  early_stop: true\n",
      "  early_stop_patience: 30\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.025\n",
      "  limit_test_batches: 0.035\n",
      "  accumulate_grad_batches: 1\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 6\n",
      "  n_head: 6\n",
      "  n_embd: 384\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "  use_fine_tune_adapter: true\n",
      "  adapter_dim: 8\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 1\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.1\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Pre-training experiment\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Loading a pre-trained model with the checkpoint path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SurvivEHR-cr-small-v1.ckpt.\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp7_4rsveb\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp7_4rsveb/_remote_module_non_scriptable.py\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Creating hidden state embedding callback\n",
      "INFO:root:Created Performance metric callback for causal self-supervised tasks.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 11.211302 M parameters\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()\n",
    "\n",
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "    cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                  overrides=[# Experiment setup\n",
    "                             \"experiment.project_name='Evaluating pre-trained models'\",\n",
    "                             f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                             \"experiment.train=False\",\n",
    "                             \"experiment.test=False\",\n",
    "                             # Dataloader\n",
    "                             \"data.batch_size=128\",\n",
    "                             \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                             \"data.min_workers=3\",\n",
    "                             # \"data.global_diagnoses=True\",\n",
    "                             # Optimiser\n",
    "                             \"optim.limit_test_batches=0.035\",\n",
    "                             # Model\n",
    "                             # \"transformer.n_embd=192\",  #384\n",
    "                             # \"transformer.block_size=512\", \n",
    "                            ]\n",
    "                 )     \n",
    "\n",
    "model, dm = run(cfg)\n",
    "print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe5a8c6-7533-4a9a-a6d8-4bb71b9545ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurvivEHR-cr-small-v1\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()\n",
    "print(pre_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d078715e-c1dc-4726-bf06-0d6cba9261fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95, 41, 67, 65, 28]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[129]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dm.encode(['IHDINCLUDINGMI_OPTIMALV2', 'ISCHAEMICSTROKE_V2', 'MINFARCTION', 'STROKEUNSPECIFIED_V2', 'STROKE_HAEMRGIC']))\n",
    "display(dm.encode(['HYPERTENSION']))\n",
    "# display(dm.decode([95, 175, 263,249]).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aa0352a-f7cc-40ea-b456-97f1e59adcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NSAIDS_oral_OPTIMAL_final',\n",
       " 'Diastolic_blood_pressure_5',\n",
       " 'Systolic_blood_pressure_4',\n",
       " 'Statins',\n",
       " 'Lipid_lowering_drugs_Optimal']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.tokenizer._event_counts[\"EVENT\"][-5:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5c6a2c-91b7-43c3-8164-1150608858d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b622b-ab48-428a-becb-3cc57cff8b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e60f13-a1db-4750-b1a8-c4c2d4848352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_nondiagnosis = [cn for cn in dm.tokenizer._event_counts[\"EVENT\"] if cn.upper() != cn]\n",
    "# display([cn for cn in all_nondiagnosis if \"Warf\" in cn])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d96b8d-59a6-44eb-90e1-d1c31854b2a2",
   "metadata": {},
   "source": [
    "# Get the data from the callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9d7a7c-242a-4ba1-ae98-2a5ac7ed8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42a8bb11-e10a-4319-8050-2703af0e4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = api.run(\"SurvivEHR/test_causal_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41fce410-de87-41a1-a76c-fbb981dff07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_from_wandb = {\n",
    "  \"Test:Cinter\": 0.9923065858471094,\n",
    "  \"Test:Cinter+0\": 0.9845138238722124,\n",
    "  \"Test:Cinter+1\": 0.9366127214016844,\n",
    "  \"Test:Cinter+10\": 0.8252010439713312,\n",
    "  \"Test:Cinter+13\": 0.7866451755111037,\n",
    "  \"Test:Cinter+16\": 0.7641013179336177,\n",
    "  \"Test:Cinter+19\": 0.7604122318951223,\n",
    "  \"Test:Cinter+2\": 0.9158513102720236,\n",
    "  \"Test:Cinter+3\": 0.899843080451446,\n",
    "  \"Test:Cinter+4\": 0.868315386991299,\n",
    "  \"Test:Cinter+7\": 0.8239121250528096,\n",
    "  \"Test:Cintra100\": 0.8992395437262358,\n",
    "  \"Test:Cintra101\": 0.929024081115336,\n",
    "  \"Test:Cintra104\": 0.8466413181242078,\n",
    "  \"Test:Cintra106\": 0.9320659062103928,\n",
    "  \"Test:Cintra107\": 0.8193916349809885,\n",
    "  \"Test:Cintra11\": 0.4258555133079848,\n",
    "  \"Test:Cintra110\": 0.8365019011406845,\n",
    "  \"Test:Cintra112\": 0.95519920648041,\n",
    "  \"Test:Cintra113\": 0.9942965779467682,\n",
    "  \"Test:Cintra114\": 0.8859315589353612,\n",
    "  \"Test:Cintra115\": 0.9935361216730038,\n",
    "  \"Test:Cintra116\": 0.9931558935361215,\n",
    "  \"Test:Cintra118\": 0.9785024861070488,\n",
    "  \"Test:Cintra119\": 0.9852344740177446,\n",
    "  \"Test:Cintra120\": 0.8935361216730038,\n",
    "  \"Test:Cintra121\": 0.9923954372623576,\n",
    "  \"Test:Cintra123\": 0.9635505441195752,\n",
    "  \"Test:Cintra124\": 0.9484790874524716,\n",
    "  \"Test:Cintra126\": 0.9302915082382762,\n",
    "  \"Test:Cintra127\": 0.9798003802281368,\n",
    "  \"Test:Cintra129\": 0.9398247644238716,\n",
    "  \"Test:Cintra130\": 0.9745722433460076,\n",
    "  \"Test:Cintra131\": 0.985258847616262,\n",
    "  \"Test:Cintra133\": 0.9369907658881044,\n",
    "  \"Test:Cintra134\": 0.9424472865537504,\n",
    "  \"Test:Cintra135\": 0.9163498098859316,\n",
    "  \"Test:Cintra136\": 0.9566092596734512,\n",
    "  \"Test:Cintra141\": 0.8073510773130544,\n",
    "  \"Test:Cintra142\": 0.9910127894918772,\n",
    "  \"Test:Cintra143\": 0.9787417905288628,\n",
    "  \"Test:Cintra144\": 0.9883555133079848,\n",
    "  \"Test:Cintra145\": 0.988593155893536,\n",
    "  \"Test:Cintra146\": 0.9371420320546764,\n",
    "  \"Test:Cintra148\": 0.9712206634325424,\n",
    "  \"Test:Cintra149\": 0.9927289707157628,\n",
    "  \"Test:Cintra150\": 0.979619771863118,\n",
    "  \"Test:Cintra151\": 0.9991183115666502,\n",
    "  \"Test:Cintra152\": 0.9714828897338402,\n",
    "  \"Test:Cintra153\": 0.9977689092794524,\n",
    "  \"Test:Cintra154\": 0.9440304182509504,\n",
    "  \"Test:Cintra155\": 0.98696360673547,\n",
    "  \"Test:Cintra156\": 0.9948557369715948,\n",
    "  \"Test:Cintra157\": 0.959388398996845,\n",
    "  \"Test:Cintra158\": 0.9989562364869902,\n",
    "  \"Test:Cintra159\": 0.9916349809885932,\n",
    "  \"Test:Cintra160\": 0.9641499185225422,\n",
    "  \"Test:Cintra161\": 0.9973828452915906,\n",
    "  \"Test:Cintra162\": 0.9929386203150462,\n",
    "  \"Test:Cintra163\": 0.9868163888987604,\n",
    "  \"Test:Cintra164\": 0.9987992795677406,\n",
    "  \"Test:Cintra165\": 0.9919079652919964,\n",
    "  \"Test:Cintra166\": 0.9896795219989136,\n",
    "  \"Test:Cintra167\": 0.976559131355102,\n",
    "  \"Test:Cintra168\": 0.9845880861850452,\n",
    "  \"Test:Cintra169\": 0.979800380228137,\n",
    "  \"Test:Cintra170\": 0.997558535121073,\n",
    "  \"Test:Cintra171\": 0.9754286534184672,\n",
    "  \"Test:Cintra172\": 0.9716032150936136,\n",
    "  \"Test:Cintra173\": 0.9973177705072662,\n",
    "  \"Test:Cintra174\": 0.998370450841934,\n",
    "  \"Test:Cintra175\": 0.9934516265314746,\n",
    "  \"Test:Cintra176\": 0.9750739332488384,\n",
    "  \"Test:Cintra177\": 0.9886406844106465,\n",
    "  \"Test:Cintra178\": 0.998068682479329,\n",
    "  \"Test:Cintra179\": 0.9876158089219732,\n",
    "  \"Test:Cintra180\": 0.9972161868549708,\n",
    "  \"Test:Cintra181\": 0.9930664280921496,\n",
    "  \"Test:Cintra182\": 0.9833967046894808,\n",
    "  \"Test:Cintra183\": 0.9982819321222366,\n",
    "  \"Test:Cintra184\": 0.9748035487959448,\n",
    "  \"Test:Cintra185\": 0.8836501901140683,\n",
    "  \"Test:Cintra186\": 0.9982335858207844,\n",
    "  \"Test:Cintra187\": 0.999049429657795,\n",
    "  \"Test:Cintra188\": 0.993723218057819,\n",
    "  \"Test:Cintra189\": 0.9736630969407336,\n",
    "  \"Test:Cintra190\": 0.9937135614702156,\n",
    "  \"Test:Cintra191\": 0.9722855935783694,\n",
    "  \"Test:Cintra192\": 0.9740611490181784,\n",
    "  \"Test:Cintra193\": 0.9835958718088008,\n",
    "  \"Test:Cintra194\": 0.9956025789386675,\n",
    "  \"Test:Cintra195\": 0.9797718631178708,\n",
    "  \"Test:Cintra196\": 0.989287348342616,\n",
    "  \"Test:Cintra197\": 0.955133079847909,\n",
    "  \"Test:Cintra198\": 0.95162653147444,\n",
    "  \"Test:Cintra199\": 0.9904271974949678,\n",
    "  \"Test:Cintra200\": 0.9974546711497976,\n",
    "  \"Test:Cintra201\": 0.9934108192188044,\n",
    "  \"Test:Cintra202\": 0.9884935328009036,\n",
    "  \"Test:Cintra203\": 0.9956344176876496,\n",
    "  \"Test:Cintra204\": 0.9996630889926358,\n",
    "  \"Test:Cintra205\": 0.9504819170572112,\n",
    "  \"Test:Cintra206\": 0.9937726415376792,\n",
    "  \"Test:Cintra207\": 0.9843243909308528,\n",
    "  \"Test:Cintra208\": 0.9995434408862952,\n",
    "  \"Test:Cintra209\": 0.9892231196706188,\n",
    "  \"Test:Cintra210\": 0.991660189483856,\n",
    "  \"Test:Cintra211\": 0.9952176274708922,\n",
    "  \"Test:Cintra212\": 0.9985695597422762,\n",
    "  \"Test:Cintra213\": 0.9924521877305488,\n",
    "  \"Test:Cintra214\": 0.9898637916927352,\n",
    "  \"Test:Cintra215\": 0.997156554802446,\n",
    "  \"Test:Cintra216\": 0.9867514258555138,\n",
    "  \"Test:Cintra217\": 0.9907195502135356,\n",
    "  \"Test:Cintra218\": 0.9925342066553804,\n",
    "  \"Test:Cintra219\": 0.9952201944985496,\n",
    "  \"Test:Cintra220\": 0.9997080925720776,\n",
    "  \"Test:Cintra221\": 0.9937737642585556,\n",
    "  \"Test:Cintra222\": 0.9913848308985383,\n",
    "  \"Test:Cintra223\": 0.9863806214763312,\n",
    "  \"Test:Cintra224\": 0.9956796055655364,\n",
    "  \"Test:Cintra225\": 0.9997915415916214,\n",
    "  \"Test:Cintra226\": 0.998986582031862,\n",
    "  \"Test:Cintra227\": 0.9992373330975328,\n",
    "  \"Test:Cintra228\": 0.986046985334058,\n",
    "  \"Test:Cintra229\": 0.994151542471872,\n",
    "  \"Test:Cintra230\": 0.9945803302877212,\n",
    "  \"Test:Cintra231\": 0.9884724485484906,\n",
    "  \"Test:Cintra232\": 0.9996713282206598,\n",
    "  \"Test:Cintra233\": 0.9952554141180364,\n",
    "  \"Test:Cintra234\": 0.9909108811900648,\n",
    "  \"Test:Cintra235\": 0.9922888934761904,\n",
    "  \"Test:Cintra236\": 0.9988664408184944,\n",
    "  \"Test:Cintra237\": 0.9999805343957228,\n",
    "  \"Test:Cintra238\": 0.999644948259278,\n",
    "  \"Test:Cintra239\": 0.9998008940499432,\n",
    "  \"Test:Cintra240\": 0.9946419570236412,\n",
    "  \"Test:Cintra241\": 0.997118583650187,\n",
    "  \"Test:Cintra242\": 0.9906354292925068,\n",
    "  \"Test:Cintra243\": 0.9986555133079844,\n",
    "  \"Test:Cintra244\": 0.9937155893536108,\n",
    "  \"Test:Cintra245\": 0.998238649071794,\n",
    "  \"Test:Cintra246\": 0.9991077679098432,\n",
    "  \"Test:Cintra247\": 0.9905098979669062,\n",
    "  \"Test:Cintra248\": 0.998428577441666,\n",
    "  \"Test:Cintra249\": 0.9970999548881874,\n",
    "  \"Test:Cintra25\": 0.9011406844106464,\n",
    "  \"Test:Cintra250\": 0.994548536350726,\n",
    "  \"Test:Cintra251\": 0.9941556913223728,\n",
    "  \"Test:Cintra252\": 0.9969941424314044,\n",
    "  \"Test:Cintra253\": 0.9989326929491028,\n",
    "  \"Test:Cintra254\": 0.995261902152377,\n",
    "  \"Test:Cintra255\": 0.9844649646931009,\n",
    "  \"Test:Cintra256\": 0.9932580693790716,\n",
    "  \"Test:Cintra257\": 0.9972628528257022,\n",
    "  \"Test:Cintra258\": 0.9999876147186684,\n",
    "  \"Test:Cintra259\": 0.996629657794674,\n",
    "  \"Test:Cintra260\": 0.9922048344688004,\n",
    "  \"Test:Cintra261\": 0.9966445846889564,\n",
    "  \"Test:Cintra262\": 0.998749619644012,\n",
    "  \"Test:Cintra263\": 0.9997189443549964,\n",
    "  \"Test:Cintra264\": 0.9972448916504352,\n",
    "  \"Test:Cintra27\": 0.6159695817490495,\n",
    "  \"Test:Cintra31\": 0.8821292775665399,\n",
    "  \"Test:Cintra34\": 0.020278833967046897,\n",
    "  \"Test:Cintra38\": 0.5285171102661597,\n",
    "  \"Test:Cintra39\": 0.015209125475285173,\n",
    "  \"Test:Cintra40\": 0.8010139416983524,\n",
    "  \"Test:Cintra41\": 0.01140684410646388,\n",
    "  \"Test:Cintra44\": 0.752851711026616,\n",
    "  \"Test:Cintra47\": 0.8517110266159695,\n",
    "  \"Test:Cintra48\": 0.6596958174904943,\n",
    "  \"Test:Cintra51\": 0.855513307984791,\n",
    "  \"Test:Cintra55\": 0.9543726235741444,\n",
    "  \"Test:Cintra57\": 0.6863117870722433,\n",
    "  \"Test:Cintra58\": 0.900190114068441,\n",
    "  \"Test:Cintra60\": 0.7338403041825095,\n",
    "  \"Test:Cintra63\": 0.9746514575411912,\n",
    "  \"Test:Cintra65\": 0.8174904942965779,\n",
    "  \"Test:Cintra67\": 0.6692015209125475,\n",
    "  \"Test:Cintra70\": 0.832699619771863,\n",
    "  \"Test:Cintra71\": 0.17490494296577946,\n",
    "  \"Test:Cintra75\": 0.8149556400506971,\n",
    "  \"Test:Cintra78\": 0.015209125475285173,\n",
    "  \"Test:Cintra79\": 0.9182509505703422,\n",
    "  \"Test:Cintra80\": 0.9967409016838674,\n",
    "  \"Test:Cintra81\": 0.7547528517110266,\n",
    "  \"Test:Cintra82\": 0.844106463878327,\n",
    "  \"Test:Cintra83\": 0.8745247148288973,\n",
    "  \"Test:Cintra84\": 0.01406844106463878,\n",
    "  \"Test:Cintra85\": 0.7239543726235742,\n",
    "  \"Test:Cintra89\": 0.7566539923954373,\n",
    "  \"Test:Cintra91\": 0.8054499366286438,\n",
    "  \"Test:Cintra93\": 0.7934093789607098,\n",
    "  \"Test:Cintra94\": 0.8761256754052432,\n",
    "  \"Test:Cintra95\": 1,\n",
    "  \"Test:Cintra97\": 0.863661053775122,\n",
    "  \"Test:Cintra98\": 0.9564321926489228,\n",
    "  \"Test:Cintra99\": 0.8783269961977186,\n",
    "  \"Test:base_Cinter\": 0.8626828301681702,\n",
    "  \"Test:base_Cinter+0\": 0.8549209927966827,\n",
    "  \"Test:base_Cinter+1\": 0.8549209927966827,\n",
    "  \"Test:base_Cinter+10\": 0.8498032617479898,\n",
    "  \"Test:base_Cinter+13\": 0.848335813082052,\n",
    "  \"Test:base_Cinter+16\": 0.8504674233111297,\n",
    "  \"Test:base_Cinter+19\": 0.8518284716003348,\n",
    "  \"Test:base_Cinter+2\": 0.8554057884602225,\n",
    "  \"Test:base_Cinter+3\": 0.8562878467821434,\n",
    "  \"Test:base_Cinter+4\": 0.8553855002076877,\n",
    "  \"Test:base_Cinter+7\": 0.8501297603959204,\n",
    "  \"Test:base_Cintra100\": 0.376425855513308,\n",
    "  \"Test:base_Cintra101\": 0.38022813688212925,\n",
    "  \"Test:base_Cintra104\": 0.3916349809885931,\n",
    "  \"Test:base_Cintra106\": 0.3992395437262359,\n",
    "  \"Test:base_Cintra107\": 0.4030418250950571,\n",
    "  \"Test:base_Cintra11\": 0.03802281368821293,\n",
    "  \"Test:base_Cintra110\": 0.41444866920152096,\n",
    "  \"Test:base_Cintra112\": 0.4220532319391635,\n",
    "  \"Test:base_Cintra113\": 0.4258555133079848,\n",
    "  \"Test:base_Cintra114\": 0.4296577946768061,\n",
    "  \"Test:base_Cintra115\": 0.4334600760456273,\n",
    "  \"Test:base_Cintra116\": 0.4372623574144487,\n",
    "  \"Test:base_Cintra118\": 0.4448669201520912,\n",
    "  \"Test:base_Cintra119\": 0.44866920152091183,\n",
    "  \"Test:base_Cintra120\": 0.45247148288973377,\n",
    "  \"Test:base_Cintra121\": 0.4562737642585551,\n",
    "  \"Test:base_Cintra123\": 0.4638783269961979,\n",
    "  \"Test:base_Cintra124\": 0.467680608365019,\n",
    "  \"Test:base_Cintra126\": 0.4752851711026616,\n",
    "  \"Test:base_Cintra127\": 0.479087452471483,\n",
    "  \"Test:base_Cintra129\": 0.48669201520912553,\n",
    "  \"Test:base_Cintra130\": 0.49049429657794685,\n",
    "  \"Test:base_Cintra131\": 0.49429657794676896,\n",
    "  \"Test:base_Cintra133\": 0.5019011406844106,\n",
    "  \"Test:base_Cintra134\": 0.5057034220532319,\n",
    "  \"Test:base_Cintra135\": 0.5095057034220533,\n",
    "  \"Test:base_Cintra136\": 0.5133079847908741,\n",
    "  \"Test:base_Cintra141\": 0.532319391634981,\n",
    "  \"Test:base_Cintra142\": 0.536121673003802,\n",
    "  \"Test:base_Cintra143\": 0.539923954372624,\n",
    "  \"Test:base_Cintra144\": 0.5437262357414447,\n",
    "  \"Test:base_Cintra145\": 0.5475285171102662,\n",
    "  \"Test:base_Cintra146\": 0.5513307984790876,\n",
    "  \"Test:base_Cintra148\": 0.5589353612167296,\n",
    "  \"Test:base_Cintra149\": 0.5627376425855521,\n",
    "  \"Test:base_Cintra150\": 0.5665399239543727,\n",
    "  \"Test:base_Cintra151\": 0.5703422053231935,\n",
    "  \"Test:base_Cintra152\": 0.5741444866920152,\n",
    "  \"Test:base_Cintra153\": 0.5779467680608357,\n",
    "  \"Test:base_Cintra154\": 0.5817490494296573,\n",
    "  \"Test:base_Cintra155\": 0.5855513307984791,\n",
    "  \"Test:base_Cintra156\": 0.5893536121673008,\n",
    "  \"Test:base_Cintra157\": 0.5931558935361212,\n",
    "  \"Test:base_Cintra158\": 0.5969581749049425,\n",
    "  \"Test:base_Cintra159\": 0.6007604562737643,\n",
    "  \"Test:base_Cintra160\": 0.6045627376425854,\n",
    "  \"Test:base_Cintra161\": 0.6083650190114078,\n",
    "  \"Test:base_Cintra162\": 0.6121673003802284,\n",
    "  \"Test:base_Cintra163\": 0.615969581749049,\n",
    "  \"Test:base_Cintra164\": 0.6197718631178707,\n",
    "  \"Test:base_Cintra165\": 0.6235741444866912,\n",
    "  \"Test:base_Cintra166\": 0.6273764258555133,\n",
    "  \"Test:base_Cintra167\": 0.6311787072243358,\n",
    "  \"Test:base_Cintra168\": 0.6349809885931562,\n",
    "  \"Test:base_Cintra169\": 0.6387832699619767,\n",
    "  \"Test:base_Cintra170\": 0.642585551330798,\n",
    "  \"Test:base_Cintra171\": 0.6463878326996174,\n",
    "  \"Test:base_Cintra172\": 0.6501901140684417,\n",
    "  \"Test:base_Cintra173\": 0.653992395437262,\n",
    "  \"Test:base_Cintra174\": 0.6577946768060839,\n",
    "  \"Test:base_Cintra175\": 0.6615969581749045,\n",
    "  \"Test:base_Cintra176\": 0.6653992395437258,\n",
    "  \"Test:base_Cintra177\": 0.6692015209125464,\n",
    "  \"Test:base_Cintra178\": 0.6730038022813708,\n",
    "  \"Test:base_Cintra179\": 0.6768060836501868,\n",
    "  \"Test:base_Cintra180\": 0.6806083650190117,\n",
    "  \"Test:base_Cintra181\": 0.6844106463878322,\n",
    "  \"Test:base_Cintra182\": 0.6882129277566531,\n",
    "  \"Test:base_Cintra183\": 0.6920152091254733,\n",
    "  \"Test:base_Cintra184\": 0.6958174904942973,\n",
    "  \"Test:base_Cintra185\": 0.6996197718631177,\n",
    "  \"Test:base_Cintra186\": 0.7034220532319374,\n",
    "  \"Test:base_Cintra187\": 0.7072243346007637,\n",
    "  \"Test:base_Cintra188\": 0.7110266159695826,\n",
    "  \"Test:base_Cintra189\": 0.7148288973384025,\n",
    "  \"Test:base_Cintra190\": 0.718631178707225,\n",
    "  \"Test:base_Cintra191\": 0.7224334600760467,\n",
    "  \"Test:base_Cintra192\": 0.7262357414448671,\n",
    "  \"Test:base_Cintra193\": 0.7300380228136875,\n",
    "  \"Test:base_Cintra194\": 0.7338403041825081,\n",
    "  \"Test:base_Cintra195\": 0.7376425855513306,\n",
    "  \"Test:base_Cintra196\": 0.7414448669201497,\n",
    "  \"Test:base_Cintra197\": 0.7452471482889734,\n",
    "  \"Test:base_Cintra198\": 0.7490494296577949,\n",
    "  \"Test:base_Cintra199\": 0.7528517110266153,\n",
    "  \"Test:base_Cintra200\": 0.7566539923954361,\n",
    "  \"Test:base_Cintra201\": 0.7604562737642592,\n",
    "  \"Test:base_Cintra202\": 0.764258555133078,\n",
    "  \"Test:base_Cintra203\": 0.7680608365019019,\n",
    "  \"Test:base_Cintra204\": 0.7718631178707158,\n",
    "  \"Test:base_Cintra205\": 0.7756653992395429,\n",
    "  \"Test:base_Cintra206\": 0.7794676806083684,\n",
    "  \"Test:base_Cintra207\": 0.7832699619771852,\n",
    "  \"Test:base_Cintra208\": 0.7870722433460138,\n",
    "  \"Test:base_Cintra209\": 0.790874524714831,\n",
    "  \"Test:base_Cintra210\": 0.794676806083648,\n",
    "  \"Test:base_Cintra211\": 0.7984790874524759,\n",
    "  \"Test:base_Cintra212\": 0.8022813688212963,\n",
    "  \"Test:base_Cintra213\": 0.8060836501901127,\n",
    "  \"Test:base_Cintra214\": 0.8098859315589376,\n",
    "  \"Test:base_Cintra215\": 0.8136882129277554,\n",
    "  \"Test:base_Cintra216\": 0.817490494296578,\n",
    "  \"Test:base_Cintra217\": 0.8212927756654119,\n",
    "  \"Test:base_Cintra218\": 0.8250950570342191,\n",
    "  \"Test:base_Cintra219\": 0.8288973384030506,\n",
    "  \"Test:base_Cintra220\": 0.8326996197718595,\n",
    "  \"Test:base_Cintra221\": 0.8365019011406819,\n",
    "  \"Test:base_Cintra222\": 0.8403041825095002,\n",
    "  \"Test:base_Cintra223\": 0.8441064638783322,\n",
    "  \"Test:base_Cintra224\": 0.8479087452471428,\n",
    "  \"Test:base_Cintra225\": 0.8517110266159725,\n",
    "  \"Test:base_Cintra226\": 0.8555133079847834,\n",
    "  \"Test:base_Cintra227\": 0.8593155893536092,\n",
    "  \"Test:base_Cintra228\": 0.8631178707224335,\n",
    "  \"Test:base_Cintra229\": 0.8669201520912636,\n",
    "  \"Test:base_Cintra230\": 0.8707224334600675,\n",
    "  \"Test:base_Cintra231\": 0.8745247148289041,\n",
    "  \"Test:base_Cintra232\": 0.8783269961977118,\n",
    "  \"Test:base_Cintra233\": 0.8821292775665415,\n",
    "  \"Test:base_Cintra234\": 0.8859315589353532,\n",
    "  \"Test:base_Cintra235\": 0.8897338403041877,\n",
    "  \"Test:base_Cintra236\": 0.8935361216729947,\n",
    "  \"Test:base_Cintra237\": 0.8973384030418267,\n",
    "  \"Test:base_Cintra238\": 0.901140684410634,\n",
    "  \"Test:base_Cintra239\": 0.9049429657794688,\n",
    "  \"Test:base_Cintra240\": 0.908745247148278,\n",
    "  \"Test:base_Cintra241\": 0.9125475285171164,\n",
    "  \"Test:base_Cintra242\": 0.9163498098859406,\n",
    "  \"Test:base_Cintra243\": 0.9201520912547496,\n",
    "  \"Test:base_Cintra244\": 0.923954372623586,\n",
    "  \"Test:base_Cintra245\": 0.9277566539923904,\n",
    "  \"Test:base_Cintra246\": 0.9315589353612244,\n",
    "  \"Test:base_Cintra247\": 0.9353612167300316,\n",
    "  \"Test:base_Cintra248\": 0.9391634980988668,\n",
    "  \"Test:base_Cintra249\": 0.9429657794676788,\n",
    "  \"Test:base_Cintra25\": 0.09125475285171104,\n",
    "  \"Test:base_Cintra250\": 0.9467680608365008,\n",
    "  \"Test:base_Cintra251\": 0.950570342205312,\n",
    "  \"Test:base_Cintra252\": 0.9543726235741544,\n",
    "  \"Test:base_Cintra253\": 0.9581749049429704,\n",
    "  \"Test:base_Cintra254\": 0.961977186311795,\n",
    "  \"Test:base_Cintra255\": 0.9657794676806072,\n",
    "  \"Test:base_Cintra256\": 0.9695817490494358,\n",
    "  \"Test:base_Cintra257\": 0.9733840304182504,\n",
    "  \"Test:base_Cintra258\": 0.9771863117870776,\n",
    "  \"Test:base_Cintra259\": 0.9809885931558822,\n",
    "  \"Test:base_Cintra260\": 0.984790874524719,\n",
    "  \"Test:base_Cintra261\": 0.9885931558935528,\n",
    "  \"Test:base_Cintra262\": 0.9923954372623228,\n",
    "  \"Test:base_Cintra263\": 0.9961977186311592,\n",
    "  \"Test:base_Cintra264\": 1,\n",
    "  \"Test:base_Cintra27\": 0.0988593155893536,\n",
    "  \"Test:base_Cintra31\": 0.1140684410646388,\n",
    "  \"Test:base_Cintra34\": 0.12547528517110265,\n",
    "  \"Test:base_Cintra38\": 0.14068441064638784,\n",
    "  \"Test:base_Cintra39\": 0.1444866920152091,\n",
    "  \"Test:base_Cintra40\": 0.1482889733840304,\n",
    "  \"Test:base_Cintra41\": 0.1520912547528517,\n",
    "  \"Test:base_Cintra44\": 0.1634980988593156,\n",
    "  \"Test:base_Cintra47\": 0.17490494296577946,\n",
    "  \"Test:base_Cintra48\": 0.17870722433460076,\n",
    "  \"Test:base_Cintra51\": 0.19011406844106463,\n",
    "  \"Test:base_Cintra55\": 0.20532319391634984,\n",
    "  \"Test:base_Cintra57\": 0.2129277566539924,\n",
    "  \"Test:base_Cintra58\": 0.21673003802281368,\n",
    "  \"Test:base_Cintra60\": 0.22433460076045628,\n",
    "  \"Test:base_Cintra63\": 0.23574144486692017,\n",
    "  \"Test:base_Cintra65\": 0.2433460076045627,\n",
    "  \"Test:base_Cintra67\": 0.2509505703422053,\n",
    "  \"Test:base_Cintra70\": 0.2623574144486692,\n",
    "  \"Test:base_Cintra71\": 0.2661596958174905,\n",
    "  \"Test:base_Cintra75\": 0.2813688212927757,\n",
    "  \"Test:base_Cintra78\": 0.29277566539923955,\n",
    "  \"Test:base_Cintra79\": 0.2965779467680608,\n",
    "  \"Test:base_Cintra80\": 0.3003802281368821,\n",
    "  \"Test:base_Cintra81\": 0.3041825095057034,\n",
    "  \"Test:base_Cintra82\": 0.30798479087452474,\n",
    "  \"Test:base_Cintra83\": 0.311787072243346,\n",
    "  \"Test:base_Cintra84\": 0.3155893536121673,\n",
    "  \"Test:base_Cintra85\": 0.3193916349809886,\n",
    "  \"Test:base_Cintra89\": 0.33460076045627374,\n",
    "  \"Test:base_Cintra91\": 0.34220532319391633,\n",
    "  \"Test:base_Cintra93\": 0.349809885931559,\n",
    "  \"Test:base_Cintra94\": 0.3536121673003801,\n",
    "  \"Test:base_Cintra95\": 0.3574144486692015,\n",
    "  \"Test:base_Cintra97\": 0.3650190114068441,\n",
    "  \"Test:base_Cintra98\": 0.3688212927756655,\n",
    "  \"Test:base_Cintra99\": 0.3726235741444867,\n",
    "  \"_runtime\": 1564.4211275577543,\n",
    "  \"_step\": 0,\n",
    "  \"_timestamp\": 1738600508.0473976,\n",
    "  \"_wandb.runtime\": 1568,\n",
    "  \"epoch\": 0,\n",
    "  \"test_loss\": -23.58771514892578,\n",
    "  \"test_loss_desurv\": -20.35793685913086,\n",
    "  \"test_loss_values\": -55.8855094909668,\n",
    "  \"trainer/global_step\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f4754-a482-483f-b4c0-ba4824bf79af",
   "metadata": {},
   "source": [
    "# Next event concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba935a0f-f700-4bf0-974f-b3804415b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cinter_keys = [_key for _key in raw_data_from_wandb.keys() if \"Test:Cintra\" in _key ]\n",
    "\n",
    "decoded_cintra_diagnoses = {}\n",
    "decoded_cintra_other = {}\n",
    "\n",
    "for _key in Cinter_keys:\n",
    "    _event = int(_key[len(\"Test:Cintra\"):])                 # token\n",
    "    _event_name = dm.decode([_event]).split(\" \")[0]         # string\n",
    "    _event_cintra = raw_data_from_wandb[_key]               # concordance\n",
    "\n",
    "    if _event_name.upper() == _event_name:\n",
    "        decoded_cintra_diagnoses = {**decoded_cintra_diagnoses, _event_name: _event_cintra}\n",
    "    else:\n",
    "        decoded_cintra_other = {**decoded_cintra_other, _event_name: _event_cintra}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc76e749-8d83-42ce-8d19-1af25d11bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(decoded_cintra_diagnoses)\n",
    "# display(decoded_cintra_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b196c186-8b32-440b-9b11-143910078375",
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseCinter_keys = [_key for _key in raw_data_from_wandb.keys() if \"Test:base_Cintra\" in _key ]\n",
    "\n",
    "base_decoded_cintra_diagnoses = {}\n",
    "base_decoded_cintra_other = {}\n",
    "base_prevalence_diagnoses = {}\n",
    "base_prevalence_other = {}\n",
    "\n",
    "for _key in BaseCinter_keys:\n",
    "    _event = int(_key[len(\"Test:base_Cintra\"):])                 # token\n",
    "    _event_name = dm.decode([_event]).split(\" \")[0]         # string\n",
    "    _event_cintra = raw_data_from_wandb[_key]               # concordance\n",
    "\n",
    "    prevalence = dm.tokenizer._event_counts\n",
    "    prevalence = prevalence.filter(pl.col(\"EVENT\") ==_event_name)[\"COUNT\"][0]\n",
    "\n",
    "    if _event_name.upper() == _event_name:\n",
    "        base_decoded_cintra_diagnoses = {**base_decoded_cintra_diagnoses, _event_name: _event_cintra}\n",
    "        base_prevalence_diagnoses = {**base_prevalence_diagnoses, _event_name: prevalence}\n",
    "    else:\n",
    "        base_decoded_cintra_other = {**base_decoded_cintra_other, _event_name: _event_cintra}\n",
    "        base_prevalence_other = {**base_prevalence_other, _event_name: prevalence}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0258566-9f3c-440f-8e26-a628af9ca03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(base_decoded_cintra_diagnoses)\n",
    "# display(base_decoded_cintra_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c52e4962-be5c-451a-84fe-0bfd016f5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_included_diagnoses = list(set(base_decoded_cintra_diagnoses.keys()) & set(decoded_cintra_diagnoses.keys()))\n",
    "keys_included_other = list(set(base_decoded_cintra_other.keys()) & set(decoded_cintra_other.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25187e0e-ecd7-49e9-b715-99cf1248bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_name, result_dict, result_dict_base, result_dict_prev, keys_to_include in zip([\"diagnoses\", \"other\"],\n",
    "                                                                     [decoded_cintra_diagnoses, decoded_cintra_other], \n",
    "                                                                     [base_decoded_cintra_diagnoses, base_decoded_cintra_other], \n",
    "                                                                     [base_prevalence_diagnoses, base_prevalence_other],\n",
    "                                                                     [keys_included_diagnoses, keys_included_other]\n",
    "                                                                     ):\n",
    "    # plt.figure(figsize=(len(keys_to_include)/5,5))\n",
    "    fig, ax1 = plt.subplots(figsize=(len(keys_to_include)/4,8))\n",
    "    ax2 = ax1.twinx()  \n",
    "\n",
    "    X_axis = np.arange(len(keys_to_include)) \n",
    "\n",
    "    Y_base = [result_dict_base[_key] for _key in keys_to_include]\n",
    "    Y_survivEHR = [result_dict[_key] for _key in keys_to_include]\n",
    "    Y_log_prevalence = [np.log(result_dict_prev[_key]) for _key in keys_to_include]\n",
    "    # print(Y_log_prevalence)\n",
    "    # print(np.min(Y_log_prevalence))\n",
    "    # print(np.max(Y_log_prevalence))\n",
    "\n",
    "    # Sort by prevalence\n",
    "    arg_sort = np.argsort(Y_log_prevalence)\n",
    "    Y_base = [Y_base[_i] for _i in arg_sort]\n",
    "    Y_survivEHR = [Y_survivEHR[_i] for _i in arg_sort]\n",
    "    Y_log_prevalence = [Y_log_prevalence[_i] for _i in arg_sort]\n",
    "    keys_to_include = [keys_to_include[_i] for _i in arg_sort]\n",
    "\n",
    "    width = 0.25\n",
    "    ax1.bar(X_axis - width, Y_base, width, label = 'Concordance by prevalence', color=\"mediumblue\") \n",
    "    ax1.bar(X_axis, Y_survivEHR, width, label = 'Concordance by SurvivEHR', color=\"firebrick\") \n",
    "    ax2.bar(X_axis + width, Y_log_prevalence, width, label = 'Log-prevalence', color=\"darkseagreen\") \n",
    "\n",
    "    ax1.set_xticks(X_axis, keys_to_include, rotation=90) \n",
    "    # ax1.xticks(X_axis, keys_to_include) \n",
    "    ax1.set_xlabel(\"Events\") \n",
    "    ax1.set_ylabel(\"Self-supervised Concordance\") \n",
    "    ax2.set_ylabel(\"Log Prevalence\") \n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax1.set_ylim(0, 1.2)\n",
    "    ax2.set_ylim(np.min(Y_log_prevalence)*0.95, np.max(Y_log_prevalence)*1.1)\n",
    "    \n",
    "\n",
    "    # plt.bar(result_dict.keys(), result_dict.values(), 0.5, color='g')\n",
    "    # ax1.xticks()\n",
    "\n",
    "    ybar = raw_data_from_wandb[\"Test:Cinter\"]\n",
    "    ax1.plot([0, len(result_dict)-1], \n",
    "             [ybar, ybar],\n",
    "             label=f\"SurvivEHR marginalised over events\",\n",
    "             color=\"firebrick\")\n",
    "\n",
    "    ybar = raw_data_from_wandb[\"Test:base_Cinter\"]\n",
    "    ax1.plot([0, len(result_dict)-1], \n",
    "             [ybar, ybar],\n",
    "             label=f\"Prevalence marginalised over events\",\n",
    "             color=\"mediumblue\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figs/{pre_trained_model}_inter_causal_eval_{dict_name}.png\", bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a725dee-47bd-4b49-848a-9454c7a5b73c",
   "metadata": {},
   "source": [
    "# Future events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aee3da8-7cad-4ca9-9014-aefe689bc1e9",
   "metadata": {},
   "source": [
    "## SurvivEHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb31808-b4f2-475f-b0c4-2a41dd451561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test:Cinter+0', 'Test:Cinter+1', 'Test:Cinter+10', 'Test:Cinter+13', 'Test:Cinter+16', 'Test:Cinter+19', 'Test:Cinter+2', 'Test:Cinter+3', 'Test:Cinter+4', 'Test:Cinter+7']\n",
      "[1, 2, 3, 4, 5, 8, 11, 14, 17, 20]\n",
      "[0.9845138238722124, 0.9366127214016844, 0.9158513102720236, 0.899843080451446, 0.868315386991299, 0.8239121250528096, 0.8252010439713312, 0.7866451755111037, 0.7641013179336177, 0.7604122318951223]\n"
     ]
    }
   ],
   "source": [
    "Cinter_keys = [_key for _key in raw_data_from_wandb.keys() if \"+\" in _key and \"base\" not in _key ]\n",
    "print(Cinter_keys)\n",
    "\n",
    "x_survivEHR, y_survivEHR = [], []\n",
    "for _key in Cinter_keys:\n",
    "    x_survivEHR.append(int(_key[len(\"Test:Cinter+\"):]) + 1 )                # steps ahead\n",
    "    y_survivEHR.append(raw_data_from_wandb[_key] )                   # concordance\n",
    "\n",
    "\n",
    "arg_sort = np.argsort(x_survivEHR)\n",
    "x_survivEHR = [x_survivEHR[_i] for _i in arg_sort]\n",
    "y_survivEHR = [y_survivEHR[_i] for _i in arg_sort]\n",
    "\n",
    "print(x_survivEHR)\n",
    "print(y_survivEHR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f726c877-af90-43e9-a6ef-eb213bd0530e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test:base_Cinter+0', 'Test:base_Cinter+1', 'Test:base_Cinter+10', 'Test:base_Cinter+13', 'Test:base_Cinter+16', 'Test:base_Cinter+19', 'Test:base_Cinter+2', 'Test:base_Cinter+3', 'Test:base_Cinter+4', 'Test:base_Cinter+7']\n"
     ]
    }
   ],
   "source": [
    "Cinter_keys = [_key for _key in raw_data_from_wandb.keys() if \"+\" in _key and \"base\" in _key ]\n",
    "print(Cinter_keys)\n",
    "\n",
    "x_base, y_base = [], []\n",
    "for _key in Cinter_keys:\n",
    "    x_base.append(int(_key[len(\"Test:base_Cinter+\"):]) + 1 )                # steps ahead\n",
    "    y_base.append(raw_data_from_wandb[_key] )                   # concordance\n",
    "\n",
    "arg_sort = np.argsort(x_base)\n",
    "x_base = [x_base[_i] for _i in arg_sort]\n",
    "y_base = [y_base[_i] for _i in arg_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b858192c-6bc3-4382-8a5e-750c2caf19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "plt.plot(x_survivEHR, y_survivEHR,\n",
    "         label=f\"SurvivEHR decay\",\n",
    "         color=\"firebrick\")\n",
    "\n",
    "plt.plot(x_base, y_base,\n",
    "         label=f\"Prevalence prognosis decay\",\n",
    "         color=\"mediumblue\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figs/{pre_trained_model}_inter_decay.png\", bbox_inches=\"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043f7cc-4b9f-462a-a38d-a3c5dd0817bc",
   "metadata": {},
   "source": [
    "## Comparison of decay across different pre-trained runs\n",
    "\n",
    "Note: These are not fair comparisons as each run has been trained with different learning schedulers and for different lengths of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d48123e-d837-4158-bedb-5cc991d267d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_survivEHR = {\n",
    "    \"SurvivEHR-cr-small-v1\": (\n",
    "        \"baseline: 11M, 384 latent\",\n",
    "        [1, 2, 3, 4, 5, 8, 11, 14, 17, 20],\n",
    "        [0.9845138238722124, 0.9366127214016844, 0.9158513102720236, 0.899843080451446, 0.868315386991299, 0.8239121250528096, 0.8252010439713312, 0.7866451755111037, 0.7641013179336177, 0.7604122318951223]\n",
    "        ),\n",
    "    \"SurvivEHR-cr-small-192\": (\n",
    "        \"11M, 192 latent\",\n",
    "        [1, 2, 3, 4, 5, 8, 11, 14, 17, 20], \n",
    "        [0.9530637980778408, 0.8965454649674218, 0.8732735785430125, 0.8556641921660932, 0.8248607427761983, 0.761096022692981, 0.7637418688146687, 0.7261393067724697, 0.7002773092426885, 0.7196441416973737]\n",
    "        ),\n",
    "    \"SurvivEHR-cr-384-v1\": (\n",
    "        \"129M, 384 latent\",\n",
    "        [1, 2, 3, 4, 5, 8, 11, 14, 17, 20],\n",
    "        [0.9707854863671966, 0.9347402411296004, 0.9142678409102016, 0.8998330215060252, 0.8802228115580834, 0.8381073088297424, 0.856944131635776, 0.8165261475726017, 0.8077417879299013, 0.8017675470146958]\n",
    "        ),\n",
    "    \"crPreTrain_small_1337\": (\n",
    "        \"1M, 192 latent\",\n",
    "        [1, 2, 3, 4, 5, 8, 11, 14, 17, 20],\n",
    "        [0.9785524581080296, 0.9322563387278594, 0.9193310330671408, 0.8942603657432556, 0.8602421957376115, 0.808292594604382, 0.8126680886580727, 0.7806386730589077, 0.7502644443809143, 0.7436763216230898]\n",
    "        ),\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267a335-58f9-4f48-85ab-3e3c84044b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "for run_id in all_survivEHR.keys():\n",
    "\n",
    "    plt.plot(all_survivEHR[run_id][1], all_survivEHR[run_id][2],\n",
    "             label=f\"{all_survivEHR[run_id][0]}\")\n",
    "\n",
    "plt.plot(x_base, y_base,\n",
    "         label=f\"Prevalence prognosis decay\",\n",
    "         color=\"k\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Performance across pre-trained runs (note, different LR schedulers and run times)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figs/all_inter_decay.png\", bbox_inches=\"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccde1a2-e6d6-4560-9142-48dd30f673c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be7370-9cf6-4dc5-9fb2-6e36eb6df3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1baa48-6b58-454d-8f41-27d743c680e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1b1f27a-4235-4c9c-88c2-c309e282529f",
   "metadata": {},
   "source": [
    "# Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891765b-f534-41cc-8969-791d413f6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.tokenizer._event_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644335f-9a9e-49be-963a-6ed1ca22adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/{cfg.experiment.run_id}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2b285-c23f-4fd2-8e66-e20159e8e271",
   "metadata": {},
   "source": [
    "# Load Pre-Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f37089-e294-46c0-bc4a-ce3ae00300b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ckpt_path = cfg.experiment.log_dir + f'checkpoints/{cfg.experiment.run_id}.ckpt'\n",
    "model = SurvivalExperiment.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae57fb-6ca7-4e7f-9b79-b99bb5a10b52",
   "metadata": {},
   "source": [
    "# Initialise fine-tuning data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e90c2f-04c5-4f31-86f0-4f3800fa9325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update dataset path to point to the new dataset \n",
    "cfg.data.path_to_ds = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "\n",
    "# Build \n",
    "dm = FoundationalDataModule(path_to_db=cfg.data.path_to_db,\n",
    "                            path_to_ds=cfg.data.path_to_ds,\n",
    "                            load=True,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            batch_size=cfg.data.batch_size,\n",
    "                            max_seq_length=cfg.transformer.block_size,\n",
    "                            freq_threshold=cfg.data.unk_freq_threshold,\n",
    "                            min_workers=cfg.data.min_workers,\n",
    "                            overwrite_meta_information=cfg.data.meta_information_path,\n",
    "                           )\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "print(f\"{vocab_size} vocab elements\")\n",
    "\n",
    "# list of univariate measurements to model with Normal distribution\n",
    "# Extract the measurements, using the fact that the diagnoses are all up upper case.\n",
    "measurements_for_univariate_regression = [record for record in dm.tokenizer._event_counts[\"EVENT\"] if record.upper() != record]\n",
    "cfg.head.tokens_for_univariate_regression = dm.encode(measurements_for_univariate_regression) \n",
    "# display(measurements_for_univariate_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f982ce1-7d8d-4eca-960d-8866ac757c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_diagnoses = len(dm.train_set.meta_information[\"diagnosis_table\"][\"count\"])\n",
    "num_diagnosis_events = sum(dm.train_set.meta_information[\"diagnosis_table\"][\"count\"])\n",
    "\n",
    "is_medication = dm.train_set.meta_information[\"measurement_tables\"][\"count_obs\"] == 0\n",
    "\n",
    "num_medications = sum(is_medication)\n",
    "num_medication_events = sum(dm.train_set.meta_information[\"measurement_tables\"][is_medication][\"count\"])\n",
    "num_measurement_test = sum(~is_medication)\n",
    "num_measurement_test_events = sum(dm.train_set.meta_information[\"measurement_tables\"][~is_medication][\"count\"])\n",
    "\n",
    "num_measurement_test_events = sum(dm.train_set.meta_information[\"measurement_tables\"][~is_medication][\"count_obs\"])\n",
    "\n",
    "print(f'{num_diagnosis_events:,} diagnoses of {num_diagnoses} types')\n",
    "print(f'{num_medication_events:,} medications of {num_medications} types')\n",
    "print(f'{num_measurement_test_events:,} measurements and tests of {num_measurement_test} types')\n",
    "print(f'{num_diagnoses+num_medication_events+num_measurement_test_events:,}')\n",
    "\n",
    "print(f'{num_measurement_test_events:,}')\n",
    "dm.train_set.meta_information.keys()\n",
    "\n",
    "print(dm.train_set.tokenizer._event_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7a64a-4a5b-4811-847a-5ad8abe04c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # import pickle as pkl\n",
    "# # import pathlib\n",
    "\n",
    "# pkl_file_to_amend = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/file_row_count_dict_test.pickle\"\n",
    "\n",
    "# with open(pkl_file_to_amend, 'rb') as pickle_file:\n",
    "#     content = pickle.load(pickle_file)\n",
    "# display(content)\n",
    "\n",
    "# # new_dictionary = {}\n",
    "# # for key in content.keys():\n",
    "# #     str_to_remove = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/split=val/\"\n",
    "# #     new_key = str(key)[len(str_to_remove):]\n",
    "# #     new_dictionary[new_key] = content[key]\n",
    "# # display(new_dictionary)\n",
    "\n",
    "\n",
    "# # with open(pkl_file_to_amend, 'wb') as handle:\n",
    "# #     pickle.dump(new_dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3bd66-0f95-4d0f-9e85-b05bf609037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a45cf-dcbe-4d66-a8fa-34fcc1e4a4de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "start = time.time()   # starting time\n",
    "for batch in dm.train_dataloader():\n",
    "    # print(batch[\"tokens\"][1,:])\n",
    "    \n",
    "    c_batch = convert_batch_to_none_causal(batch)\n",
    "    # print(c_batch[\"tokens\"][1,:])\n",
    "    # print(c_batch[\"target_token\"][1])\n",
    "\n",
    "    # print(batch[\"tokens\"][1,:])\n",
    "    \n",
    "    break\n",
    "    \n",
    "print(f\"batch loaded in {time.time()-start} seconds\")    \n",
    "    \n",
    "# for key in batch.keys():\n",
    "#     print(f\"{key}\".ljust(20) + f\"{batch[key].shape}\")\n",
    "\n",
    "# tokens = batch[\"tokens\"][0].tolist()    \n",
    "# sentence = dm.decode(tokens).split(\" \")\n",
    "# for token, value in zip(sentence, batch[\"values\"][0].tolist()):\n",
    "#     print(f\"{token}:\".ljust(40) + f\"{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4c5b5-2121-4d10-8f8e-11a88ed16cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(batch.keys())\n",
    "display(c_batch.keys())\n",
    "\n",
    "print(batch[\"static_covariates\"].shape)\n",
    "\n",
    "# print(dm.train_set.static_1hot)\n",
    "# print(dm.train_set.static_1hot[\"SEX\"].categories_)\n",
    "# print(dm.train_set.static_1hot[\"IMD\"].categories_)\n",
    "# print(dm.train_set.static_1hot[\"ETHNICITY\"].categories_)\n",
    "\n",
    "print(batch[\"tokens\"][1,:])\n",
    "print(c_batch[\"tokens\"][1,:])\n",
    "print(c_batch[\"target_token\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3e15f-1b7c-466b-825e-a84100d224a0",
   "metadata": {},
   "source": [
    "## View an example sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa22fa-ef08-485f-a948-c4ff8b3aade5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm.test_set.view_sample(11003, max_dynamic_events=None, report_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1943eec-f491-4a94-92d9-65b9cedbd433",
   "metadata": {},
   "source": [
    "# Custom wrapper prediction last token\n",
    "\n",
    "To begin with, I will just loop over samples individually to test the zero-shot capacity of SurvivEHR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439343da-a813-4ffa-b0a6-26074e80d11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Verifying on datamodule \n",
    "for _idx, batch in enumerate(dm.test_dataloader()):\n",
    "    if _idx > 10:\n",
    "        break\n",
    "    print(_idx)\n",
    "    print(torch.stack([batch[\"tokens\"][10,:5], \n",
    "                       batch[\"values\"][10,:5],  \n",
    "                       batch[\"ages\"][10,:5],\n",
    "                       batch[\"attention_mask\"][10,:5]]))\n",
    "    batch = replace_last_non_pad_with_pad(batch)\n",
    "    print(torch.stack([batch[\"tokens\"][10,:5], \n",
    "                       batch[\"values\"][10,:5],  \n",
    "                       batch[\"ages\"][10,:5],\n",
    "                       batch[\"attention_mask\"][10,:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c069ad-f41d-420e-819e-cf2c5a390baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_of_interest = [\"COPD\", \"SUBSTANCEMISUSE\"]\n",
    "outcome_token = dm.encode(outcome_of_interest)[0]\n",
    "print(outcome_token)\n",
    "# print(model(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f35b1-02d3-4db9-b376-ca44d9c1f770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Hs, labels = [], []\n",
    "mins,maxes=[],[]\n",
    "for _idx, batch in enumerate(dm.test_dataloader()):\n",
    "\n",
    "    batch = replace_last_non_pad_with_pad(batch)\n",
    "    print(batch[\"tokens\".shape)\n",
    "    outputs, _, hidden_states = model(batch, is_generation=True)\n",
    "    print(outputs)\n",
    "    \n",
    "    hidden_states = hidden_states.cpu().detach().numpy()                           # (64, 128, 384) \n",
    "    Hs.append( hidden_states.reshape(hidden_states.shape[0], -1) )\n",
    "    labels.append((batch[\"target_token\"] == outcome_token).long().numpy())\n",
    "\n",
    "    if _idx == 9:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bf156-cc66-4276-8c8d-23caec948e2d",
   "metadata": {},
   "source": [
    "# Visualise hidden dimension labelled by target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d857d-dbb0-487b-8278-42c04bcbea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "H = np.concatenate(Hs, 0)\n",
    "lbl = np.concatenate(labels, 0)\n",
    "\n",
    "H = StandardScaler().fit_transform(H)\n",
    "reducer = umap.UMAP()\n",
    "H_proj = reducer.fit_transform(H)\n",
    "\n",
    "plt.close()\n",
    "plt.scatter(H_proj[:,0], H_proj[:,1], c=lbl)\n",
    "plt.savefig(save_path + f\"zero_shot/hidden_umap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e686a-ebe9-43d4-8a14-b88df279ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[\"surv\"][\"surv_CDF\"][outcome_token].shape)\n",
    "\n",
    "# The first two tokens in the vocab correspond to the PAD and UNK tokens. There is no CDF corresponding to the PAD token, so the indexing for surv_CDF begins as [\"UNK\", \"ADDISONS_DISEASE\", ...]\n",
    "# print(dm.decode([0,1,2]))\n",
    "\n",
    "outcomes = [\"COPD\", \"SUBSTANCEMISUSE\"]\n",
    "outcome_tokens = dm.encode(outcomes)\n",
    "\n",
    "# for outcome in outcomes:\n",
    "    # observed_outcome_token = dm.encode([outcome])[0]\n",
    "cdf = np.zeros_like(outputs[\"surv\"][\"surv_CDF\"][0])\n",
    "lbls = np.zeros_like(batch[\"target_token\"])\n",
    "\n",
    "for _outcome_token in outcome_tokens:\n",
    "    cdf += outputs[\"surv\"][\"surv_CDF\"][_outcome_token - 1] \n",
    "    lbls += (batch[\"target_token\"] == _outcome_token).long().numpy()\n",
    "\n",
    "plt.close()\n",
    "cdf_true = cdf[lbls==1,:]\n",
    "cdf_false = cdf[lbls==0,:]\n",
    "for i in range(cdf_true.shape[0]):\n",
    "    plt.plot(np.linspace(1,1826,1826), cdf_true[i,:], c=\"r\", label=\"outcome occurred next\" if i == 0 else None, alpha=1)\n",
    "for i in range(cdf_false.shape[0]):\n",
    "    plt.plot(np.linspace(1,1826,1826), cdf_false[i,:], c=\"k\", label=\"outcome did not occur next\" if i == 0 else None, alpha=0.3)\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(f\"P(t>T) - outcomes={','.join(outcomes)}\")\n",
    "plt.savefig(save_path + f\"zero_shot/cdf_outcomes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c2049-56bc-47ff-bcea-ce2e529266e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[\"target_token\"].unique())\n",
    "print(len(outputs[\"surv\"][\"surv_CDF\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3417a-d3c7-42f9-b288-82ab49ddb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90115137-0805-4f93-877b-2d98e51439d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[\"surv\"][\"surv_CDF\"][observed_outcome_token - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacadcc-f857-45e2-94e8-0ca43ccbd196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
