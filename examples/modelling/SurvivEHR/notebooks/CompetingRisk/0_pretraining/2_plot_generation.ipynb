{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16809777-7fc5-4b7f-9af7-2a050e3bb2f9",
   "metadata": {},
   "source": [
    "# Create figures for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa11d5c6-006a-4b79-b349-4f5866ef7542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvivEHR/notebooks/CompetingRisk/0_pretraining\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: SLURM_NTASKS_PER_NODE=28       # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env SLURM_NTASKS_PER_NODE=28       # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29ae262-94e1-4537-a6fc-09243173578f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg  width=\"330\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fedbcc;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fcaf93;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fc8161;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#f44f39;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#d52221;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#aa1016;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.9950634371395617, 0.8596539792387543, 0.7986620530565167),\n",
       " (0.9882352941176471, 0.6866743560169165, 0.5778854286812765),\n",
       " (0.9865897731641676, 0.5067281814686659, 0.38123798539023457),\n",
       " (0.9570011534025374, 0.3087120338331411, 0.22191464821222606),\n",
       " (0.8370472895040368, 0.13394848135332565, 0.13079584775086506),\n",
       " (0.6663437139561708, 0.06339100346020761, 0.08641291810841982)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objects as go\n",
    "import wandb\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from hydra import compose, initialize\n",
    "import seaborn as sns\n",
    "import json\n",
    "import io\n",
    "from CPRD.examples.data.map_to_reduced_names import convert_event_names, EVENT_NAME_SHORT_MAP\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import logging\n",
    "\n",
    "from CPRD.examples.modelling.SurvivEHR.run_experiment import run\n",
    "\n",
    "%env SLURM_NTASKS_PER_NODE=28   \n",
    "\n",
    "sns.set(style=\"ticks\", context=\"notebook\")\n",
    "sns.color_palette(\"Reds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e58e39-4b59-4daa-9877-2936dece846b",
   "metadata": {},
   "source": [
    "## Initialise the dataloader used for pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed96bba6-b28c-4d6e-a731-4f491af88cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 11.20919 M parameters\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = \"SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1\"\n",
    "\n",
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"causal_metric_testing_notebook\"):\n",
    "    cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                  overrides=[# Experiment setup\n",
    "                             f\"experiment.run_id={pre_trained_model}\",\n",
    "                             \"experiment.train=False\",\n",
    "                             \"experiment.test=False\",\n",
    "                             \"experiment.log=False\",\n",
    "                             \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                             \"data.min_workers=12\",\n",
    "                            ]\n",
    "                 )     \n",
    "\n",
    "model, dm = run(cfg)\n",
    "print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeed15f-b3db-44a3-b0b6-361887bf8f5e",
   "metadata": {},
   "source": [
    "# Load the generated data for a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78541af0-7bc1-4039-b621-78a6ea3a9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_stratified_next_event_matrix(df, dm, events_of_interest=None):\n",
    "\n",
    "    df[\"Next event\"] = df[\"Next event\"].map(EVENT_NAME_SHORT_MAP)\n",
    "    df[\"Previous event\"] = df[\"Previous event\"].map(EVENT_NAME_SHORT_MAP)\n",
    "\n",
    "    df = pd.crosstab(df['Next event'], df['Previous event'])\n",
    "    \n",
    "    # Drop columns and rows \n",
    "    if events_of_interest is not None:\n",
    "        cols_to_keep = df.columns.intersection(events_of_interest[0])\n",
    "        rows_to_keep = df.index.intersection(events_of_interest[1])\n",
    "        df = df.loc[rows_to_keep, cols_to_keep]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85d190-a40c-46d0-a482-dd1be63c3954",
   "metadata": {},
   "source": [
    "## Transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a879bedf-c370-4de3-9154-cbd9dcd4da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stratified_next_event_matrix(\n",
    "    df,\n",
    "    dm,\n",
    "    events_of_interest=None, \n",
    "    total_threshold=0.0,\n",
    "    conditional=True, \n",
    "    conditional_probability_threshold=0.0,\n",
    "    max_steps=10, \n",
    "    save_name=\"next_event.png\"\n",
    "):\n",
    "\n",
    "    # Filter out by how long into the future we generate\n",
    "    df = df[df[\"Generation step\"] < max_steps].copy()\n",
    "    \n",
    "    df = _get_stratified_next_event_matrix(df, dm, events_of_interest=events_of_interest)\n",
    "\n",
    "    # Get original statistics\n",
    "    total_observed = df.values.sum()\n",
    "    col_totals = df.sum(0).replace(0, np.nan)\n",
    "    counts_annot = df.copy()                     # preserve counts for annotatiob\n",
    "\n",
    "    # For combinations occuring fewer than `total_frequency_threshold` times, set to zero\n",
    "    minimum_threshold = int(total_threshold * total_observed) if type(total_threshold) is float else total_threshold\n",
    "    df = df.mask(df < minimum_threshold, 0)\n",
    "            \n",
    "    # Standardise columns\n",
    "    if conditional:\n",
    "        df = df.div(col_totals, axis=1).fillna(0)\n",
    "        df = df.mask(df < conditional_probability_threshold, 0)\n",
    "        \n",
    "    # Remove columns and rows that are all zeros\n",
    "    nonzero_rows = ~(df == 0).all(1)\n",
    "    nonzero_cols = (df != 0).any(0)\n",
    "    df = df.loc[nonzero_rows, nonzero_cols]\n",
    "    counts_annot = counts_annot.loc[nonzero_rows, nonzero_cols]\n",
    "\n",
    "    # Set remaining zeros to nan so they don't convolute plot\n",
    "    df.replace(0, np.nan, inplace=True)\n",
    "    counts_annot = counts_annot.where(~df.isna())\n",
    "\n",
    "    n_rows, n_cols = df.shape\n",
    "    # make the canvas large enough so labels stay readable\n",
    "    fig_w = min(15, max(8, n_cols * 0.55))   # 0.55 inch per column\n",
    "    fig_h = max(8, n_rows * 0.45)            # 0.45 inch per row\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, fig_h), constrained_layout=True)\n",
    "\n",
    "    # shrink factor: less than 1 and never below 0.35\n",
    "    shrink = max(0.35, 8 / max(fig_w, fig_h))\n",
    "    # thickness in points; larger gives a chunkier bar\n",
    "    cbar_aspect = 30  \n",
    "    \n",
    "    label = f\"Conditional transition probability $(p > {conditional_probability_threshold};\" if conditional else f\"Event transitions $(\"\n",
    "    label += f\"N\\geq{minimum_threshold})$\"\n",
    "    \n",
    "    sns.heatmap(\n",
    "        df,\n",
    "        ax=ax,\n",
    "        cmap=\"YlOrRd\",\n",
    "        vmin=0,\n",
    "        annot=counts_annot,\n",
    "        fmt=\".0f\",\n",
    "        cbar_kws={\"label\": label,\n",
    "                  \"shrink\": shrink,\n",
    "                  \"aspect\": cbar_aspect,\n",
    "                  },\n",
    "        linewidths=0.5,              # thin grid helps visual alignment\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Prior event\")\n",
    "    plt.ylabel(\"Next event\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.savefig(save_name)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f24ed62-03ae-46fe-8454-7b206d3f0d8a",
   "metadata": {},
   "source": [
    "# Plot heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd787bf8-4811-4e9a-bb93-c9b7df4b5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the subgroups of tokens we want to plot by\n",
    "lab_names = dm.meta_information[\"measurement_tables\"][dm.meta_information[\"measurement_tables\"][\"count_obs\"] > 0][\"event\"].to_list()\n",
    "medication_names = dm.meta_information[\"measurement_tables\"][dm.meta_information[\"measurement_tables\"][\"count_obs\"] == 0][\"event\"].to_list()\n",
    "diagnosis_names = dm.meta_information[\"diagnosis_table\"][\"event\"].to_list()\n",
    "max_steps = 3\n",
    "supplementary_plot = False\n",
    "\n",
    "datasets = [\"FineTune_CVD\", \"PreTrain\", \"FineTune_Hypertension\", \"FineTune_MultiMorbidity50+\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "    gen_data_path = f'figs/generation/{pre_trained_model}/{dataset}_dataset/'\n",
    "    \n",
    "    df = pd.read_csv(gen_data_path + f\"next_event_{dataset}.csv\")\n",
    "\n",
    "    for name, events_of_interest in zip([\"diagnosis vs diagnosis\", \"diagnosis vs drug\", \"investigation vs diagnosis\"], \n",
    "                                        [[diagnosis_names, diagnosis_names],\n",
    "                                         [diagnosis_names, medication_names],\n",
    "                                         [lab_names, diagnosis_names],\n",
    "                                         ]):\n",
    "    \n",
    "        \n",
    "    \n",
    "        for i in range(2):\n",
    "            events_of_interest[i] = [EVENT_NAME_SHORT_MAP[col] if col in EVENT_NAME_SHORT_MAP else col for col in events_of_interest[i]]\n",
    "    \n",
    "        plot_stratified_next_event_matrix(\n",
    "            df,\n",
    "            dm,\n",
    "            events_of_interest=events_of_interest,\n",
    "            total_threshold=5 if supplementary_plot else 15,\n",
    "            conditional=True,\n",
    "            conditional_probability_threshold=0.01 if supplementary_plot else 0.05,\n",
    "            max_steps=max_steps,\n",
    "            save_name=gen_data_path+f\"generation_matrix_{name}_{max_steps}_SM{supplementary_plot}.png\" \n",
    "            )\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e7a9c-ba95-48ee-b400-0d1c5a7f389a",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959f3fb-88a5-4e0f-9995-00a22fa29f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stratified_next_event_histogram(df, dm, events_of_interest=None, top_k=10, max_steps=10, save_name=\"next_event.png\"):\n",
    "\n",
    "    # Filter out by how long into the future we generate\n",
    "    df = df[df[\"Generation step\"] < max_steps].copy()\n",
    "    \n",
    "    df[\"Previous event\"] = df[\"Previous event\"].map(EVENT_NAME_SHORT_MAP)\n",
    "        \n",
    "    counts = df['Previous event'].value_counts()\n",
    "    top_labels = counts.head(top_k).index.tolist()\n",
    "\n",
    "    filtered_df = df[df['Previous event'].isin(top_labels)].copy()\n",
    "    filtered_df[\"Previous event\"] = pd.Categorical(filtered_df[\"Previous event\"], top_labels)\n",
    "\n",
    "    fig, axis = plt.subplots(1,1,figsize=(8,5))\n",
    "\n",
    "    sns.histplot(\n",
    "        data=filtered_df, \n",
    "        y=\"Previous event\", \n",
    "        stat=\"percent\",\n",
    "    )\n",
    "\n",
    "    plt.ylabel(f\"Frequency of events following T2DM diagnosis\")\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(save_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d1311d7-3e75-4dfd-a4e8-66fa45850b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "df = pd.read_csv(gen_data_path + \"next_event_data.csv\")\n",
    "\n",
    "plot_stratified_next_event_histogram(\n",
    "    df,\n",
    "    dm,\n",
    "    events_of_interest=events_of_interest,\n",
    "    top_k=20,\n",
    "    max_steps=3,\n",
    "    save_name=f\"next_event_generation_histogram.png\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa25fe3-aa7c-409c-baf7-e35e1c723dd4",
   "metadata": {},
   "source": [
    "## Sankey flow diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "196e3855-1200-4b4e-bf6f-524cd2e7a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transition_to_sankey_df(\n",
    "    counts_df: pd.DataFrame,\n",
    "    *,\n",
    "    k_per_token: int = 3,\n",
    "    min_prob: float = 1e-4,\n",
    "    normalise: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build Plotly Sankey inputs from a transition-count DataFrame\n",
    "    (index = “Next event”, columns = “Previous event”).\n",
    "\n",
    "    • Makes the matrix square by adding missing rows/columns (zeros).\n",
    "    • Transposes so rows = previous events, cols = next events.\n",
    "    • Optionally row-normalises to probabilities.\n",
    "    • Keeps only the top-k outgoing transitions per previous event\n",
    "      with prob ≥ min_prob.\n",
    "    \"\"\"\n",
    "    if not isinstance(counts_df, pd.DataFrame):\n",
    "        raise TypeError(\"counts_df must be a pandas.DataFrame\")\n",
    "\n",
    "    # 1. Square the matrix\n",
    "    events = sorted(set(counts_df.columns).union(counts_df.index))\n",
    "    df = counts_df.reindex(index=events, columns=events, fill_value=0)\n",
    "\n",
    "    # 2. Transpose → rows = previous, cols = next\n",
    "    mat = df.T.to_numpy(dtype=float)\n",
    "    labels = events                       # same order as rows\n",
    "\n",
    "    # 3. Row-normalise (optional)\n",
    "    if normalise:\n",
    "        row_sums = mat.sum(axis=1, keepdims=True)\n",
    "        row_sums[row_sums == 0] = 1.0\n",
    "        mat = mat / row_sums\n",
    "\n",
    "    # 4. Build edge lists\n",
    "    n = mat.shape[0]\n",
    "    src, tgt, val = [], [], []\n",
    "    for i in range(n):                    # previous event\n",
    "        top_idx = np.argsort(mat[i])[::-1][:k_per_token]\n",
    "        for j in top_idx:                 # next event\n",
    "            p = mat[i, j]\n",
    "            if p >= min_prob:\n",
    "                src.append(i)\n",
    "                tgt.append(j)\n",
    "                val.append(float(p))\n",
    "\n",
    "    # --- RETURN in Plotly’s expected structure ------------------------\n",
    "    return {\n",
    "        \"node\": dict(\n",
    "            label=labels,\n",
    "            pad=15,\n",
    "            thickness=8,\n",
    "            line=dict(color=\"grey\", width=0.5),\n",
    "        ),\n",
    "        \"link\": dict(\n",
    "            source=src,\n",
    "            target=tgt,\n",
    "            value=val,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def transition_to_circular_sankey_df(\n",
    "    counts_df: pd.DataFrame,\n",
    "    *,\n",
    "    k_per_token: int = 4,\n",
    "    min_prob: float = 0.01,\n",
    "    normalise: bool = True,\n",
    "    link_opacity: float = 0.35,\n",
    "    node_colour: str = \"#4C72B0\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a (possibly non-square) transition-count DataFrame to a Plotly\n",
    "    Sankey dict whose nodes sit on a circle (circular “flow” diagram).\n",
    "\n",
    "    Expected DataFrame layout\n",
    "    -------------------------\n",
    "    * columns = “Previous event”\n",
    "    * index   = “Next event”\n",
    "\n",
    "    Steps\n",
    "    -----\n",
    "    1.  Make the matrix square by adding missing rows/columns (0).\n",
    "    2.  Transpose so rows = previous, cols = next.\n",
    "    3.  Optionally row-normalise counts → probabilities.\n",
    "    4.  Keep top-k outgoing edges per row with prob ≥ min_prob.\n",
    "    5.  Place every node at an angle θ on a unit circle and output a\n",
    "        Plotly-ready dict (node & link) for go.Sankey.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts_df : pd.DataFrame\n",
    "    k_per_token : int – keep this many strongest edges per event\n",
    "    min_prob    : float – probability cut-off after normalising\n",
    "    normalise   : bool  – if False, edges are raw counts\n",
    "    link_opacity: float – RGBA alpha for links (0 … 1)\n",
    "    node_colour : str   – hex for node colour\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict  # suitable for go.Sankey(**dict)\n",
    "    \"\"\"\n",
    "    if not isinstance(counts_df, pd.DataFrame):\n",
    "        raise TypeError(\"counts_df must be a pandas.DataFrame\")\n",
    "\n",
    "    # 1 ▸ square matrix (union of row+col labels)\n",
    "    events = sorted(set(counts_df.columns).union(counts_df.index))\n",
    "    df_sq = counts_df.reindex(index=events, columns=events, fill_value=0)\n",
    "\n",
    "    # 2 ▸ rows = previous, cols = next\n",
    "    mat = df_sq.T.to_numpy(dtype=float)      # shape (N, N); rows = previous\n",
    "    n = mat.shape[0]\n",
    "\n",
    "    # 3 ▸ optional row-normalisation\n",
    "    if normalise:\n",
    "        row_sums = mat.sum(axis=1, keepdims=True)\n",
    "        row_sums[row_sums == 0] = 1.0        # avoid divide-by-zero\n",
    "        mat = mat / row_sums\n",
    "\n",
    "    # 4 ▸ build edge lists\n",
    "    src, tgt, val = [], [], []\n",
    "    for i in range(n):\n",
    "        top_idx = np.argsort(mat[i])[::-1][:k_per_token]\n",
    "        for j in top_idx:\n",
    "            p = mat[i, j]\n",
    "            if p >= min_prob and i != j:     # skip self-loops\n",
    "                src.append(i)\n",
    "                tgt.append(j)\n",
    "                val.append(float(p))\n",
    "\n",
    "    if not src:\n",
    "        raise ValueError(\"No edges survived; lower `min_prob` or raise `k_per_token`.\")\n",
    "\n",
    "    # 5 ▸ node positions: equally spaced on a circle (radius 0.45, centre 0.5)\n",
    "    theta = np.linspace(0, 2 * np.pi, n, endpoint=False)\n",
    "    node_x = 0.5 + 0.45 * np.cos(theta)      # in Plotly Sankey, 0…1 coordinates\n",
    "    node_y = 0.5 + 0.45 * np.sin(theta)\n",
    "\n",
    "    return dict(\n",
    "        arrangement=\"fixed\",                 # keep our positions\n",
    "        node=dict(\n",
    "            label=events,\n",
    "            x=node_x.tolist(),\n",
    "            y=node_y.tolist(),\n",
    "            pad=4,\n",
    "            thickness=8,\n",
    "            line=dict(color=\"grey\", width=0.5),\n",
    "            color=node_colour,\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=src,\n",
    "            target=tgt,\n",
    "            value=val,\n",
    "            color=f\"rgba(76,114,176,{link_opacity})\",\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddc22670-bc43-454e-b6fd-61fe585f0fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "261\n",
      "missing index Death\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(gen_data_path + \"next_event_data.csv\")\n",
    "\n",
    "print(len(df[\"Previous event\"].unique()))\n",
    "print(len(df[\"Next event\"].unique()))\n",
    "\n",
    "\n",
    "# df = df[df[\"Generation step\"] == 0]\n",
    "# df = df[df[\"Previous event\"] != \"DEATH\"]\n",
    "\n",
    "df = _get_stratified_next_event_matrix(df, dm)\n",
    "\n",
    "for ind in df.index:\n",
    "    if ind not in df.columns:\n",
    "        print(f\"missing column {ind}\")\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in df.index:\n",
    "        print(f\"missing index {col}\")\n",
    "\n",
    "# print(df)\n",
    "# print(df.index)\n",
    "# print(df.columns)\n",
    "\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51163440-a782-47aa-88f1-4a89e447221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_data = transition_to_sankey_df(\n",
    "    df, k_per_token=4, min_prob=0.01, normalise=True\n",
    ")\n",
    "\n",
    "print(\"edges kept:\", len(sankey_data[\"link\"][\"source\"]))\n",
    "print(\"unique nodes:\", len(set(sankey_data[\"link\"][\"source\"] + \n",
    "                              sankey_data[\"link\"][\"target\"])))\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"   # or \"browser\" / \"png\"\n",
    "\n",
    "fig = go.Figure(go.Sankey(**sankey_data))\n",
    "fig.update_layout(title=\"Event transition flows\")\n",
    "fig.write_html(\"sankey.html\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "581eb7e7-8b75-4f72-aa3d-6f8df08ae933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_data = transition_to_circular_sankey_df(\n",
    "    df,\n",
    "    k_per_token=1,\n",
    "    min_prob=0.1,\n",
    "    normalise=True,\n",
    ")\n",
    "fig = go.Figure(go.Sankey(**sankey_data))\n",
    "fig.update_layout(\n",
    "    title=\"Circular event-to-event flows\",\n",
    "    title_x=0.5,\n",
    "    margin=dict(t=40, l=20, r=20, b=20),\n",
    ")\n",
    "# fig.show()          # or \n",
    "fig.write_html(\"circle_flow.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c74158-c930-4775-b8c8-e4739ddd5a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
