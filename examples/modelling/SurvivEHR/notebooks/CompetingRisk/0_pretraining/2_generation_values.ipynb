{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Generation Demo Notebook:\n",
    "## SurvivEHR: Competing Risk Survival Transformer For Causal Sequence Modelling \n",
    "\n",
    "In this notebook we demonstrate how different risk factors contribute to the generation of future patient timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvivEHR/notebooks/CompetingRisk/0_pretraining\n",
      "env: SLURM_NTASKS_PER_NODE=28       # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env SLURM_NTASKS_PER_NODE=28       # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from pycox.evaluation import EvalSurv\n",
    "from tqdm import tqdm\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from contextlib import redirect_stdout\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from CPRD.examples.modelling.SurvivEHR.run_experiment import run\n",
    "from CPRD.examples.modelling.SurvivEHR.setup_causal_experiment import CausalExperiment\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "from CPRD.examples.data.map_to_reduced_names import convert_event_names, EVENT_NAME_SHORT_MAP\n",
    "\n",
    "from FastEHR.dataloader import FoundationalDataModule\n",
    "from FastEHR.database.collector import SQLiteDataCollector\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "warnings.simplefilter('error', np.VisibleDeprecationWarning)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of how input can affect future risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_batch_to_t2dm_risk_profile(batch, risk=\"low\"):\n",
    "    \"\"\"\n",
    "    Given a loaded batch, replace certain risk-factors for cardiovascular disease and t2dm to three levels: low, medium, and high.\n",
    "    This can then be used to see the 'what-if?' effect of changing these factors in next-event prediction risk\n",
    "    \"\"\"\n",
    "\n",
    "    match risk:\n",
    "        case \"low\":            \n",
    "            # Normal person\n",
    "            static_covariates = dm.test_set._encode_covariates(\"F\", 1.0, \"ASIAN\", 1963)\n",
    "\n",
    "            risk_event_map = {\"Ex_smoker_84\": \"Never_smoked_tobacco_85\",\n",
    "                              \"Current_smoker_83\": \"Never_smoked_tobacco_85\",\n",
    "                             }\n",
    "            risk_value_map = {\"Diastolic_blood_pressure_5\": 80,\n",
    "                              \"Systolic_blood_pressure_4\": 120,\n",
    "                              \"Body_mass_index_3\": 24,\n",
    "                              \"O_E___weight_2\": np.nan,\n",
    "                             }\n",
    "            # new_risk_events = []\n",
    "            \n",
    "        case \"medium\" | \"mid\":\n",
    "            # At some risk\n",
    "            static_covariates = dm.test_set._encode_covariates(\"F\", 3.0, \"ASIAN\", 1963)\n",
    "\n",
    "            risk_event_map = {\"Never_smoked_tobacco_85\": \"Ex_smoker_84\",\n",
    "                              \"Current_smoker_83\": \"Ex_smoker_84\"\n",
    "                             }\n",
    "            risk_value_map = {\"Diastolic_blood_pressure_5\": 90,\n",
    "                              \"Systolic_blood_pressure_4\": 140,\n",
    "                              \"Body_mass_index_3\": 28,\n",
    "                              \"O_E___weight_2\": np.nan,\n",
    "                             }\n",
    "            # new_risk_events = []\n",
    "                        \n",
    "        case \"high\":\n",
    "            # At higher risk\n",
    "            static_covariates = dm.test_set._encode_covariates(\"F\", 5.0, \"ASIAN\", 1963)\n",
    "\n",
    "            risk_event_map = {\"Never_smoked_tobacco_85\": \"Current_smoker_83\",\n",
    "                              \"Ex_smoker_84\": \"Current_smoker_83\"\n",
    "                             }\n",
    "            risk_value_map = {\"Diastolic_blood_pressure_5\": 100,\n",
    "                              \"Systolic_blood_pressure_4\": 150,\n",
    "                              \"Body_mass_index_3\": 32,\n",
    "                              \"O_E___weight_2\": np.nan,\n",
    "                             }\n",
    "            # new_risk_events = [\"ALCOHOLMISUSE_V2\"]\n",
    "            \n",
    "        case _:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    # Shape\n",
    "    bsz, L = batch[\"tokens\"].shape\n",
    "    device = batch[\"tokens\"].device\n",
    "\n",
    "    # Tokenize maps\n",
    "    ###############\n",
    "    \n",
    "    # Put all event conversions into token form\n",
    "    token_event_map = {}\n",
    "    for old_key, old_item in risk_event_map.items():\n",
    "        new_key = dm.encode([old_key])[0]\n",
    "        new_item = dm.encode([old_item])[0]\n",
    "        token_event_map.update({new_key: new_item})\n",
    "    \n",
    "    # Put all value conversions into token form\n",
    "    token_value_map = {}\n",
    "    for old_key, item in risk_value_map.items():\n",
    "        new_key = dm.encode([old_key])[0]\n",
    "        standardised_item = dm.standardise(old_key, item)\n",
    "        token_value_map.update({new_key: standardised_item})\n",
    "\n",
    "    # Update patient profiles\n",
    "    #########################\n",
    "\n",
    "    # Set everyone in batch to the same risk-profile's baseline static covariates\n",
    "    static_covariates = torch.tile(static_covariates, (bsz, 1))\n",
    "    \n",
    "    # apply event conversions\n",
    "    tokens = batch[\"tokens\"].clone()\n",
    "    for old, new in token_event_map.items():\n",
    "        mask           = (batch[\"tokens\"] == old)\n",
    "        tokens[mask]   = new\n",
    "\n",
    "    # Apply value conversion\n",
    "    values = batch[\"values\"].clone()\n",
    "    for old, new in token_value_map.items():\n",
    "        mask           = (batch[\"tokens\"] == old)\n",
    "        values[mask]   = new\n",
    "\n",
    "    new_batch = {\n",
    "        \"static_covariates\": static_covariates.to(device),\n",
    "        \"tokens\": tokens.to(device),\n",
    "        \"ages\": batch[\"ages\"],\n",
    "        \"values\": values.to(device),\n",
    "        \"attention_mask\": batch[\"attention_mask\"],\n",
    "        }\n",
    "    \n",
    "    return new_batch\n",
    "\n",
    "def clip_outliers(token, unstandardised_value):\n",
    "    \"\"\"\n",
    "    Because of heavy right tails in the value distributions, standardisation of some token values over-estimates the lower quantile.\n",
    "    This method ensures no values beyond those seen in the data are reported.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert not np.isnan(unstandardised_value)\n",
    "        token_meta = dm.meta_information[\"measurement_tables\"][dm.meta_information[\"measurement_tables\"][\"event\"] == token]\n",
    "        _min = token_meta[\"min\"]\n",
    "        _max = token_meta[\"max\"]\n",
    "        unstandardised_value = np.min((unstandardised_value, _max))\n",
    "        unstandardised_value = np.max((unstandardised_value, _min))\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    return unstandardised_value\n",
    "\n",
    "def report_generation(static, tokens, ages, values, attention_mask, true_seq_len, dm, eos_token=\"DEATH\", **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    tokens = tokens[0, :]\n",
    "    ages = ages[0, :]\n",
    "    values = values[0, :]\n",
    "    attention_mask = attention_mask[0, :]\n",
    "\n",
    "    static = dm.test_set._decode_covariates(static.cpu())\n",
    "    print(\"STATIC INFORMATION\")\n",
    "    print(\"=\"*120)\n",
    "    for key, item in static.items():\n",
    "        print(f\"\\t{key}:\".ljust(20) + f\"{item[0]}\")\n",
    "\n",
    "    # Report\n",
    "    tokens = dm.tokenizer.decode(tokens.tolist()).split(\" \")\n",
    "    diagnoses = []\n",
    "    last_age_day, last_age_week = 0, 0\n",
    "    print(\"\\n\\nGiven patient context\".upper())\n",
    "    print(\"=\"*120)\n",
    "    print(f\"\\tEVENT\".ljust(75) + \"| AGE IN WEEKS (days, years)\".ljust(30) + \" | VALUE\")\n",
    "    for idx_event, (token, _age, value, attn_mask) in enumerate(zip(tokens, ages, values, attention_mask)):\n",
    "\n",
    "        if attn_mask == 0:\n",
    "            break\n",
    "            \n",
    "        # Unscale age and bin to week fidelity\n",
    "        age_day = int(_age * dm.test_set.time_scale)\n",
    "        age_week = int(age_day / 7) \n",
    "        age_years = int(age_day / 365)\n",
    "\n",
    "        # If new event create break\n",
    "        if age_week != last_age_week:\n",
    "            print(\"\\t\" + \".\"*60 + \"new week\" + \".\"*60)\n",
    "\n",
    "        # Report next event\n",
    "        age = f\"{age_week}\\t ({age_day}, {age_years})\"\n",
    "        unstandardised_value = clip_outliers(token, dm.unstandardise(token, value))\n",
    "        value = f\"{unstandardised_value:.2f}\".ljust(10) + f\"({value:.2f})\"\n",
    "        print(f\"\\t{token.ljust(75)}| {age.ljust(30)}| {value}\".ljust(20))\n",
    "        \n",
    "        if token.upper() == token:\n",
    "            diagnoses.append(token)\n",
    "\n",
    "        if idx_event == true_seq_len - 1:\n",
    "            print(\"\\n\" + \"=\"*120)\n",
    "            print(\"Diagnosis summary\".upper())\n",
    "            print(f\"{diagnoses}\")\n",
    "            print(\"=\"*120)\n",
    "            print(\"\\n\")\n",
    "            print(\"Predicted future events\".upper())\n",
    "            print(\"=\"*120)\n",
    "            print(f\"\\tEVENT\".ljust(75) + \"| AGE IN WEEKS (days, years)\".ljust(30) + \"| VALUE\")\n",
    "\n",
    "\n",
    "        last_age_day = age_day\n",
    "        last_age_week = age_week\n",
    "        if token == eos_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mdm\u001b[49m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39m_event_counts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEVENT\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiab\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m i\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dm' is not defined"
     ]
    }
   ],
   "source": [
    "for i in list(dm.tokenizer._event_counts[\"EVENT\"]):\n",
    "    if \"diab\" in i.lower():\n",
    "        print(i)\n",
    "\n",
    "print(batch[\"static_covariates\"].shape)\n",
    "# static = dm.test_set._decode_covariates(batch[\"static_covariates\"].cpu())\n",
    "# print(static)\n",
    "\n",
    "static = dm.test_set._encode_covariates(\"F\", 1.0, \"ASIAN\", 1963)\n",
    "print(static.shape)\n",
    "print(dm.test_set._decode_covariates(static))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(map_batch_to_t2dm_risk_profile(\u001b[43mbatch\u001b[49m, risk\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(map_batch_to_t2dm_risk_profile(batch, risk\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "print(map_batch_to_t2dm_risk_profile(batch, risk=\"low\"))\n",
    "print(map_batch_to_t2dm_risk_profile(batch, risk=\"high\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_models = [\"SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1\"]\n",
    "config_names = [\"config_CompetingRisk11M\"]\n",
    "\n",
    "datasets = [ \"PreTrain\", \"FineTune_Hypertension\", \"FineTune_CVD\", \"FineTune_MultiMorbidity50+\"]\n",
    "patients_of_interest = [[10],[0],[10],[1]]\n",
    "\n",
    "risk_levels = [\"low\", \"mid\", \"high\"]\n",
    "outcomes_of_interest = [\"HYPERTENSION\", \"Body_mass_index_3\", \"HF_V3\", \"TYPE2DIABETES\", \"DEATH\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate \"what-if?\" next-event risks for a handful of selected patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/. This will be loaded in causal form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating unsupervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Set seed to 1337\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=train/ dataset, with 23,613,894 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=test/ dataset, with 1,508,320 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=val/ dataset, with 1,426,714 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 64\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 3\n",
      "  global_diagnoses: false\n",
      "  repeating_events: true\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/cprd.db\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: null\n",
      "experiment:\n",
      "  type: pre-train\n",
      "  project_name: SurvivEHR\n",
      "  run_id: SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1\n",
      "  fine_tune_id: null\n",
      "  notes: null\n",
      "  tags: null\n",
      "  train: false\n",
      "  test: false\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: false\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "fine_tuning:\n",
      "  fine_tune_outcomes: null\n",
      "  custom_outcome_method:\n",
      "    _target_: null\n",
      "  custom_stratification_method:\n",
      "    _target_: null\n",
      "  use_callbacks:\n",
      "    hidden_embedding:\n",
      "      num_batches: 1\n",
      "      mask_static: false\n",
      "      mask_value: false\n",
      "    performance_metrics: true\n",
      "    rmst: false\n",
      "  head:\n",
      "    surv_weight: 1\n",
      "    value_weight: 0\n",
      "    learning_rate: 0.0005\n",
      "optim:\n",
      "  num_epochs: 1\n",
      "  learning_rate: 0.0003\n",
      "  scheduler_warmup: true\n",
      "  scheduler: decaycawarmrestarts\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 2500\n",
      "  early_stop: true\n",
      "  early_stop_patience: 30\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.025\n",
      "  limit_test_batches: null\n",
      "  accumulate_grad_batches: 1\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 6\n",
      "  n_head: 6\n",
      "  n_embd: 384\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "  use_fine_tune_adapter: false\n",
      "  adapter_dim: 8\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 1\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.1\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Pre-training experiment\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Loading a pre-trained model with the checkpoint path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1.ckpt.\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using a DeSurv Competing-Risk head.\n",
      "INFO:root:\tWith concurrent strategy=add_noise for handling simultaneous events.\n",
      "INFO:root:\tEvaluating on a time grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Created hidden state embedding callback  \n",
      "INFO:root:Created PerformanceMetrics callback for causal self-supervised tasks.\n",
      "INFO:root:\t \n",
      "INFO:root:Interactive job = True\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:root:Creating unsupervised collator for DataModule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1 with 11.20919 M parameters\n",
      "Generating patient's next event risk for dataset PreTrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=train/ dataset, with 23,613,894 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=test/ dataset, with 1,508,320 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=val/ dataset, with 1,426,714 samples\n",
      "Saving low-converted timeline for all considered patients in batch: 100%|##########| 1/1 [00:00<00:00, 27.19it/s]\n",
      "Recording low-converted outcome risks for all considered patients in batch:   0%|          | 0/128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "replace expected at least 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 114\u001b[0m\n\u001b[1;32m    103\u001b[0m                 tkn_of_interest \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39mencode([event_name])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    104\u001b[0m                 event_surv_pred \u001b[38;5;241m=\u001b[39m pred_surv[tkn_of_interest \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m][idx_patient]\n\u001b[1;32m    106\u001b[0m                 data_rows\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    107\u001b[0m                     \u001b[38;5;28mdict\u001b[39m(dataset             \u001b[38;5;241m=\u001b[39m dataset,\n\u001b[1;32m    108\u001b[0m                          risk_level          \u001b[38;5;241m=\u001b[39m risk_level,\n\u001b[1;32m    109\u001b[0m                          patient_idx         \u001b[38;5;241m=\u001b[39m idx_patient,\n\u001b[1;32m    110\u001b[0m                          token               \u001b[38;5;241m=\u001b[39m tkn_of_interest,\n\u001b[1;32m    111\u001b[0m                          survival_risk       \u001b[38;5;241m=\u001b[39m event_surv_pred,\n\u001b[1;32m    112\u001b[0m                          total_survival_risk \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(event_surv_pred),\n\u001b[1;32m    113\u001b[0m                          context_len         \u001b[38;5;241m=\u001b[39m l,\n\u001b[0;32m--> 114\u001b[0m                          last_observed_event \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_event_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_observed_event\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    115\u001b[0m                          )\n\u001b[1;32m    116\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data_rows)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/Projects/CPRD/examples/data/map_to_reduced_names.py:539\u001b[0m, in \u001b[0;36mconvert_event_names\u001b[0;34m(dataframe_column, format_to)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_event_names\u001b[39m(dataframe_column, format_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mmatch\u001b[39;00m format_to:\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 539\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataframe_column\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEVENT_NAME_LONG_MAP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m dataframe_column\u001b[38;5;241m.\u001b[39mreplace(EVENT_NAME_SHORT_MAP)\n\u001b[1;32m    542\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[1;32m    543\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m NotImplemtedError\n",
      "\u001b[0;31mTypeError\u001b[0m: replace expected at least 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "for pre_trained_model, config_name in zip(pre_trained_models, config_names):\n",
    "    os.makedirs(f\"figs/generation/{pre_trained_model}/\", exist_ok=True) \n",
    "\n",
    "    # load the configuration file, override any settings \n",
    "    with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "        cfg = compose(config_name=config_name, \n",
    "                      overrides=[# Experiment setup\n",
    "                                 f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                                 \"experiment.train=False\",\n",
    "                                 \"experiment.test=False\",\n",
    "                                 \"experiment.log=False\",\n",
    "                                 # Dataloader\n",
    "                                 \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                                 \"data.min_workers=3\",\n",
    "                                ]\n",
    "                     )     \n",
    "    experiment, dm = run(cfg)     \n",
    "    print(f\"Loaded model {pre_trained_model} with {sum(p.numel() for p in experiment.parameters())/1e6} M parameters\")\n",
    "    \n",
    "    for idx_dataset, dataset in enumerate(datasets):\n",
    "        print(f\"Generating patient's next event risk for dataset {dataset}\")        \n",
    "        gen_save_path = f'figs/generation/{pre_trained_model}/{dataset}_dataset/'\n",
    "        os.makedirs(gen_save_path, exist_ok=True) \n",
    "\n",
    "        # store dataset results in\n",
    "        data_rows = []\n",
    "\n",
    "        # Load dataset\n",
    "        dm = FoundationalDataModule(path_to_db=cfg.data.path_to_db,\n",
    "                                    path_to_ds=f\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/{dataset}/\",\n",
    "                                    overwrite_meta_information=cfg.data.meta_information_path,\n",
    "                                    load=True,\n",
    "                                    supervised=False if dataset.lower()==\"pretrain\" else True,\n",
    "                                    )\n",
    "        \n",
    "        # Load the first batch\n",
    "        for batch in dm.test_dataloader():\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            break\n",
    "\n",
    "        # The patients within the batch we are interested in\n",
    "        bsz, L = batch[\"tokens\"].shape\n",
    "        patients = patients_of_interest[idx_dataset] if patients_of_interest[idx_dataset] is not None else [i for i in range(bsz)]\n",
    "\n",
    "        # For each risk level, map the patients of interest to the risk level, report them to file, and plot the next-event risks\n",
    "        batches_by_risk = []\n",
    "        for risk_level in risk_levels:\n",
    "\n",
    "            # Map to risk level\n",
    "            ###################\n",
    "            batch_risk_adjusted = map_batch_to_t2dm_risk_profile(batch, risk=risk_level)\n",
    "            batches_by_risk.append(batch_risk_adjusted)\n",
    "\n",
    "            # Report mapped timelines for each patient of interest\n",
    "            ######################################################\n",
    "            for idx_patient in tqdm(patients, ascii=True, desc=f\"Saving {risk_level}-converted timeline for all considered patients in batch\"):\n",
    "                out_dir = gen_save_path + f'patient{idx_patient}/'\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "                with open(out_dir + f\"mapped_to_risk_level_{risk_level}.txt\", 'w') as f:\n",
    "                    with redirect_stdout(f):\n",
    "                        report_generation(\n",
    "                            static         = batch_risk_adjusted[\"static_covariates\"][idx_patient], \n",
    "                            tokens         = batch_risk_adjusted[\"tokens\"][[idx_patient],:],\n",
    "                            ages           = batch_risk_adjusted[\"ages\"][[idx_patient],:], \n",
    "                            values         = batch_risk_adjusted[\"values\"][[idx_patient], :], \n",
    "                            attention_mask = batch_risk_adjusted[\"attention_mask\"][[idx_patient], :],\n",
    "                            true_seq_len   = batch_risk_adjusted[\"attention_mask\"][[idx_patient], :].sum(), \n",
    "                            dm             = dm\n",
    "                        )\n",
    "\n",
    "            # Plot final risks after full timeline has been given to SurvivEHR\n",
    "            ###################################################################\n",
    "\n",
    "            for l in tqdm(range(1, L, 1), \n",
    "                          ascii=True, desc=f\"Recording {risk_level}-converted outcome risks for all considered patients in batch\"):\n",
    "                # Get next-event risks for patients in batch mapped to the risk level\n",
    "                outputs, _, _  = experiment.model(\n",
    "                    covariates        = batch_risk_adjusted[\"static_covariates\"],\n",
    "                    tokens            = batch_risk_adjusted['tokens'][:, :l],\n",
    "                    ages              = batch_risk_adjusted['ages'][:, :l],\n",
    "                    values            = batch_risk_adjusted['values'][:, :l],\n",
    "                    attention_mask    = batch_risk_adjusted['attention_mask'][:, :l],\n",
    "                    is_generation     = True,\n",
    "                    return_loss       = False,\n",
    "                    return_generation = True,\n",
    "                    )\n",
    "                pred_surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "                pred_values = outputs[\"values_dist\"]\n",
    "    \n",
    "                for idx_patient in patients:\n",
    "                    out_dir = gen_save_path + f'patient{idx_patient}/'\n",
    "                    patient_true_seq_len = batch_risk_adjusted[\"attention_mask\"][[idx_patient], :].sum()\n",
    "                    \n",
    "                    last_observed_token = batch_risk_adjusted['tokens'][idx_patient, l-1]\n",
    "                    last_observed_event = dm.decode([last_observed_token.tolist()])\n",
    "\n",
    "                    \n",
    "                    if l > patient_true_seq_len:\n",
    "                        continue\n",
    "                    \n",
    "                    for event_name in outcomes_of_interest:\n",
    "    \n",
    "                        tkn_of_interest = dm.encode([event_name])[0]\n",
    "                        event_surv_pred = pred_surv[tkn_of_interest - 1][idx_patient]\n",
    "    \n",
    "                        data_rows.append(\n",
    "                            dict(dataset             = dataset,\n",
    "                                 risk_level          = risk_level,\n",
    "                                 patient_idx         = idx_patient,\n",
    "                                 token               = tkn_of_interest,\n",
    "                                 survival_risk       = event_surv_pred,\n",
    "                                 total_survival_risk = np.mean(event_surv_pred),\n",
    "                                 context_len         = l,\n",
    "                                 last_observed_event = last_observed_event,\n",
    "                                 )\n",
    "                        )\n",
    "\n",
    "        df = pd.DataFrame(data_rows)\n",
    "        print(df.head())\n",
    "        df.to_pickle(gen_save_path + \"risk_level_survival_table.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre_trained_model, config_name in zip(pre_trained_models, config_names):\n",
    "    os.makedirs(f\"figs/generation/{pre_trained_model}/\", exist_ok=True) \n",
    "    \n",
    "    for idx_dataset, dataset in enumerate(datasets):\n",
    "        gen_save_path = f'figs/generation/{pre_trained_model}/{dataset}_dataset/'\n",
    "        patients = patients_of_interest[idx_dataset] if patients_of_interest[idx_dataset] is not None else [i for i in range(bsz)]\n",
    "        df = pd.read_pickle(gen_save_path + \"risk_level_survival_table.pkl\")\n",
    "\n",
    "        for idx_patient in patients:\n",
    "            out_dir = gen_save_path + f'patient{idx_patient}/'\n",
    "\n",
    "            for event_name in outcomes_of_interest:\n",
    "    \n",
    "                tkn_of_interest = dm.encode([event_name])[0]\n",
    "                \n",
    "                plot_df = (df.query(\"dataset==@dataset & patient_idx==@idx_patient & token==@tkn_of_interest\")\n",
    "                           .sort_values('context_len', ascending=False)                            # largest first\n",
    "                           .drop_duplicates(['dataset', \"risk_level\", \"token\", 'patient_idx'])     # keep first row it meets per group, the one with largest context\n",
    "                           .reset_index(drop=True)\n",
    "                          )\n",
    "\n",
    "                # Explode along the survival_risk vector to expand the dataframe\n",
    "                plot_df_long = (\n",
    "                    plot_df\n",
    "                      .explode(\"survival_risk\")                 # duplicates meta‑columns\n",
    "                      .assign(                                  # add the matching time point\n",
    "                          time_idx=lambda d: d.groupby(\n",
    "                              [\"dataset\", \"patient_idx\", \"risk_level\"]\n",
    "                          ).cumcount()\n",
    "                      )\n",
    "                )\n",
    "\n",
    "                plt.close()\n",
    "                sns.set(style=\"whitegrid\")\n",
    "                ax = sns.lineplot(\n",
    "                        data=plot_df_long,\n",
    "                        x=\"time_idx\", y=\"survival_risk\",\n",
    "                        hue=\"risk_level\",\n",
    "                     )\n",
    "\n",
    "                \n",
    "                ax.set_xlabel(\"Time index\")\n",
    "                ax.set_ylabel(\"Survival risk\")\n",
    "                ax.set_title(f\"Survival curves for {event_name} by risk level\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(out_dir + f\"risk_{event_name}.png\") \n",
    "        \n",
    "                # print(event_name)\n",
    "                # print(event_surv_pred.shape)\n",
    "                # plt.close()\n",
    "                # plt.plot(experiment.model.surv_layer.t_eval / 365, ) #  label=f\"{'->'.join(exp_prompts[p_idx]).lower()}\"\n",
    "                # plt.savefig(out_dir + f\"{risk_level}_{event_name}.png\")\n",
    "                    \n",
    "                    # for p_idx in range(len(exp_prompts)):\n",
    "                        # plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{'->'.join(exp_prompts[p_idx]).lower()}\")\n",
    "                        \n",
    "                    # plt.xlabel(\"Time (years)\")\n",
    "                    # plt.ylabel(f\"$P(T>t)$ ({event_name})\")\n",
    "                    # plt.legend()\n",
    "                    # plt.savefig(out_dir + f\"{event_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre_trained_model, config_name in zip(pre_trained_models, config_names):\n",
    "    os.makedirs(f\"figs/generation/{pre_trained_model}/\", exist_ok=True) \n",
    "    \n",
    "    for idx_dataset, dataset in enumerate(datasets):\n",
    "        gen_save_path = f'figs/generation/{pre_trained_model}/{dataset}_dataset/'\n",
    "        patients = patients_of_interest[idx_dataset] if patients_of_interest[idx_dataset] is not None else [i for i in range(bsz)]\n",
    "        df = pd.read_pickle(gen_save_path + \"risk_level_survival_table.pkl\")\n",
    "\n",
    "        df[\"last_observed_event\"] = df[\"last_observed_event\"].map(EVENT_NAME_SHORT_MAP)\n",
    "\n",
    "        for idx_patient in patients:\n",
    "            out_dir = gen_save_path + f'patient{idx_patient}/'\n",
    "\n",
    "            for event_name in outcomes_of_interest:\n",
    "    \n",
    "                tkn_of_interest = dm.encode([event_name])[0]\n",
    "                \n",
    "                plot_df = df.query(\"dataset==@dataset & patient_idx==@idx_patient & token==@tkn_of_interest\")\n",
    "                          \n",
    "                plt.close()\n",
    "                plt.figure(dpi=600)\n",
    "                sns.set(style=\"whitegrid\")\n",
    "                ax = sns.lineplot(\n",
    "                        data=plot_df,\n",
    "                        x=\"context_len\", y=\"total_survival_risk\",\n",
    "                        hue=\"risk_level\",\n",
    "                        marker='.'\n",
    "                     )\n",
    "\n",
    "                # add labels here\n",
    "                for v in plot_df.iterrows():\n",
    "                    plt.text(v[1][6], v[1][5], f'{v[1][7]}', size=4)\n",
    "\n",
    "                ax.set_xlabel(\"Context length\")\n",
    "                ax.set_ylabel(\"Predicted Restricted Mean Survival Time\")\n",
    "                ax.set_title(f\"AUC survival curves for {event_name} against provided context length, stratified by risk level\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(out_dir + f\"rmst_{event_name}.png\") \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset                                       FineTune_MultiMorbidity50+\n",
      "risk_level                                                           low\n",
      "patient_idx                                                            1\n",
      "token                                                                106\n",
      "survival_risk          [0.0, 8.3127753e-07, 1.5807328e-06, 2.2548534e...\n",
      "total_survival_risk                                             0.000074\n",
      "context_len                                                            1\n",
      "last_observed_event                                        TYPE2DIABETES\n",
      "Name: 4, dtype: object\n",
      "7.399753667414188e-05\n",
      "1\n",
      "TYPE2DIABETES\n"
     ]
    }
   ],
   "source": [
    "for v in plot_df.iterrows():\n",
    "    print(v[1])\n",
    "    print(v[1][5])\n",
    "    print(v[1][6])\n",
    "    print(v[1][7])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx_patient)\n",
    "print(df.head())\n",
    "rows_of_interest = (df.query(\"dataset==@dataset & patient_idx==@idx_patient\")\n",
    "                    .sort_values('context_len', ascending=False)  # largest first\n",
    "                    .drop_duplicates(['dataset', \"risk_level\", \"token\", 'patient_idx'])     # keep max per group\n",
    "                    .reset_index(drop=True))\n",
    "print(rows_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate \"what-if?\" next-event risks for a handful of curated cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Version of SurvStreamGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../../confs\", job_name=\"testing_notebook\"):\n",
    "    cfg = compose(config_name=\"config_SingleRisk11M\", \n",
    "                  # overrides=[\n",
    "                  #     ]\n",
    "                 )\n",
    "\n",
    "# Just load in pretrained model\n",
    "cfg.experiment.train = False\n",
    "cfg.experiment.test = False\n",
    "cfg.experiment.log = False\n",
    "cfg.experiment.run_id = \"SR_11M\" \n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "save_path = f\"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/{cfg.experiment.run_id}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28      \n",
    "\n",
    "model, dm = run(cfg)     \n",
    "print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm.train_set.view_sample(100, report_time=True)\n",
    "\n",
    "# for batch in dm.train_dataloader():\n",
    "#     break\n",
    "# print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(200)\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "display(dm.tokenizer._event_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dm.meta_information[\"measurement_tables\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default context start\n",
    "baseline_covariates = {\"sex\": \"F\", \"deprivation\": 1.0, \"ethnicity\": \"WHITE\", \"year_of_birth\": 1997-40}\n",
    "prompt = [\"O_E___height_1\", \"O_E___weight_2\"]\n",
    "values = [163, 80]\n",
    "ages_in_years = [18.2, 18.2]\n",
    "\n",
    "# define encoding functions (TODO: add this wrap to datamodule\n",
    "encode_prompt = lambda prompt_list: torch.from_numpy(np.array(dm.encode(prompt_list)).reshape((1,-1))).to(device)\n",
    "encode_value = lambda prompt_list, value_list: torch.tensor(np.array([dm.standardise(_cat, _val) for _cat, _val in zip(prompt_list, value_list) ]).reshape((1,-1)), dtype=torch.float32).to(device)\n",
    "encode_age = lambda age_list: torch.tensor([365 * _age for _age in age_list], dtype=torch.int64).reshape((1,-1)).to(device)\n",
    "\n",
    "# Convert for model\n",
    "covariates = dm.train_set._encode_covariates(**baseline_covariates).reshape(1,-1).to(device)\n",
    "tokens = encode_prompt(prompt)\n",
    "values_scaled = encode_value(prompt, values)\n",
    "ages_in_days = encode_age(ages_in_years)\n",
    "\n",
    "print(values_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate: sample the next 10 tokens\n",
    "new_tokens, new_ages, new_values = model.generate(tokens, ages_in_days, values_scaled, covariates, max_new_tokens=40)\n",
    "\n",
    "# report:\n",
    "print(f\"Baseline covariates: \\n{baseline_covariates}\\n\" + \"=\"*90)\n",
    "print(f\"PROMPT:\")\n",
    "for _idx, (_cat, _age, _value) in enumerate(zip(dm.decode(new_tokens[0].tolist()).split(\" \"), \n",
    "                                                new_ages[0, :], \n",
    "                                                new_values[0, :]\n",
    "                                               )\n",
    "                                           ):\n",
    "    # _value = dm.unstandardise(_cat, _value)\n",
    "    print(f\"{_cat}\".ljust(50) + f\"{_value:.02f}\".ljust(15) + f\"at age {_age/365:.0f} ({int(_age)} days)\")    # with value {_value}\n",
    "    if _idx == tokens.shape[-1] - 1:\n",
    "        print(\"=\"*90)\n",
    "        print(f\"GENERATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnoses: How related conditions are impacted by each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_prompts = [[\"DEPRESSION\"], [\"TYPE1DM\"], [\"TYPE2DIABETES\"], [\"Never_smoked_tobacco_85\"], [\"Ex_smoker_84\"]]\n",
    "exp_ages = [[20] for _ in range(len(exp_prompts))]\n",
    "exp_values = [[np.nan] for _ in range(len(exp_prompts))]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, (_exp_prompt, _exp_age, _exp_value) in enumerate(zip(exp_prompts, \n",
    "                                                                    exp_ages, \n",
    "                                                                    exp_values)):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "        \n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        for p_idx in range(len(exp_prompts)):\n",
    "            plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{'->'.join(exp_prompts[p_idx]).lower()}\")\n",
    "        plt.xlabel(\"Time (years)\")\n",
    "        plt.ylabel(f\"$P(T>t)$ ({event_name})\")\n",
    "        plt.legend()\n",
    "        plt.savefig(save_path + f\"diabetes/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing BMI affects diagnosis risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\",\n",
    "                      \"DEATH\"\n",
    "                     ]\n",
    "\n",
    "_exp_prompt = [\"Body_mass_index_3\"]\n",
    "_exp_age = [40]\n",
    "_exp_values = [[18.], [21.], [24.], [30.], [40.]]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, _exp_value in enumerate(_exp_values):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "\n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        if event_name in events_of_interest:\n",
    "            for p_idx in range(len(_exp_values)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{_exp_values[p_idx][0]:.2f}\")\n",
    "            plt.xlabel(\"t (years)\")\n",
    "            plt.ylabel(f\"$P(T>t)$ ({event_name})\")\n",
    "            plt.legend()\n",
    "            plt.savefig(save_path + f\"bmi/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing DBP affects diagnosis risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\",\n",
    "                      \"DEATH\"\n",
    "                     ]\n",
    "\n",
    "\n",
    "_exp_prompt = [\"Diastolic_blood_pressure_5\"]\n",
    "_exp_age = [40]\n",
    "_exp_values = [[60.], [70.], [80.], [90.], [100.], [110.]]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, _exp_value in enumerate(_exp_values):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "\n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        if event_name in events_of_interest:\n",
    "            for p_idx in range(len(_exp_values)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{_exp_values[p_idx][0]:.2f}\")\n",
    "            plt.xlabel(\"t (years)\")\n",
    "            plt.ylabel(\"P(T>t) ()\")\n",
    "            plt.legend()\n",
    "            plt.savefig(save_path + f\"diastolic_blood_pressure/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How varying diagnosis affects value of DBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_of_interest = \"Diastolic_blood_pressure_5\"\n",
    "\n",
    "\n",
    "_exp_prompts = [[\"DEPRESSION\"], [\"TYPE2DIABETES\"], [\"HF_V3\"], [\"HYPERTENSION\"]]\n",
    "_exp_age = [20]\n",
    "_exp_value = [np.nan]\n",
    "\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    for p_idx, _exp_prompt in enumerate(_exp_prompts):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "        \n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        val_dist = outputs[\"values_dist\"]\n",
    "\n",
    "        dist = val_dist[model.value_layer.token_key(dm.tokenizer._stoi[measurements_of_interest])]\n",
    "        print(f\"{'->'.join(_exp_prompt)}\".ljust(30) + \"leads to\".ljust(20) + f\"standardised {measurements_of_interest} ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing bmi affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_of_interest = \"Diastolic_blood_pressure_5\"\n",
    "\n",
    "\n",
    "_exp_prompt = [\"Body_mass_index_3\"]\n",
    "_exp_values = [[18.], [21.], [24.], [30.], [40.]]\n",
    "_exp_value = [np.nan]\n",
    "\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    for p_idx, _exp_value in enumerate(_exp_values):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "        \n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        val_dist = outputs[\"values_dist\"]\n",
    "\n",
    "        dist = val_dist[model.value_layer.token_key(dm.tokenizer._stoi[measurements_of_interest])]\n",
    "        print(f\"{'->'.join(_exp_prompt)} of {_exp_value[0]}\".ljust(30) + \"leads to\".ljust(20) + f\"standardised {measurements_of_interest} ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, impact of gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\",\n",
    "                      \"POLYCYSTIC_OVARIAN_SYNDROME_PCOS_V2\",\n",
    "                      \"DEATH\"\n",
    "                     ]\n",
    "\n",
    "_genders = [\"M\", \"F\", \"I\"]\n",
    "_exp_prompt = [\"Diastolic_blood_pressure_5\"]\n",
    "_exp_age = [20]\n",
    "_exp_value = [90.]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, _gender in enumerate(_genders):\n",
    "\n",
    "        _baseline_covariate = {\"sex\": _gender, \"deprivation\": 4.0, \"ethnicity\": \"WHITE\", \"year_of_birth\": 1997}\n",
    "        _covariates = dm.train_set._encode_covariates(**_baseline_covariate).reshape(1,-1).to(device)\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "\n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=_covariates,\n",
    "                              is_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        if event_name in events_of_interest:\n",
    "            for p_idx in range(len(_genders)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{_genders[p_idx]}\")\n",
    "            plt.xlabel(\"t (years)\")\n",
    "            plt.ylabel(\"P(T>t) ()\")\n",
    "            plt.legend()\n",
    "            plt.savefig(save_path + f\"gender/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html --no-input generation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
