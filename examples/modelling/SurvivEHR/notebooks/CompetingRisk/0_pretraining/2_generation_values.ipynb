{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Generation Demo Notebook:\n",
    "## SurvivEHR: Competing Risk Survival Transformer For Causal Sequence Modelling \n",
    "\n",
    "In this notebook we demonstrate how different risk factors contribute to the generation of future patient timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/modelling/SurvivEHR/notebooks/CompetingRisk/0_pretraining\n",
      "env: SLURM_NTASKS_PER_NODE=28       # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env SLURM_NTASKS_PER_NODE=28       # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from pycox.evaluation import EvalSurv\n",
    "from tqdm import tqdm\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from contextlib import redirect_stdout\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from CPRD.examples.modelling.SurvivEHR.run_experiment import run\n",
    "from CPRD.examples.modelling.SurvivEHR.setup_causal_experiment import CausalExperiment\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "from CPRD.examples.data.map_to_reduced_names import convert_event_names, EVENT_NAME_SHORT_MAP\n",
    "\n",
    "from FastEHR.dataloader import FoundationalDataModule\n",
    "from FastEHR.database.collector import SQLiteDataCollector\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "warnings.simplefilter('error', np.VisibleDeprecationWarning)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of how input can affect future risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_batch_to_t2dm_risk_profile(batch, risk=\"low\"):\n",
    "    \"\"\"\n",
    "    Given a loaded batch, replace certain risk-factors for cardiovascular disease and t2dm to three levels: low, medium, and high.\n",
    "    This can then be used to see the 'what-if?' effect of changing these factors in next-event prediction risk\n",
    "    \"\"\"\n",
    "\n",
    "    match risk:\n",
    "        case \"low\":            \n",
    "            # Normal person\n",
    "            static_covariates = dm.test_set._encode_covariates(\"F\", 1.0, \"ASIAN\", 1963)\n",
    "\n",
    "            risk_event_map = {\"Ex_smoker_84\": \"Never_smoked_tobacco_85\",\n",
    "                              \"Current_smoker_83\": \"Never_smoked_tobacco_85\",\n",
    "                             }\n",
    "            risk_value_map = {\"Diastolic_blood_pressure_5\": 80,\n",
    "                              \"Systolic_blood_pressure_4\": 120,\n",
    "                              \"Body_mass_index_3\": 24,\n",
    "                              \"O_E___weight_2\": np.nan,\n",
    "                             }\n",
    "            # new_risk_events = []\n",
    "            \n",
    "        case \"medium\" | \"mid\":\n",
    "            # At some risk\n",
    "            static_covariates = dm.test_set._encode_covariates(\"F\", 3.0, \"ASIAN\", 1963)\n",
    "\n",
    "            risk_event_map = {\"Never_smoked_tobacco_85\": \"Ex_smoker_84\",\n",
    "                              \"Current_smoker_83\": \"Ex_smoker_84\"\n",
    "                             }\n",
    "            risk_value_map = {\"Diastolic_blood_pressure_5\": 90,\n",
    "                              \"Systolic_blood_pressure_4\": 140,\n",
    "                              \"Body_mass_index_3\": 28,\n",
    "                              \"O_E___weight_2\": np.nan,\n",
    "                             }\n",
    "            # new_risk_events = []\n",
    "                        \n",
    "        case \"high\":\n",
    "            # At higher risk\n",
    "            static_covariates = dm.test_set._encode_covariates(\"F\", 5.0, \"ASIAN\", 1963)\n",
    "\n",
    "            risk_event_map = {\"Never_smoked_tobacco_85\": \"Current_smoker_83\",\n",
    "                              \"Ex_smoker_84\": \"Current_smoker_83\"\n",
    "                             }\n",
    "            risk_value_map = {\"Diastolic_blood_pressure_5\": 100,\n",
    "                              \"Systolic_blood_pressure_4\": 150,\n",
    "                              \"Body_mass_index_3\": 32,\n",
    "                              \"O_E___weight_2\": np.nan,\n",
    "                             }\n",
    "            # new_risk_events = [\"ALCOHOLMISUSE_V2\"]\n",
    "            \n",
    "        case _:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    # Shape\n",
    "    bsz, L = batch[\"tokens\"].shape\n",
    "    device = batch[\"tokens\"].device\n",
    "\n",
    "    # Tokenize maps\n",
    "    ###############\n",
    "    \n",
    "    # Put all event conversions into token form\n",
    "    token_event_map = {}\n",
    "    for old_key, old_item in risk_event_map.items():\n",
    "        new_key = dm.encode([old_key])[0]\n",
    "        new_item = dm.encode([old_item])[0]\n",
    "        token_event_map.update({new_key: new_item})\n",
    "    \n",
    "    # Put all value conversions into token form\n",
    "    token_value_map = {}\n",
    "    for old_key, item in risk_value_map.items():\n",
    "        new_key = dm.encode([old_key])[0]\n",
    "        standardised_item = dm.standardise(old_key, item)\n",
    "        token_value_map.update({new_key: standardised_item})\n",
    "\n",
    "    # Update patient profiles\n",
    "    #########################\n",
    "\n",
    "    # Set everyone in batch to the same risk-profile's baseline static covariates\n",
    "    static_covariates = torch.tile(static_covariates, (bsz, 1))\n",
    "    \n",
    "    # apply event conversions\n",
    "    tokens = batch[\"tokens\"].clone()\n",
    "    for old, new in token_event_map.items():\n",
    "        mask           = (batch[\"tokens\"] == old)\n",
    "        tokens[mask]   = new\n",
    "\n",
    "    # Apply value conversion\n",
    "    values = batch[\"values\"].clone()\n",
    "    for old, new in token_value_map.items():\n",
    "        mask           = (batch[\"tokens\"] == old)\n",
    "        values[mask]   = new\n",
    "\n",
    "    new_batch = {\n",
    "        \"static_covariates\": static_covariates.to(device),\n",
    "        \"tokens\": tokens.to(device),\n",
    "        \"ages\": batch[\"ages\"],\n",
    "        \"values\": values.to(device),\n",
    "        \"attention_mask\": batch[\"attention_mask\"],\n",
    "        }\n",
    "    \n",
    "    return new_batch\n",
    "\n",
    "def clip_outliers(token, unstandardised_value):\n",
    "    \"\"\"\n",
    "    Because of heavy right tails in the value distributions, standardisation of some token values over-estimates the lower quantile.\n",
    "    This method ensures no values beyond those seen in the data are reported.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert not np.isnan(unstandardised_value)\n",
    "        token_meta = dm.meta_information[\"measurement_tables\"][dm.meta_information[\"measurement_tables\"][\"event\"] == token]\n",
    "        _min = token_meta[\"min\"]\n",
    "        _max = token_meta[\"max\"]\n",
    "        unstandardised_value = np.min((unstandardised_value, _max))\n",
    "        unstandardised_value = np.max((unstandardised_value, _min))\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    return unstandardised_value\n",
    "\n",
    "def report_generation(static, tokens, ages, values, attention_mask, true_seq_len, dm, eos_token=\"DEATH\", **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    tokens = tokens[0, :]\n",
    "    ages = ages[0, :]\n",
    "    values = values[0, :]\n",
    "    attention_mask = attention_mask[0, :]\n",
    "\n",
    "    static = dm.test_set._decode_covariates(static.cpu())\n",
    "    print(\"STATIC INFORMATION\")\n",
    "    print(\"=\"*120)\n",
    "    for key, item in static.items():\n",
    "        print(f\"\\t{key}:\".ljust(20) + f\"{item[0]}\")\n",
    "\n",
    "    # Report\n",
    "    tokens = dm.tokenizer.decode(tokens.tolist()).split(\" \")\n",
    "    diagnoses = []\n",
    "    last_age_day, last_age_week = 0, 0\n",
    "    print(\"\\n\\nGiven patient context\".upper())\n",
    "    print(\"=\"*120)\n",
    "    print(f\"\\tEVENT\".ljust(75) + \"| AGE IN WEEKS (days, years)\".ljust(30) + \" | VALUE\")\n",
    "    for idx_event, (token, _age, value, attn_mask) in enumerate(zip(tokens, ages, values, attention_mask)):\n",
    "\n",
    "        if attn_mask == 0:\n",
    "            break\n",
    "            \n",
    "        # Unscale age and bin to week fidelity\n",
    "        age_day = int(_age * dm.test_set.time_scale)\n",
    "        age_week = int(age_day / 7) \n",
    "        age_years = int(age_day / 365)\n",
    "\n",
    "        # If new event create break\n",
    "        if age_week != last_age_week:\n",
    "            print(\"\\t\" + \".\"*60 + \"new week\" + \".\"*60)\n",
    "\n",
    "        # Report next event\n",
    "        age = f\"{age_week}\\t ({age_day}, {age_years})\"\n",
    "        unstandardised_value = clip_outliers(token, dm.unstandardise(token, value))\n",
    "        value = f\"{unstandardised_value:.2f}\".ljust(10) + f\"({value:.2f})\"\n",
    "        print(f\"\\t{token.ljust(75)}| {age.ljust(30)}| {value}\".ljust(20))\n",
    "        \n",
    "        if token.upper() == token:\n",
    "            diagnoses.append(token)\n",
    "\n",
    "        if idx_event == true_seq_len - 1:\n",
    "            print(\"\\n\" + \"=\"*120)\n",
    "            print(\"Diagnosis summary\".upper())\n",
    "            print(f\"{diagnoses}\")\n",
    "            print(\"=\"*120)\n",
    "            print(\"\\n\")\n",
    "            print(\"Predicted future events\".upper())\n",
    "            print(\"=\"*120)\n",
    "            print(f\"\\tEVENT\".ljust(75) + \"| AGE IN WEEKS (days, years)\".ljust(30) + \"| VALUE\")\n",
    "\n",
    "\n",
    "        last_age_day = age_day\n",
    "        last_age_week = age_week\n",
    "        if token == eos_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_models = [\"SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1\"]\n",
    "config_names = [\"config_CompetingRisk11M\"]\n",
    "\n",
    "datasets = [ \"PreTrain\",\n",
    "             #\"FineTune_Hypertension\",\n",
    "             #\"FineTune_CVD\", \n",
    "             #\"FineTune_MultiMorbidity50+\"\n",
    "           ]\n",
    "patients_of_interest = [[10],\n",
    "                        #[0],\n",
    "                        #[10],\n",
    "                        #[1]\n",
    "                       ]\n",
    "\n",
    "risk_levels = [\"low\", \"mid\", \"high\",]\n",
    "outcomes_of_interest = [\"HYPERTENSION\", \"Body_mass_index_3\", \"HF_V3\", \"TYPE2DIABETES\",  \"TYPE1DM\", \"DEATH\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate \"what-if?\" next-event risks for a handful of selected patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 1 GPUs\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/. This will be loaded in causal form.\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Creating unsupervised collator for DataModule\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Set seed to 1337\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=train/ dataset, with 23,613,894 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=test/ dataset, with 1,508,320 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=val/ dataset, with 1,426,714 samples\n",
      "INFO:root:is_decoder: true\n",
      "data:\n",
      "  batch_size: 64\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 3\n",
      "  global_diagnoses: false\n",
      "  repeating_events: true\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/cprd.db\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "  subsample_training: null\n",
      "experiment:\n",
      "  type: pre-train\n",
      "  project_name: SurvivEHR\n",
      "  run_id: SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1\n",
      "  fine_tune_id: null\n",
      "  notes: null\n",
      "  tags: null\n",
      "  train: false\n",
      "  test: false\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: false\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "fine_tuning:\n",
      "  fine_tune_outcomes: null\n",
      "  custom_outcome_method:\n",
      "    _target_: null\n",
      "  custom_stratification_method:\n",
      "    _target_: null\n",
      "  use_callbacks:\n",
      "    hidden_embedding:\n",
      "      num_batches: 1\n",
      "      mask_static: false\n",
      "      mask_value: false\n",
      "    performance_metrics: true\n",
      "    rmst: false\n",
      "  head:\n",
      "    surv_weight: 1\n",
      "    value_weight: 0\n",
      "    learning_rate: 0.0005\n",
      "optim:\n",
      "  num_epochs: 1\n",
      "  learning_rate: 0.0003\n",
      "  scheduler_warmup: true\n",
      "  scheduler: decaycawarmrestarts\n",
      "  scheduler_periods: 10000\n",
      "  learning_rate_decay: 0.8\n",
      "  val_check_interval: 2500\n",
      "  early_stop: true\n",
      "  early_stop_patience: 30\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.025\n",
      "  limit_test_batches: null\n",
      "  accumulate_grad_batches: 1\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 256\n",
      "  n_layer: 6\n",
      "  n_head: 6\n",
      "  n_embd: 384\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "  private_heads: 0\n",
      "  use_fine_tune_adapter: false\n",
      "  adapter_dim: 8\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 1\n",
      "  tokens_for_univariate_regression:\n",
      "  - 84\n",
      "  - 86\n",
      "  - 107\n",
      "  - 154\n",
      "  - 42\n",
      "  - 231\n",
      "  - 63\n",
      "  - 85\n",
      "  - 247\n",
      "  - 51\n",
      "  - 103\n",
      "  - 146\n",
      "  - 66\n",
      "  - 172\n",
      "  - 152\n",
      "  - 261\n",
      "  - 235\n",
      "  - 193\n",
      "  - 184\n",
      "  - 101\n",
      "  - 223\n",
      "  - 135\n",
      "  - 226\n",
      "  - 202\n",
      "  - 145\n",
      "  - 244\n",
      "  - 165\n",
      "  - 64\n",
      "  - 185\n",
      "  - 238\n",
      "  - 220\n",
      "  - 232\n",
      "  - 240\n",
      "  - 237\n",
      "  - 17\n",
      "  - 239\n",
      "  - 217\n",
      "  - 118\n",
      "  - 219\n",
      "  - 251\n",
      "  - 25\n",
      "  - 150\n",
      "  - 111\n",
      "  - 102\n",
      "  - 15\n",
      "  - 110\n",
      "  - 130\n",
      "  - 128\n",
      "  - 122\n",
      "  - 99\n",
      "  - 77\n",
      "  - 96\n",
      "  - 140\n",
      "  - 50\n",
      "  - 80\n",
      "  - 108\n",
      "  - 138\n",
      "  - 27\n",
      "  - 139\n",
      "  - 125\n",
      "  - 117\n",
      "  - 105\n",
      "  - 109\n",
      "  - 243\n",
      "  - 236\n",
      "  - 208\n",
      "  - 98\n",
      "  - 176\n",
      "  - 209\n",
      "  - 194\n",
      "  - 61\n",
      "  - 73\n",
      "  - 214\n",
      "  - 206\n",
      "  - 229\n",
      "  - 225\n",
      "  - 183\n",
      "  - 186\n",
      "  - 215\n",
      "  - 187\n",
      "  - 248\n",
      "  - 179\n",
      "  - 163\n",
      "  - 180\n",
      "  - 181\n",
      "  - 153\n",
      "  - 245\n",
      "  - 54\n",
      "  - 246\n",
      "  - 112\n",
      "  - 212\n",
      "  - 141\n",
      "  - 204\n",
      "  - 227\n",
      "  - 173\n",
      "  - 55\n",
      "  - 119\n",
      "  - 262\n",
      "  - 127\n",
      "  - 71\n",
      "  - 59\n",
      "  - 144\n",
      "  - 113\n",
      "  - 170\n",
      "  - 241\n",
      "  - 168\n",
      "  - 47\n",
      "  - 159\n",
      "  value_weight: 0.1\n",
      "\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:# Pre-training experiment\n",
      "INFO:root:====================================================================================================\n",
      "INFO:root:Loading a pre-trained model with the checkpoint path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1.ckpt.\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using a DeSurv Competing-Risk head.\n",
      "INFO:root:\tWith concurrent strategy=add_noise for handling simultaneous events.\n",
      "INFO:root:\tEvaluating on a time grid between [0.0, 1.0] with 1000 intervals\n",
      "INFO:root:Created hidden state embedding callback  \n",
      "INFO:root:Created PerformanceMetrics callback for causal self-supervised tasks.\n",
      "INFO:root:\t \n",
      "INFO:root:Interactive job = True\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:root:Creating unsupervised collator for DataModule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model SurvivEHR-cr-small-debug7_exp1000-v1-v4-v1 with 11.20919 M parameters\n",
      "Generating patient's next event risk for dataset PreTrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=train/ dataset, with 23,613,894 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=test/ dataset, with 1,508,320 samples\n",
      "INFO:root:Set seed to 42\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=val/ dataset, with 1,426,714 samples\n",
      "Saving low-converted timeline for all considered patients in batch: 100%|##########| 1/1 [00:00<00:00, 29.15it/s]\n",
      "Recording low-converted outcome risks for all considered patients in batch: 100%|##########| 255/255 [00:42<00:00,  6.00it/s]\n",
      "Saving mid-converted timeline for all considered patients in batch: 100%|##########| 1/1 [00:00<00:00, 32.13it/s]\n",
      "Recording mid-converted outcome risks for all considered patients in batch: 100%|##########| 255/255 [00:42<00:00,  6.03it/s]\n",
      "Saving high-converted timeline for all considered patients in batch: 100%|##########| 1/1 [00:00<00:00, 32.48it/s]\n",
      "Recording high-converted outcome risks for all considered patients in batch: 100%|##########| 255/255 [00:42<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset risk_level  patient_idx  token  \\\n",
      "0  PreTrain        low           10    129   \n",
      "1  PreTrain        low           10    247   \n",
      "2  PreTrain        low           10     74   \n",
      "3  PreTrain        low           10    100   \n",
      "4  PreTrain        low           10     36   \n",
      "\n",
      "                                       survival_risk  total_survival_risk  \\\n",
      "0  [0.0, 9.656151e-08, 1.3165229e-07, 1.4441537e-...         1.514882e-07   \n",
      "1  [0.0, 3.3511304e-05, 4.8969396e-05, 5.6102104e...         6.210396e-05   \n",
      "2  [0.0, 5.6980434e-09, 9.533974e-09, 1.2116994e-...         1.740161e-08   \n",
      "3  [0.0, 3.266222e-08, 5.3049597e-08, 6.578297e-0...         8.682732e-08   \n",
      "4  [0.0, 1.4359887e-09, 2.2147377e-09, 2.6371827e...         3.131878e-09   \n",
      "\n",
      "   context_len         last_observed_event  \n",
      "0            1  Diastolic_blood_pressure_5  \n",
      "1            1  Diastolic_blood_pressure_5  \n",
      "2            1  Diastolic_blood_pressure_5  \n",
      "3            1  Diastolic_blood_pressure_5  \n",
      "4            1  Diastolic_blood_pressure_5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for pre_trained_model, config_name in zip(pre_trained_models, config_names):\n",
    "    os.makedirs(f\"figs/generation/{pre_trained_model}/\", exist_ok=True) \n",
    "\n",
    "    # load the configuration file, override any settings \n",
    "    with initialize(version_base=None, config_path=\"../../../confs\", job_name=\"testing_notebook\"):\n",
    "        cfg = compose(config_name=config_name, \n",
    "                      overrides=[# Experiment setup\n",
    "                                 f\"experiment.run_id='{pre_trained_model}'\",\n",
    "                                 \"experiment.train=False\",\n",
    "                                 \"experiment.test=False\",\n",
    "                                 \"experiment.log=False\",\n",
    "                                 # Dataloader\n",
    "                                 \"data.meta_information_path=/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\",\n",
    "                                 \"data.min_workers=3\",\n",
    "                                ]\n",
    "                     )     \n",
    "    experiment, dm = run(cfg)     \n",
    "    print(f\"Loaded model {pre_trained_model} with {sum(p.numel() for p in experiment.parameters())/1e6} M parameters\")\n",
    "    \n",
    "    for idx_dataset, dataset in enumerate(datasets):\n",
    "        print(f\"Generating patient's next event risk for dataset {dataset}\")        \n",
    "        gen_save_path = f'figs/generation/{pre_trained_model}/{dataset}_dataset/'\n",
    "        os.makedirs(gen_save_path, exist_ok=True) \n",
    "\n",
    "        # store dataset results in\n",
    "        data_rows = []\n",
    "\n",
    "        # Load dataset\n",
    "        dm = FoundationalDataModule(path_to_db=cfg.data.path_to_db,\n",
    "                                    path_to_ds=f\"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/{dataset}/\",\n",
    "                                    overwrite_meta_information=cfg.data.meta_information_path,\n",
    "                                    load=True,\n",
    "                                    supervised=False if dataset.lower()==\"pretrain\" else True,\n",
    "                                    )\n",
    "        \n",
    "        # Load the first batch\n",
    "        for batch in dm.test_dataloader():\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            break\n",
    "\n",
    "        # The patients within the batch we are interested in\n",
    "        bsz, L = batch[\"tokens\"].shape\n",
    "        patients = patients_of_interest[idx_dataset] if patients_of_interest[idx_dataset] is not None else [i for i in range(bsz)]\n",
    "\n",
    "        # For each risk level, map the patients of interest to the risk level, report them to file, and plot the next-event risks\n",
    "        batches_by_risk = []\n",
    "        for risk_level in risk_levels:\n",
    "\n",
    "            # Map to risk level\n",
    "            ###################\n",
    "            batch_risk_adjusted = map_batch_to_t2dm_risk_profile(batch, risk=risk_level)\n",
    "            batches_by_risk.append(batch_risk_adjusted)\n",
    "\n",
    "            # Report mapped timelines for each patient of interest\n",
    "            ######################################################\n",
    "            for idx_patient in tqdm(patients, ascii=True, desc=f\"Saving {risk_level}-converted timeline for all considered patients in batch\"):\n",
    "                out_dir = gen_save_path + f'patient{idx_patient}/'\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "                with open(out_dir + f\"mapped_to_risk_level_{risk_level}.txt\", 'w') as f:\n",
    "                    with redirect_stdout(f):\n",
    "                        report_generation(\n",
    "                            static         = batch_risk_adjusted[\"static_covariates\"][idx_patient], \n",
    "                            tokens         = batch_risk_adjusted[\"tokens\"][[idx_patient],:],\n",
    "                            ages           = batch_risk_adjusted[\"ages\"][[idx_patient],:], \n",
    "                            values         = batch_risk_adjusted[\"values\"][[idx_patient], :], \n",
    "                            attention_mask = batch_risk_adjusted[\"attention_mask\"][[idx_patient], :],\n",
    "                            true_seq_len   = batch_risk_adjusted[\"attention_mask\"][[idx_patient], :].sum(), \n",
    "                            dm             = dm\n",
    "                        )\n",
    "\n",
    "            # Plot final risks after full timeline has been given to SurvivEHR\n",
    "            ###################################################################\n",
    "\n",
    "            for l in tqdm(range(1, L, 1), \n",
    "                          ascii=True, desc=f\"Recording {risk_level}-converted outcome risks for all considered patients in batch\"):\n",
    "                # Get next-event risks for patients in batch mapped to the risk level\n",
    "                outputs, _, _  = experiment.model(\n",
    "                    covariates        = batch_risk_adjusted[\"static_covariates\"],\n",
    "                    tokens            = batch_risk_adjusted['tokens'][:, :l],\n",
    "                    ages              = batch_risk_adjusted['ages'][:, :l],\n",
    "                    values            = batch_risk_adjusted['values'][:, :l],\n",
    "                    attention_mask    = batch_risk_adjusted['attention_mask'][:, :l],\n",
    "                    is_generation     = True,\n",
    "                    return_loss       = False,\n",
    "                    return_generation = True,\n",
    "                    )\n",
    "                pred_surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "                pred_values = outputs[\"values_dist\"]\n",
    "    \n",
    "                for idx_patient in patients:\n",
    "                    out_dir = gen_save_path + f'patient{idx_patient}/'\n",
    "                    patient_true_seq_len = batch_risk_adjusted[\"attention_mask\"][[idx_patient], :].sum()\n",
    "                    \n",
    "                    last_observed_token = batch_risk_adjusted['tokens'][idx_patient, l-1]\n",
    "                    last_observed_event = dm.decode([last_observed_token.tolist()])\n",
    "\n",
    "                    \n",
    "                    if l > patient_true_seq_len:\n",
    "                        continue\n",
    "                    \n",
    "                    for event_name in outcomes_of_interest:\n",
    "    \n",
    "                        tkn_of_interest = dm.encode([event_name])[0]\n",
    "                        event_surv_pred = pred_surv[tkn_of_interest - 1][idx_patient]\n",
    "    \n",
    "                        data_rows.append(\n",
    "                            dict(dataset             = dataset,\n",
    "                                 risk_level          = risk_level,\n",
    "                                 patient_idx         = idx_patient,\n",
    "                                 token               = tkn_of_interest,\n",
    "                                 survival_risk       = event_surv_pred,\n",
    "                                 total_survival_risk = np.mean(event_surv_pred),\n",
    "                                 context_len         = l,\n",
    "                                 last_observed_event = last_observed_event,\n",
    "                                 )\n",
    "                        )\n",
    "\n",
    "        df = pd.DataFrame(data_rows)\n",
    "        print(df.head())\n",
    "        df.to_pickle(gen_save_path + \"risk_level_survival_table.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in list(dm.tokenizer._event_counts[\"EVENT\"]):\n",
    "#     if \"diab\" in i.lower():\n",
    "#         print(i)\n",
    "\n",
    "# print(batch[\"static_covariates\"].shape)\n",
    "# # static = dm.test_set._decode_covariates(batch[\"static_covariates\"].cpu())\n",
    "# # print(static)\n",
    "\n",
    "# static = dm.test_set._encode_covariates(\"F\", 1.0, \"ASIAN\", 1963)\n",
    "# print(static.shape)\n",
    "# print(dm.test_set._decode_covariates(static))\n",
    "\n",
    "# print(map_batch_to_t2dm_risk_profile(batch, risk=\"low\"))\n",
    "# print(map_batch_to_t2dm_risk_profile(batch, risk=\"high\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147334/990206439.py:60: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  ax = sns.lineplot(\n",
      "/tmp/ipykernel_147334/990206439.py:60: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  ax = sns.lineplot(\n",
      "/tmp/ipykernel_147334/990206439.py:60: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  ax = sns.lineplot(\n"
     ]
    }
   ],
   "source": [
    "datasets = [ \"PreTrain\",\n",
    "             \"FineTune_Hypertension\",\n",
    "             \"FineTune_CVD\", \n",
    "             \"FineTune_MultiMorbidity50+\"]\n",
    "patients_of_interest = [[10],\n",
    "                        [0],\n",
    "                        [10],\n",
    "                        [1]]\n",
    "\n",
    "\n",
    "for pre_trained_model, config_name in zip(pre_trained_models, config_names):\n",
    "    os.makedirs(f\"figs/generation/{pre_trained_model}/\", exist_ok=True) \n",
    "    \n",
    "    for idx_dataset, dataset in enumerate(datasets):\n",
    "        gen_save_path = f'figs/generation/{pre_trained_model}/{dataset}_dataset/'\n",
    "        patients = patients_of_interest[idx_dataset] if patients_of_interest[idx_dataset] is not None else [i for i in range(bsz)]\n",
    "        df = pd.read_pickle(gen_save_path + \"risk_level_survival_table.pkl\")\n",
    "\n",
    "        for idx_patient in patients:\n",
    "            out_dir = gen_save_path + f'patient{idx_patient}/'\n",
    "\n",
    "            for event_name in outcomes_of_interest:\n",
    "    \n",
    "                tkn_of_interest = dm.encode([event_name])[0]\n",
    "\n",
    "                # Create colour pallete\n",
    "                custom_colors = {\n",
    "                    \"low\": sns.xkcd_rgb['avocado'], \n",
    "                    \"mid\": sns.xkcd_rgb[\"golden rod\"], \n",
    "                    \"high\": sns.xkcd_rgb[\"burnt red\"],\n",
    "                }\n",
    "    \n",
    "                \n",
    "                plot_df = (df.query(\"dataset==@dataset & patient_idx==@idx_patient & token==@tkn_of_interest\")\n",
    "                           .sort_values('context_len', ascending=False)                            # largest first\n",
    "                           .drop_duplicates(['dataset', \"risk_level\", \"token\", 'patient_idx'])     # keep first row it meets per group, the one with largest context\n",
    "                           .reset_index(drop=True)\n",
    "                          )\n",
    "\n",
    "                # Explode along the survival_risk vector to expand the dataframe\n",
    "                plot_df_long = (\n",
    "                    plot_df\n",
    "                      .explode(\"survival_risk\")                 # duplicates metaâ€‘columns\n",
    "                      .assign(                                  # add the matching time point\n",
    "                          time_idx=lambda d: d.groupby(\n",
    "                              [\"dataset\", \"patient_idx\", \"risk_level\"]\n",
    "                          ).cumcount()\n",
    "                      )\n",
    "                )\n",
    "\n",
    "                # Get the times SurvivEHR forecasts over\n",
    "                model_time = experiment.model.surv_layer.t_eval\n",
    "                scale_time = model_time = dm.train_set.time_scale\n",
    "                plot_df_long[\"Time to event (years)\"] = plot_df_long[\"time_idx\"].apply(lambda i: experiment.model.surv_layer.t_eval[i] * scale_time / 365)\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "                plt.figure(figsize=(6*0.9,4*0.9))\n",
    "                sns.set(style=\"whitegrid\")\n",
    "                ax = sns.lineplot(\n",
    "                    data=plot_df_long,\n",
    "                    x=\"Time to event (years)\", \n",
    "                    y=\"survival_risk\",\n",
    "                    hue=\"risk_level\",\n",
    "                    legend=False,\n",
    "                    palette=custom_colors,\n",
    "                    lw=2.5,\n",
    "                 )\n",
    "                \n",
    "                # ax.set_xlabel(\"Time index\")\n",
    "                ax.set_ylabel(\"Risk of event\")\n",
    "                # ax.set_title(f\"Survival curves for {event_name} by risk level\")\n",
    "                \n",
    "                # plt.grid()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(out_dir + f\"risk_{event_name}.png\") \n",
    "        \n",
    "                # print(event_name)\n",
    "                # print(event_surv_pred.shape)\n",
    "                # plt.close()\n",
    "                # plt.plot(experiment.model.surv_layer.t_eval / 365, ) #  label=f\"{'->'.join(exp_prompts[p_idx]).lower()}\"\n",
    "                # plt.savefig(out_dir + f\"{risk_level}_{event_name}.png\")\n",
    "                    \n",
    "                    # for p_idx in range(len(exp_prompts)):\n",
    "                        # plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{'->'.join(exp_prompts[p_idx]).lower()}\")\n",
    "                        \n",
    "                    # plt.xlabel(\"Time (years)\")\n",
    "                    # plt.ylabel(f\"$P(T>t)$ ({event_name})\")\n",
    "                    # plt.legend()\n",
    "                    # plt.savefig(out_dir + f\"{event_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dataset', 'risk_level', 'patient_idx', 'token', 'survival_risk',\n",
      "       'total_survival_risk', 'context_len', 'last_observed_event', 'time_idx',\n",
      "       'Time to event (years)'],\n",
      "      dtype='object')\n",
      "['high' 'mid' 'low']\n"
     ]
    }
   ],
   "source": [
    "print(plot_df_long.columns)\n",
    "print(plot_df_long[\"risk_level\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre_trained_model, config_name in zip(pre_trained_models, config_names):\n",
    "    os.makedirs(f\"figs/generation/{pre_trained_model}/\", exist_ok=True) \n",
    "    \n",
    "    for idx_dataset, dataset in enumerate(datasets):\n",
    "        gen_save_path = f'figs/generation/{pre_trained_model}/{dataset}_dataset/'\n",
    "        patients = patients_of_interest[idx_dataset] if patients_of_interest[idx_dataset] is not None else [i for i in range(bsz)]\n",
    "        df = pd.read_pickle(gen_save_path + \"risk_level_survival_table.pkl\")\n",
    "\n",
    "        df[\"last_observed_event\"] = df[\"last_observed_event\"].map(EVENT_NAME_SHORT_MAP)\n",
    "\n",
    "        for idx_patient in patients:\n",
    "            out_dir = gen_save_path + f'patient{idx_patient}/'\n",
    "\n",
    "            for event_name in outcomes_of_interest:\n",
    "    \n",
    "                tkn_of_interest = dm.encode([event_name])[0]\n",
    "                \n",
    "                plot_df = df.query(\"dataset==@dataset & patient_idx==@idx_patient & token==@tkn_of_interest\")\n",
    "                          \n",
    "                plt.close()\n",
    "                plt.figure(dpi=600)\n",
    "                sns.set(style=\"whitegrid\")\n",
    "                ax = sns.lineplot(\n",
    "                        data=plot_df,\n",
    "                        x=\"context_len\", y=\"total_survival_risk\",\n",
    "                        hue=\"risk_level\",\n",
    "                        marker='.'\n",
    "                     )\n",
    "\n",
    "                # add labels here\n",
    "                for v in plot_df.iterrows():\n",
    "                    plt.text(v[1][6], v[1][5], f'{v[1][7]}', size=4)\n",
    "\n",
    "                ax.set_xlabel(\"Context length\")\n",
    "                ax.set_ylabel(\"Predicted Restricted Mean Survival Time\")\n",
    "                ax.set_title(f\"AUC survival curves for {event_name} against provided context length, stratified by risk level\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(out_dir + f\"rmst_{event_name}.png\") \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in plot_df.iterrows():\n",
    "    print(v[1])\n",
    "    print(v[1][5])\n",
    "    print(v[1][6])\n",
    "    print(v[1][7])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx_patient)\n",
    "print(df.head())\n",
    "rows_of_interest = (df.query(\"dataset==@dataset & patient_idx==@idx_patient\")\n",
    "                    .sort_values('context_len', ascending=False)  # largest first\n",
    "                    .drop_duplicates(['dataset', \"risk_level\", \"token\", 'patient_idx'])     # keep max per group\n",
    "                    .reset_index(drop=True))\n",
    "print(rows_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate \"what-if?\" next-event risks for a handful of curated cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Version of SurvStreamGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../../confs\", job_name=\"testing_notebook\"):\n",
    "    cfg = compose(config_name=\"config_SingleRisk11M\", \n",
    "                  # overrides=[\n",
    "                  #     ]\n",
    "                 )\n",
    "\n",
    "# Just load in pretrained model\n",
    "cfg.experiment.train = False\n",
    "cfg.experiment.test = False\n",
    "cfg.experiment.log = False\n",
    "cfg.experiment.run_id = \"SR_11M\" \n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "save_path = f\"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/{cfg.experiment.run_id}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28      \n",
    "\n",
    "model, dm = run(cfg)     \n",
    "print(f\"Loaded model with {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm.train_set.view_sample(100, report_time=True)\n",
    "\n",
    "# for batch in dm.train_dataloader():\n",
    "#     break\n",
    "# print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(200)\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "display(dm.tokenizer._event_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dm.meta_information[\"measurement_tables\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default context start\n",
    "baseline_covariates = {\"sex\": \"F\", \"deprivation\": 1.0, \"ethnicity\": \"WHITE\", \"year_of_birth\": 1997-40}\n",
    "prompt = [\"O_E___height_1\", \"O_E___weight_2\"]\n",
    "values = [163, 80]\n",
    "ages_in_years = [18.2, 18.2]\n",
    "\n",
    "# define encoding functions (TODO: add this wrap to datamodule\n",
    "encode_prompt = lambda prompt_list: torch.from_numpy(np.array(dm.encode(prompt_list)).reshape((1,-1))).to(device)\n",
    "encode_value = lambda prompt_list, value_list: torch.tensor(np.array([dm.standardise(_cat, _val) for _cat, _val in zip(prompt_list, value_list) ]).reshape((1,-1)), dtype=torch.float32).to(device)\n",
    "encode_age = lambda age_list: torch.tensor([365 * _age for _age in age_list], dtype=torch.int64).reshape((1,-1)).to(device)\n",
    "\n",
    "# Convert for model\n",
    "covariates = dm.train_set._encode_covariates(**baseline_covariates).reshape(1,-1).to(device)\n",
    "tokens = encode_prompt(prompt)\n",
    "values_scaled = encode_value(prompt, values)\n",
    "ages_in_days = encode_age(ages_in_years)\n",
    "\n",
    "print(values_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate: sample the next 10 tokens\n",
    "new_tokens, new_ages, new_values = model.generate(tokens, ages_in_days, values_scaled, covariates, max_new_tokens=40)\n",
    "\n",
    "# report:\n",
    "print(f\"Baseline covariates: \\n{baseline_covariates}\\n\" + \"=\"*90)\n",
    "print(f\"PROMPT:\")\n",
    "for _idx, (_cat, _age, _value) in enumerate(zip(dm.decode(new_tokens[0].tolist()).split(\" \"), \n",
    "                                                new_ages[0, :], \n",
    "                                                new_values[0, :]\n",
    "                                               )\n",
    "                                           ):\n",
    "    # _value = dm.unstandardise(_cat, _value)\n",
    "    print(f\"{_cat}\".ljust(50) + f\"{_value:.02f}\".ljust(15) + f\"at age {_age/365:.0f} ({int(_age)} days)\")    # with value {_value}\n",
    "    if _idx == tokens.shape[-1] - 1:\n",
    "        print(\"=\"*90)\n",
    "        print(f\"GENERATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnoses: How related conditions are impacted by each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_prompts = [[\"DEPRESSION\"], [\"TYPE1DM\"], [\"TYPE2DIABETES\"], [\"Never_smoked_tobacco_85\"], [\"Ex_smoker_84\"]]\n",
    "exp_ages = [[20] for _ in range(len(exp_prompts))]\n",
    "exp_values = [[np.nan] for _ in range(len(exp_prompts))]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, (_exp_prompt, _exp_age, _exp_value) in enumerate(zip(exp_prompts, \n",
    "                                                                    exp_ages, \n",
    "                                                                    exp_values)):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "        \n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        for p_idx in range(len(exp_prompts)):\n",
    "            plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{'->'.join(exp_prompts[p_idx]).lower()}\")\n",
    "        plt.xlabel(\"Time (years)\")\n",
    "        plt.ylabel(f\"$P(T>t)$ ({event_name})\")\n",
    "        plt.legend()\n",
    "        plt.savefig(save_path + f\"diabetes/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing BMI affects diagnosis risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\",\n",
    "                      \"DEATH\"\n",
    "                     ]\n",
    "\n",
    "_exp_prompt = [\"Body_mass_index_3\"]\n",
    "_exp_age = [40]\n",
    "_exp_values = [[18.], [21.], [24.], [30.], [40.]]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, _exp_value in enumerate(_exp_values):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "\n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        if event_name in events_of_interest:\n",
    "            for p_idx in range(len(_exp_values)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{_exp_values[p_idx][0]:.2f}\")\n",
    "            plt.xlabel(\"t (years)\")\n",
    "            plt.ylabel(f\"$P(T>t)$ ({event_name})\")\n",
    "            plt.legend()\n",
    "            plt.savefig(save_path + f\"bmi/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing DBP affects diagnosis risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\",\n",
    "                      \"DEATH\"\n",
    "                     ]\n",
    "\n",
    "\n",
    "_exp_prompt = [\"Diastolic_blood_pressure_5\"]\n",
    "_exp_age = [40]\n",
    "_exp_values = [[60.], [70.], [80.], [90.], [100.], [110.]]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, _exp_value in enumerate(_exp_values):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "\n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        if event_name in events_of_interest:\n",
    "            for p_idx in range(len(_exp_values)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{_exp_values[p_idx][0]:.2f}\")\n",
    "            plt.xlabel(\"t (years)\")\n",
    "            plt.ylabel(\"P(T>t) ()\")\n",
    "            plt.legend()\n",
    "            plt.savefig(save_path + f\"diastolic_blood_pressure/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How varying diagnosis affects value of DBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_of_interest = \"Diastolic_blood_pressure_5\"\n",
    "\n",
    "\n",
    "_exp_prompts = [[\"DEPRESSION\"], [\"TYPE2DIABETES\"], [\"HF_V3\"], [\"HYPERTENSION\"]]\n",
    "_exp_age = [20]\n",
    "_exp_value = [np.nan]\n",
    "\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    for p_idx, _exp_prompt in enumerate(_exp_prompts):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "        \n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        val_dist = outputs[\"values_dist\"]\n",
    "\n",
    "        dist = val_dist[model.value_layer.token_key(dm.tokenizer._stoi[measurements_of_interest])]\n",
    "        print(f\"{'->'.join(_exp_prompt)}\".ljust(30) + \"leads to\".ljust(20) + f\"standardised {measurements_of_interest} ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values: How increasing bmi affects value of diastolic_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_of_interest = \"Diastolic_blood_pressure_5\"\n",
    "\n",
    "\n",
    "_exp_prompt = [\"Body_mass_index_3\"]\n",
    "_exp_values = [[18.], [21.], [24.], [30.], [40.]]\n",
    "_exp_value = [np.nan]\n",
    "\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    for p_idx, _exp_value in enumerate(_exp_values):\n",
    "\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "        \n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=covariates,\n",
    "                              is_generation=True)\n",
    "        val_dist = outputs[\"values_dist\"]\n",
    "\n",
    "        dist = val_dist[model.value_layer.token_key(dm.tokenizer._stoi[measurements_of_interest])]\n",
    "        print(f\"{'->'.join(_exp_prompt)} of {_exp_value[0]}\".ljust(30) + \"leads to\".ljust(20) + f\"standardised {measurements_of_interest} ~ N({dist.loc.item():.1f}, {dist.scale.item():.1f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, impact of gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = [\"Body_mass_index_3\", \"Diastolic_blood_pressure_5\", \n",
    "                      \"TYPE1DM\", \"TYPE2DIABETES\",\n",
    "                      \"HYPERTENSION\", \"OSTEOARTHRITIS\",\n",
    "                      \"CKDSTAGE3TO5\",\n",
    "                      \"HF_V3\", \"ISCHAEMICSTROKE_V2\",\n",
    "                      \"POLYCYSTIC_OVARIAN_SYNDROME_PCOS_V2\",\n",
    "                      \"DEATH\"\n",
    "                     ]\n",
    "\n",
    "_genders = [\"M\", \"F\", \"I\"]\n",
    "_exp_prompt = [\"Diastolic_blood_pressure_5\"]\n",
    "_exp_age = [20]\n",
    "_exp_value = [90.]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "\n",
    "    _exp_survs = []\n",
    "    for p_idx, _gender in enumerate(_genders):\n",
    "\n",
    "        _baseline_covariate = {\"sex\": _gender, \"deprivation\": 4.0, \"ethnicity\": \"WHITE\", \"year_of_birth\": 1997}\n",
    "        _covariates = dm.train_set._encode_covariates(**_baseline_covariate).reshape(1,-1).to(device)\n",
    "        _tokens = encode_prompt(_exp_prompt)\n",
    "        _values_scaled = encode_value(_exp_prompt, _exp_value)\n",
    "        _ages_in_days = encode_age(_exp_age)\n",
    "\n",
    "        outputs, _, _ = model(_tokens,\n",
    "                              values=_values_scaled,\n",
    "                              ages=_ages_in_days,\n",
    "                              covariates=_covariates,\n",
    "                              is_generation=True)\n",
    "        surv = outputs[\"surv\"][\"surv_CDF\"]\n",
    "        _exp_survs.append(surv)\n",
    "\n",
    "    for si, _ in enumerate(surv):\n",
    "        plt.close()\n",
    "        event_name = dm.decode([si + 1])\n",
    "        if event_name in events_of_interest:\n",
    "            for p_idx in range(len(_genders)):\n",
    "                plt.plot(model.surv_layer.t_eval / 365, _exp_survs[p_idx][si][0, :], label=f\"{_genders[p_idx]}\")\n",
    "            plt.xlabel(\"t (years)\")\n",
    "            plt.ylabel(\"P(T>t) ()\")\n",
    "            plt.legend()\n",
    "            plt.savefig(save_path + f\"gender/{event_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html --no-input generation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
