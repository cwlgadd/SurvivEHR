{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4921342e-8ff8-45d4-b1f6-9fe480c2ee1d",
   "metadata": {},
   "source": [
    "# CPRD Notebook:\n",
    "## Evaluation of a loaded pre-trained SurvivEHR-CR model for causal sequence modelling on CPRD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a671c59b-4428-4e63-a138-7244418a87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d866c7f0-eaa8-4129-b3b1-d4d6b504d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n",
      "env: SLURM_NTASKS_PER_NODE=28\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from CPRD.examples.modelling.SurvStreamGPT.run_experiment import run\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.survival.task_heads.causal import SurvStreamGPTForCausalModelling\n",
    "\n",
    "import time\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(10000)\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10000\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}.\")\n",
    "\n",
    "# TODO: define an env variable to fix for a local hpc environment issue, this shouldn't be needed\n",
    "%env SLURM_NTASKS_PER_NODE=28   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316b39b-7bd9-43dd-84e5-561c70351a45",
   "metadata": {},
   "source": [
    "## Load configurations\n",
    "The default configuration is for pre-training. Here we modify as necesssary\n",
    "\n",
    "Here we choose to load in the configuration for a small **pre-trained** 11.4M parameter model, named \"CR_11M\". We specfiy the `causal` (equivalently `pre-train` or `self-supervised`) experiment type, which will lead to running the ```CausalExperiment```. \n",
    "\n",
    "We tell this experiment that no further training is needed. Additionally, we do choose to perform testing (true by default). As this is a causal model, this would not test the ability to predict the outcomes of interest, but to perform the causal modelling task on the chosen dataset. In this notebook, this is chosen to be the original training dataset, containing over 7 billion medical events.\n",
    "\n",
    "Finally, we set the number of workers to be appropriate for the number of CPUs available to reduce bottlenecking, and tell the experiment that we do not want to limit the number of testing batches. In addition, we specify where we want any checkpoints to be saved to avoid bloating the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e00688-1426-4046-910c-45bde94db899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_decoder: true\n",
      "data:\n",
      "  batch_size: 64\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 12\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "experiment:\n",
      "  type: causal\n",
      "  project_name: SurvEHR_${head.SurvLayer}\n",
      "  run_id: CR_11M_old\n",
      "  train: false\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "  fine_tune_outcomes: null\n",
      "optim:\n",
      "  num_epochs: 1\n",
      "  learning_rate: 0.0003\n",
      "  scheduler: CAWarmRestarts\n",
      "  scheduler_periods: 5000\n",
      "  scheduler_warmup: true\n",
      "  lr_cosine_decay_period: 10000000.0\n",
      "  val_check_interval: 1000\n",
      "  early_stop: false\n",
      "  early_stop_patience: 5\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.05\n",
      "  limit_test_batches: null\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 128\n",
      "  n_layer: 6\n",
      "  n_head: 6\n",
      "  n_embd: 384\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.0\n",
      "  attention_dropout: 0.0\n",
      "  resid_dropout: 0.0\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression: None\n",
      "  value_weight: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../../confs\", job_name=\"testing_notebook\"):\n",
    "    cfg = compose(config_name=\"config_CompetingRisk11M\", \n",
    "                  overrides=[# Experiment setup\n",
    "                             \"experiment.type='causal'\",\n",
    "                             \"experiment.run_id='CR_11M'\",\n",
    "                             \"experiment.train=False\",\n",
    "                             \"experiment.test=True\",\n",
    "                             # Dataloader\n",
    "                             \"data.min_workers=12\",\n",
    "                             # Optimiser\n",
    "                             \"optim.limit_test_batches=null\",\n",
    "                            ]\n",
    "                 )     \n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "save_path = f\"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/{cfg.experiment.run_id}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e0a69-cc78-43d6-8e6c-bac2194a3f1b",
   "metadata": {},
   "source": [
    "# Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b018c920-1f4d-40a5-b6a9-a6877430385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running cr on 72 CPUs and 2 GPUs\n",
      "INFO:root:\n",
      "Loading DataModule for dataset /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/. This will be loaded in causal form.\n",
      "INFO:root:Using meta information from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "INFO:root:Using train file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_train.pickle\n",
      "INFO:root:Using test file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_test.pickle\n",
      "INFO:root:Using val file-row count dictionary from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/file_row_count_dict_val.pickle\n",
      "INFO:root:Tokenzier created based on 7,555,415,275 tokens\n",
      "INFO:root:Using tabular tokenizer, created from meta information and containing 265 tokens\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=train/ dataset, with 23,613,894 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=test/ dataset, with 1,508,320 samples\n",
      "INFO:root:Loaded /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/split=val/ dataset, with 1,426,714 samples\n",
      "INFO:root:A pre-trained causal experiment with the checkpoint path /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/CR_11M_old.ckpt already exists, loading.\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp5h5karj1\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp5h5karj1/_remote_module_non_scriptable.py\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n",
      "INFO:root:Using Competing-Risk DeSurv head.\n",
      "INFO:root:Internally scaling time in survival head by 1825 days\n",
      "INFO:root:In generation forwarding DeSurv on the grid between [0.0, 1825.0] with 1826 time-points of delta=1.0\n",
      "INFO:root:Creating hidden state embedding callback\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:root:Testing model.\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcwlgadd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20240920_114506-3ek6smgf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cwlgadd/SurvEHR_cr/runs/3ek6smgf\" target=\"_blank\">CR_11M_old</a></strong> to <a href=\"https://wandb.ai/cwlgadd/SurvEHR_cr\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20d8c30e1bc4e9695a550e0bb424695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -17.54701042175293     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_loss_desurv      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.0479955673217773     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_loss_values      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -37.14216232299805     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -17.54701042175293    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_loss_desurv     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.0479955673217773    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_loss_values     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -37.14216232299805    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f0f3e274ff4450bc09256520e0c665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_loss_desurv</td><td>▁</td></tr><tr><td>test_loss_values</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test_loss</td><td>-17.54701</td></tr><tr><td>test_loss_desurv</td><td>2.048</td></tr><tr><td>test_loss_values</td><td>-37.14216</td></tr><tr><td>trainer/global_step</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">CR_11M_old</strong>: <a href=\"https://wandb.ai/cwlgadd/SurvEHR_cr/runs/3ek6smgf\" target=\"_blank\">https://wandb.ai/cwlgadd/SurvEHR_cr/runs/3ek6smgf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/wandb/run-20240920_114506-3ek6smgf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded model contains 11.433294 M parameters\n"
     ]
    }
   ],
   "source": [
    "# Run experiment, returning configured loader and best (in the case of training) model\n",
    "model, dm = run(cfg)\n",
    "\n",
    "# End logging session to print summary\n",
    "wandb.finish()\n",
    "\n",
    "print(f\"The loaded model contains {sum(p.numel() for p in model.parameters())/1e6} M parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4e2467-bfc5-47cf-8e26-7a38cc093965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurvStreamGPTForCausalModelling(\n",
      "  (transformer): TTETransformer(\n",
      "    (wpe): TemporalPositionalEncoding()\n",
      "    (wte): DataEmbeddingLayer(\n",
      "      (static_proj): Linear(in_features=16, out_features=384, bias=True)\n",
      "      (dynamic_embedding_layer): SplitDynamicEmbeddingLayer(\n",
      "        (cat_event_embed_layer): Embedding(265, 384, padding_idx=0)\n",
      "        (cat_event_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (num_value_embed_layer): EmbeddingBag(265, 384, mode='sum', padding_idx=0)\n",
      "        (num_value_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-5): 6 x Block(\n",
      "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
      "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (acti): ReLU()\n",
      "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (surv_layer): ODESurvCompetingRiskLayer(\n",
      "    (sr_ode): ODESurvMultiple(\n",
      "      (pinet): FCNet(\n",
      "        (mapping): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=264, bias=True)\n",
      "          (1): Softmax(dim=1)\n",
      "        )\n",
      "      )\n",
      "      (odenet): CondODENet(\n",
      "        (BaseNet): FCNet(\n",
      "          (mapping): Sequential(\n",
      "            (0): Linear(in_features=385, out_features=264, bias=True)\n",
      "            (1): Softplus(beta=1, threshold=20)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (value_layer): GaussianRegressionLayer(\n",
      "    (regression_layers): ModuleDict(\n",
      "      (Token 84): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 86): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 107): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 154): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 42): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 231): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 63): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 85): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 247): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 51): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 103): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 146): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 66): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 172): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 152): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 261): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 235): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 193): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 184): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 101): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 223): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 135): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 226): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 202): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 145): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 244): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 165): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 64): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 185): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 238): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 220): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 232): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 240): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 237): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 17): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 239): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 217): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 118): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 219): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 251): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 25): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 150): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 111): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 102): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 15): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 110): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 130): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 128): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 122): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 99): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 77): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 96): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 140): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 50): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 80): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 108): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 138): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 27): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 139): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 125): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 117): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 105): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 109): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 243): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 236): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 208): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 98): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 176): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 209): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 194): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 61): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 73): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 214): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 206): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 229): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 225): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 183): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 186): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 215): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 187): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 248): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 179): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 163): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 180): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 181): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 153): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 245): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 54): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 246): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 112): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 212): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 141): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 204): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 227): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 173): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 55): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 119): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 262): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 127): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 71): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 59): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 144): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 113): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 170): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 241): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 168): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 47): Linear(in_features=384, out_features=2, bias=True)\n",
      "      (Token 159): Linear(in_features=384, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aa0352a-f7cc-40ea-b456-97f1e59adcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NSAIDS_oral_OPTIMAL_final',\n",
       " 'Diastolic_blood_pressure_5',\n",
       " 'Systolic_blood_pressure_4',\n",
       " 'Statins',\n",
       " 'Lipid_lowering_drugs_Optimal']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.tokenizer._event_counts[\"EVENT\"][-5:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacadcc-f857-45e2-94e8-0ca43ccbd196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
