{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "## GPT - demo on subset of CPRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.gpt_pico.transformer import GPTLanguageModel\n",
    "from CPRD.src.models.gpt_simple.task_heads import GPTModelForCausalLM\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# replace boilerplate with pytorch lightning\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# device = \"cpu\"    # just for debug errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPT config to be equivalent\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    block_size: int = 256             # what is the maximum context length for predictions?\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 6\n",
    "    n_embd: int = 384\n",
    "    pos_encoding: str = \"index-embedding\"                 # Manually adding later\n",
    "    bias: bool = True\n",
    "    attention_type: str = \"global\"    \n",
    "    dropout: float = 0.0\n",
    "    unk_freq_threshold: float = 0.0\n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "@dataclass\n",
    "class OptConfig:\n",
    "    batch_size: int = 64\n",
    "    eval_interval: int = 1\n",
    "    learning_rate: float = 3e-4\n",
    "    epochs: int = 10\n",
    "    \n",
    "opt = OptConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate on a reduced cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CPRD.data.database import queries\n",
    "\n",
    "PATH_TO_DB = \"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModel/preprocessing/processed/cprd.db\"\n",
    "conn = sqlite3.connect(PATH_TO_DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# # Check what measurements are available\n",
    "# cursor.execute(\"SELECT DISTINCT * FROM measurement_table\")\n",
    "# measurements = cursor.fetchall()\n",
    "# print(measurements)\n",
    "\n",
    "# Check what diagnoses are available\n",
    "# cursor.execute(\"SELECT DISTINCT * FROM diagnosis_table\")\n",
    "# diagnoses = cursor.fetchall()\n",
    "# print(diagnoses)\n",
    "\n",
    "# Get a list of patients which fit a reduced set of criterion\n",
    "identifiers1 = queries.query_measurement([\"bmi\", \"diastolic_blood_pressure\"], cursor)        \n",
    "identifiers2 = queries.query_diagnosis([\"DEPRESSION\", \"TYPE1DM\", \"TYPE2DIABETES\"], cursor)    #  \"DEPRESSION\"  ,  \"ANXIETY\"\n",
    "all_identifiers = list(set(identifiers1).intersection(identifiers2))    # Turn smaller list into the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using N=10000 random samples, from the available 117102\n"
     ]
    }
   ],
   "source": [
    "# Take only the first N\n",
    "N = np.min((len(all_identifiers), 10000))\n",
    "print(f\"Using N={N} random samples, from the available {len(all_identifiers)}\")\n",
    "\n",
    "identifiers = random.choices(all_identifiers, k=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DL-friendly representation\n",
      "Dropping samples with no temporal events\n",
      "8657 training samples\n",
      "481 validation samples\n",
      "481 test samples\n"
     ]
    }
   ],
   "source": [
    "dm = FoundationalDataModule(identifiers=identifiers,\n",
    "                            batch_size=opt.batch_size,\n",
    "                            max_seq_length=config.block_size,\n",
    "                            unk_freq_threshold=config.unk_freq_threshold)\n",
    "\n",
    "print(f\"{len(dm.train_set)} training samples\")\n",
    "print(f\"{len(dm.val_set)} validation samples\")\n",
    "print(f\"{len(dm.test_set)} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample from the dataloader batch gives:\n",
      "\n",
      "The position index of inputs and targets: \n",
      "inputs: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])  \n",
      "targets: tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "\n",
      "The time of event (in days since birth) of event of inputs and targets: \n",
      "inputs: tensor([23368, 23368, 23399, 23399, 23399, 23399, 23399, 23399, 23399, 23399])  \n",
      "targets: tensor([23368, 23399, 23399, 23399, 23399, 23399, 23399, 23399, 23399, 23399])\n",
      "\n",
      "The shifted next-step, tokenized and padded (within batch), representation from a block of a patient's sequence for events: \n",
      "inputs: tensor([12,  2, 19,  3,  6, 12,  2, 16,  2, 12]) \n",
      "targets: tensor([ 2, 19,  3,  6, 12,  2, 16,  2, 12,  2])\n",
      "\n",
      "Which can be decoded. E.g. first sample's first 10 block tokens: \n",
      "inputs: . 0 serum_level 1 4 . 0 basophil_count 0 .  \n",
      "targets: 0 serum_level 1 4 . 0 basophil_count 0 . 0\n",
      "\n",
      "The attention mask (torch.Size([64, 256])) for padding: \n",
      "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(dm.train_dataloader()):\n",
    "    break\n",
    "print(\"A sample from the dataloader batch gives:\")\n",
    "print(f\"\\nThe position index of inputs and targets: \\ninputs: {batch['input_pos'][0,:10]}  \\ntargets: {batch['target_pos'][0,:10]}\")\n",
    "print(f\"\\nThe time of event (in days since birth) of event of inputs and targets: \\ninputs: {batch['input_ages'][0,:10]}  \\ntargets: {batch['target_ages'][0,:10]}\")\n",
    "print(f\"\\nThe shifted next-step, tokenized and padded (within batch), representation from a block of a patient's sequence for events: \\ninputs: {batch['input_ids'][0,:10]} \\ntargets: {batch['target_ids'][0,:10]}\")\n",
    "print(f\"\\nWhich can be decoded. E.g. first sample's first 10 block tokens: \\ninputs: {dm.decode(batch['input_ids'][0,:10].tolist())}  \\ntargets: {dm.decode(batch['target_ids'][0,:10].tolist())}\")\n",
    "print(f\"\\nThe attention mask ({batch['attention_mask'].shape}) for padding: \\n{batch['attention_mask']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "{0: 'PAD', 1: 'UNK', 2: '0', 3: '1', 4: '2', 5: '3', 6: '4', 7: '5', 8: '6', 9: '7', 10: '8', 11: '9', 12: '.', 13: 'diastolic_blood_pressure', 14: 'bmi', 15: 'eosinophil_count', 16: 'basophil_count', 17: 'corrected_serum_calcium_level', 18: 'DEPRESSION', 19: 'serum_level', 20: 'calculated_LDL_cholesterol_level', 21: 'ANXIETY', 22: 'HYPERTENSION', 23: 'TYPE2DIABETES', 24: 'OSTEOARTHRITIS', 25: 'ASTHMA_PUSHASTHMA', 26: 'ATOPICECZEMA', 27: 'ALLERGICRHINITISCONJ', 28: 'ANY_DEAFNESS_HEARING_LOSS', 29: 'aspartate_transam', 30: 'ALLCA_NOBCC_VFINAL', 31: 'PREVALENT_IBS', 32: 'IHD_NOMI', 33: 'ALCOHOLMISUSE', 34: 'CKDSTAGE3TO5', 35: 'blood_urea', 36: 'calcium_adjusted_level', 37: 'PERIPHERAL_NEUROPATHY', 38: 'HYPOTHYROIDISM_DRAFT_V1', 39: 'COPD', 40: 'AF', 41: 'HF', 42: 'combined_total_vitamin_D2_and_D3_level', 43: 'OSTEOPOROSIS', 44: 'SUBSTANCEMISUSE', 45: 'PSORIASIS', 46: 'GOUT', 47: 'MINFARCTION', 48: 'STROKEUNSPECIFIED', 49: 'ALL_DEMENTIA', 50: 'hydroxyvitamin3', 51: 'hydroxyvitamin2', 52: 'VALVULARDISEASES', 53: 'PAD_STRICT', 54: 'OSA', 55: 'OTHER_CHRONIC_LIVER_DISEASE_OPTIMAL', 56: 'TYPE1DM', 57: 'FIBROMYALGIA', 58: 'EPILEPSY', 59: 'POLYCYSTIC_OVARIAN_SYNDROME_PCOS', 60: 'NAFLD', 61: 'RHEUMATOIDARTHRITIS', 62: 'PMRANDGCA', 63: 'ENDOMETRIOSIS_ADENOMYOSIS_V2', 64: 'EATINGDISORDERS', 65: 'HYPERTHYROIDISM', 66: 'PTSDDIAGNOSIS', 67: 'ISCHAEMICSTROKE', 68: 'creatinine_ratio', 69: 'VISUAL_IMPAIRMENT', 70: 'SCHIZOPHRENIAMM', 71: 'BIPOLAR', 72: 'BRONCHIECTASIS', 73: 'ULCERATIVE_COLITIS', 74: 'AORTICANEURYSM', 75: 'STROKE_HAEMRGIC', 76: 'PERNICIOUSANAEMIA', 77: 'PARKINSONS', 78: 'CHRONICFATIGUESYNDROMEMM', 79: 'LEARNINGDISABILITY', 80: 'CHRONIC_LIVER_DISEASE_ALCOHOL', 81: 'brain_natriuretic_peptide_level', 82: 'CROHNS_DISEASE', 83: 'ILD_SH', 84: 'MENIERESDISEASE', 85: 'PSORIATICARTHRITIS2021', 86: 'AUTISM', 87: 'LYMPHOMA_PREVALENCE', 88: 'LEUKAEMIA_PREVALENCE', 89: 'MS', 90: 'HIVAIDS', 91: 'blood_calcium', 92: 'HAEMOCHROMATOSIS', 93: 'SJOGRENSSYNDROME', 94: 'SYSTEMIC_LUPUS_ERYTHEMATOSUS', 95: 'ADDISON_DISEASE', 96: 'PLASMACELL_NEOPLASM', 97: 'SYSTEMIC_SCLEROSIS', 98: 'SICKLE_CELL_DISEASE', 99: 'DOWNSSYNDROME', 100: 'CYSTICFIBROSIS'}\n"
     ]
    }
   ],
   "source": [
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "\n",
    "print(vocab_size)\n",
    "print(dm.train_set.tokenizer._itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Positional Embedding. This module uses the index position of an event within the block of events.\n",
      "INFO:root:Using Positional Encoding. This module uses the index position of an event within the block of events.\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "# Baseline model to test my changes against\n",
    "#   Note: this benchmark model uses index position along the batch\n",
    "models.append(GPTLanguageModel(config, vocab_size).to(device))\n",
    "\n",
    "# My development model\n",
    "# Handle positional vs. temporal encoding/embedding\n",
    "# Cases: \n",
    "#     index-embedding:       use index position along the batch\n",
    "#     index-encoding:        use index position along the batch\n",
    "#     temporal-encoding:     use age along a patient's timeline\n",
    "pos_encodings = [\"index-embedding\", \"index-encoding\", \"temporal-encoding\"]\n",
    "for pe in pos_encodings:\n",
    "    config = DemoConfig()\n",
    "    config.pos_encoding = pe\n",
    "    models.append(GPTModelForCausalLM(config, vocab_size).to(device))\n",
    "\n",
    "m_names = [\"kaparthy benchmark\"] + pos_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curves_train = [[] for _ in models]\n",
    "loss_curves_val = [[] for _ in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.816613 M parameters\n",
      "Epoch 0:\tTrain loss 1.20. Val loss 1.20\n",
      "Epoch 1:\tTrain loss 0.94. Val loss 0.94\n",
      "Epoch 2:\tTrain loss 0.71. Val loss 0.78\n",
      "Epoch 3:\tTrain loss 0.66. Val loss 0.75\n",
      "Epoch 4:\tTrain loss 0.64. Val loss 0.73\n",
      "Epoch 5:\tTrain loss 0.63. Val loss 0.72\n",
      "Epoch 6:\tTrain loss 0.62. Val loss 0.71\n",
      "Epoch 7:\tTrain loss 0.61. Val loss 0.71\n",
      "Epoch 8:\tTrain loss 0.61. Val loss 0.70\n",
      "Epoch 9:\tTrain loss 0.60. Val loss 0.70\n",
      "DEPRESSION diastolic_blood_pressure 7 0 . 0 diastolic_blood_pressure 8 0 . 0 diastolic_blood_pressure 8 0 . 0 diastolic_blood_pressure 8 4 . 0 diastolic_blood_pressure 8 5 . 0 diastolic_blood_pressure 7 0 . 0\n",
      "10.777829 M parameters\n",
      "Epoch 0:\tTrain loss 1.16. Val loss 0.96\n",
      "Epoch 1:\tTrain loss 0.73. Val loss 0.79\n",
      "Epoch 2:\tTrain loss 0.66. Val loss 0.74\n",
      "Epoch 3:\tTrain loss 0.63. Val loss 0.72\n",
      "Epoch 4:\tTrain loss 0.61. Val loss 0.71\n",
      "Epoch 5:\tTrain loss 0.61. Val loss 0.70\n",
      "Epoch 6:\tTrain loss 0.60. Val loss 0.70\n",
      "Epoch 7:\tTrain loss 0.60. Val loss 0.70\n",
      "Epoch 8:\tTrain loss 0.60. Val loss 0.69\n",
      "Epoch 9:\tTrain loss 0.60. Val loss 0.70\n",
      "DEPRESSION ANXIETY bmi 2 0 . 9 diastolic_blood_pressure 8 1 . 0 diastolic_blood_pressure 7 1 . 0 eosinophil_count 0 . 2 bmi 2 5 . 7 2 diastolic_blood_pressure 8 0 .\n",
      "10.679525 M parameters\n",
      "Epoch 0:\tTrain loss 1.59. Val loss 1.53\n",
      "Epoch 1:\tTrain loss 1.08. Val loss 0.99\n",
      "Epoch 2:\tTrain loss 0.80. Val loss 0.89\n",
      "Epoch 3:\tTrain loss 0.74. Val loss 0.83\n",
      "Epoch 4:\tTrain loss 0.70. Val loss 0.80\n",
      "Epoch 5:\tTrain loss 0.68. Val loss 0.78\n",
      "Epoch 6:\tTrain loss 0.67. Val loss 0.76\n",
      "Epoch 7:\tTrain loss 0.66. Val loss 0.75\n",
      "Epoch 8:\tTrain loss 0.65. Val loss 0.75\n",
      "Epoch 9:\tTrain loss 0.64. Val loss 0.74\n",
      "DEPRESSION ANXIETY bmi 3 3 . 6 diastolic_blood_pressure 8 0 . 0 diastolic_blood_pressure 7 0 . 0 ATOPICECZEMA POLYCYSTIC_OVARIAN_SYNDROME_PCOS basophil_count 0 . 1 eosinophil_count 0 . 6 eosinophil_count 0 . 2\n",
      "10.679717 M parameters\n",
      "Epoch 0:\tTrain loss 1.61. Val loss 1.77\n",
      "Epoch 1:\tTrain loss 1.47. Val loss 1.46\n",
      "Epoch 2:\tTrain loss 1.02. Val loss 1.01\n",
      "Epoch 3:\tTrain loss 0.76. Val loss 0.84\n",
      "Epoch 4:\tTrain loss 0.71. Val loss 0.81\n",
      "Epoch 5:\tTrain loss 0.69. Val loss 0.79\n",
      "Epoch 6:\tTrain loss 0.67. Val loss 0.78\n",
      "Epoch 7:\tTrain loss 0.66. Val loss 0.76\n",
      "Epoch 8:\tTrain loss 0.64. Val loss 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using positional temporal-encoding requires ages, \n",
      "                                but this head has no way of sampling age at next event.\n",
      "                                Using 50 days as intervals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\tTrain loss 0.63. Val loss 0.75\n",
      "DEPRESSION diastolic_blood_pressure 8 calcium_adjusted_level 2 diastolic_blood_pressure 7 bmi 2 diastolic_blood_pressure 4 diastolic_blood_pressure 7 bmi 1 diastolic_blood_pressure 7 SCHIZOPHRENIAMM basophil_count 0 corrected_serum_calcium_level 2 bmi 2 3 2 3 . 2 3 2\n"
     ]
    }
   ],
   "source": [
    "for m_idx, model in enumerate(models):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # print the number of parameters in the model\n",
    "    print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "    best_val, best_iter = np.inf, 0\n",
    "    for epoch in range(opt.epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for i, batch in enumerate(dm.train_dataloader()):\n",
    "            # evaluate the loss\n",
    "            logits, loss = model(batch['input_ids'].to(device),\n",
    "                                 ages=batch['input_ages'].to(device),\n",
    "                                 targets=batch['target_ids'].to(device),\n",
    "                                 attention_mask=batch['attention_mask'].to(device)\n",
    "                                 )\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss /= i\n",
    "        loss_curves_train[m_idx].append(epoch_loss)\n",
    "\n",
    "        # evaluate the loss on val set\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            if epoch % opt.eval_interval == 0 or epoch == opt.epochs - 1:\n",
    "                val_loss = 0\n",
    "                for j, batch in enumerate(dm.val_dataloader()):\n",
    "                    _, loss = model(batch['input_ids'].to(device), \n",
    "                                    ages=batch['input_ages'].to(device), \n",
    "                                    targets=batch['target_ids'].to(device),\n",
    "                                    attention_mask=batch['attention_mask'].to(device)   \n",
    "                                   )\n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= j\n",
    "                loss_curves_val[m_idx].append(val_loss)\n",
    "                print(f\"Epoch {epoch}:\\tTrain loss {epoch_loss:.2f}. Val loss {val_loss:.2f}\")          \n",
    "                # TODO: Note not fully accurate as last batch is likely not the same size, will be fixed with lightning\n",
    "        \n",
    "            if val_loss >= best_val:\n",
    "                best_iter += 1\n",
    "                if best_iter > 2:\n",
    "                    break\n",
    "            else:\n",
    "                best_val = val_loss\n",
    "                best_iter = 0\n",
    "                \n",
    "    prompt = [\"DEPRESSION\"]\n",
    "    context = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "    fut_tokens, fut_ages = model.generate(context, max_new_tokens=30)\n",
    "    fut_words = dm.decode(fut_tokens[0].tolist())\n",
    "    print(fut_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"k\", \"r\", \"b\", \"y\"]\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train[m_idx]), len(loss_curves_train[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val[m_idx]), len(loss_curves_val[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(\"figs/loss_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of type II diabetes before and after a type I diagnosis\n",
    "\n",
    "keys: \n",
    "\n",
    "    70: 'TYPE1DM'\n",
    "    31: 'TYPE2DIABETES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small context comparison, high bmi and blood pressure vs low for diabetes risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_risk_prompt = [\"bmi\", \"2\", \"2\", \".\", \"5\", \"diastolic_blood_pressure\", \"7\", \"9\", \".\", \"0\"]\n",
    "high_risk_prompt = [\"bmi\", \"3\", \"7\", \".\", \"5\", \"diastolic_blood_pressure\", \"9\", \"9\", \".\", \"0\"]\n",
    "ages_in_years = [18, 19, 19, 19, 19, 20, 20, 20, 20, 20]\n",
    "\n",
    "to_days = lambda a_list: torch.FloatTensor([365 * _a for _a in a_list]).reshape((1,-1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MODEL_IDX 0\n",
      "==================\n",
      "\n",
      "Control: Low risk: \n",
      "\t (bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0006%\n",
      "probability of type II diabetes 0.0016%\n",
      "\n",
      "Control: High risk: \n",
      "\t (bmi,3,7,.,5,diastolic_blood_pressure,9,9,.,0): \n",
      "probability of type I diabetes 0.0006%\n",
      "probability of type II diabetes 0.0016%\n",
      "\n",
      "Control: Low risk + depression: \n",
      "\t (DEPRESSION,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.5578%\n",
      "probability of type II diabetes 1.5259%\n",
      "\n",
      "Low risk context: Type 1 diagnosis in prompt: \n",
      "\t (TYPE1DM,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.2655%\n",
      "probability of type II diabetes 1.1427%\n",
      "\n",
      "Low risk context: Type 1I diagnosis in prompt: \n",
      "\t (TYPE2DIABETES,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0885%\n",
      "probability of type II diabetes 0.4090%\n",
      "\n",
      "\n",
      "MODEL_IDX 1\n",
      "==================\n",
      "\n",
      "Control: Low risk: \n",
      "\t (bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0011%\n",
      "probability of type II diabetes 0.0012%\n",
      "\n",
      "Control: High risk: \n",
      "\t (bmi,3,7,.,5,diastolic_blood_pressure,9,9,.,0): \n",
      "probability of type I diabetes 0.0011%\n",
      "probability of type II diabetes 0.0012%\n",
      "\n",
      "Control: Low risk + depression: \n",
      "\t (DEPRESSION,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.5554%\n",
      "probability of type II diabetes 1.7912%\n",
      "\n",
      "Low risk context: Type 1 diagnosis in prompt: \n",
      "\t (TYPE1DM,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.1890%\n",
      "probability of type II diabetes 1.5010%\n",
      "\n",
      "Low risk context: Type 1I diagnosis in prompt: \n",
      "\t (TYPE2DIABETES,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.1667%\n",
      "probability of type II diabetes 0.6209%\n",
      "\n",
      "\n",
      "MODEL_IDX 2\n",
      "==================\n",
      "\n",
      "Control: Low risk: \n",
      "\t (bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0009%\n",
      "probability of type II diabetes 0.0009%\n",
      "\n",
      "Control: High risk: \n",
      "\t (bmi,3,7,.,5,diastolic_blood_pressure,9,9,.,0): \n",
      "probability of type I diabetes 0.0009%\n",
      "probability of type II diabetes 0.0009%\n",
      "\n",
      "Control: Low risk + depression: \n",
      "\t (DEPRESSION,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.3585%\n",
      "probability of type II diabetes 1.1762%\n",
      "\n",
      "Low risk context: Type 1 diagnosis in prompt: \n",
      "\t (TYPE1DM,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.5319%\n",
      "probability of type II diabetes 2.0240%\n",
      "\n",
      "Low risk context: Type 1I diagnosis in prompt: \n",
      "\t (TYPE2DIABETES,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.5841%\n",
      "probability of type II diabetes 1.7258%\n",
      "\n",
      "\n",
      "MODEL_IDX 3\n",
      "==================\n",
      "\n",
      "Control: Low risk: \n",
      "\t (bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0019%\n",
      "probability of type II diabetes 0.0086%\n",
      "\n",
      "Control: High risk: \n",
      "\t (bmi,3,7,.,5,diastolic_blood_pressure,9,9,.,0): \n",
      "probability of type I diabetes 0.0019%\n",
      "probability of type II diabetes 0.0086%\n",
      "\n",
      "Control: Low risk + depression: \n",
      "\t (DEPRESSION,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.4154%\n",
      "probability of type II diabetes 2.0709%\n",
      "\n",
      "Low risk context: Type 1 diagnosis in prompt: \n",
      "\t (TYPE1DM,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.3349%\n",
      "probability of type II diabetes 2.8350%\n",
      "\n",
      "Low risk context: Type 1I diagnosis in prompt: \n",
      "\t (TYPE2DIABETES,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.3319%\n",
      "probability of type II diabetes 2.7368%\n"
     ]
    }
   ],
   "source": [
    "prompts, ages, desc = [], [], []\n",
    "\n",
    "desc.append(\"Control: Low risk\")\n",
    "prompts.append(low_risk_prompt)\n",
    "ages.append(ages_in_years)\n",
    "\n",
    "desc.append(\"Control: High risk\")\n",
    "prompts.append(high_risk_prompt)\n",
    "ages.append(ages_in_years)\n",
    "\n",
    "desc.append(\"Control: Low risk + depression\")\n",
    "prompts.append([\"DEPRESSION\"] + low_risk_prompt)\n",
    "ages.append([17] + ages_in_years)\n",
    "\n",
    "desc.append(\"Low risk context: Type 1 diagnosis in prompt\")\n",
    "prompts.append([\"TYPE1DM\"] + low_risk_prompt)\n",
    "ages.append([17] + ages_in_years)\n",
    "\n",
    "desc.append(\"Low risk context: Type 1I diagnosis in prompt\")\n",
    "prompts.append([\"TYPE2DIABETES\"] + low_risk_prompt)\n",
    "ages.append([17] + ages_in_years)\n",
    "\n",
    "for model_idx in range(len(pos_encodings)+1):\n",
    "    print(f\"\\n\\nMODEL_IDX {model_idx}\\n==================\")\n",
    "    \n",
    "    for p_idx, (prompt, age) in enumerate(zip(prompts, ages)):\n",
    "        print(f\"\\n{desc[p_idx]}: \\n\\t ({','.join(prompt)}): \")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        lgts, _ = models[model_idx](encoded_prompt,\n",
    "                                    ages=to_days(age))\n",
    "        probs = torch.nn.functional.softmax(lgts, dim=2)\n",
    "        print(f\"probability of type I diabetes {100*float(probs[0, 0, 70].cpu().detach().numpy()):.4f}%\")\n",
    "        print(f\"probability of type II diabetes {100*float(probs[0, 0, 31].cpu().detach().numpy()):.4f}%\")\n",
    "\n",
    "# Note: adding a diagnosis (even if potentially orthogonal) at the beginning of the prompt increases probability of either type"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
