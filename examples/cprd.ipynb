{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "## CPRD GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.gpt_pico.transformer import GPTLanguageModel\n",
    "from CPRD.src.models.gpt_simple.task_heads import GPTModelForCausalLM\n",
    "\n",
    "# TODO:\n",
    "# mask padding tokens\n",
    "# replace boilerplate with pytorch lightning\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# device = \"cpu\"    # just for debug errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPT config to be equivalent\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    block_size: int = 256             # what is the maximum context length for predictions?\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 6\n",
    "    n_embd: int = 384\n",
    "    pos_encoding: str = \"index-embedding\"                 # Manually adding later\n",
    "    bias: bool = True\n",
    "    attention_type: str = \"global\"    \n",
    "    dropout: float = 0.0\n",
    "    \n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "# optim hyperparameters\n",
    "batch_size = 64\n",
    "eval_interval = 5\n",
    "learning_rate = 3e-4\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate on a reduced cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p20485_2544331320485', 'p20426_632238320426', 'p20415_270000020415', 'p20655_1200089720655', 'p20508_940887220508', 'p20485_2547686820485', 'p20524_6918058520524', 'p20758_2523011320758', 'p20495_2858389320495', 'p20508_940152320508']\n",
      "16327\n"
     ]
    }
   ],
   "source": [
    "from CPRD.data.database import queries\n",
    "\n",
    "PATH_TO_DB = \"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModel/preprocessing/processed/cprd.db\"\n",
    "conn = sqlite3.connect(PATH_TO_DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# # Check what measurements are available\n",
    "# cursor.execute(\"SELECT DISTINCT * FROM measurement_table\")\n",
    "# measurements = cursor.fetchall()\n",
    "# print(measurements)\n",
    "\n",
    "# Check what diagnoses are available\n",
    "# cursor.execute(\"SELECT DISTINCT * FROM diagnosis_table\")\n",
    "# diagnoses = cursor.fetchall()\n",
    "# print(diagnoses)\n",
    "\n",
    "# Get a list of patients which fit a reduced set of criterion\n",
    "identifiers1 = queries.query_measurement([\"bmi\", \"hydroxyvitamin2\", \"hydroxyvitamin3\"], cursor)         #  \n",
    "identifiers2 = queries.query_diagnosis([ \"FIBROMYALGIA\", \"HF\"], cursor)    #  \"DEPRESSION\"  ,  \"ANXIETY\"\n",
    "identifiers = list(set(identifiers1).intersection(identifiers2))    # Turn smaller list into the set\n",
    "\n",
    "print(identifiers[:10])\n",
    "print(len(identifiers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DL-friendly representation\n",
      "Dropping samples with no temporal events\n",
      "14694 training samples\n",
      "817 validation samples\n",
      "816 test samples\n"
     ]
    }
   ],
   "source": [
    "dm = FoundationalDataModule(identifiers=identifiers, batch_size=batch_size, max_seq_length=config.block_size, unk_freq_threshold=0)\n",
    "\n",
    "print(f\"{len(dm.train_set)} training samples\")\n",
    "print(f\"{len(dm.val_set)} validation samples\")\n",
    "print(f\"{len(dm.test_set)} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample from the dataloader batch gives:\n",
      "\n",
      "The position index of inputs and targets: \n",
      "inputs: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])  \n",
      "targets: tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
      "\n",
      "The time of event (in days since birth) of event of inputs and targets: \n",
      "inputs: tensor([20639, 23842, 23842, 23842, 23842, 23842, 23849, 23849, 23849, 23849])  \n",
      "targets: tensor([23842, 23842, 23842, 23842, 23842, 23849, 23849, 23849, 23849, 23849])\n",
      "\n",
      "The shifted next-step tokenized and padded (within batch) representation from a block of a patient's sequence for events: \n",
      "inputs: tensor([22, 13, 11,  3, 12,  2, 13, 10,  2, 12]) \n",
      "targets: tensor([13, 11,  3, 12,  2, 13, 10,  2, 12,  2])\n",
      "\n",
      "Which can be decoded. E.g. first sample's first 10 block tokens: \n",
      "inputs: OSTEOARTHRITIS diastolic_blood_pressure 9 1 . 0 diastolic_blood_pressure 8 0 .  \n",
      "targets: diastolic_blood_pressure 9 1 . 0 diastolic_blood_pressure 8 0 . 0\n",
      "\n",
      "The attention mask for padding (shapetorch.Size([64, 256])): \n",
      "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(dm.train_dataloader()):\n",
    "    break\n",
    "print(\"A sample from the dataloader batch gives:\")\n",
    "print(f\"\\nThe position index of inputs and targets: \\ninputs: {batch['input_pos'][0,:10]}  \\ntargets: {batch['target_pos'][0,:10]}\")\n",
    "print(f\"\\nThe time of event (in days since birth) of event of inputs and targets: \\ninputs: {batch['input_ages'][0,:10]}  \\ntargets: {batch['target_ages'][0,:10]}\")\n",
    "print(f\"\\nThe shifted next-step, tokenized and padded (within batch), representation from a block of a patient's sequence for events: \\ninputs: {batch['input_ids'][0,:10]} \\ntargets: {batch['target_ids'][0,:10]}\")\n",
    "print(f\"\\nWhich can be decoded. E.g. first sample's first 10 block tokens: \\ninputs: {dm.decode(batch['input_ids'][0,:10].tolist())}  \\ntargets: {dm.decode(batch['target_ids'][0,:10].tolist())}\")\n",
    "print(f\"\\nThe attention mask ({batch['attention_mask'].shape}) for padding: \\n{batch['attention_mask']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "{0: 'PAD', 1: 'UNK', 2: '0', 3: '1', 4: '2', 5: '3', 6: '4', 7: '5', 8: '6', 9: '7', 10: '8', 11: '9', 12: '.', 13: 'diastolic_blood_pressure', 14: 'eosinophil_count', 15: 'bmi', 16: 'basophil_count', 17: 'corrected_serum_calcium_level', 18: 'serum_level', 19: 'calculated_LDL_cholesterol_level', 20: 'HF', 21: 'HYPERTENSION', 22: 'OSTEOARTHRITIS', 23: 'IHD_NOMI', 24: 'aspartate_transam', 25: 'DEPRESSION', 26: 'AF', 27: 'CKDSTAGE3TO5', 28: 'ANY_DEAFNESS_HEARING_LOSS', 29: 'ASTHMA_PUSHASTHMA', 30: 'ANXIETY', 31: 'TYPE2DIABETES', 32: 'ATOPICECZEMA', 33: 'blood_urea', 34: 'MINFARCTION', 35: 'FIBROMYALGIA', 36: 'ALLCA_NOBCC_VFINAL', 37: 'COPD', 38: 'calcium_adjusted_level', 39: 'VALVULARDISEASES', 40: 'ALLERGICRHINITISCONJ', 41: 'GOUT', 42: 'HYPOTHYROIDISM_DRAFT_V1', 43: 'PERIPHERAL_NEUROPATHY', 44: 'OSTEOPOROSIS', 45: 'combined_total_vitamin_D2_and_D3_level', 46: 'PREVALENT_IBS', 47: 'STROKEUNSPECIFIED', 48: 'PAD_STRICT', 49: 'ALL_DEMENTIA', 50: 'ALCOHOLMISUSE', 51: 'PSORIASIS', 52: 'hydroxyvitamin3', 53: 'PMRANDGCA', 54: 'hydroxyvitamin2', 55: 'OSA', 56: 'RHEUMATOIDARTHRITIS', 57: 'ISCHAEMICSTROKE', 58: 'OTHER_CHRONIC_LIVER_DISEASE_OPTIMAL', 59: 'HYPERTHYROIDISM', 60: 'AORTICANEURYSM', 61: 'VISUAL_IMPAIRMENT', 62: 'BRONCHIECTASIS', 63: 'brain_natriuretic_peptide_level', 64: 'SUBSTANCEMISUSE', 65: 'creatinine_ratio', 66: 'NAFLD', 67: 'EPILEPSY', 68: 'ILD_SH', 69: 'CHRONICFATIGUESYNDROMEMM', 70: 'TYPE1DM', 71: 'ENDOMETRIOSIS_ADENOMYOSIS_V2', 72: 'PERNICIOUSANAEMIA', 73: 'PARKINSONS', 74: 'MENIERESDISEASE', 75: 'STROKE_HAEMRGIC', 76: 'POLYCYSTIC_OVARIAN_SYNDROME_PCOS', 77: 'LYMPHOMA_PREVALENCE', 78: 'ULCERATIVE_COLITIS', 79: 'EATINGDISORDERS', 80: 'PTSDDIAGNOSIS', 81: 'BIPOLAR', 82: 'CHRONIC_LIVER_DISEASE_ALCOHOL', 83: 'SCHIZOPHRENIAMM', 84: 'LEUKAEMIA_PREVALENCE', 85: 'PSORIATICARTHRITIS2021', 86: 'SYSTEMIC_LUPUS_ERYTHEMATOSUS', 87: 'CROHNS_DISEASE', 88: 'SJOGRENSSYNDROME', 89: 'LEARNINGDISABILITY', 90: 'PLASMACELL_NEOPLASM', 91: 'HAEMOCHROMATOSIS', 92: 'MS', 93: 'AUTISM', 94: 'ADDISON_DISEASE', 95: 'blood_calcium', 96: 'SYSTEMIC_SCLEROSIS', 97: 'DOWNSSYNDROME', 98: 'HIVAIDS', 99: 'CYSTICFIBROSIS', 100: 'SICKLE_CELL_DISEASE'}\n"
     ]
    }
   ],
   "source": [
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "\n",
    "print(vocab_size)\n",
    "print(dm.train_set.tokenizer._itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "# Baseline model to test my changes against\n",
    "models.append(GPTLanguageModel(config, vocab_size).to(device))\n",
    "\n",
    "# My development model\n",
    "pos_encodings = [\"index-embedding\", \"index-encoding\", \"temporal-encoding\"]\n",
    "for pe in pos_encodings:\n",
    "    config = DemoConfig()\n",
    "    config.pos_encoding = pe\n",
    "    models.append(GPTModelForCausalLM(config, vocab_size).to(device))\n",
    "\n",
    "m_names = [\"kaparthy benchmark\"] + pos_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curves_train = [[] for _ in models]\n",
    "loss_curves_val = [[] for _ in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.816613 M parameters\n",
      "Epoch 0:\tTrain loss 1.50. Val loss 1.21\n",
      "Epoch 5:\tTrain loss 0.85. Val loss 0.92\n",
      "Epoch 10:\tTrain loss 0.83. Val loss 0.90\n",
      "Epoch 14:\tTrain loss 0.83. Val loss 0.90\n",
      "DEPRESSION HYPOTHYROIDISM_DRAFT_V1 bmi 3 7 . 3 diastolic_blood_pressure 8 6 . 0 basophil_count 0 . 1 calculated_LDL_cholesterol_level 4 . 6 corrected_serum_calcium_level 2 . 3 3 eosinophil_count 0 . 5 diastolic_blood_pressure 7\n",
      "10.777829 M parameters\n",
      "Epoch 0:\tTrain loss 1.36. Val loss 1.04\n",
      "Epoch 5:\tTrain loss 0.84. Val loss 0.90\n",
      "Epoch 10:\tTrain loss 0.83. Val loss 0.90\n",
      "Epoch 14:\tTrain loss 0.82. Val loss 0.90\n",
      "DEPRESSION SUBSTANCEMISUSE bmi 1 8 . 8 diastolic_blood_pressure 8 0 . 0 diastolic_blood_pressure 7 0 . 0 OSTEOPOROSIS bmi 2 0 . 8 eosinophil_count 0 . 2 diastolic_blood_pressure 8 1 .\n",
      "10.679525 M parameters\n",
      "Epoch 0:\tTrain loss 1.91. Val loss 1.50\n",
      "Epoch 5:\tTrain loss 0.97. Val loss 1.05\n",
      "Epoch 10:\tTrain loss 0.88. Val loss 0.95\n",
      "Epoch 14:\tTrain loss 0.86. Val loss 0.92\n",
      "DEPRESSION bmi 2 3 . 8 diastolic_blood_pressure 7 4 . 0 FIBROMYALGIA HF STROKEUNSPECIFIED diastolic_blood_pressure 7 0 . 0 bmi 2 3 . 1 diastolic_blood_pressure 9 0 . 0 diastolic_blood_pressure 8\n",
      "10.679717 M parameters\n",
      "Epoch 0:\tTrain loss 2.14. Val loss 1.91\n",
      "Epoch 5:\tTrain loss 0.87. Val loss 0.94\n",
      "Epoch 10:\tTrain loss 0.83. Val loss 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using positional temporal-encoding requires ages, \n",
      "                                but this head has no way of sampling age at next event.\n",
      "                                Using 50 days as intervals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\tTrain loss 0.81. Val loss 0.93\n",
      "DEPRESSION ANXIETY ENDOMETRIOSIS_ADENOMYOSIS_V2 diastolic_blood_pressure 6 2 2 calculated_LDL_cholesterol_level 2 corrected_serum_calcium_level 2 basophil_count 0 bmi 3 2 5 FIBROMYALGIA bmi 2 eosinophil_count 0 diastolic_blood_pressure 8 basophil_count 0 diastolic_blood_pressure 7 eosinophil_count 0 diastolic_blood_pressure\n"
     ]
    }
   ],
   "source": [
    "for m_idx, model in enumerate(models):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # print the number of parameters in the model\n",
    "    print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for i, batch in enumerate(dm.train_dataloader()):\n",
    "            # evaluate the loss\n",
    "            logits, loss = model(batch['input_ids'].to(device),\n",
    "                                 positions=batch['input_pos'].to(device),\n",
    "                                 ages=batch['input_ages'].to(device),\n",
    "                                 targets=batch['target_ids'].to(device),\n",
    "                                 attention_mask=batch['attention_mask'].to(device)\n",
    "                                 )\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss /= i\n",
    "        loss_curves_train[m_idx].append(epoch_loss)\n",
    "\n",
    "        # every once in a while evaluate the loss on val set\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            if epoch % eval_interval == 0 or epoch == epochs - 1:\n",
    "                val_loss = 0\n",
    "                for j, batch in enumerate(dm.val_dataloader()):\n",
    "                    _, loss = model(batch['input_ids'].to(device), \n",
    "                                    positions=batch['input_pos'].to(device),\n",
    "                                    ages=batch['input_ages'].to(device), \n",
    "                                    targets=batch['target_ids'].to(device),\n",
    "                                    attention_mask=batch['attention_mask'].to(device)   \n",
    "                                   )\n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= j\n",
    "                loss_curves_val[m_idx].append(val_loss)\n",
    "                print(f\"Epoch {epoch}:\\tTrain loss {epoch_loss:.2f}. Val loss {val_loss:.2f}\")          \n",
    "                # TODO: Note not fully accurate as last batch is likely not the same size, will be fixed with lightning\n",
    "                \n",
    "    prompt = [\"DEPRESSION\"]\n",
    "    context = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "    fut_tokens, fut_positions, fut_ages = model.generate(context, max_new_tokens=30)\n",
    "    fut_words = dm.decode(fut_tokens[0].tolist())\n",
    "    print(fut_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "cols = [\"k\", \"r\", \"b\", \"y\"]\n",
    "for m_idx, _ in enumerate(models):\n",
    "    plt.plot(np.linspace(0,epochs,len(loss_curves_train[m_idx])), loss_curves_train[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    plt.plot(np.linspace(0,epochs,len(loss_curves_val[m_idx])), loss_curves_val[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "\n",
    "    # plt.plot(np.arange(v.shape[0]), v, label=f\"{m_idx}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(\"figs/loss_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"bmi 1 8 . 6 bmi 3 0 . 6\"\n",
    "# context = torch.from_numpy(np.array(encode(prompt)).reshape((1,-1)))\n",
    "# print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjjvMifYZf7x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
