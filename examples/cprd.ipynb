{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "## GPT - demo on subset of CPRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "from CPRD.src.models.gpt_pico.transformer import GPTLanguageModel\n",
    "from CPRD.src.models.gpt_simple.task_heads import GPTModelForCausalLM\n",
    "\n",
    "# TODO:\n",
    "# replace boilerplate with pytorch lightning\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# device = \"cpu\"    # just for debug errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPT config to be equivalent\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    block_size: int = 256             # what is the maximum context length for predictions?\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 6\n",
    "    n_embd: int = 384\n",
    "    pos_encoding: str = None          # Manually adding later\n",
    "    bias: bool = True\n",
    "    attention_type: str = \"global\"    \n",
    "    dropout: float = 0.0\n",
    "    unk_freq_threshold: float = 0.0\n",
    "    tokenizer = \"non-tabular\"\n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "@dataclass\n",
    "class OptConfig:\n",
    "    batch_size: int = 64\n",
    "    eval_interval: int = 1\n",
    "    learning_rate: float = 3e-4\n",
    "    epochs: int = 10\n",
    "    \n",
    "opt = OptConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate on a reduced cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CPRD.data.database import queries\n",
    "\n",
    "PATH_TO_DB = \"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModel/preprocessing/processed/cprd.db\"\n",
    "conn = sqlite3.connect(PATH_TO_DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get a list of patients which fit a reduced set of criterion\n",
    "identifiers1 = queries.query_measurement([\"bmi\", \"diastolic_blood_pressure\"], cursor)        \n",
    "identifiers2 = queries.query_diagnosis([\"DEPRESSION\", \"TYPE1DM\", \"TYPE2DIABETES\"], cursor)    #  \"DEPRESSION\"  ,  \"ANXIETY\"\n",
    "all_identifiers = list(set(identifiers1).intersection(identifiers2))    # Turn smaller list into the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using N=10000 random samples, from the available 117102\n"
     ]
    }
   ],
   "source": [
    "# Lets take only the first N for faster development\n",
    "N = np.min((len(all_identifiers), 10000))\n",
    "print(f\"Using N={N} random samples, from the available {len(all_identifiers)}\")\n",
    "\n",
    "identifiers = random.choices(all_identifiers, k=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building DL-friendly representation\n",
      "INFO:root:Dropping samples with no dynamic events\n",
      "INFO:root:Using non-tabular tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8626 training samples\n",
      "480 validation samples\n",
      "479 test samples\n",
      "101 vocab elements\n"
     ]
    }
   ],
   "source": [
    "dm = FoundationalDataModule(identifiers=identifiers,\n",
    "                            tokenizer=config.tokenizer,\n",
    "                            batch_size=opt.batch_size,\n",
    "                            max_seq_length=config.block_size,\n",
    "                            unk_freq_threshold=config.unk_freq_threshold)\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "\n",
    "print(f\"{len(dm.train_set)} training samples\")\n",
    "print(f\"{len(dm.val_set)} validation samples\")\n",
    "print(f\"{len(dm.test_set)} test samples\")\n",
    "print(f\"{vocab_size} vocab elements\")\n",
    "# print(dm.train_set.tokenizer._itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Positional Embedding. This module uses the index position of an event within the block of events.\n",
      "INFO:root:Using Positional Encoding. This module uses the index position of an event within the block of events.\n",
      "INFO:root:Using Temporal Positional Encoding. This module uses the patient's age at an event within their time series.\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "# Baseline model to test my changes against\n",
    "#   Note: this benchmark model uses index position along the batch\n",
    "models.append(GPTLanguageModel(config, vocab_size).to(device))\n",
    "\n",
    "# My development model\n",
    "# Handle positional vs. temporal encoding/embedding\n",
    "# Cases: \n",
    "#     index-embedding:       use index position along the batch\n",
    "#     index-encoding:        use index position along the batch\n",
    "#     temporal-encoding:     use age along a patient's timeline\n",
    "pos_encodings = [\"index-embedding\", \"index-encoding\", \"temporal-encoding\"]\n",
    "for pe in pos_encodings:\n",
    "    config = DemoConfig()\n",
    "    config.pos_encoding = pe\n",
    "    models.append(GPTModelForCausalLM(config, vocab_size).to(device))\n",
    "\n",
    "m_names = [\"kaparthy benchmark\"] + pos_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curves_train = [[] for _ in models]\n",
    "loss_curves_val = [[] for _ in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.816613 M parameters\n",
      "Epoch 0:\tTrain loss 1.21. Val loss 1.27\n",
      "Epoch 1:\tTrain loss 0.94. Val loss 0.95\n",
      "Epoch 2:\tTrain loss 0.72. Val loss 0.81\n",
      "Epoch 3:\tTrain loss 0.67. Val loss 0.78\n",
      "Epoch 4:\tTrain loss 0.64. Val loss 0.76\n",
      "Epoch 5:\tTrain loss 0.63. Val loss 0.75\n",
      "Epoch 6:\tTrain loss 0.62. Val loss 0.74\n",
      "Epoch 7:\tTrain loss 0.62. Val loss 0.73\n",
      "Epoch 8:\tTrain loss 0.61. Val loss 0.73\n",
      "Epoch 9:\tTrain loss 0.61. Val loss 0.73\n",
      "DEPRESSION diastolic_blood_pressure 7 0 . 0 diastolic_blood_pressure 8 0 . 0 diastolic_blood_pressure 8 0 . 0 diastolic_blood_pressure 8 4 . 0 diastolic_blood_pressure 8 5 . 0 diastolic_blood_pressure 7 6 . 0\n",
      "10.777829 M parameters\n",
      "Epoch 0:\tTrain loss 1.23. Val loss 1.24\n",
      "Epoch 1:\tTrain loss 0.81. Val loss 0.85\n",
      "Epoch 2:\tTrain loss 0.68. Val loss 0.78\n",
      "Epoch 3:\tTrain loss 0.65. Val loss 0.75\n",
      "Epoch 4:\tTrain loss 0.62. Val loss 0.74\n",
      "Epoch 5:\tTrain loss 0.61. Val loss 0.73\n",
      "Epoch 6:\tTrain loss 0.61. Val loss 0.73\n",
      "Epoch 7:\tTrain loss 0.61. Val loss 0.73\n",
      "Epoch 8:\tTrain loss 0.60. Val loss 0.72\n",
      "Epoch 9:\tTrain loss 0.60. Val loss 0.72\n",
      "DEPRESSION ANXIETY bmi 2 0 . 9 diastolic_blood_pressure 6 1 . 0 diastolic_blood_pressure 7 1 . 0 eosinophil_count 0 . 2 bmi 2 5 . 7 2 diastolic_blood_pressure 8 0 .\n",
      "10.679525 M parameters\n",
      "Epoch 0:\tTrain loss 1.61. Val loss 1.46\n",
      "Epoch 1:\tTrain loss 1.06. Val loss 1.04\n",
      "Epoch 2:\tTrain loss 0.86. Val loss 0.93\n",
      "Epoch 3:\tTrain loss 0.76. Val loss 0.88\n",
      "Epoch 4:\tTrain loss 0.73. Val loss 0.84\n",
      "Epoch 5:\tTrain loss 0.70. Val loss 0.82\n",
      "Epoch 6:\tTrain loss 0.68. Val loss 0.80\n",
      "Epoch 7:\tTrain loss 0.67. Val loss 0.78\n",
      "Epoch 8:\tTrain loss 0.66. Val loss 0.78\n",
      "Epoch 9:\tTrain loss 0.64. Val loss 0.76\n",
      "DEPRESSION diastolic_blood_pressure 7 7 . 0 PSORIASIS PERIPHERAL_NEUROPATHY DEPRESSION basophil_count 0 . 0 2 eosinophil_count 0 . 0 3 basophil_count 0 . 0 4 corrected_serum_calcium_level 2 . 2 5 eosinophil_count 0\n",
      "10.679717 M parameters\n",
      "Epoch 0:\tTrain loss 1.62. Val loss 1.85\n",
      "Epoch 1:\tTrain loss 1.45. Val loss 1.47\n",
      "Epoch 2:\tTrain loss 0.95. Val loss 0.95\n",
      "Epoch 3:\tTrain loss 0.74. Val loss 0.86\n",
      "Epoch 4:\tTrain loss 0.70. Val loss 0.83\n",
      "Epoch 5:\tTrain loss 0.68. Val loss 0.80\n",
      "Epoch 6:\tTrain loss 0.66. Val loss 0.78\n",
      "Epoch 7:\tTrain loss 0.64. Val loss 0.78\n",
      "Epoch 8:\tTrain loss 0.63. Val loss 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using positional temporal-encoding requires ages, but this head has no way of sampling age at next event. Using 50 days as intervals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\tTrain loss 0.62. Val loss 0.77\n",
      "DEPRESSION diastolic_blood_pressure 8 PERIPHERAL_NEUROPATHY diastolic_blood_pressure 6 basophil_count 0 . 0 4 diastolic_blood_pressure 7 bmi 1 diastolic_blood_pressure 8 4 diastolic_blood_pressure 8 6 . 4 diastolic_blood_pressure 8 corrected_serum_calcium_level 1 . 0 diastolic_blood_pressure 7\n"
     ]
    }
   ],
   "source": [
    "for m_idx, model in enumerate(models):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # print the number of parameters in the model\n",
    "    print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "    best_val, best_iter = np.inf, 0\n",
    "    for epoch in range(opt.epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for i, batch in enumerate(dm.train_dataloader()):\n",
    "            # evaluate the loss\n",
    "            logits, loss = model(batch['tokens'].to(device),\n",
    "                                 ages=batch['ages'].to(device),\n",
    "                                 targets=batch['target_tokens'].to(device),\n",
    "                                 attention_mask=batch['attention_mask'].to(device)\n",
    "                                 )\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss /= i\n",
    "        loss_curves_train[m_idx].append(epoch_loss)\n",
    "\n",
    "        # evaluate the loss on val set\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            if epoch % opt.eval_interval == 0 or epoch == opt.epochs - 1:\n",
    "                val_loss = 0\n",
    "                for j, batch in enumerate(dm.val_dataloader()):\n",
    "                    _, loss = model(batch['tokens'].to(device), \n",
    "                                    ages=batch['ages'].to(device), \n",
    "                                    targets=batch['target_tokens'].to(device),\n",
    "                                    attention_mask=batch['attention_mask'].to(device)   \n",
    "                                   )\n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= j\n",
    "                loss_curves_val[m_idx].append(val_loss)\n",
    "                print(f\"Epoch {epoch}:\\tTrain loss {epoch_loss:.2f}. Val loss {val_loss:.2f}\")          \n",
    "                # TODO: Note not fully accurate as last batch is likely not the same size, will be fixed with lightning\n",
    "        \n",
    "            if val_loss >= best_val:\n",
    "                best_iter += 1\n",
    "                if best_iter > 2:\n",
    "                    break\n",
    "            else:\n",
    "                best_val = val_loss\n",
    "                best_iter = 0\n",
    "                \n",
    "    prompt = [\"DEPRESSION\"]\n",
    "    context = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "    fut_tokens, fut_ages = model.generate(context, max_new_tokens=30)\n",
    "    fut_words = dm.decode(fut_tokens[0].tolist())\n",
    "    print(fut_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"k\", \"r\", \"b\", \"y\"]\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "for m_idx, _ in enumerate(models):\n",
    "    # Training\n",
    "    iterations = np.linspace(0, len(loss_curves_train[m_idx]), len(loss_curves_train[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_train[m_idx], label=f\"{m_names[m_idx]}-train\", c=cols[m_idx], linestyle='dashed')\n",
    "    # Validation\n",
    "    iterations = np.linspace(0, len(loss_curves_val[m_idx]), len(loss_curves_val[m_idx])) * opt.eval_interval\n",
    "    plt.plot(iterations, loss_curves_val[m_idx], label=f\"{m_names[m_idx]}-val\", c=cols[m_idx])\n",
    "plt.legend()\n",
    "plt.savefig(\"figs/loss_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of type II diabetes before and after a type I diagnosis\n",
    "\n",
    "keys: \n",
    "\n",
    "    70: 'TYPE1DM'\n",
    "    31: 'TYPE2DIABETES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small context comparison, high bmi and blood pressure vs low for diabetes risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.tokenizer == \"tabular\":\n",
    "    low_risk_prompt = [\"bmi\", \"diastolic_blood_pressure\"]\n",
    "    high_risk_prompt = [\"bmi\", \"diastolic_blood_pressure\"]\n",
    "    ages_in_years = [19, 20]\n",
    "else:\n",
    "    low_risk_prompt = [\"bmi\", \"2\", \"2\", \".\", \"5\", \"diastolic_blood_pressure\", \"7\", \"9\", \".\", \"0\"]\n",
    "    high_risk_prompt = [\"bmi\", \"3\", \"7\", \".\", \"5\", \"diastolic_blood_pressure\", \"9\", \"9\", \".\", \"0\"]\n",
    "    ages_in_years = [19, 19, 19, 19, 19, 20, 20, 20, 20, 20]\n",
    "\n",
    "to_days = lambda a_list: torch.FloatTensor([365 * _a for _a in a_list]).reshape((1,-1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MODEL_IDX 0\n",
      "==================\n",
      "\n",
      "Control: Low risk: \n",
      "\t (bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0002%\n",
      "probability of type II diabetes 0.0004%\n",
      "\n",
      "Control: High risk: \n",
      "\t (bmi,3,7,.,5,diastolic_blood_pressure,9,9,.,0): \n",
      "probability of type I diabetes 0.0002%\n",
      "probability of type II diabetes 0.0004%\n",
      "\n",
      "Control: Low risk + depression: \n",
      "\t (DEPRESSION,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.2374%\n",
      "probability of type II diabetes 0.3447%\n",
      "\n",
      "Low risk context: Type 1 diagnosis in prompt: \n",
      "\t (TYPE1DM,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0964%\n",
      "probability of type II diabetes 0.2813%\n",
      "\n",
      "Low risk context: Type 1I diagnosis in prompt: \n",
      "\t (TYPE2DIABETES,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.1217%\n",
      "probability of type II diabetes 0.7006%\n",
      "\n",
      "\n",
      "MODEL_IDX 1\n",
      "==================\n",
      "\n",
      "Control: Low risk: \n",
      "\t (bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0015%\n",
      "probability of type II diabetes 0.0012%\n",
      "\n",
      "Control: High risk: \n",
      "\t (bmi,3,7,.,5,diastolic_blood_pressure,9,9,.,0): \n",
      "probability of type I diabetes 0.0015%\n",
      "probability of type II diabetes 0.0012%\n",
      "\n",
      "Control: Low risk + depression: \n",
      "\t (DEPRESSION,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.3991%\n",
      "probability of type II diabetes 0.3438%\n",
      "\n",
      "Low risk context: Type 1 diagnosis in prompt: \n",
      "\t (TYPE1DM,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.1658%\n",
      "probability of type II diabetes 0.4196%\n",
      "\n",
      "Low risk context: Type 1I diagnosis in prompt: \n",
      "\t (TYPE2DIABETES,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.1507%\n",
      "probability of type II diabetes 0.5525%\n",
      "\n",
      "\n",
      "MODEL_IDX 2\n",
      "==================\n",
      "\n",
      "Control: Low risk: \n",
      "\t (bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0005%\n",
      "probability of type II diabetes 0.0004%\n",
      "\n",
      "Control: High risk: \n",
      "\t (bmi,3,7,.,5,diastolic_blood_pressure,9,9,.,0): \n",
      "probability of type I diabetes 0.0005%\n",
      "probability of type II diabetes 0.0004%\n",
      "\n",
      "Control: Low risk + depression: \n",
      "\t (DEPRESSION,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.1545%\n",
      "probability of type II diabetes 0.2848%\n",
      "\n",
      "Low risk context: Type 1 diagnosis in prompt: \n",
      "\t (TYPE1DM,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0913%\n",
      "probability of type II diabetes 0.2678%\n",
      "\n",
      "Low risk context: Type 1I diagnosis in prompt: \n",
      "\t (TYPE2DIABETES,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.1149%\n",
      "probability of type II diabetes 0.2952%\n",
      "\n",
      "\n",
      "MODEL_IDX 3\n",
      "==================\n",
      "\n",
      "Control: Low risk: \n",
      "\t (bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.0315%\n",
      "probability of type II diabetes 0.0082%\n",
      "\n",
      "Control: High risk: \n",
      "\t (bmi,3,7,.,5,diastolic_blood_pressure,9,9,.,0): \n",
      "probability of type I diabetes 0.0315%\n",
      "probability of type II diabetes 0.0082%\n",
      "\n",
      "Control: Low risk + depression: \n",
      "\t (DEPRESSION,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.4573%\n",
      "probability of type II diabetes 0.1921%\n",
      "\n",
      "Low risk context: Type 1 diagnosis in prompt: \n",
      "\t (TYPE1DM,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.4819%\n",
      "probability of type II diabetes 0.2006%\n",
      "\n",
      "Low risk context: Type 1I diagnosis in prompt: \n",
      "\t (TYPE2DIABETES,bmi,2,2,.,5,diastolic_blood_pressure,7,9,.,0): \n",
      "probability of type I diabetes 0.4780%\n",
      "probability of type II diabetes 0.2213%\n"
     ]
    }
   ],
   "source": [
    "prompts, ages, desc = [], [], []\n",
    "\n",
    "desc.append(\"Control: Low risk\")\n",
    "prompts.append(low_risk_prompt)\n",
    "ages.append(ages_in_years)\n",
    "\n",
    "desc.append(\"Control: High risk\")\n",
    "prompts.append(high_risk_prompt)\n",
    "ages.append(ages_in_years)\n",
    "\n",
    "desc.append(\"Control: Low risk + depression\")\n",
    "prompts.append([\"DEPRESSION\"] + low_risk_prompt)\n",
    "ages.append([17] + ages_in_years)\n",
    "\n",
    "desc.append(\"Low risk context: Type 1 diagnosis in prompt\")\n",
    "prompts.append([\"TYPE1DM\"] + low_risk_prompt)\n",
    "ages.append([17] + ages_in_years)\n",
    "\n",
    "desc.append(\"Low risk context: Type 1I diagnosis in prompt\")\n",
    "prompts.append([\"TYPE2DIABETES\"] + low_risk_prompt)\n",
    "ages.append([17] + ages_in_years)\n",
    "\n",
    "for model_idx in range(len(pos_encodings)+1):\n",
    "    print(f\"\\n\\nMODEL_IDX {model_idx}\\n==================\")\n",
    "    \n",
    "    for p_idx, (prompt, age) in enumerate(zip(prompts, ages)):\n",
    "        print(f\"\\n{desc[p_idx]}: \\n\\t ({','.join(prompt)}): \")\n",
    "        encoded_prompt = torch.from_numpy(np.array(dm.encode(prompt)).reshape((1,-1))).to(device)\n",
    "        lgts, _ = models[model_idx](encoded_prompt,\n",
    "                                    ages=to_days(age))\n",
    "        probs = torch.nn.functional.softmax(lgts, dim=2)\n",
    "        print(f\"probability of type I diabetes {100*float(probs[0, 0, 70].cpu().detach().numpy()):.4f}%\")\n",
    "        print(f\"probability of type II diabetes {100*float(probs[0, 0, 31].cpu().detach().numpy()):.4f}%\")\n",
    "\n",
    "# Note: adding a diagnosis (even if potentially orthogonal) at the beginning of the prompt increases probability of either type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
