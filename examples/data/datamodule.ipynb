{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Dataloader tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning \n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "\n",
    "import CPRD\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# device = \"cpu\"    # just for debug errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPT config to be equivalent\n",
    "@dataclass\n",
    "class DemoConfig:\n",
    "    tokenizer: str = \"tabular\"\n",
    "    unk_freq_threshold: float = 0.0\n",
    "    block_size: int = 64             # what is the maximum context length for predictions?\n",
    "    # n_layer: int = 6\n",
    "    # n_head: int = 6\n",
    "    # n_embd: int = 384\n",
    "    # pos_encoding: str = \"index-embedding\"                 # Manually adding later\n",
    "    # bias: bool = True\n",
    "    # attention_type: str = \"global\"    \n",
    "    # dropout: float = 0.0\n",
    "\n",
    "config = DemoConfig()\n",
    "\n",
    "@dataclass\n",
    "class OptConfig:\n",
    "    batch_size: int = 64\n",
    "    # eval_interval: int = 1\n",
    "    # learning_rate: float = 3e-4\n",
    "    # epochs: int = 10\n",
    "    \n",
    "opt = OptConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is first extracted from CPRD using [DExtER](https://link.springer.com/article/10.1007/s10654-020-00677-6) and is available within the optimal project master dataset. Some outlier filtering has already been done in this extraction, and the ICD diagnostic codes in CPRD have been summarised and processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 70K\n",
      "drwx--S--- 7 nobody nobody  16K Nov 29 10:15 \u001b[0m\u001b[01;34m.\u001b[0m\n",
      "drwx--S--- 8 nobody nobody 4.0K Nov 29 10:16 \u001b[01;34m..\u001b[0m\n",
      "drwx--S--- 2 nobody nobody 4.0K Nov 14 10:44 \u001b[01;34mbaseline\u001b[0m\n",
      "-rwx------ 1 nobody nobody 4.0K Oct 23 08:26 \u001b[01;32m._.DS_Store\u001b[0m\n",
      "-rwx------ 1 nobody nobody 6.1K Nov  4 13:01 \u001b[01;32m.DS_Store\u001b[0m\n",
      "drwx--S--- 3 nobody nobody 4.0K Nov 29 10:15 \u001b[01;34mHES\u001b[0m\n",
      "drwx--S--- 2 nobody nobody 4.0K Nov 13 10:27 \u001b[01;34mmetadata\u001b[0m\n",
      "drwx--S--- 4 nobody nobody 4.0K Nov  4 12:57 \u001b[01;34mtimeseries\u001b[0m\n",
      "drwx--S--- 2 nobody nobody 4.0K Nov 28 10:30 \u001b[01;34mzip\u001b[0m\n",
      "total 30G\n",
      "drwx--S--- 2 nobody nobody 4.0K Nov 14 10:44 \u001b[0m\u001b[01;34m.\u001b[0m\n",
      "drwx--S--- 7 nobody nobody  16K Nov 29 10:15 \u001b[01;34m..\u001b[0m\n",
      "-rwx------ 1 nobody nobody  15G Nov 10 15:43 \u001b[01;32mmasterDataOptimal_v3.csv\u001b[0m\n",
      "-rwx------ 1 nobody nobody  15G Nov 14 10:27 \u001b[01;32mmasterDataOptimalWithIMD_v3.csv\u001b[0m\n",
      "total 98K\n",
      "drwx--S--- 4 nobody nobody 4.0K Nov  4 12:57 \u001b[0m\u001b[01;34m.\u001b[0m\n",
      "drwx--S--- 7 nobody nobody  16K Nov 29 10:15 \u001b[01;34m..\u001b[0m\n",
      "-rwx------ 1 nobody nobody 4.0K Nov  4 12:57 \u001b[01;32m._.DS_Store\u001b[0m\n",
      "-rwx------ 1 nobody nobody 6.1K Nov  4 19:11 \u001b[01;32m.DS_Store\u001b[0m\n",
      "drwx--S--- 2 nobody nobody  16K Nov 13 10:27 \u001b[01;34mmeasurement_and_tests\u001b[0m\n",
      "drwx--S--- 2 nobody nobody 4.0K Nov 13 10:27 \u001b[01;34mmedication\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ls --color -lah /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data\n",
    "!ls --color -lah /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/baseline\n",
    "!ls --color -lah /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are pre-processed further in R to obtain three .csv files which are in turn compiled into an SQLite database within the `CPRD.data` module. \n",
    "\n",
    "* TODO: Replace R filtering with in-built python script\n",
    "* TODO: It is future work to combine these steps into DExtER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 67K\n",
      "drwx--S---  3 gaddcz nobody 4.0K Sep 28 11:12 \u001b[0m\u001b[01;34m.\u001b[0m\n",
      "drwx--S---. 5 gaddcz nobody 4.0K Oct 24 11:21 \u001b[01;34m..\u001b[0m\n",
      "drwx--S---  2 gaddcz nobody  16K Oct 18 15:48 \u001b[01;34mprocessed\u001b[0m\n",
      "-rwx------  1 gaddcz nobody 7.5K Sep 28 15:22 \u001b[01;32mprocessing_diagnoses.R\u001b[0m\n",
      "-rwx------. 1 gaddcz nobody  14K Oct 18 16:10 \u001b[01;32mprocessing_measurements_and_tests.R\u001b[0m\n",
      "-rwx------  1 gaddcz nobody 2.2K Sep 19 11:00 \u001b[01;32mprocessing_static.R\u001b[0m\n",
      "total 2.0G\n",
      "drwx--S--- 2 gaddcz nobody  16K Oct 18 15:48 \u001b[0m\u001b[01;34m.\u001b[0m\n",
      "drwx--S--- 3 gaddcz nobody 4.0K Sep 28 11:12 \u001b[01;34m..\u001b[0m\n",
      "-rwx------ 1 gaddcz nobody 983M Oct 18 15:48 \u001b[01;32mcprd.db\u001b[0m\n",
      "-rwx------ 1 gaddcz nobody 128M Oct  2 15:06 \u001b[01;32mdiagnosis_history.csv\u001b[0m\n",
      "-rwx------ 1 gaddcz nobody 874M Sep 28 15:38 \u001b[01;32mmeasurements.csv\u001b[0m\n",
      "-rwx------ 1 gaddcz nobody  42M Sep 20 12:06 \u001b[01;32mstatic.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ls --color -lah /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModel/preprocessing\n",
    "!ls --color -lah /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModel/preprocessing/processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In doing this we convert each of these files into an SQL table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static table\n",
    "<div align=\"justify\">\n",
    "The static table has one row per data owner. \n",
    "\n",
    "* PRACTICE_PATIENT_ID: The data owner identifier,\n",
    "* ETHNICITY, SEX, etc: The static variables which remain constant throughout a lifetime.\n",
    "* INDEX_AGE / START_AGE / END_AGE: \n",
    "</div>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "TODO: \n",
    "</div>\n",
    "\n",
    "* Repace missing with nans or some other unique value so these can be masked later\n",
    "* Add filtering to only include events after index age\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Static table` docstring:\n",
      "\n",
      "    \n",
      "    Produced anonymized table:\n",
      "    ┌──────────────────────┬─────┬───────────┬───────────────┬─────────────┬─────────────┬───────────────┐\n",
      "    │ PRACTICE_PATIENT_ID  ┆ SEX ┆ ETHNICITY ┆ YEAR_OF_BIRTH ┆ INDEX_AGE   ┆ START_AGE   ┆ END_AGE       │\n",
      "    │ ---                  ┆ --- ┆ ---       ┆ ---           ┆ ---         ┆ ---         ┆ ---           │\n",
      "    │ str                  ┆ str ┆ str       ┆ str           ┆ i64 (days)  ┆ i64 (days)  ┆ i64 (days)    │\n",
      "    ╞══════════════════════╪═════╪═══════════╪═══════════════╪═════════════╪═════════════╪═══════════════╡\n",
      "    │ <anonymous 1>        ┆ M   ┆ WHITE     ┆ yyyy--mm-dd   ┆ dd          ┆ dd          ┆ dd            │\n",
      "    │ <anonymous 2>        ┆ F   ┆ MISSING   ┆ yyyy--mm-dd   ┆ dd          ┆ dd          ┆ dd            │\n",
      "    │ …                    ┆ …   ┆ …         ┆ …             ┆             ┆             ┆               │\n",
      "    │ <anonymous N>        ┆ M   ┆ WHITE     ┆ yyyy--mm-dd   ┆ dd          ┆ dd          ┆ dd            │\n",
      "    └──────────────────────┴─────┴───────────┴───────────────┴─────────────┴─────────────┴───────────────┘\n",
      "        \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"`Static table` docstring:\\n{CPRD.data.database.build_static_db.build_static_table.__doc__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis table\n",
    "<div align=\"justify\">\n",
    "The diagnosis table has one row per diagnosis. \n",
    "\n",
    "* PRACTICE_PATIENT_ID: The data owner identifier,\n",
    "* EVENT: The categorical event\n",
    "* AGE_AT_EVENT: Number if days between subject birth and the day of event\n",
    "* VALUE: to be removed\n",
    "* EVENT_TYPE: to be removed\n",
    "</div>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  TODO: \n",
    "</div>\n",
    "\n",
    "* We could embed based on subgroups. For example each of these conditions are categorical, but they could be further sub categories. For example, diabetes can be one category and types further divide this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Diagnosis table` docstring:\n",
      "\n",
      "    Build measurements and tests table in database\n",
      "\n",
      "    Produced anonymized table:\n",
      "    ┌──────────────────────┬───────┬──────────────┬──────────────┬────────────────────────────┐\n",
      "    │ PRACTICE_PATIENT_ID  ┆ VALUE ┆ EVENT        ┆ AGE_AT_EVENT ┆ EVENT_TYPE                 │\n",
      "    │ ---                  ┆ ---   ┆ ---          ┆ ---          ┆ ---                        │\n",
      "    │ str                  ┆ f64   ┆ str          ┆ i64 (days)   ┆ str                        │\n",
      "    ╞══════════════════════╪═══════╪══════════════╪══════════════╪════════════════════════════╡\n",
      "    │ <anonymous 1>        ┆ null  ┆ HF           ┆ 11632        ┆ categorical                │\n",
      "    │ <anonymous 2>        ┆ null  ┆ HF           ┆ 25635        ┆ categorical                │\n",
      "    │ …                    ┆ …     ┆ …            ┆ …            ┆ …                          │\n",
      "    │ <anonymous N>        ┆ null  ┆ FIBROMYALGIA ┆ 8546         ┆ categorical                │\n",
      "    └──────────────────────┴───────┴──────────────┴──────────────┴────────────────────────────┘\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"`Diagnosis table` docstring:\\n{CPRD.data.database.build_diagnosis_db.build_diagnosis_table.__doc__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements and tests table\n",
    "<div align=\"justify\">\n",
    "The measurements table has one row per diagnosis. \n",
    "\n",
    "* PRACTICE_PATIENT_ID: The data owner identifier,\n",
    "* EVENT: The categorical event\n",
    "* AGE_AT_EVENT: Number if days between subject birth and the day of event\n",
    "* VALUE: The measurement/test record\n",
    "* EVENT_TYPE: whether the value is categorical (e.g. EVENT==\"smoking\", value=\"ex-smoker\"), or continuous (e.g. EVENT==\"bmi\", value=23.3)\n",
    "</div>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  TODO: \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Measurements and tests table` docstring:\n",
      " \n",
      "    Build measurements and tests table in database\n",
      "\n",
      "    Produced anonymized table:\n",
      "    ┌──────────────────────┬───────┬──────────────────┬──────────────┬───────────────────────┐\n",
      "    │ PRACTICE_PATIENT_ID  ┆ VALUE ┆ EVENT            ┆ AGE_AT_EVENT ┆ EVENT_TYPE            │\n",
      "    │ ---                  ┆ ---   ┆ ---              ┆ ---          ┆ ---                   │\n",
      "    │ str                  ┆ f64   ┆ str              ┆ i64 (days)   ┆ str                   │\n",
      "    ╞══════════════════════╪═══════╪══════════════════╪══════════════╪═══════════════════════╡\n",
      "    │ <anonymous 1>        ┆ 23.3  ┆ bmi              ┆ 10254        ┆ univariate_regression │\n",
      "    │ <anonymous 1>        ┆ 24.1  ┆ bmi              ┆ 11829        ┆ univariate_regression │\n",
      "    │ …                    ┆ …     ┆ …                ┆ …            ┆ …                     │\n",
      "    │ <anonymous N>        ┆ 0.17  ┆ eosinophil_count ┆ 12016        ┆ univariate_regression │\n",
      "    └──────────────────────┴───────┴──────────────────┴──────────────┴───────────────────────┘\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"`Measurements and tests table` docstring:\\n{CPRD.data.database.build_measurements_and_tests_db.build_measurements_table.__doc__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "\n",
    "We can query the SQL tables separately to find the set of patients that fit the study criteria. \n",
    "\n",
    "First we can connect directly to the database using sqlite3\n",
    "\n",
    "<div align=\"center\">\n",
    "  TODO: \n",
    "</div>\n",
    "\n",
    "* The db shouldn't really be interfaced with like this, this is mostly for demonstration and a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DB = \"/rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModel/preprocessing/processed/cprd.db\"\n",
    "conn = sqlite3.connect(PATH_TO_DB)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a look-up directly on the tables shows what diagnoses, measurements and tests are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have access to measurements and tests:\n",
      " * bmi\n",
      " * hydroxyvitamin2\n",
      " * hydroxyvitamin3\n",
      " * aspartate_transam\n",
      " * serum_level\n",
      " * creatinine_ratio\n",
      " * basophil_count\n",
      " * blood_calcium\n",
      " * blood_urea\n",
      " * brain_natriuretic_peptide_level\n",
      " * calcium_adjusted_level\n",
      " * calculated_LDL_cholesterol_level\n",
      " * combined_total_vitamin_D2_and_D3_level\n",
      " * corrected_serum_calcium_level\n",
      " * diastolic_blood_pressure\n",
      " * eosinophil_count\n",
      "\n",
      "Additionally, we have access to diagnoses:\n",
      " * HF\n",
      " * AF\n",
      " * ISCHAEMICSTROKE\n",
      " * STROKEUNSPECIFIED\n",
      " * STROKE_HAEMRGIC\n",
      " * HYPERTENSION\n",
      " * MINFARCTION\n",
      " * IHD_NOMI\n",
      " * PAD_STRICT\n",
      " * VALVULARDISEASES\n",
      " * AORTICANEURYSM\n",
      " * TYPE1DM\n",
      " * TYPE2DIABETES\n",
      " * CKDSTAGE3TO5\n",
      " * DEPRESSION\n",
      " * ANXIETY\n",
      " * BIPOLAR\n",
      " * EATINGDISORDERS\n",
      " * SCHIZOPHRENIAMM\n",
      " * AUTISM\n",
      " * ALCOHOLMISUSE\n",
      " * SUBSTANCEMISUSE\n",
      " * CHRONIC_LIVER_DISEASE_ALCOHOL\n",
      " * NAFLD\n",
      " * OTHER_CHRONIC_LIVER_DISEASE_OPTIMAL\n",
      " * ULCERATIVE_COLITIS\n",
      " * CROHNS_DISEASE\n",
      " * ALL_DEMENTIA\n",
      " * PARKINSONS\n",
      " * EPILEPSY\n",
      " * ALLCA_NOBCC_VFINAL\n",
      " * LYMPHOMA_PREVALENCE\n",
      " * LEUKAEMIA_PREVALENCE\n",
      " * PLASMACELL_NEOPLASM\n",
      " * ASTHMA_PUSHASTHMA\n",
      " * COPD\n",
      " * OSA\n",
      " * BRONCHIECTASIS\n",
      " * CYSTICFIBROSIS\n",
      " * ATOPICECZEMA\n",
      " * ALLERGICRHINITISCONJ\n",
      " * HIVAIDS\n",
      " * OSTEOPOROSIS\n",
      " * OSTEOARTHRITIS\n",
      " * RHEUMATOIDARTHRITIS\n",
      " * GOUT\n",
      " * SYSTEMIC_LUPUS_ERYTHEMATOSUS\n",
      " * SJOGRENSSYNDROME\n",
      " * SYSTEMIC_SCLEROSIS\n",
      " * PMRANDGCA\n",
      " * CHRONICFATIGUESYNDROMEMM\n",
      " * HYPOTHYROIDISM_DRAFT_V1\n",
      " * HYPERTHYROIDISM\n",
      " * ADDISON_DISEASE\n",
      " * MS\n",
      " * VISUAL_IMPAIRMENT\n",
      " * MENIERESDISEASE\n",
      " * PERIPHERAL_NEUROPATHY\n",
      " * DOWNSSYNDROME\n",
      " * PERNICIOUSANAEMIA\n",
      " * PSORIASIS\n",
      " * PSORIATICARTHRITIS2021\n",
      " * ILD_SH\n",
      " * PTSDDIAGNOSIS\n",
      " * PREVALENT_IBS\n",
      " * ANY_DEAFNESS_HEARING_LOSS\n",
      " * LEARNINGDISABILITY\n",
      " * ENDOMETRIOSIS_ADENOMYOSIS_V2\n",
      " * POLYCYSTIC_OVARIAN_SYNDROME_PCOS\n",
      " * SICKLE_CELL_DISEASE\n",
      " * HAEMOCHROMATOSIS\n",
      " * FIBROMYALGIA\n"
     ]
    }
   ],
   "source": [
    "# Check what measurements are available\n",
    "cursor.execute(\"SELECT DISTINCT EVENT FROM measurement_table\")\n",
    "measurements = [_item[0] for _item in cursor.fetchall()]\n",
    "print(\"We have access to measurements and tests:\\n * \" + '\\n * '.join(measurements))\n",
    "\n",
    "# Check what diagnoses are available\n",
    "cursor.execute(\"SELECT DISTINCT EVENT FROM diagnosis_table\")\n",
    "diagnoses = [_item[0] for _item in cursor.fetchall()]\n",
    "print(\"\\nAdditionally, we have access to diagnoses:\\n * \" + '\\n * '.join(diagnoses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given some subset of these we can query the database to find those subjects who have at least one entry of a list of measurements, tests or diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiers1 = CPRD.data.database.queries.query_measurement([\"bmi\", \"diastolic_blood_pressure\"], cursor)        \n",
    "identifiers2 = CPRD.data.database.queries.query_diagnosis([\"DEPRESSION\", \"TYPE1DM\", \"TYPE2DIABETES\"], cursor)    #  \"DEPRESSION\"  ,  \"ANXIETY\"\n",
    "all_identifiers = list(set(identifiers1).intersection(identifiers2))    # Turn smaller list into the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using N=10000 random samples, from the available 117102\n"
     ]
    }
   ],
   "source": [
    "# For now, lets take only the first 10,000\n",
    "N = np.min((len(all_identifiers), 10000))\n",
    "print(f\"Using N={N} random samples, from the available {len(all_identifiers)}\")\n",
    "\n",
    "identifiers = random.choices(all_identifiers, k=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make PyTorch dataloader\n",
    "\n",
    "We can now initialise our DL friendly datasets. This is done within the DataModule initialisation. \n",
    "\n",
    "Initialisation takes one required argument, which is the set of patient `identifiers` we wish to build into our dataset. The remaining arguments are optional and explained in the docstring\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  TODO: \n",
    "</div>\n",
    "\n",
    "* Add option of saving and loading initialised train/test/val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`FoundationalDataModule` docstring:\n",
      "\n",
      "    PyTorch-Lightning datamodule for foundational models\n",
      "    \n",
      "    ARGS:\n",
      "        practice_patient_id (list[str])\n",
      "            List of practice patient identifiers which satisfy study criteria.\n",
      "            \n",
      "    KWARGS:\n",
      "        batch_size (int): \n",
      "        \n",
      "        unk_freq_threshold (float). \n",
      "            Value between 0 and 1, controlling at what level of frequency rare tokens (equiv. conditions/measurements \n",
      "            with this tokenizer) are mapped to the UNK token. Used to reduce vocabulary size\n",
      "            \n",
      "        min_workers (int):\n",
      "\n",
      "        load_event_stream (optional, str):\n",
      "        \n",
      "        save_event_stream (optional, str):\n",
      "        \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"`FoundationalDataModule` docstring:\\n{FoundationalDataModule.__doc__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building polars dataset\n",
      "INFO:root:Dropping samples with no dynamic events\n",
      "INFO:root:Using tabular tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8633 training samples\n",
      "480 validation samples\n",
      "480 test samples\n",
      "90 dictionary elements\n",
      "\n",
      "Dictionaries\n",
      "{0: 'PAD', 1: 'UNK', 2: 'diastolic_blood_pressure', 3: 'bmi', 4: 'eosinophil_count', 5: 'basophil_count', 6: 'corrected_serum_calcium_level', 7: 'DEPRESSION', 8: 'serum_level', 9: 'calculated_LDL_cholesterol_level', 10: 'ANXIETY', 11: 'HYPERTENSION', 12: 'TYPE2DIABETES', 13: 'OSTEOARTHRITIS', 14: 'ASTHMA_PUSHASTHMA', 15: 'ATOPICECZEMA', 16: 'ALLERGICRHINITISCONJ', 17: 'aspartate_transam', 18: 'ANY_DEAFNESS_HEARING_LOSS', 19: 'PREVALENT_IBS', 20: 'ALLCA_NOBCC_VFINAL', 21: 'IHD_NOMI', 22: 'ALCOHOLMISUSE', 23: 'CKDSTAGE3TO5', 24: 'blood_urea', 25: 'PERIPHERAL_NEUROPATHY', 26: 'HYPOTHYROIDISM_DRAFT_V1', 27: 'calcium_adjusted_level', 28: 'COPD', 29: 'AF', 30: 'PSORIASIS', 31: 'SUBSTANCEMISUSE', 32: 'HF', 33: 'combined_total_vitamin_D2_and_D3_level', 34: 'GOUT', 35: 'OSTEOPOROSIS', 36: 'MINFARCTION', 37: 'STROKEUNSPECIFIED', 38: 'ALL_DEMENTIA', 39: 'hydroxyvitamin3', 40: 'hydroxyvitamin2', 41: 'PAD_STRICT', 42: 'VALVULARDISEASES', 43: 'OTHER_CHRONIC_LIVER_DISEASE_OPTIMAL', 44: 'TYPE1DM', 45: 'FIBROMYALGIA', 46: 'OSA', 47: 'EPILEPSY', 48: 'EATINGDISORDERS', 49: 'PMRANDGCA', 50: 'POLYCYSTIC_OVARIAN_SYNDROME_PCOS', 51: 'HYPERTHYROIDISM', 52: 'RHEUMATOIDARTHRITIS', 53: 'NAFLD', 54: 'PTSDDIAGNOSIS', 55: 'ENDOMETRIOSIS_ADENOMYOSIS_V2', 56: 'ISCHAEMICSTROKE', 57: 'VISUAL_IMPAIRMENT', 58: 'creatinine_ratio', 59: 'BIPOLAR', 60: 'SCHIZOPHRENIAMM', 61: 'BRONCHIECTASIS', 62: 'AORTICANEURYSM', 63: 'CHRONICFATIGUESYNDROMEMM', 64: 'ULCERATIVE_COLITIS', 65: 'CHRONIC_LIVER_DISEASE_ALCOHOL', 66: 'STROKE_HAEMRGIC', 67: 'MENIERESDISEASE', 68: 'PERNICIOUSANAEMIA', 69: 'brain_natriuretic_peptide_level', 70: 'LEARNINGDISABILITY', 71: 'PARKINSONS', 72: 'PSORIATICARTHRITIS2021', 73: 'LYMPHOMA_PREVALENCE', 74: 'CROHNS_DISEASE', 75: 'ILD_SH', 76: 'LEUKAEMIA_PREVALENCE', 77: 'MS', 78: 'AUTISM', 79: 'HIVAIDS', 80: 'SJOGRENSSYNDROME', 81: 'SYSTEMIC_LUPUS_ERYTHEMATOSUS', 82: 'ADDISON_DISEASE', 83: 'PLASMACELL_NEOPLASM', 84: 'blood_calcium', 85: 'HAEMOCHROMATOSIS', 86: 'CYSTICFIBROSIS', 87: 'SYSTEMIC_SCLEROSIS', 88: 'DOWNSSYNDROME', 89: 'SICKLE_CELL_DISEASE'}\n"
     ]
    }
   ],
   "source": [
    "dm = FoundationalDataModule(identifiers=identifiers,\n",
    "                            tokenizer=config.tokenizer,\n",
    "                            batch_size=opt.batch_size,\n",
    "                            max_seq_length=config.block_size,\n",
    "                            unk_freq_threshold=config.unk_freq_threshold)\n",
    "\n",
    "print(f\"{len(dm.train_set)} training samples\")\n",
    "print(f\"{len(dm.val_set)} validation samples\")\n",
    "print(f\"{len(dm.test_set)} test samples\")\n",
    "print(f\"{dm.tokenizer.vocab_size} dictionary elements\")\n",
    "\n",
    "print(\"\\nDictionaries\")\n",
    "print(dm.tokenizer._itos)\n",
    "# print(dm.tokenizer._stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Each dataset within the DataModule is a ``cprd.data.dataset.dataset_polars.EventStreamDataset`` object. Within this class we process the SQL tables from a form in which each patient (static) or record (dianosis/measurement/test) has its own row, into a ragged form where each patient has their own row in every case. This does not change the form of the static table. However, the form of the diagnoses and measurements/tests changes - and during the same update we combine these frames to one frame which contains dynamic information.\n",
    "\n",
    "This is all wrapped in the method ``fit()``, but we can see the separate steps below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`_load_dynamic` docstring:\n",
      "    \n",
      "        Load and merge dynamic tables from SQL\n",
      "        \n",
      "        ARGS:\n",
      "            practice_patient_id (list[str])\n",
      "                List of practice patient identifiers which satisfy study criteria.\n",
      "            \n",
      "        KWARGS:\n",
      "            include_measurements: bool = True,\n",
      "                Flag of whether to include measurements and tests in polars dataframe\n",
      "            include_diagnoses: bool = True\n",
      "                Flag of whether to include diagnoses in polars dataframe\n",
      "        \n",
      "        RETURNS:\n",
      "            Polars lazy frame, of the form:\n",
      "            ┌──────────────────────┬───────────────────────┬───────────────────────────────────┬─────────────────────────┬───────────────────────────────────┐\n",
      "            │ PRACTICE_PATIENT_ID  ┆ VALUE                 ┆ EVENT                             ┆ AGE_AT_EVENT            ┆ EVENT_TYPE                        │\n",
      "            │ ---                  ┆ ---                   ┆ ---                               ┆ ---                     ┆ ---                               │\n",
      "            │ str                  ┆ list[f64]             ┆ list[str]                         ┆ list[i64]   (in days)   ┆ list[str]                         │\n",
      "            ╞══════════════════════╪═══════════════════════╪═══════════════════════════════════╪═════════════════════════╪═══════════════════════════════════╡\n",
      "            │ <anonymous 1>        ┆ [null, 21.92]         ┆ [\"diagnosis name\", \"record name\"  ┆ [age 1, age 2]          ┆ [\"categorical\", \"univariate_regre │\n",
      "            │ <anonymous 2>        ┆ [27.1, 75.0, … 91.0]  ┆ [\"record name\", ...]              ┆ [age 1, age 2, … ]      ┆ [\"univariate_regression\", \"univa… │\n",
      "            │ …                    ┆ …                     ┆ …                                 ┆ …                       ┆ …                                 │\n",
      "            │ <anonymous N2>       ┆ [70.0, 0.1, … 80.0]   ┆ [\"record name\", ...]              ┆ [age 1, age 2, … ]      ┆ [\"univariate_regression\", \"univa… │\n",
      "            └──────────────────────┴───────────────────────┴───────────────────────────────────┴─────────────────────────┴───────────────────────────────────┘\n",
      "            (synthetic entries)\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f\"`_load_dynamic` docstring:\\n{CPRD.data.dataset.dataset_polars.EventStreamDataset._load_dynamic.__doc__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is then combined into one DL friendly representation, which our DataModule uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`_build_DL_representation` docstring:\n",
      "\n",
      "        Build the DL-friendly representation in polars given the list of `practice_patient_id`s which fit study criteria\n",
      "                \n",
      "        ARGS:\n",
      "            practice_patient_id (list[str])\n",
      "                List of practice patient identifiers which satisfy study criteria.\n",
      "            \n",
      "        KWARGS:\n",
      "        \n",
      "        \n",
      "        RETURNS:\n",
      "            Polars lazy frame, of the (anonymized) form:\n",
      "            ┌──────────────────────┬─────┬─────────────┬───────────────┬──────────────────────┬─────────────────────────┬─────────────────────┬────────────────────────┐\n",
      "            │ PRACTICE_PATIENT_ID  ┆ SEX ┆ ETHNICITY   ┆ YEAR_OF_BIRTH ┆ VALUE                ┆ EVENT                   ┆ AGE_AT_EVENT        ┆ EVENT_TYPE             │\n",
      "            │ ---                  ┆ --- ┆ ---         ┆ ---           ┆ ---                  ┆ ---                     ┆ ---                 ┆ ---                    │\n",
      "            │ str                  ┆ str ┆ str         ┆ str           ┆ list[f64]            ┆ list[str]               ┆ list[i64]           ┆ list[str]              │\n",
      "            ╞══════════════════════╪═════╪═════════════╪═══════════════╪══════════════════════╪═════════════════════════╪═════════════════════╪════════════════════════╡\n",
      "            │ <anonymous 1>        ┆ M   ┆ MISSING     ┆ yyy-mm-dd     ┆ [null, 21.92]        ┆ [\"diagnosis name\", ...] ┆ [age 1, age 2]      ┆ [\"multi_label_cl...\", ]│\n",
      "            │ <anonymous 2>        ┆ F   ┆ WHITE       ┆ yyy-mm-dd     ┆ [27.1, 75.0, … 91.0] ┆ [\"record name\", ...]    ┆ [age 1, age 2, … ]  ┆ [\"univariate_reg...\", ]│\n",
      "            │ …                    ┆ …                 ┆ …             ┆ …                    ┆ …                       ┆ …                   ┆ …                      │\n",
      "            │ <anonymous N>        ┆ F   ┆ SOUTH_ASIAN ┆ yyy-mm-dd     ┆ [70.0, 0.1, … 80.0]  ┆ [\"record name\", ...]    ┆ [age 1, age 2, … ]  ┆ [\"univariate_reg...\", ]│\n",
      "            └──────────────────────┴─────┴─────────────┴───────────────┴──────────────────────┴─────────────────────────┴─────────────────────┴────────────────────────┘\n",
      "            with index cols: (age at index, age at start, age at end)\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f\"`_build_DL_representation` docstring:\\n{CPRD.data.dataset.dataset_polars.EventStreamDataset._build_DL_representation.__doc__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``__getitem__`` within the dataset class then retrieves rows of this table and performs the relevant processing such as tokenization. Speed ups could be obtained by pre-processing this tokenization.\n",
    "\n",
    "As these are ragged lists for memory efficiency, we also provide a ``collate_fn`` in the DataModule. This performs padding - and by performing padding this way we can avoid excessive padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using \\_\\_getitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single element of the training dataset contains:\n",
      "  * identifier\n",
      "  * tokens\n",
      "  * ages\n",
      "  * values\n",
      "\n",
      "identifier: p20720_2962458420720\n",
      "\n",
      "tokens: tensor([ 6,  2,  2,  4,  2,  3,  2,  4,  9,  6,  2,  3,  3,  2,  4,  3,  2,  2,\n",
      "         9,  4,  9, 33,  4,  5,  4,  2,  2,  9,  5,  4,  5,  4,  5, 33,  2,  4,\n",
      "        55,  3,  2,  5,  4,  5,  4,  2,  2,  2,  3,  2,  5, 33,  4,  5, 33,  4,\n",
      "         3,  3,  2,  2,  3,  9,  2,  5,  9,  4])\n",
      "... decoding to `corrected_serum_calcium_level diastolic_blood_pressure diastolic_blood_pressure eosinophil_count diastolic_blood_pressure bmi diastolic_blood_pressure eosinophil_count calculated_LDL_cholesterol_level corrected_serum_calcium_level diastolic_blood_pressure bmi bmi diastolic_blood_pressure eosinophil_count bmi diastolic_blood_pressure diastolic_blood_pressure calculated_LDL_cholesterol_level eosinophil_count calculated_LDL_cholesterol_level combined_total_vitamin_D2_and_D3_level eosinophil_count basophil_count eosinophil_count diastolic_blood_pressure diastolic_blood_pressure calculated_LDL_cholesterol_level basophil_count eosinophil_count basophil_count eosinophil_count basophil_count combined_total_vitamin_D2_and_D3_level diastolic_blood_pressure eosinophil_count ENDOMETRIOSIS_ADENOMYOSIS_V2 bmi diastolic_blood_pressure basophil_count eosinophil_count basophil_count eosinophil_count diastolic_blood_pressure diastolic_blood_pressure diastolic_blood_pressure bmi diastolic_blood_pressure basophil_count combined_total_vitamin_D2_and_D3_level eosinophil_count basophil_count combined_total_vitamin_D2_and_D3_level eosinophil_count bmi bmi diastolic_blood_pressure diastolic_blood_pressure bmi calculated_LDL_cholesterol_level diastolic_blood_pressure basophil_count calculated_LDL_cholesterol_level eosinophil_count`\n",
      "\n",
      "ages: tensor([12272, 12280, 12538, 12755, 12760, 12810, 12810, 12973, 12974, 12974,\n",
      "        13238, 13296, 13596, 13596, 13631, 13897, 13897, 14083, 14234, 14234,\n",
      "        14700, 14700, 14700, 15022, 15022, 15144, 15329, 15609, 15654, 15654,\n",
      "        15665, 15665, 15673, 15673, 15673, 15673, 15911, 16085, 16165, 16169,\n",
      "        16169, 16191, 16191, 16215, 16340, 16347, 16480, 16480, 16488, 16488,\n",
      "        16488, 16548, 16548, 16548, 16571, 16571, 16571, 16583, 16627, 16654,\n",
      "        16659, 16744, 16744, 16744])\n",
      "\n",
      "values: tensor([2.2300e+00, 6.8000e+01, 8.1000e+01, 3.0000e-01, 7.1000e+01, 2.6300e+01,\n",
      "        8.0000e+01, 2.0000e-01, 2.3000e+00, 2.2400e+00, 6.8000e+01, 2.8100e+01,\n",
      "        2.8600e+01, 6.8000e+01, 2.0000e-01, 2.7100e+01, 7.8000e+01, 8.4000e+01,\n",
      "        1.9000e+00, 2.0000e-01, 2.0000e+00, 6.4000e+01, 2.0000e-01, 5.0000e-02,\n",
      "        1.7000e-01, 8.4000e+01, 8.0000e+01, 2.8000e+00, 4.0000e-02, 1.5000e-01,\n",
      "        4.0000e-02, 1.5000e-01, 6.0000e-02, 5.6000e+01, 7.0000e+01, 1.5000e-01,\n",
      "               nan, 3.1100e+01, 7.2000e+01, 4.0000e-02, 1.2000e-01, 3.0000e-02,\n",
      "        8.0000e-02, 9.7000e+01, 7.8000e+01, 6.0000e+01, 3.1100e+01, 7.0000e+01,\n",
      "        5.0000e-02, 6.2000e+01, 1.6000e-01, 5.0000e-02, 6.0000e+01, 2.4000e-01,\n",
      "        3.2080e+01, 3.2100e+01, 9.0000e+01, 9.5000e+01, 3.1930e+01, 2.4000e+00,\n",
      "        9.5000e+01, 5.0000e-02, 2.1000e+00, 2.0000e-01])\n"
     ]
    }
   ],
   "source": [
    "# print(dm.train_set[0])\n",
    "print(\"A single element of the training dataset contains:\\n  * \" + '\\n  * '.join(dm.train_set[0].keys()))\n",
    "\n",
    "sample = np.random.randint(len(dm.train_set))\n",
    "\n",
    "for k, v in dm.train_set[sample].items():\n",
    "    print(f\"\\n{k}: {v}\")\n",
    "    if k == \"tokens\":\n",
    "        print(f\"... decoding to `{dm.decode(v.tolist())}`\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collating into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample from the dataloader batch gives:\n",
      "  * tokens\n",
      "  * ages\n",
      "  * values\n",
      "  * attention_mask\n",
      "\n",
      "For example, a single sample from a collated batch gives (viewing only first 10 elements of each sequence):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_3099052/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1171556092.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_3099052/1171556092.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'target_ages'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_3099052/\u001b[0m\u001b[1;33m1171556092.py\u001b[0m:\u001b[94m11\u001b[0m in \u001b[92m<module>\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_3099052/1171556092.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'target_ages'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, batch in enumerate(dm.train_dataloader()):\n",
    "    break\n",
    "print(\"A sample from the dataloader batch gives:\\n  * \" + '\\n  * '.join(batch.keys()))\n",
    "\n",
    "k = 10\n",
    "print(f\"\\nFor example, a single sample from a collated batch gives (viewing only first {k} elements of each sequence):\")\n",
    "\n",
    "# ages\n",
    "print(f\"\\n* The time of event (in days since birth) of events:\" + \n",
    "      f\"\\n \\tIn: {batch['ages'][0, :k]}\" + \n",
    "      f\"\\n \\tOut: {batch['target_ages'][0, :k]}\")\n",
    "\n",
    "# tokens\n",
    "print(f\"\\n* The tokenized and padded (within batch) block of a patient's sequence of events:\"\n",
    "      f\"\\n \\tIn: {batch['tokens'][0,:k]}\" + \n",
    "      f\"\\n \\tOut: {batch['target_tokens'][0,:k]}\")\n",
    "print(f\"\\t ... which can be decoded. E.g. the above tokens decode to:\" + \n",
    "      f\"\\n \\t\\tIn: `{dm.decode(batch['tokens'][0,:k].tolist())}`\" + \n",
    "      f\"\\n \\t\\tOut: `{dm.decode(batch['target_tokens'][0,:k].tolist())}`\")\n",
    "\n",
    "# values\n",
    "print(f\"\\n* When we use a {config.tokenizer} tokenizer, the corresponding values are given as\" + \n",
    "      f\"\\n \\tIn: {batch['values'][0,:k]}\" + \n",
    "      f\"\\n \\tOut: {batch['target_values'][0,:k]}\")\n",
    "\n",
    "# attention mask\n",
    "#   B = batch size, L = Longest sequence length within batch\n",
    "print(f\"\\n* The attention mask tells us which values are padded entries, so we can then mask them alongside the self-attention masking\" + \n",
    "      f\"\\n\\t This is of shape (B={batch['attention_mask'].shape[0]} * L={batch['attention_mask'].shape[1]})\" +\n",
    "      f\"\\n{batch['attention_mask']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular vs. non-tabular tokenization\n",
    "\n",
    "We can also use a non-tabular tokenizer.\n",
    "\n",
    "<div align=\"center\">\n",
    "  TODO: \n",
    "</div>\n",
    "\n",
    "* Possibly replace returning value tensor full of NaNs, to returning None. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = FoundationalDataModule(identifiers=identifiers,\n",
    "                            tokenizer=\"non-tabular\",\n",
    "                            batch_size=opt.batch_size,\n",
    "                            max_seq_length=config.block_size,\n",
    "                            unk_freq_threshold=config.unk_freq_threshold)\n",
    "\n",
    "print(f\"{len(dm.train_set)} training samples\")\n",
    "print(f\"{len(dm.val_set)} validation samples\")\n",
    "print(f\"{len(dm.test_set)} test samples\")\n",
    "print(f\"{dm.tokenizer.vocab_size} dictionary elements\")\n",
    "\n",
    "print(\"\\nDictionaries\")\n",
    "print(dm.tokenizer._itos)\n",
    "# print(dm.tokenizer._stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(dm.train_dataloader()):\n",
    "    break\n",
    "print(\"A sample from the dataloader batch gives:\\n  * \" + '\\n  * '.join(batch.keys()))\n",
    "\n",
    "k = 10\n",
    "print(f\"\\nRepeating the above example, a single sample from a collated batch gives (viewing only first {k} elements of each sequence):\")\n",
    "\n",
    "# ages\n",
    "print(f\"\\n* The time of event (in days since birth) of events remains in the same format:\" + \n",
    "      f\"\\n \\tIn: {batch['ages'][0, :k]}\" + \n",
    "      f\"\\n \\tOut: {batch['target_ages'][0, :k]}\")\n",
    "\n",
    "# tokens\n",
    "print(f\"\\n* The tokenized and padded (within batch) block of a patient's sequence for events now contains a non-tabular form of the values:\"\n",
    "      f\"\\n \\tIn: {batch['tokens'][0,:k]}\" + \n",
    "      f\"\\n \\tOut: {batch['target_tokens'][0,:k]}\")\n",
    "print(f\"\\t ... which can be decoded. E.g. the above tokens decode to:\" + \n",
    "      f\"\\n \\t\\tIn: `{dm.decode(batch['tokens'][0,:k].tolist())}`\" + \n",
    "      f\"\\n \\t\\tOut: `{dm.decode(batch['target_tokens'][0,:k].tolist())}`\")\n",
    "\n",
    "# values\n",
    "print(f\"\\n* and now with our non-tabular tokenizer no valid values are given.\" +\n",
    "      f\"\\n \\tIn: {batch['values'][0,:k]}\" + \n",
    "      f\"\\n \\tOut: {batch['target_values'][0,:k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
