{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f58899f-4329-4fff-b4cb-cf80a4e7a4e4",
   "metadata": {},
   "source": [
    "# Creating the parquet dataset from SQLite tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c70662-7dcf-4a1f-a343-8afd16a58be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/data/study_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f229a9ea-a77b-45ea-b5db-da34e291ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from CPRD.data.foundational_loader import FoundationalDataModule\n",
    "\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from CPRD.examples.data.study_data.study_criteria import cvd_inclusion_method\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"    # if more informative debugging statements are needed\n",
    "print(f\"Using device: {device}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff00f74b-f1a5-43d3-8e28-6c302d43b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_decoder: true\n",
      "data:\n",
      "  batch_size: 64\n",
      "  unk_freq_threshold: 0.0\n",
      "  min_workers: 20\n",
      "  global_diagnoses: false\n",
      "  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/\n",
      "  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information.pickle\n",
      "experiment:\n",
      "  project_name: SurvStreamGPT_${head.SurvLayer}\n",
      "  run_id: PreTrain_${head.SurvLayer}_129M_${experiment.seed}\n",
      "  train: true\n",
      "  test: true\n",
      "  verbose: true\n",
      "  seed: 1337\n",
      "  log: true\n",
      "  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/\n",
      "  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/\n",
      "optim:\n",
      "  num_epochs: 1\n",
      "  learning_rate: 0.0001\n",
      "  scheduler: CAWarmRestarts\n",
      "  scheduler_periods: 5000\n",
      "  scheduler_warmup: true\n",
      "  lr_cosine_decay_period: 10000000.0\n",
      "  val_check_interval: 1000\n",
      "  early_stop: false\n",
      "  early_stop_patience: 5\n",
      "  log_every_n_steps: 20\n",
      "  limit_val_batches: 0.05\n",
      "  limit_test_batches: 0.05\n",
      "transformer:\n",
      "  block_type: Neo\n",
      "  block_size: 128\n",
      "  n_layer: 10\n",
      "  n_head: 8\n",
      "  n_embd: 1024\n",
      "  layer_norm_bias: false\n",
      "  attention_type: global\n",
      "  bias: true\n",
      "  dropout: 0.2\n",
      "  attention_dropout: 0.2\n",
      "  resid_dropout: 0.2\n",
      "head:\n",
      "  SurvLayer: cr\n",
      "  surv_weight: 0.5\n",
      "  tokens_for_univariate_regression: None\n",
      "  value_weight: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the configuration file, override any settings \n",
    "with initialize(version_base=None, config_path=\"../../modelling/SurvStreamGPT/confs\", job_name=\"dataset_creation_notebook\"):\n",
    "    cfg = compose(config_name=\"config_CompetingRisk129M\", overrides=[])\n",
    "\n",
    "# Create new dataset \n",
    "cfg.data.path_to_ds = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\"\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b7aba-8aca-4859-b0c9-d6a58f4bcd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Building Polars datasets and saving to /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/\n",
      "INFO:root:Using train/test/val splits from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/practice_id_splits.pickle\n",
      "INFO:root:Writing train split into a DL friendly .parquet dataset.\n",
      " 82%|████████▏ | 1089/1330 [6:16:06<1:37:30, 24.28s/it]"
     ]
    }
   ],
   "source": [
    "# Build \n",
    "dm = FoundationalDataModule(path_to_db=cfg.data.path_to_db,\n",
    "                            path_to_ds=cfg.data.path_to_ds,\n",
    "                            load=False,\n",
    "                            include_diagnoses=True,                            \n",
    "                            include_measurements=True,\n",
    "                            drop_missing_data=False,\n",
    "                            drop_empty_dynamic=True,\n",
    "                            tokenizer=\"tabular\",\n",
    "                            overwrite_practice_ids = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/practice_id_splits.pickle\",\n",
    "                            overwrite_meta_information=cfg.data.meta_information_path,\n",
    "                            study_inclusion_method=cvd_inclusion_method,\n",
    "                           )\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "\n",
    "print(f\"{len(dm.train_set)} training patients\")\n",
    "print(f\"{len(dm.val_set)} validation patients\")\n",
    "print(f\"{len(dm.test_set)} test patients\")\n",
    "print(f\"{vocab_size} vocab elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d2a6c-39e8-4f1e-bcb2-057fa0cabad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(200)\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "print(dm.train_set.tokenizer._event_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ae8d6-7899-4f89-ab4a-ff753c1fa9ba",
   "metadata": {},
   "source": [
    "# Test data loading times (so we can optimise cpu usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0164d4-9829-451e-a169-55569f4aaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "dataset1 = pq.ParquetDataset(path_to_db + \"polars/split=train/\", \n",
    "                            filters=[('PRACTICE_ID','=','p20763')]\n",
    "                            )\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()   # starting time\n",
    "df  = dataset1.read().to_pandas()\n",
    "df = df[df[\"row_nr\"] == 100]\n",
    "print(df)\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bdc9021-702c-4b5f-a77b-6a49eac7e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2044/23343104 [01:24<269:23:50, 24.07it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "times = []\n",
    "start = time.time()   # starting time\n",
    "for row_idx, row in enumerate(tqdm(dm.train_set)):\n",
    "    # print(f\"Sample loaded in {time.time()-start} seconds\")\n",
    "    times.append(time.time()-start)\n",
    "    start = time.time()\n",
    "    if row_idx > 1e4:\n",
    "        break\n",
    "print(np.mean(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9a9ee3b-bb5f-4272-94b9-40833d71384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/364736 [00:31<808:15:55,  7.98s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "start = time.time()   # starting time\n",
    "for batch_idx, batch in enumerate(tqdm(dm.train_dataloader())):\n",
    "    # print(f\"batch loaded in {time.time()-start} seconds\")    \n",
    "    times.append(time.time()-start)\n",
    "    start = time.time()\n",
    "    if batch_idx > 1e4:\n",
    "        break\n",
    "print(np.mean(times))\n",
    "\n",
    "# for key in batch.keys():\n",
    "#     print(f\"{key}\".ljust(20) + f\"{batch[key].shape}\")\n",
    "\n",
    "# tokens = batch[\"tokens\"][0].tolist()    \n",
    "# sentence = dm.decode(tokens).split(\" \")\n",
    "# for token, value in zip(sentence, batch[\"values\"][0].tolist()):\n",
    "#     print(f\"{token}:\".ljust(40) + f\"{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46573a7f-6131-4f27-9877-feb27cc60789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to retrieve sample index 1236 was 0.02561783790588379 seconds\n",
      "\n",
      "SEX                 | F\n",
      "IMD                 | 4.0\n",
      "ETHNICITY           | ASIAN\n",
      "birth_year          | 2013.0\n",
      "\n",
      "Token                                                                      | Age               | Standardised value\n",
      "===================================================================================================================\n",
      "O_E___height_1                                                             | 47                | nan               \n",
      "O_E___weight_2                                                             | 47                | nan               \n",
      "O_E___weight_2                                                             | 1468              | nan               \n",
      "Body_mass_index_3                                                          | 1503              | -0.39             \n",
      "O_E___height_1                                                             | 1503              | nan               \n",
      "O_E___weight_2                                                             | 1503              | nan               \n",
      "GFR_calculated_abbreviated_MDRD_34                                         | 1520              | nan               \n",
      "Serum_TSH_level_71                                                         | 1520              | -0.02             \n",
      "Serum_alanine_aminotransferase_level_45                                    | 1520              | nan               \n",
      "Serum_albumin_51                                                           | 1520              | -0.04             \n",
      "Serum_creatinine_31                                                        | 1520              | -0.44             \n",
      "Serum_free_T4_level_75                                                     | 1520              | 0.13              \n"
     ]
    }
   ],
   "source": [
    "dm.train_set.view_sample(1236, max_dynamic_events=12, report_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb3df6-37e5-4e8e-9a4e-3b4fb709a586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
