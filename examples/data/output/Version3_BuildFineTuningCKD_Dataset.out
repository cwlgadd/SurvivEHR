GCCcore/11.3.0
zlib/1.2.12-GCCcore-11.3.0
binutils/2.38-GCCcore-11.3.0
GCC/11.3.0
numactl/2.0.14-GCCcore-11.3.0
XZ/5.2.5-GCCcore-11.3.0
libxml2/2.9.13-GCCcore-11.3.0
libpciaccess/0.16-GCCcore-11.3.0
hwloc/2.7.1-GCCcore-11.3.0
OpenSSL/1.1
libevent/2.1.12-GCCcore-11.3.0
UCX/1.12.1-GCCcore-11.3.0
libfabric/1.15.1-GCCcore-11.3.0
PMIx/4.1.2-GCCcore-11.3.0
UCC/1.0.0-GCCcore-11.3.0
OpenMPI/4.1.4-GCC-11.3.0
OpenBLAS/0.3.20-GCC-11.3.0
FlexiBLAS/3.2.0-GCC-11.3.0
FFTW/3.3.10-GCC-11.3.0
gompi/2022a
FFTW.MPI/3.3.10-gompi-2022a
ScaLAPACK/2.2.0-gompi-2022a-fb
foss/2022a
CUDA/11.7.0
bzip2/1.0.8-GCCcore-11.3.0
ncurses/6.3-GCCcore-11.3.0
libreadline/8.1.2-GCCcore-11.3.0
ncurses/6.3-GCCcore-11.3.0
Tcl/8.6.12-GCCcore-11.3.0
SQLite/3.38.3-GCCcore-11.3.0
GMP/6.2.1-GCCcore-11.3.0
libffi/3.4.2-GCCcore-11.3.0
Python/3.10.4-GCCcore-11.3.0
pybind11/2.9.2-GCCcore-11.3.0
SciPy-bundle/2022.05-foss-2022a
libyaml/0.2.5-GCCcore-11.3.0
PyYAML/6.0-GCCcore-11.3.0
Ninja/1.10.2-GCCcore-11.3.0
protobuf/3.19.4-GCCcore-11.3.0
protobuf-python/3.19.4-GCCcore-11.3.0
MPFR/4.1.0-GCCcore-11.3.0
slurmstepd: error: *** JOB 14421470 ON bear-pg0208u31a CANCELLED AT 2024-10-29T10:59:37 ***
GCCcore/11.3.0
zlib/1.2.12-GCCcore-11.3.0
binutils/2.38-GCCcore-11.3.0
GCC/11.3.0
numactl/2.0.14-GCCcore-11.3.0
XZ/5.2.5-GCCcore-11.3.0
libxml2/2.9.13-GCCcore-11.3.0
libpciaccess/0.16-GCCcore-11.3.0
hwloc/2.7.1-GCCcore-11.3.0
OpenSSL/1.1
libevent/2.1.12-GCCcore-11.3.0
UCX/1.12.1-GCCcore-11.3.0
libfabric/1.15.1-GCCcore-11.3.0
PMIx/4.1.2-GCCcore-11.3.0
UCC/1.0.0-GCCcore-11.3.0
OpenMPI/4.1.4-GCC-11.3.0
OpenBLAS/0.3.20-GCC-11.3.0
FlexiBLAS/3.2.0-GCC-11.3.0
FFTW/3.3.10-GCC-11.3.0
gompi/2022a
FFTW.MPI/3.3.10-gompi-2022a
ScaLAPACK/2.2.0-gompi-2022a-fb
foss/2022a
CUDA/11.7.0
bzip2/1.0.8-GCCcore-11.3.0
ncurses/6.3-GCCcore-11.3.0
libreadline/8.1.2-GCCcore-11.3.0
ncurses/6.3-GCCcore-11.3.0
Tcl/8.6.12-GCCcore-11.3.0
SQLite/3.38.3-GCCcore-11.3.0
GMP/6.2.1-GCCcore-11.3.0
libffi/3.4.2-GCCcore-11.3.0
Python/3.10.4-GCCcore-11.3.0
pybind11/2.9.2-GCCcore-11.3.0
SciPy-bundle/2022.05-foss-2022a
libyaml/0.2.5-GCCcore-11.3.0
PyYAML/6.0-GCCcore-11.3.0
Ninja/1.10.2-GCCcore-11.3.0
protobuf/3.19.4-GCCcore-11.3.0
protobuf-python/3.19.4-GCCcore-11.3.0
MPFR/4.1.0-GCCcore-11.3.0
NASM/2.15.05-GCCcore-11.3.0
x264/20220620-GCCcore-11.3.0
LAME/3.100-GCCcore-11.3.0
x265/3.5-GCCcore-11.3.0
expat/2.4.8-GCCcore-11.3.0
libpng/1.6.37-GCCcore-11.3.0
Brotli/1.0.9-GCCcore-11.3.0
freetype/2.12.1-GCCcore-11.3.0
util-linux/2.38-GCCcore-11.3.0
fontconfig/2.14.0-GCCcore-11.3.0
freetype/2.12.1-GCCcore-11.3.0
xorg-macros/1.19.3-GCCcore-11.3.0
X11/20220504-GCCcore-11.3.0
freetype/2.12.1-GCCcore-11.3.0
fontconfig/2.14.0-GCCcore-11.3.0
FriBidi/1.0.12-GCCcore-11.3.0
FFmpeg/4.4.2-GCCcore-11.3.0
libjpeg-turbo/2.1.3-GCCcore-11.3.0
jbigkit/2.1-GCCcore-11.3.0
gzip/1.12-GCCcore-11.3.0
lz4/1.9.3-GCCcore-11.3.0
zstd/1.5.2-GCCcore-11.3.0
libdeflate/1.10-GCCcore-11.3.0
LibTIFF/4.3.0-GCCcore-11.3.0
Pillow/9.1.1-GCCcore-11.3.0
cuDNN/8.4.1.50-CUDA-11.7.0
GDRCopy/2.3-GCCcore-11.3.0
UCX-CUDA/1.12.1-GCCcore-11.3.0-CUDA-11.7.0
magma/2.6.2-foss-2022a-CUDA-11.7.0
NCCL/2.12.12-GCCcore-11.3.0-CUDA-11.7.0
expecttest/0.1.3-GCCcore-11.3.0
PyTorch/1.12.1-foss-2022a-CUDA-11.7.0
tqdm/4.64.0-GCCcore-11.3.0
Transformers/4.24.0-foss-2022a-CUDA-11.7.0
ICU/71.1-GCCcore-11.3.0
Boost/1.79.0-GCC-11.3.0
snappy/1.1.9-GCCcore-11.3.0
RapidJSON/1.1.0-GCCcore-11.3.0
RE2/2022-06-01-GCCcore-11.3.0
utf8proc/2.7.0-GCCcore-11.3.0
Arrow/8.0.0-foss-2022a
Tk/8.6.12-GCCcore-11.3.0
Tkinter/3.10.4-GCCcore-11.3.0
Qhull/2020.2-GCCcore-11.3.0
matplotlib/3.5.2-foss-2022a
polars/0.17.12-foss-2022a
poetry/1.2.2-GCCcore-11.3.0
aiohttp/3.8.3-GCCcore-11.3.0
BeautifulSoup/4.10.0-GCCcore-11.3.0
deepdiff/5.8.1-GCCcore-11.3.0
tensorboardX/2.5.1-foss-2022a
PyTorch-Lightning/1.9.3-foss-2022a-CUDA-11.7.0
Hydra/1.3.2-GCCcore-11.3.0
scikit-learn/1.1.2-foss-2022a
sklearn-pandas/2.2.0-foss-2022a
/rds/projects/g/gokhalkm-optimal/DataforCharles
/rds/projects/g/gokhalkm-optimal/DataforCharles
dumb
icelake
/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake
Build CVD fine-tuning dataset from CPRD.db database from Version 3 of DeXTER output
INFO:root:Building study dataset on 72 CPUs and 1 GPUs
INFO:root:Creating unsupervised collator for DataModule
INFO:root:Building Polars datasets and saving to /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CKD/
INFO:root:Using train/test/val splits from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/practice_id_splits.pickle
INFO:root:Writing test split into a DL friendly .parquet dataset.
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  7.5min
[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  8.6min
[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed: 11.4min
[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 17.3min
[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 23.7min
[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 27.0min
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 36.7min
[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 50.8min
[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 58.1min
[Parallel(n_jobs=3)]: Done  74 out of  74 | elapsed: 59.0min finished
INFO:root:Creating file_row_count_dicts for file-index look-ups
Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages' at start of search paths.
Using device: cuda.
Fitting dataset over 3 threads
is_decoder: true
data:
  batch_size: 64
  unk_freq_threshold: 0.0
  min_workers: 20
  global_diagnoses: false
  path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/
  path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CKD/
  meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle
experiment:
  type: pre-train
  project_name: SurvEHR_${head.SurvLayer}
  run_id: PreTrain_${head.SurvLayer}_11M_${experiment.seed}
  fine_tune_id: null
  train: true
  test: true
  verbose: true
  seed: 1337
  log: true
  log_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/
  ckpt_dir: /rds/projects/s/subramaa-mum-predict/CharlesGadd_Oxford/FoundationModelOutput/checkpoints/
  fine_tune_outcomes: null
optim:
  num_epochs: 5
  learning_rate: 0.0003
  scheduler_warmup: true
  scheduler: CAWarmRestarts
  scheduler_periods: 10000
  learning_rate_decay: 0.8
  val_check_interval: 1000
  early_stop: true
  early_stop_patience: 30
  log_every_n_steps: 20
  limit_val_batches: 0.025
  limit_test_batches: 0.025
transformer:
  block_type: Neo
  block_size: 256
  n_layer: 6
  n_head: 6
  n_embd: 384
  layer_norm_bias: false
  attention_type: global
  bias: true
  dropout: 0.0
  attention_dropout: 0.0
  resid_dropout: 0.0
  private_heads: 0
head:
  SurvLayer: cr
  surv_weight: 0.5
  tokens_for_univariate_regression: None
  value_weight: 0.5

Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 0it [00:00, ?it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 1it [00:00,  7.62it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 7it [00:00, 34.70it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 15it [00:00, 52.77it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 24it [00:00, 63.23it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 31it [00:00, 63.12it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 38it [00:00, 62.45it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 48it [00:00, 72.85it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 56it [00:00, 72.15it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 65it [00:01, 75.05it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 73it [00:01, 64.97it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 80it [00:01, 64.71it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 88it [00:01, 67.71it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 98it [00:01, 74.56it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 106it [00:01, 72.44it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 118it [00:01, 78.62it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 126it [00:01, 70.77it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 134it [00:02, 66.62it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 142it [00:02, 69.61it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 154it [00:02, 82.43it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 166it [00:02, 88.81it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 178it [00:02, 96.59it/s]Getting file row counts. This allows the creation of an index to file map, increasing read efficiency: 180it [00:02, 73.12it/s]
INFO:root:	 Obtained with a total of 35758 samples
INFO:root:Writing train split into a DL friendly .parquet dataset.
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  4.0min
[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:  5.3min
[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:  8.7min
[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 13.9min
[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed: 17.9min
[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed: 23.2min
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 35.6min
[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed: 41.2min
[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed: 50.2min
[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed: 58.3min
[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed: 72.1min
[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed: 84.4min
[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 96.1min
[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed: 107.7min
[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 120.3min
[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed: 133.0min
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed: 148.9min
[Parallel(n_jobs=3)]: Done 215 tasks      | elapsed: 162.0min
[Parallel(n_jobs=3)]: Done 236 tasks      | elapsed: 172.6min
[Parallel(n_jobs=3)]: Done 259 tasks      | elapsed: 184.0min
[Parallel(n_jobs=3)]: Done 282 tasks      | elapsed: 192.3min
[Parallel(n_jobs=3)]: Done 307 tasks      | elapsed: 200.4min
[Parallel(n_jobs=3)]: Done 332 tasks      | elapsed: 213.7min
[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed: 230.4min
[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed: 254.2min
[Parallel(n_jobs=3)]: Done 415 tasks      | elapsed: 266.5min
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed: 285.5min
[Parallel(n_jobs=3)]: Done 475 tasks      | elapsed: 298.8min
[Parallel(n_jobs=3)]: Done 506 tasks      | elapsed: 314.3min
[Parallel(n_jobs=3)]: Done 539 tasks      | elapsed: 328.1min
[Parallel(n_jobs=3)]: Done 572 tasks      | elapsed: 338.7min
[Parallel(n_jobs=3)]: Done 607 tasks      | elapsed: 346.8min
[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed: 356.3min
[Parallel(n_jobs=3)]: Done 679 tasks      | elapsed: 366.8min
Exception in thread Thread-13 (_handle_results):
Traceback (most recent call last):
  File "/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/threading.py", line 1009, in _bootstrap_inner
    self.run()
  File "/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/threading.py", line 946, in run
    self._target(*self._args, **self._kwargs)
  File "/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/multiprocessing/pool.py", line 592, in _handle_results
    cache[job]._set(i, obj)
  File "/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/multiprocessing/pool.py", line 776, in _set
    self._callback(self._value)
  File "/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages/joblib/parallel.py", line 814, in __call__
    self._dispatch_new()
  File "/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages/joblib/parallel.py", line 829, in _dispatch_new
    self.parallel.dispatch_next()
  File "/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages/joblib/parallel.py", line 1395, in dispatch_next
    if not self.dispatch_one_batch(self._original_iterator):
  File "/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/dataset_polars.py", line 225, in <genexpr>
    Parallel(n_jobs=num_threads, prefer="threads", verbose=10)(delayed(self._write_lazy_to_parquet_dl)(lazy_table_frames_dict,
  File "/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/collector.py", line 194, in _generate_lazy_by_distinct
    df = pl.read_database(query=query, connection_uri='sqlite://' + self.db_path)
  File "/rds/bear-apps/2022a/EL8-ice/software/polars/0.17.12-foss-2022a/lib/python3.10/site-packages/polars/io/database.py", line 95, in read_database
    return _read_sql_connectorx(
  File "/rds/bear-apps/2022a/EL8-ice/software/polars/0.17.12-foss-2022a/lib/python3.10/site-packages/polars/io/database.py", line 222, in _read_sql_connectorx
    tbl = cx.read_sql(
  File "/rds/bear-apps/2022a/EL8-ice/software/polars/0.17.12-foss-2022a/lib/python3.10/site-packages/connectorx/__init__.py", line 257, in read_sql
    result = _read_sql(
RuntimeError: timed out waiting for connection
slurmstepd: error: *** JOB 14433225 ON bear-pg0208u31a CANCELLED AT 2024-10-30T04:30:47 DUE TO TIME LIMIT ***
GCCcore/11.3.0
zlib/1.2.12-GCCcore-11.3.0
binutils/2.38-GCCcore-11.3.0
GCC/11.3.0
numactl/2.0.14-GCCcore-11.3.0
XZ/5.2.5-GCCcore-11.3.0
libxml2/2.9.13-GCCcore-11.3.0
libpciaccess/0.16-GCCcore-11.3.0
hwloc/2.7.1-GCCcore-11.3.0
OpenSSL/1.1
libevent/2.1.12-GCCcore-11.3.0
UCX/1.12.1-GCCcore-11.3.0
libfabric/1.15.1-GCCcore-11.3.0
PMIx/4.1.2-GCCcore-11.3.0
UCC/1.0.0-GCCcore-11.3.0
OpenMPI/4.1.4-GCC-11.3.0
OpenBLAS/0.3.20-GCC-11.3.0
FlexiBLAS/3.2.0-GCC-11.3.0
FFTW/3.3.10-GCC-11.3.0
gompi/2022a
FFTW.MPI/3.3.10-gompi-2022a
ScaLAPACK/2.2.0-gompi-2022a-fb
foss/2022a
CUDA/11.7.0
bzip2/1.0.8-GCCcore-11.3.0
ncurses/6.3-GCCcore-11.3.0
libreadline/8.1.2-GCCcore-11.3.0
ncurses/6.3-GCCcore-11.3.0
Tcl/8.6.12-GCCcore-11.3.0
SQLite/3.38.3-GCCcore-11.3.0
GMP/6.2.1-GCCcore-11.3.0
libffi/3.4.2-GCCcore-11.3.0
Python/3.10.4-GCCcore-11.3.0
pybind11/2.9.2-GCCcore-11.3.0
SciPy-bundle/2022.05-foss-2022a
libyaml/0.2.5-GCCcore-11.3.0
PyYAML/6.0-GCCcore-11.3.0
Ninja/1.10.2-GCCcore-11.3.0
protobuf/3.19.4-GCCcore-11.3.0
protobuf-python/3.19.4-GCCcore-11.3.0
MPFR/4.1.0-GCCcore-11.3.0
NASM/2.15.05-GCCcore-11.3.0
x264/20220620-GCCcore-11.3.0
LAME/3.100-GCCcore-11.3.0
x265/3.5-GCCcore-11.3.0
expat/2.4.8-GCCcore-11.3.0
libpng/1.6.37-GCCcore-11.3.0
Brotli/1.0.9-GCCcore-11.3.0
freetype/2.12.1-GCCcore-11.3.0
util-linux/2.38-GCCcore-11.3.0
fontconfig/2.14.0-GCCcore-11.3.0
freetype/2.12.1-GCCcore-11.3.0
xorg-macros/1.19.3-GCCcore-11.3.0
X11/20220504-GCCcore-11.3.0
freetype/2.12.1-GCCcore-11.3.0
fontconfig/2.14.0-GCCcore-11.3.0
FriBidi/1.0.12-GCCcore-11.3.0
FFmpeg/4.4.2-GCCcore-11.3.0
libjpeg-turbo/2.1.3-GCCcore-11.3.0
jbigkit/2.1-GCCcore-11.3.0
gzip/1.12-GCCcore-11.3.0
lz4/1.9.3-GCCcore-11.3.0
zstd/1.5.2-GCCcore-11.3.0
libdeflate/1.10-GCCcore-11.3.0
LibTIFF/4.3.0-GCCcore-11.3.0
Pillow/9.1.1-GCCcore-11.3.0
cuDNN/8.4.1.50-CUDA-11.7.0
GDRCopy/2.3-GCCcore-11.3.0
UCX-CUDA/1.12.1-GCCcore-11.3.0-CUDA-11.7.0
magma/2.6.2-foss-2022a-CUDA-11.7.0
NCCL/2.12.12-GCCcore-11.3.0-CUDA-11.7.0
expecttest/0.1.3-GCCcore-11.3.0
PyTorch/1.12.1-foss-2022a-CUDA-11.7.0
tqdm/4.64.0-GCCcore-11.3.0
Transformers/4.24.0-foss-2022a-CUDA-11.7.0
ICU/71.1-GCCcore-11.3.0
Boost/1.79.0-GCC-11.3.0
snappy/1.1.9-GCCcore-11.3.0
RapidJSON/1.1.0-GCCcore-11.3.0
RE2/2022-06-01-GCCcore-11.3.0
utf8proc/2.7.0-GCCcore-11.3.0
Arrow/8.0.0-foss-2022a
Tk/8.6.12-GCCcore-11.3.0
Tkinter/3.10.4-GCCcore-11.3.0
Qhull/2020.2-GCCcore-11.3.0
matplotlib/3.5.2-foss-2022a
polars/0.17.12-foss-2022a
poetry/1.2.2-GCCcore-11.3.0
aiohttp/3.8.3-GCCcore-11.3.0
BeautifulSoup/4.10.0-GCCcore-11.3.0
deepdiff/5.8.1-GCCcore-11.3.0
tensorboardX/2.5.1-foss-2022a
PyTorch-Lightning/1.9.3-foss-2022a-CUDA-11.7.0
Hydra/1.3.2-GCCcore-11.3.0
scikit-learn/1.1.2-foss-2022a
sklearn-pandas/2.2.0-foss-2022a
/rds/projects/g/gokhalkm-optimal/DataforCharles
/rds/projects/g/gokhalkm-optimal/DataforCharles
dumb
icelake
/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake
Build CVD fine-tuning dataset from CPRD.db database from Version 3 of DeXTER output
INFO:root:Building study dataset on 72 CPUs and 1 GPUs
INFO:root:Creating unsupervised collator for DataModule
INFO:root:Building Polars datasets and saving to /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_BPpostHypertension/
INFO:root:Using train/test/val splits from /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/practice_id_splits.pickle
INFO:root:Writing test split into a DL friendly .parquet dataset.
[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.
Exception in thread Thread-13 (_handle_results):
Traceback (most recent call last):
  File "/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/threading.py", line 1009, in _bootstrap_inner
    self.run()
  File "/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/threading.py", line 946, in run
    self._target(*self._args, **self._kwargs)
  File "/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/multiprocessing/pool.py", line 592, in _handle_results
    cache[job]._set(i, obj)
  File "/rds/bear-apps/2022a/EL8-ice/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/multiprocessing/pool.py", line 776, in _set
    self._callback(self._value)
  File "/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages/joblib/parallel.py", line 814, in __call__
    self._dispatch_new()
  File "/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages/joblib/parallel.py", line 829, in _dispatch_new
    self.parallel.dispatch_next()
  File "/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages/joblib/parallel.py", line 1395, in dispatch_next
    if not self.dispatch_one_batch(self._original_iterator):
  File "/rds/homes/g/gaddcz/Projects/CPRD/virtual-env-icelake/lib/python3.10/site-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/dataset_polars.py", line 225, in <genexpr>
    Parallel(n_jobs=num_threads, prefer="threads", verbose=10)(delayed(self._write_lazy_to_parquet_dl)(lazy_table_frames_dict,
  File "/rds/homes/g/gaddcz/Projects/CPRD/data/dataset/collector.py", line 202, in _generate_lazy_by_distinct
    pandas_df = pd.read_sql_query(query, self.connection)
  File "/rds/bear-apps/2022a/EL8-ice/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/io/sql.py", line 399, in read_sql_query
    return pandas_sql.read_query(
  File "/rds/bear-apps/2022a/EL8-ice/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/io/sql.py", line 2080, in read_query
    cursor = self.execute(*args)
  File "/rds/bear-apps/2022a/EL8-ice/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in execute
    cur = self.con.cursor()
sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139751824354176 and this is thread id 139743123732224.
slurmstepd: error: *** JOB 15531055 ON bear-pg0208u35a CANCELLED AT 2024-11-29T11:49:00 ***
