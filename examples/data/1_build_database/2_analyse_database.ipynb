{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece5a676-6298-4645-8292-27b819154d2d",
   "metadata": {},
   "source": [
    "# Analyse the SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dbac65e-ba6c-4eb8-aeb0-4b23c0856e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/data/1_build_database\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cae725-1c84-4562-b96f-d1dfcb2af4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from FastEHR.database.collector import SQLiteDataCollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ae185a-ad13-4306-a131-4566a66727bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 64\n",
      "unk_freq_threshold: 0.0\n",
      "min_workers: 12\n",
      "global_diagnoses: false\n",
      "repeating_events: true\n",
      "path_to_db: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/cprd.db\n",
      "path_to_ds: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/\n",
      "meta_information_path: /rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/meta_information_QuantJenny.pickle\n",
      "subsample_training: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the configuration file\n",
    "with initialize(version_base=None, config_path=\"../../modelling/SurvivEHR/confs\", job_name=\"testing_notebook\"):\n",
    "    cfg = compose(config_name=\"config_CompetingRisk11M\", overrides=[])\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc337802-0fe8-4a21-8ee2-99df7dcb0539",
   "metadata": {},
   "source": [
    "# Initialise connector to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2621eb7a-2eff-42d0-bc7f-346b93e6f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SQLiteDataCollector(db_path=cfg.data.path_to_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19536922-4fa5-47c0-ae40-e44bed5e44da",
   "metadata": {},
   "source": [
    "## Reminder of what the ``static_table`` looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96fdd1c4-7dd4-4e17-bde3-a09344e841bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20960, 2595705420960, 'WHITE', '1994-07-15', 'M', 'E', 1, 'North West', '2017-09-12', '2017-09-12', '2020-02-13')\n",
      "(20960, 2595768620960, 'WHITE', '1961-07-15', 'M', 'E', 1, 'North West', '2005-01-01', '2005-01-01', '2022-02-22')\n",
      "(20960, 2595914820960, 'WHITE', '1975-07-15', 'M', 'E', 1, 'North West', '2018-01-31', '2018-01-31', '2019-09-09')\n",
      "(20960, 2595926220960, 'WHITE', '1937-07-15', 'M', 'E', 1, 'North West', '2005-01-01', '2005-01-01', '2009-08-25')\n",
      "(20960, 2596034820960, 'WHITE', '1987-07-15', 'M', 'E', 1, 'North West', '2016-02-24', '2016-02-24', '2019-01-30')\n",
      "(20960, 2596039620960, 'WHITE', '1945-07-15', 'M', 'E', 1, 'North West', '2005-01-01', '2005-01-01', '2018-09-28')\n",
      "(20960, 2596131020960, 'WHITE', '1980-07-15', 'M', 'E', 1, 'North West', '2012-08-16', '2012-08-16', '2022-02-22')\n",
      "(20960, 2596183720960, 'WHITE', '1988-07-15', 'M', 'E', 1, 'North West', '2005-01-01', '2005-01-01', '2022-02-22')\n",
      "(21011, 2723778021011, 'MISSING', '1971-07-15', 'M', 'E', 1, 'London', '2005-01-01', '2005-01-01', '2011-03-07')\n",
      "(21011, 2804288021011, 'MISSING', '2018-12-15', 'M', 'E', 1, 'London', '2020-01-08', '2020-01-08', '2022-03-17')\n"
     ]
    }
   ],
   "source": [
    "collector.connect()\n",
    "\n",
    "collector.cursor.execute(\"\"\"SELECT * FROM static_table WHERE sex=='M' AND imd=='1' LIMIT 10\"\"\")   # \n",
    "results = collector.cursor.fetchall()\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "collector.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7d5af9-c9fa-4494-98e3-432a445b8bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'PRACTICE_ID', 'INTEGER', 0, None, 0)\n",
      "(1, 'PATIENT_ID', 'INTEGER', 0, None, 0)\n",
      "(2, 'ETHNICITY', 'TEXT', 0, None, 0)\n",
      "(3, 'YEAR_OF_BIRTH', 'TEXT', 0, None, 0)\n",
      "(4, 'SEX', 'TEXT', 0, None, 0)\n",
      "(5, 'COUNTRY', 'TEXT', 0, None, 0)\n",
      "(6, 'IMD', 'INTEGER', 0, None, 0)\n",
      "(7, 'HEALTH_AUTH', 'TEXT', 0, None, 0)\n",
      "(8, 'INDEX_DATE', 'TEXT', 0, None, 0)\n",
      "(9, 'START_DATE', 'TEXT', 0, None, 0)\n",
      "(10, 'END_DATE', 'TEXT', 0, None, 0)\n"
     ]
    }
   ],
   "source": [
    "collector.connect()\n",
    "\n",
    "collector.cursor.execute(\"\"\"PRAGMA table_info(static_table);\"\"\") \n",
    "results = collector.cursor.fetchall()\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "collector.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c189af-f96a-4a2a-b536-4cade21a0847",
   "metadata": {},
   "source": [
    "## Make figures of the demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "862badab-211d-4c57-abc9-65b25518fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pie_chart(df, col_lbl, sort_by=\"values\"):\n",
    "    \n",
    "    # ── handle labels ────────────────────────────────────────────────────────\n",
    "    if df[\"labels\"].dtype == np.float64:   \n",
    "        # Numerical categories\n",
    "        df = (\n",
    "            df.fillna(0)              # 1. give every NaN a harmless temporary value\n",
    "              .astype(int)            # 2. fast C-level cast floats → ints\n",
    "              .mask(df.isna(), \"Missing\")   # 3. restore the NaN positions as \"Missing\"\n",
    "        )\n",
    "    else:\n",
    "        # String categories\n",
    "        df = df.mask(df.isna(), \"Missing\")  \n",
    "        \n",
    "        mask = df[\"labels\"].str.isupper()          # rows where the label is ALL CAPS\n",
    "        df.loc[mask, \"labels\"] = df.loc[mask, \"labels\"].str.capitalize()\n",
    "\n",
    "    # Sort order labels will apear in the legend\n",
    "    priority = {\"Other\": 1, \"Missing\": 2}                            # lower = earlier\n",
    "    df = (df.assign(_p=df[\"labels\"].map(priority).fillna(0))         # 0 for all others\n",
    "             .sort_values([\"_p\", sort_by], ascending=[True, False if sort_by == \"values\" else True],  # or add \"labels\"\n",
    "                          ignore_index=True)\n",
    "             .drop(columns=\"_p\"))\n",
    "    \n",
    "    # ── seaborn style & colour palette ────────────────────────────────────────\n",
    "    # sns.set_theme(style=\"white\")                     # clean, publication-ready\n",
    "    # palette = sns.color_palette(\"pastel\", len(df))   # gentle pastel colours\n",
    "\n",
    "    # ── pie chart ─────────────────────────────────────────────────────────────\n",
    "    fig, ax = plt.subplots(figsize=(3.5/0.78, 3.5), dpi=300) \n",
    "    fig.subplots_adjust(right=0.78)   # reserve the right 22 % for the legend\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        df[\"values\"],\n",
    "        labels=None,                # legend instead of on-slice labels\n",
    "        # colors=palette,\n",
    "        autopct=lambda pct: \"\" if pct < 1 else f\"{pct:.0f}%\",  # hide <1 %,\n",
    "        pctdistance=1.2,            # pull % into the slice\n",
    "        startangle=90,              # rotate so first slice starts at 12 o’clock\n",
    "        counterclock=False,\n",
    "        wedgeprops=dict(linewidth=1, edgecolor=\"white\")  # thin slice borders\n",
    "    )\n",
    "\n",
    "    # ── legend (append “(<1%)” where we removed the label) ────────────────────\n",
    "    total = df[\"values\"].sum()\n",
    "    pct = df[\"values\"] / total * 100\n",
    "    legend_labels = [\n",
    "        f\"{lab} (<1%)\" if p < 1 else lab\n",
    "        for lab, p in zip(df[\"labels\"], pct)\n",
    "    ]\n",
    "            \n",
    "    ax.legend(wedges, \n",
    "              legend_labels,\n",
    "              title=col_lbl,\n",
    "              loc=\"center left\",\n",
    "              bbox_to_anchor=(1.02, 0.5),\n",
    "              frameon=False)\n",
    "    ax.set(aspect=\"equal\") #, title=\"Birth-Decade Distribution\")\n",
    "    sns.despine(left=True, bottom=True)  # clean up spines\n",
    "    \n",
    "    plt.savefig(f\"figs/pie_chart_{col_lbl}.png\", bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b779c-4463-4b19-afd1-85cc743dba01",
   "metadata": {},
   "source": [
    "### Categorical columns of the static table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22468880-d68c-4a92-8be4-775eeaa03454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnicity\n",
      "Sex\n",
      "Country\n",
      "IMD\n",
      "Health authority\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"ETHNICITY\", \"SEX\", \"COUNTRY\", \"IMD\", \"HEALTH_AUTH\"]\n",
    "column_labels = [\"Ethnicity\", \"Sex\", \"Country\", \"IMD\", \"Health authority\"]\n",
    "column_sort_by = [\"values\", \"values\", \"values\", \"labels\", \"values\"]\n",
    "\n",
    "# Create query string for any practice inclusion conditions that were applied during pre-train dataset creation\n",
    "practice_inclusion_conditions=[\"COUNTRY = 'E'\"]\n",
    "where_sql = f\"WHERE {' AND '.join(practice_inclusion_conditions)}\" \\\n",
    "            if practice_inclusion_conditions else \"\"\n",
    "\n",
    "for col_name, col_lbl, col_sort_by in zip(column_names, column_labels, column_sort_by):\n",
    "    print(col_lbl)\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT {col_name},\n",
    "           COUNT(*) AS freq\n",
    "    FROM   static_table\n",
    "    {where_sql}\n",
    "    GROUP  BY {col_name}\n",
    "    ORDER  BY freq DESC;\n",
    "    \"\"\"\n",
    "\n",
    "    collector.connect()\n",
    "    collector.cursor.execute(query) \n",
    "    results = collector.cursor.fetchall()\n",
    "    collector.disconnect()\n",
    "\n",
    "    df = pd.DataFrame(results, columns=[\"labels\", \"values\"])\n",
    "\n",
    "    make_pie_chart(df, col_lbl, sort_by=col_sort_by)\n",
    "\n",
    "    # Total number of patients fitting inclusion criteria\n",
    "    total_patients = sum([r[1] for r in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1933acd-afc2-4cff-afd4-4a0bbaa7a96f",
   "metadata": {},
   "source": [
    "### Continuous year of birth column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c7cdf4b-84d0-4aea-91d1-419ad7d92d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1890\n",
      "2021\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    MIN(YEAR_OF_BIRTH) AS smallest_value,\n",
    "    MAX(YEAR_OF_BIRTH) AS largest_value\n",
    "FROM   static_table;\n",
    "\"\"\"\n",
    "collector.connect()\n",
    "collector.cursor.execute(query) \n",
    "results = collector.cursor.fetchall()\n",
    "collector.disconnect()\n",
    "\n",
    "min_yob = results[0][0][:4]\n",
    "max_yob = results[0][1][:4]\n",
    "print(min_yob)\n",
    "print(max_yob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9d5477c-b7c0-4de2-84f4-ad4feea23c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 25\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT (CAST(strftime('%Y', YEAR_OF_BIRTH) AS INT) / {chunk_size}) * {chunk_size} AS chunk_start,\n",
    "           COUNT(*) AS freq\n",
    "    FROM   static_table\n",
    "    {where_sql}\n",
    "    GROUP BY chunk_start\n",
    "    ORDER BY chunk_start;\n",
    "\"\"\"\n",
    "\n",
    "collector.connect()\n",
    "collector.cursor.execute(query) \n",
    "results = collector.cursor.fetchall()\n",
    "collector.disconnect()\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"chunk_start\", \"values\"])\n",
    "df[\"chunk_end\"] = df[\"chunk_start\"] + chunk_size - 1\n",
    "\n",
    "# Combine first and second chunk\n",
    "df.loc[df.index[1], \"values\"] = df.loc[df.index[0], \"values\"] + df.loc[df.index[1], \"values\"]\n",
    "df = df.iloc[1:].reset_index(drop=True)  # keep all but the first row\n",
    "\n",
    "# update start and end points of first and last bins then make labels\n",
    "df.loc[df.index[0], \"chunk_start\"] = min_yob\n",
    "df.loc[df.index[-1], \"chunk_end\"] = max_yob\n",
    "\n",
    "df[\"labels\"] = df[\"chunk_start\"].astype(str) + \"-\" + df[\"chunk_end\"].astype(str) \n",
    "\n",
    "make_pie_chart(df, \"Birth period\", sort_by=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9746915-40e0-4f91-9734-497eeb9e916d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d6ae8-1d74-4b79-ad82-af629fa82aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
