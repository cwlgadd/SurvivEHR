{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f58899f-4329-4fff-b4cb-cf80a4e7a4e4",
   "metadata": {},
   "source": [
    "# Creating the parquet dataset from SQLite tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c70662-7dcf-4a1f-a343-8afd16a58be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/CPRD/examples/data/2_build_pre_training_dataset\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/CPRD/virtual-envTorch2.0-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f229a9ea-a77b-45ea-b5db-da34e291ccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "from FastEHR.dataloader.foundational_loader import FoundationalDataModule\n",
    "from CPRD.examples.data.map_to_reduced_names import convert_event_names, EVENT_NAME_SHORT_MAP, EVENT_NAME_LONG_MAP\n",
    "\n",
    "pl.Config.set_tbl_rows(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff00f74b-f1a5-43d3-8e28-6c302d43b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DB = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/cprd.db\"\n",
    "PATH_TO_DS = \"/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/PreTrain/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef3a1eb-28b9-42b6-9edf-3a6594386cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "\n",
    "#####\n",
    "##### See ./build_dataset.py for dataset creation.\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "626b7aba-8aca-4859-b0c9-d6a58f4bcd4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23613894 training patients\n",
      "1426714 validation patients\n",
      "1508320 test patients\n",
      "265 vocab elements\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "\n",
    "dm = FoundationalDataModule(path_to_db=PATH_TO_DB,\n",
    "                            path_to_ds=PATH_TO_DS,\n",
    "                            load=True,\n",
    "                            include_diagnoses=True,\n",
    "                            include_measurements=True,\n",
    "                            drop_missing_data=False,\n",
    "                            drop_empty_dynamic=True,\n",
    "                            tokenizer=\"tabular\",\n",
    "                           )\n",
    "\n",
    "vocab_size = dm.train_set.tokenizer.vocab_size\n",
    "\n",
    "print(f\"{len(dm.train_set)} training patients\")\n",
    "print(f\"{len(dm.val_set)} validation patients\")\n",
    "print(f\"{len(dm.test_set)} test patients\")\n",
    "print(f\"{vocab_size} vocab elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be6e87cf-fa9e-40fd-bb36-1c6fe4ebfd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'static_covariates': tensor([], size=(64, 0)), 'tokens': tensor([[  3, 263,   2,  ...,   0,   0,   0],\n",
      "        [  3, 250, 264,  ...,   0,   0,   0],\n",
      "        [  3, 259, 256,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  3, 188,   2,  ...,   0,   0,   0],\n",
      "        [  3, 233,   2,  ...,   0,   0,   0],\n",
      "        [  3, 210, 126,  ...,   0,   0,   0]]), 'ages': tensor([[ 5.2899,  5.2899,  5.2899,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 4.7551,  4.7551,  4.7551,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [10.8038, 10.8038, 10.8038,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 5.4268,  5.4268,  5.4268,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0416,  0.0416,  0.0416,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.3923,  2.3923,  2.3923,  ...,  0.0000,  0.0000,  0.0000]]), 'values': tensor([[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "        [    nan,  0.0274, -0.2522,  ...,     nan,     nan,     nan],\n",
      "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [    nan, -0.3512,     nan,  ...,     nan,     nan,     nan],\n",
      "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "368968\n"
     ]
    }
   ],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    break\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633511e4-0956-430b-9825-b5acfd1af73e",
   "metadata": {},
   "source": [
    "## Get the tokenizer mapping from string to token idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a223f5-ad30-4767-8d4a-252704cc55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_name_to_idx = dm.train_set.tokenizer._stoi\n",
    "print(map_name_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81017e77-00cc-49ee-88c9-d0de18a79cee",
   "metadata": {},
   "source": [
    "# Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31988c32-e79c-476d-83cb-0f61e4621c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DEXTER produced name to long-name\n",
    "map_to_short = lambda x: EVENT_NAME_SHORT_MAP.get(x, x)\n",
    "map_to_long = lambda x: EVENT_NAME_LONG_MAP.get(x, x)\n",
    "\n",
    "# conditional formatter\n",
    "def formatter(x):\n",
    "    \"\"\"\n",
    "    • Whole number (no decimals) if x ≥ 1  \n",
    "    • Four significant figures if 0 ≤ x < 1  \n",
    "      (uses general format so 0.0001234 → '0.0001234', 1e-7 → '1.000e-07')\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"                    # keep NaNs blank\n",
    "    if np.abs(x) >= 1000:\n",
    "        return f\"{x:.2g}\"\n",
    "    if np.abs(x) >= 100:\n",
    "        return f\"{x:.0f}\"\n",
    "    if np.abs(x) >= 10:\n",
    "        return f\"{x:.1f}\"\n",
    "    if np.abs(x) >= 1:\n",
    "        return f\"{x:.2f}\"\n",
    "    if np.abs(x) >= 0.1:\n",
    "        return f\"{x:.3f}\"\n",
    "    return f\"{x:.3g}\"                # 4-sig-figs for small numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27f7bd-2e4a-4667-adbb-10133ee18346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_table(df, report_values=False):\n",
    "    \n",
    "    # Create the plotting name column\n",
    "    df.loc[:, \"Event\"] = df[\"event\"].apply(map_to_long)\n",
    "    df.loc[:, \"Event (plotting)\"] = df[\"event\"].apply(map_to_short)\n",
    "\n",
    "    df.loc[:, \"idx\"] = df[\"event\"].map(map_name_to_idx)\n",
    "\n",
    "    if report_values:\n",
    "        df[\"missing\"] = df[\"count\"] - df[\"count_obs\"]\n",
    "        columns = [\"event\",\"mean\", \"min\", \"max\", \"count\", \"missing\"]\n",
    "    else:\n",
    "        columns = [\"event\", \"count\"]\n",
    "    \n",
    "    latex_columns = df[columns]\n",
    "    fmt = {\n",
    "        \"mean\":    formatter,   # e.g. whole numbers\n",
    "        \"min\":     formatter,   # e.g. whole numbers\n",
    "        \"max\":     formatter,   # e.g. whole numbers\n",
    "        \"count\":   \"{:.0f}\".format,   # e.g. whole numbers\n",
    "        \"missing\": \"{:.0f}\".format,   # e.g. whole numbers\n",
    "    }\n",
    "    latex_code = latex_columns.to_latex(index=False, formatters=fmt)\n",
    "    print(latex_code)\n",
    "\n",
    "def get_vocab_table(df):\n",
    "    \n",
    "    # Create the plotting name column\n",
    "    df.loc[:, \"Event\"] = df[\"event\"].apply(map_to_long)\n",
    "    df.loc[:, \"Event (plotting)\"] = df[\"event\"].apply(map_to_short)\n",
    "\n",
    "    df.loc[:, \"idx\"] = df[\"event\"].map(map_name_to_idx)\n",
    "    \n",
    "    columns = [\"event\", \"Event (plotting)\", \"idx\"]\n",
    "    \n",
    "    latex_columns = df[columns]\n",
    "    latex_code = latex_columns.to_latex(index=False)\n",
    "    print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1a32f-1df7-4d9a-9699-fbd3a86ed739",
   "metadata": {},
   "source": [
    "## Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d8742a-3c1d-418a-864e-bf49fed144c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses = dm.meta_information[\"diagnosis_table\"].copy()\n",
    "\n",
    "get_stats_table(diagnoses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b78418-8e65-493b-92f0-dd5832a2467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vocab_table(diagnoses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c9845-4eb8-40d6-9cd9-04a96064debe",
   "metadata": {},
   "source": [
    "## Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc98a695-a571-41c5-b6b0-47f0e99235bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "medication = dm.meta_information[\"measurement_tables\"][dm.meta_information[\"measurement_tables\"][\"count_obs\"] == 0].copy()\n",
    "\n",
    "get_stats_table(medication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4cc12-3ac9-4fdf-98fc-2982f8a57186",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vocab_table(medication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa31b82-327c-4e8a-a54b-ef54e4ec507d",
   "metadata": {},
   "source": [
    "## Investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351f84c-e9bd-490d-a22c-6305a7693d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "investigation = dm.meta_information[\"measurement_tables\"][dm.meta_information[\"measurement_tables\"][\"count_obs\"] > 0].copy()\n",
    "# print(investigation.head())\n",
    "\n",
    "get_stats_table(investigation, report_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd3b20-4dd6-4bf1-9a84-80f55cc1b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vocab_table(investigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543d776-7557-4313-b687-916ab6a00a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e435df-07ee-4b0e-a17b-e7c5b032b1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f3a17-32a1-4b8c-87e6-c16b489d7cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_counts = (\n",
    "    dm.train_set.tokenizer._event_counts\n",
    "        .with_columns(\n",
    "            pl.col(\"EVENT\").map_dict(EVENT_NAME_LONG_MAP, default=pl.first())\n",
    "        )\n",
    "        .groupby(\"EVENT\", maintain_order=True)     # 2️⃣ group by event name\n",
    "        .agg(pl.all().sum()) \n",
    ")\n",
    "\n",
    "print(event_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015adee7-70f8-4708-aa91-b6156789091f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be578b-2f7c-457c-828e-1bc7b2ac44a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d016af-35c8-4888-9ce7-b99639091441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e37da-a922-4234-9d62-6ae91e5f5db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "000ef6c1-4915-4e35-b98c-73dd7bfb4dd8",
   "metadata": {},
   "source": [
    "## Time to load individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc9021-702c-4b5f-a77b-6a49eac7e535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "times = []\n",
    "start = time.time()   # starting time\n",
    "for row_idx, row in enumerate(tqdm(dm.train_set)):\n",
    "    # print(f\"Sample loaded in {time.time()-start} seconds\")\n",
    "    times.append(time.time()-start)\n",
    "    start = time.time()\n",
    "    if row_idx > 100:\n",
    "        break\n",
    "print(np.mean(times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c28dd6-0809-4d8e-8e21-caa148aafeea",
   "metadata": {},
   "source": [
    "## Loading times for batches\n",
    "\n",
    "This will be over-estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9ee3b-bb5f-4272-94b9-40833d71384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "start = time.time()   # starting time\n",
    "for batch_idx, batch in enumerate(tqdm(dm.train_dataloader())):\n",
    "    # print(f\"batch loaded in {time.time()-start} seconds\")    \n",
    "    times.append(time.time()-start)\n",
    "    start = time.time()\n",
    "    if batch_idx > 2:\n",
    "        break\n",
    "print(np.mean(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e910fb6-195a-4587-81cc-0aacb2637570",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_set.view_sample(1236, max_dynamic_events=12, report_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323aa276-71bd-429b-8f1e-42c464dade8b",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29b997-5bae-49df-899e-76a966a4f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in dm.train_set.tokenizer._itos.items():\n",
    "    print(f\"{key}: {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d6efa-c4d8-4c2a-ad2b-6747a169c5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
